<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[Learning about Java Virtual Machine (JVM)]]></title>
      <url>/2099/08/13/learning-about-java-virtual-machine/</url>
      <content type="html"><![CDATA[<p><a href="../../../..//2018/08/13/jvm-architecture/">JVM Architecture</a><br><a href="../../../..//2018/09/12/java-virtual-machine-tools/">Java Virtual Machine Tools</a><br><a href="../../../..//2020/02/21/default-jvm-options/">Default JVM Options</a><br><a href="../../../..//2020/02/21/jvm-options/">JVM Options</a><br><a href="../../../..//2018/08/27/garbage-collection-basics/">Garbage Collection Basics</a><br><a href="../../../..//2020/02/23/garbage-collection-steps/">Garbage Collection Steps</a><br><a href="../../../..//2020/02/23/cms-garbage-collector/">CMS Garbage Collector</a><br><a href="../../../..//2020/02/23/g1-garbage-collector/">G1 Garbage Collector</a><br><a href="../../../..//2020/02/21/gc-details/">GC Details</a><br><a href="../../../..//2020/03/26/jit-at-a-glance/">JIT at a Glance</a><br><a href="../../../../2020/03/27/escape-analysis/">Escape Analysis</a></p>
]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Thinking in Architecture Design]]></title>
      <url>/2099/08/11/thinking-in-architecture-design/</url>
      <content type="html"><![CDATA[<p>微服务架构设计</p>
<p><a href="../../../../2019/09/01/approaches-to-architecture-development/">架构演进</a></p>
<p><a href="../../../../2019/09/01/understanding-high-availability/">高可用</a></p>
<p><a href="">无状态设计</a></p>
<p><a href="">负载均衡</a></p>
<p><a href="../../../../2019/07/31/understanding-design-with-idempotency/">幂等设计</a></p>
<p><a href="../../../../2019/06/14/lock/">分布式锁</a></p>
<p><a href="../../../..//2019/08/03/destributed-transations/">分布式事务</a></p>
<p><a href="../../../../2019/06/23/implementing-rpc/">RPC的实现demo</a></p>
<h4 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h4><p><a href="../../../../2019/07/28/one-question-one-answer-for-db-index/">MySQL的索引</a></p>
]]></content>
      
        <categories>
            
            <category> Architecture </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Microservices Learning Path]]></title>
      <url>/2099/06/16/microservices-learning-path/</url>
      <content type="html"><![CDATA[<h3 id="Spirng-Cloud-Netflix"><a href="#Spirng-Cloud-Netflix" class="headerlink" title="Spirng Cloud Netflix"></a>Spirng Cloud Netflix</h3><h4 id="Eureka"><a href="#Eureka" class="headerlink" title="Eureka"></a>Eureka</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/08/29/eureka-data-structure/">Eureka Data Structure</a> <font color="red">(Fundamental)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/08/29/communication-between-eureka-server-and-client/">Communication Between Eureka Server And Client</a> <font color="red">(Fundamental)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/08/29/synchronization-between-eureka-server-nodes/">Synchronization Between Eureka Server Nodes</a> <font color="red">(Fundamental)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/08/29/eureka-server-self-preservation-mode/">Eureka Server Self Preservation Mode</a> <font color="red">(Fundamental)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/08/29/eureka-region-and-zone/">Eureka Region and Zone</a> <font color="red">(Fundamental)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/06/16/service-registration-and-discovery/">Service Registration and Discovery</a> <font color="blue">(Practice)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2020/03/22/building-eureka-server-with-peer-awareness/">Building Eureka Server with Peer Awareness</a> <font color="blue">(Practice)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2020/03/22/building-eureka-server-with-region-and-zone/">Building Eureka Server with Region and Zone</a> <font color="blue">(Practice)</font></p>
<h4 id="Zuul"><a href="#Zuul" class="headerlink" title="Zuul"></a>Zuul</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/06/17/routing-and-filtering-with-zuul/">Routing and Filtering with Zuul</a> <font color="blue">(Practice)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2020/03/24/gazing-at-zuul/">Gazing at Zuul</a> <font color="red">(Fundamental)</font></p>
<h4 id="Ribbon"><a href="#Ribbon" class="headerlink" title="Ribbon"></a>Ribbon</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/06/30/client-side-loadbalancing-with-spring-cloud-ribbon/">Client Side Loadbalancing with Spring Cloud Ribbon</a> <font color="blue">(Practice)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2020/03/23/gazing-at-ribbon/">Gazing at Ribbon</a> <font color="red">(Fundamental)</font></p>
<h4 id="Feign"><a href="#Feign" class="headerlink" title="Feign"></a>Feign</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/06/20/services-communication-using-feign/">Services Communication using Feign</a> <font color="blue">(Practice)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2020/03/24/gazing-at-feign/">Gazing at Feign</a> <font color="red">(Fundamental)</font></p>
<h4 id="Hystrix"><a href="#Hystrix" class="headerlink" title="Hystrix"></a>Hystrix</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/06/30/circuit-breaker-using-spring-cloud-hystrix/">Circuit Breaker using Spring Cloud Hystrix</a> <font color="blue">(Practice)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2020/03/24/gazing-at-hystrix/">Gazing at Hystrix</a> <font color="red">(Fundamental)</font></p>
<h4 id="Sleuth-and-Zipkin"><a href="#Sleuth-and-Zipkin" class="headerlink" title="Sleuth and Zipkin"></a>Sleuth and Zipkin</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/07/02/tracing-with-spring-cloud-sleuth-and-zipkin/">Tracing with Spring Cloud Sleuth and Zipkin</a> <font color="blue">(Practice)</font></p>
<h4 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/06/26/configuration-management-with-spring-cloud-config/">Configuration Management with Spring Cloud Config</a> <font color="blue">(Practice)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/06/27/dynamic-configuration-management-with-spring-cloud-bus/">Dynamic Configuration Management with Spring Cloud Bus</a> <font color="blue">(Practice)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/07/01/monitoring-and-integrating-hystrix-using-hystrix-dashboard-and-turbine/">Monitoring and Integrating Hystrix using Hystrix Dashboard and Turbine</a> <font color="blue">(Practice)</font></p>
<h4 id="gRPC"><a href="#gRPC" class="headerlink" title="gRPC"></a>gRPC</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/05/18/about-rpc/">About RPC</a> <font color="red">(Fundamental)</font></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/06/09/getting-started-with-grpc/">Getting Started with gRPC</a> <font color="blue">(Practice)</font><br>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2018/06/09/spring-cloud-with-grpc/">Spring Cloud with gRPC</a> <font color="blue">(Practice)</font></p>
<h3 id="Spring-Cloud-Alibaba"><a href="#Spring-Cloud-Alibaba" class="headerlink" title="Spring Cloud Alibaba"></a>Spring Cloud Alibaba</h3><h4 id="Nacos"><a href="#Nacos" class="headerlink" title="Nacos"></a>Nacos</h4><p>&nbsp;&nbsp;&nbsp;&nbsp;<a href="../../../../2020/04/19/introducing-nacos/">Introducing Nacos</a> <font color="blue">(Practice)</font></p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Netty In Action]]></title>
      <url>/2099/05/05/netty-in-action/</url>
      <content type="html"><![CDATA[<p><a href="../../../../2016/09/21/java-nio-introduction/">Java NIO 详解</a><br><a href="../../../../2020/01/04/zero-copy/">零拷贝</a><br><a href="../../../../2020/01/04/netty-introduction/">netty 介绍</a><br><a href="../../../../2020/01/04/netty-io-model/">netty IO 模型</a><br><a href="../../../../2020/01/04/netty-asynchronous-task/">netty 异步任务</a><br><a href="../../../../2020/01/04/netty-core-concepts/">netty 核心概念</a><br><a href="../../../../2020/01/04/netty-encoder-and-decoder/">netty 编解码器</a><br><a href="../../../../2020/01/04/netty-handler-chain/">netty handler 链调用机制</a><br><a href="../../../../2020/01/04/netty-websocket-long-connection/">netty 长连接</a><br><a href="../../../../2020/01/04/packet-sticking-and-unpacking/">netty 粘包与拆包</a></p>
]]></content>
      
        <categories>
            
            <category> Netty </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Netty </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Blockchain Learning Path]]></title>
      <url>/2099/05/05/blockchain-learning-path/</url>
      <content type="html"><![CDATA[<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180520/174447525.png" style="width: 600px;"></p>
<h4 id="区块链的基本概念"><a href="#区块链的基本概念" class="headerlink" title="区块链的基本概念"></a>区块链的基本概念</h4><h4 id="区块链的技术栈"><a href="#区块链的技术栈" class="headerlink" title="区块链的技术栈"></a>区块链的技术栈</h4><h4 id="以太坊"><a href="#以太坊" class="headerlink" title="以太坊"></a>以太坊</h4><h4 id="超级账本"><a href="#超级账本" class="headerlink" title="超级账本"></a>超级账本</h4>]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Data Structure and Algorithm]]></title>
      <url>/2099/02/08/data-structure-and-algorithm/</url>
      <content type="html"><![CDATA[<p><a href="../../../../2015/11/11/sorting/">Sorting</a></p>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mysql High Availabity]]></title>
      <url>/2020/09/05/mysql-high-availabity/</url>
      <content type="html"><![CDATA[<p>高可用架构分成以下几部分：UI 层，API 层，监控服务层，管理数据库，生产数据库集群。</p>
<p>管理数据库存储数据库集群信息，vip 映射信息，日志信息。数据库集群对外有一个 vip，通过 LVS 进行负载，LVS 主备防止单点故障。</p>
<p><img src="https://s1.ax1x.com/2020/09/05/wVLx9f.png" alt="20200905215639" border="0"></p>
<p>流程如下：</p>
<ol>
<li>鉴权。</li>
<li>一个线程从管理数据库读取集群信息到队列中。</li>
<li>一个线程从队列中消费。拿到一组主从节点信息，先对主库进行 read 操作（select test 表），如果读成功，继续测试写。如果读失败，可能是网络抖动，不能断定主库挂了，此时就向从库节点发一条命令，从从库读主库，如果读成功，说明主库没挂，如果读失败，则说明主库挂了，此时再将这组集群的信息发送到故障队列。</li>
<li>测试写，对主库进行写操作（insert into test 表）。如果主库可写，则这组集群状态正常，继续下一组检查。如果写主库失败，也可能是网络抖动，此时就向主库发起一组写操作（每 5 秒写一次，持续 30 秒），如果超过半数成功，则认为状态正常，如果超过半数失败，则认为主库故障，加入到故障队列中。</li>
<li>加入到故障队列后，通知相关人员。从故障队列中取出一组主从信息。查询每个从库的 GTID ，GTID 大的作为新的主库，如果 GTID 相同，则随机选一台。</li>
<li>把从库指向主库信息换成新的，将 vip 切换到新的主库，更新原来的主从信息（管理数据库的元数据）。</li>
<li>如果成功，此次故障切换完成，通知相关人员。如果主从切换失败，记录失败日志，告警人工介入。</li>
</ol>
<p><img src="https://s1.ax1x.com/2020/09/05/wVLz38.png" alt="20200905215732" border="0"></p>
<p>此方案的问题：</p>
<ol>
<li>在健康检查的过程中，如果主库挂了，会有 30 秒的时间不可写，读不影响。</li>
<li>管理数据库是单点，需要定期监控。但没必要对管理数据库进行自动主从切换。原因一是管理数据库压力不大，故障概率小，二是，管理数据库挂了，影响健康检查，但是不影响业务数据库使用，用自动主从切换增加了复杂度。</li>
<li>为什么检查主库读，要从从库读，而检查主库写，是循环写？第一次读失败了，也可以多读几次，按半数来统计。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> uncategory </category>
            
        </categories>
        
        
        <tags>
            
            <tag> untag </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Guide to Java Agent]]></title>
      <url>/2020/08/25/guide-to-java-agent/</url>
      <content type="html"><![CDATA[<pre><code>public class MyAgent {
    public static void premain(String args, Instrumentation instrumentation) {
        System.out.println(&quot;premain start&quot;);
        System.out.println(args);
    }

    public static void premain(String args) {
        System.out.println(&quot;premain start&quot;);
        System.out.println(args);
    }
}
</code></pre><p>/METE-INF/MANIFEST.MF</p>
<pre><code>Manifest-Version: 1.0
Premain-Class: com.rolex.microlabs.agent.MyAgent
</code></pre><p>使用 maven 打包，防止 maven 生成的 MANIFEST.MF 覆盖我们自己的。</p>
<pre><code>&lt;build&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
            &lt;version&gt;3.8.1&lt;/version&gt;
            &lt;configuration&gt;
                &lt;source&gt;1.8&lt;/source&gt;
                &lt;target&gt;1.8&lt;/target&gt;
            &lt;/configuration&gt;
        &lt;/plugin&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
            &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;
            &lt;version&gt;3.2.0&lt;/version&gt;
            &lt;configuration&gt;
                &lt;archive&gt;
                    &lt;manifest&gt;
                        &lt;addClasspath&gt;true&lt;/addClasspath&gt;
                    &lt;/manifest&gt;
                    &lt;manifestEntries&gt;
                        &lt;Premain-Class&gt;
                            com.rolex.microlabs.agent.MyAgent
                        &lt;/Premain-Class&gt;
                    &lt;/manifestEntries&gt;
                &lt;/archive&gt;
            &lt;/configuration&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;
</code></pre><pre><code>java -javaagent:D:\MyAgent-1.0.jar=helloworld test.Test
</code></pre>]]></content>
      
        
    </entry>
    
    <entry>
      <title><![CDATA[Managing Documents with Elasticsearch Index Life Management]]></title>
      <url>/2020/07/09/managing-documents-with-elasticsearch-index-life-management/</url>
      <content type="html"><![CDATA[<p>上一篇讲了使用 ELK Stack 来搭建日志收集系统，这一篇来讲讲使用 Elasticsearch 来管理日志。日志存储在 Elasticsearch 是随着时间逐步增加的，有些日志会长期保存，而有些日志只需要保存一段时间后就删除，Elasticsearch 为 index 定义了生命周期，包括 4 个阶段：hot 、warm、cold 和 delete 。针对不同的阶段也定义了不同的策略，下面我们就来看一下如何使用策略来管理日志。</p>
<p>假设我们的日志规则是每 10000 条日志一个索引，日志最多保存 3 个月，那么我们可以创建一个策略。</p>
<pre><code>curl -XPUT &quot;http://localhost:9200/_ilm/policy/my_policy&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &quot;policy&quot;: {
    &quot;phases&quot;: {
      &quot;hot&quot;: {
        &quot;actions&quot;: {
          &quot;rollover&quot;: {
            &quot;max_docs&quot;: 10000
          }
        }
      },
      &quot;delete&quot;: {
        &quot;min_age&quot;: &quot;90d&quot;,
        &quot;actions&quot;: {
          &quot;delete&quot;: {}
        }
      }
    }
  }
}&#39;
</code></pre><p>我们定义了一个滚动策略 rollover ，每 10000 条就会生成一个新的索引，并且 90 天后进入 delete 阶段，即被删除。</p>
<p>接下来需要将日志索引加上这个策略。日志我们都是通过 template 生成的，所以在 template 上加上策略。</p>
<pre><code>curl -XPUT &quot;http://localhost:9200/_template/my_template&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &quot;index_patterns&quot;: [&quot;log-*&quot;], 
  &quot;settings&quot;: {
    &quot;number_of_shards&quot;: 1,
    &quot;number_of_replicas&quot;: 0,
    &quot;index.lifecycle.name&quot;: &quot;my_policy&quot;, 
    &quot;index.lifecycle.rollover_alias&quot;: &quot;log-alias&quot;
  }
}&#39;
</code></pre><p>最后在初始化的时候创建第一个索引，并将索引设为可写。</p>
<pre><code>curl -XPUT &quot;http://localhost:9200/log-000001&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &quot;aliases&quot;: {
    &quot;log-alias&quot;: {
       &quot;is_write_index&quot;: true
    }
  }
}&#39;
</code></pre><p>以后往 log-alias 中写入新的日志是，就会使用我们设置的策略了。</p>
<blockquote>
<p>详细的操作设置见 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.8/index-lifecycle-management.html" target="_blank" rel="external">https://www.elastic.co/guide/en/elasticsearch/reference/6.8/index-lifecycle-management.html</a> 。</p>
<p>这里附一些常用的操作：</p>
<p>查看策略</p>
<pre><code>curl -XGET &quot;http://localhost:9200/_ilm/policy?pretty&quot;
</code></pre><p>查看索引的信息</p>
<pre><code>curl -XGET &quot;http://localhost:9200/test-*/_ilm/explain?pretty&quot;
</code></pre><p>查看状态</p>
<pre><code>curl -XGET &quot;http://localhost:9200/_ilm/status?pretty&quot;
</code></pre><p>修改 ES 的 策略生效时间</p>
<pre><code>curl -XPUT &quot;http://localhost:9200/_cluster/settings&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &quot;transient&quot;: {
    &quot;indices.lifecycle.poll_interval&quot;: &quot;3s&quot; 
  }
}&#39;
</code></pre></blockquote>
]]></content>
      
        
    </entry>
    
    <entry>
      <title><![CDATA[how to develop a web code sdudio]]></title>
      <url>/2020/05/18/how-to-develop-a-web-sdudio/</url>
      <content type="html"><![CDATA[<p>这是一个系列，记录了我们在接到这个需求之后进行的一些调研和尝试，以及最后我们是如何做的。好了，我们下面是一个路线图。</p>
<ol>
<li>什么是 Cloud IDE</li>
<li>Cloud IDE 都具有哪些功能</li>
<li>如何动态编译源代码文本</li>
<li>如何动态执行源代码文本</li>
<li>Java如何执行命令行</li>
<li>如何进行远程debug</li>
<li>前后端如何交互</li>
<li>服务端执行日志如何返回客户端</li>
<li>前端代码编辑器</li>
<li>如何将工程发布成镜像</li>
<li>如何初始化workspace</li>
<li>如何做资源隔离</li>
</ol>
<p>首先了解一下什么是 web ide 。</p>
<p>目前市面上都有哪些类似的产品，都具有什么功能。</p>
<p>基于 git 和 maven 构建，能够在浏览器中编辑和运行代码，并且支持远程调试。</p>
<p>大概的需求清楚了，接下来就考虑如何实现。</p>
<p>最初首先想到的是，既然是基于浏览器的，那么肯定是 B/S 架构没跑了。那么可以分成两块，前端和后端。前端渲染页面，由于前端太菜，所以一笔带过，主要说说后端。本地的 ide 我们都熟悉，我们假设把本地 ide 的界面想象成浏览器，那么我们在界面上做的操作，都可以对应到一个向 server 的请求，server 接到请求，进行处理，然后将结果返回给前端进行渲染，这样一来一回，好像整个流程就串起来了。于是就有了第一版设计。<br>前端有一个 text 用来写代码，然后将整个代码作为一个字符串提交给 server ，接下来就需要 server 对前端传过来的程序字符串进行处理了。以 Java 程序为例，首先需要编译，然后才能执行。那如何编译呢？学过 Java 的都知道有个命令叫 javac 。那问题来了，javac 是在命令行执行，如果我们要用 javac 来编译，就需要让 server 能够执行 shell 。所以问题又变成了 java 如何执行 shell 。于是请出了今天的第一位选手 Runtime 。</p>
<h4 id="Runtime"><a href="#Runtime" class="headerlink" title="Runtime"></a>Runtime</h4><p>每个 Java 都会对应一个 Runtime 类的实例，用来使 Java 和环境能够进行交互。比如使用 Runtime 获取 CPU 核数和内存大小：</p>
<pre><code>int availableProcessors = Runtime.getRuntime().availableProcessors();
long freeMemory = Runtime.getRuntime().freeMemory();
System.out.println(availableProcessors);
System.out.println(freeMemory / 1024 / 1024);
</code></pre><p>Runtime 还可以用来在独立的进程中执行命令，比如这样：</p>
<pre><code>Process process = Runtime.getRuntime().exec(new String[]{&quot;powershell&quot;, &quot;java -version&quot;});
InputStream inputStream = process.getErrorStream();
BufferedReader br = new BufferedReader(new InputStreamReader(inputStream));
String line = null;
while((line = br.readLine()) !=null){
    System.out.println(line);
}
br.close();
</code></pre><p>既然是执行命令，那么就会有正常输出和错误输出，Runtime 需要我们自己处理来处理 process.getErrorStream() 和 process.getInputStream() 。这里需要注意，因为 Runtime 是 fork 子进程来执行，流是父子进程公用的，所以很容易造成阻塞。正确的做法就是创建单独的线程来处理流。</p>
<pre><code>Process proc = Runtime.getRuntime().exec(cmd);
// any error message
StreamBeat errorGobbler = new StreamBeat(ctx, proc.getErrorStream(), &quot;ERROR&quot;);
// any output
StreamBeat outputGobbler = new StreamBeat(ctx, proc.getInputStream(), &quot;OUTPUT&quot;);
// kick them off
new Thread(errorGobbler).start();
new Thread(outputGobbler).start();
// wait for finished
int exitVal = proc.waitFor();
</code></pre><p>从 JDK1.5 以后，创建进程有一种更好的方式 ProcessBuilder ，它还提供了重定向错误输出，这样我们就不用创建线程来处理流了。</p>
<pre><code>ProcessBuilder processBuilder = new ProcessBuilder();
processBuilder.redirectErrorStream(true);
processBuilder.command(&quot;powershell&quot;, cmd);
Process process = processBuilder.start();
InputStream inputStream = process.getInputStream();
BufferedReader br = new BufferedReader(new InputStreamReader(inputStream));
String line = null;
while ((line = br.readLine()) != null) {
    System.out.println(line);
}
br.close();
</code></pre><p>不管是 Runtime 还是 ProcessBuilder ，都可以解决我们执行命令的问题。 于是我们顺着这个思路就想既然有 javac 、java -jar 这样的命令，那调试应该也有命令吧，于是我们惊喜的发现在角落里有一个不起眼的家伙 jdb 。</p>
<h4 id="JDB"><a href="#JDB" class="headerlink" title="JDB"></a>JDB</h4><p>在说 jdb 之前，我们先来看几个概念。<br>JDPA(Java Platform Debugger Architecture) 是一个多层的调试架构，它包括 3 层：JVM TI(Java VM Tool Interface) 、JDWP(Java Debug Wire Protocol) 和 JDI(Java Debug Interface) 。程序开发可以在任何一层切入到调试当中，但是由于 JDI 是最贴近用户的一层，所以在 JDI 进行编程操作最为简单。我们之前说的 jdb 就可以理解为 JDI 的一种实现。jdb 是一组调试的命令，它会进入一个会话来进行交互。<br>首先启动 agent 。</p>
<pre><code>java -agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5005 test.Test
</code></pre><p>我们把被调试的程序、调试程序的后端服务以及运行程序的 VM 统称为 debuggee ，把来看看 jdb 命令怎么用。</p>
<p>命令有了，无非就再麻烦一下 Runtime 老兄嘛。燃鹅，在查看了 jdb 的用法之后，三下五除二请出了 Runtime 。纳尼？竟然卡住了。卡住的原因不是没有处理流，二十因为 jdb 会开启会话，启动 jdb 之后进入到交互模式，Process 拿不到 stream ，程序就卡入住，卡住了自然就没有响应给客户端，也就没办法再进行后续的操作了。所以直接使用 jdb 是不行的，但是 jdb 也是按照 JDI 实现的，那么我们也可以按照 JDI 来进行开发。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[logstash quickstart]]></title>
      <url>/2020/05/02/logstash-quickstart/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> uncategory </category>
            
        </categories>
        
        
        <tags>
            
            <tag> untag </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[elasticsearch quickstart]]></title>
      <url>/2020/05/02/elasticsearch-quickstart/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> uncategory </category>
            
        </categories>
        
        
        <tags>
            
            <tag> untag </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Kafka Quickstart]]></title>
      <url>/2020/05/02/kafka-quickstart/</url>
      <content type="html"><![CDATA[<p>Kafka 快速开始：</p>
<ol>
<li>下载<pre><code>wget https://www.apache.org/dyn/closer.cgi?path=/kafka/2.4.1/kafka_2.11-2.4.1.tgz
tar -xzf kafka_2.11-2.4.1.tgz
</code></pre></li>
<li>配置<br>修改 config/server.properties 。<pre><code>broker.id=0
port=9092
host.name=192.168.0.206
advertised.host.name=192.168.0.206
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/opt/kafka-logs                # Kafka 日志路径，重要
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper.connect=192.168.0.206:2181
zookeeper.connection.timeout.ms=6000
group.initial.rebalance.delay.ms=0
</code></pre>Kafka 启动需要用到 Zookeeper ，需要提前搭好。</li>
<li>启动<pre><code>./bin/kafka-server-start.sh ./config/server.properties
</code></pre></li>
<li>创建 topic<pre><code>./bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic test --replication-factor 1 --partitions 1
</code></pre>创建成功之后可以查看。<pre><code>./bin/kafka-topics.sh --bootstrap-server localhost:9092 --list
</code></pre></li>
<li>发送消息<pre><code>./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test
</code></pre></li>
<li>消费消息<pre><code>./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
</code></pre></li>
<li>查看消费进度<pre><code>./kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe
</code></pre></li>
<li>删除 topic<pre><code>./kafka-topics.sh --zookeeper localhost:2181 --delete --topic test
</code></pre></li>
</ol>
<p>单个节点就搭建完成了，现在把它扩展成集群。</p>
]]></content>
      
        <categories>
            
            <category> MQ </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Kafka </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Building Log Collection System]]></title>
      <url>/2020/05/02/building-log-collection-system/</url>
      <content type="html"><![CDATA[<p>日志收集方式有很多，本文主要介绍利用 Kafka 和 ELK 来进行日志收集。</p>
<p><img src="https://s1.ax1x.com/2020/05/02/JvOEse.png" alt="20200502190811" border="0" style="width:600px"><br>设计思路很简单：</p>
<ol>
<li>首先通过日志框架，将日志分级并存储到文件。</li>
<li>通过 Filebeat 将文件内容放到 Kafka 中。</li>
<li>Logstash 对 Kafka 中的日志进行消费，过滤出需要的日志，写到 Elasticsearch 中。</li>
<li>最后用 Kibana 进行展示。</li>
</ol>
<p>使用的环境是 Centos7 + logback + Kafka_2.11-2.4.1 + ELK Stack 6.8.8 。这里简单介绍一下 ELK Stack 。ELK Stack 就是 ELK + Beats 。ELK 是三个开源项目的首字母缩写，这三个项目分别是：Elasticsearch 、Logstash 和 Kibana 。Elasticsearch 是一个搜索和分析引擎。Logstash  是服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到诸如 Elasticsearch 等“存储库”中。Kibana 则可以让用户在 Elasticsearch  中使用图形和图表对数据进行可视化。Beats 是轻量型的单一功能数据采集器，Filebeat 是 Beats 中的一个用于文件的采集器。</p>
<h4 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h4><p>第一步首先要选择一个日志框架，日志框架有很多，根据自己习惯选就好了。这里用的是 Logback ，它是 SLF4J 的直接实现，SpringBoot 默认使用的也是它。接下来就是要将日志分级，把全量 Log 和 Error Log 分别存储，以 logback-spring.xml 为例。</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;
    &lt;contextName&gt;logback&lt;/contextName&gt;
    &lt;property name=&quot;app.name&quot; value=&quot;log-collection&quot;/&gt;
    &lt;property name=&quot;log.path&quot; value=&quot;./logs/${app.name}&quot;/&gt;
    &lt;!--输出到控制台--&gt;
    &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
        &lt;layout&gt;
            &lt;Pattern&gt;[%X{host}] [%X{ip}] [%X{appName}] %d{yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSS} %level ${PID:- } %thread %logger - %msg ##&#39;%ex&#39;%n&lt;/Pattern&gt;
        &lt;/layout&gt;
    &lt;/appender&gt;

    &lt;!--输出到文件--&gt;
    &lt;appender name=&quot;infoFile&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;file&gt;${log.path}/app.log&lt;/file&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy&quot;&gt;
            &lt;!-- 按天轮转 --&gt;
            &lt;fileNamePattern&gt;${log.path}/app-%d{yyyy-MM-dd}-%i.zip&lt;/fileNamePattern&gt;
            &lt;!-- 单个文件最大 500M --&gt;
            &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt;
            &lt;!-- 保存 30 天的历史记录，最大大小为 30GB --&gt;
            &lt;maxHistory&gt;30&lt;/maxHistory&gt;
            &lt;totalSizeCap&gt;3GB&lt;/totalSizeCap&gt;
        &lt;/rollingPolicy&gt;
        &lt;layout&gt;
            &lt;Pattern&gt;[%X{host}] [%X{ip}] [%X{appName}] %d{yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSS} %level ${PID:- } %thread %logger - %msg ##&#39;%ex&#39;%n&lt;/Pattern&gt;
        &lt;/layout&gt;
    &lt;/appender&gt;
    &lt;appender name=&quot;errorFile&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt;
        &lt;file&gt;${log.path}/error.log&lt;/file&gt;
        &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy&quot;&gt;
            &lt;!-- 按天轮转 --&gt;
            &lt;fileNamePattern&gt;${log.path}/error-%d{yyyy-MM-dd}-%i.zip&lt;/fileNamePattern&gt;
            &lt;!-- 单个文件最大 500M --&gt;
            &lt;maxFileSize&gt;500MB&lt;/maxFileSize&gt;
            &lt;!-- 保存 30 天的历史记录，最大大小为 30GB --&gt;
            &lt;maxHistory&gt;30&lt;/maxHistory&gt;
            &lt;totalSizeCap&gt;3GB&lt;/totalSizeCap&gt;
        &lt;/rollingPolicy&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt;
            &lt;level&gt;ERROR&lt;/level&gt;
            &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt;
            &lt;onMismatch&gt;DENY&lt;/onMismatch&gt;
        &lt;/filter&gt;
        &lt;layout&gt;
            &lt;Pattern&gt;[%X{host}] [%X{ip}] [%X{appName}] %d{yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSS} %level ${PID:- } %thread %logger - %msg ##&#39;%ex&#39;%n&lt;/Pattern&gt;
        &lt;/layout&gt;
    &lt;/appender&gt;

    &lt;root level=&quot;info&quot;&gt;
        &lt;appender-ref ref=&quot;console&quot;/&gt;
        &lt;appender-ref ref=&quot;infoFile&quot;/&gt;
        &lt;appender-ref ref=&quot;errorFile&quot;/&gt;
    &lt;/root&gt;

&lt;/configuration&gt;
</code></pre><p>这里需要特殊说明的是 Layout.Pattern 。一行日志通过空格分隔，前 3 个是自定义 MDC 属性，第 4 部分是 UTC Timestamp ，第 5 部分是日志级别，第 6 部分是进程号，第 7 部分是线程名字，第 8 部分是类的名字，第 9 部分是日志信息，最后一部分是异常信息。由于异常堆栈是多行，所以通过 ”‘“ 包起来便于后续处理。<br>Logback 更多内容参考 <a href="http://www.logback.cn/" target="_blank" rel="external">http://www.logback.cn/</a> 。</p>
<h4 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a>Filebeat</h4><p>Filebeat 用来对文件内容进行收集，将其和应用程序部署在同一台机器。下载解压之后修改配置文件 filebeat.yml 。</p>
<pre><code>filebeat.inputs:

- type: log
  enabled: true
  paths:
    - /logs/log-collection/app.log     # 指定日志文件
  document_type: &quot;app-log&quot;
  multiline:
    pattern: &#39;^\[&#39;                    # 以 ”[“ 开头，不是 [ 开头则合并到上一行，最大2000行
    negate: true
    match: after
    max_lines: 2000
    timeout: 2s
  fields:
    logbiz: log-collection            # 应用名称
    log_topic: app-log-collection    # Kafka 的 Topic
    evn: dev                        # 环境

- type: log
  enabled: true
  paths:
    - /logs/log-collection/error.log
  document_type: &quot;error-log&quot;
  multiline:
    pattern: &#39;^\[&#39;
    negate: true
    match: after
    max_lines: 2000
    timeout: 2s
  fields:
    logbiz: log-collection
    log_topic: error-log-collection
    evn: dev

output.kafka:                        # 输出到 Kafka
  enabled: true
  hosts: [&quot;192.168.0.106:9092&quot;]        # Kafka Broker 地址
  topic: &#39;%{[fields.log_topic]}&#39;    # Kafka Topic ，动态获取上边配置的 Topic
  partition.hash:
    reachable_only: true
  compression: gzip
  max_message_bytes: 1000000
  required_acks: 1
logging.to_files: true
</code></pre><p>启动，带 -e 可以看到日志。</p>
<pre><code>./filebeat -e
</code></pre><h4 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h4><p>Kafka 安装配置参考 <a href="../../../../2020/05/02/kafka-quickstart/">Kafka Quickstart</a> 。</p>
<p>创建 Filebeat 要用到的 Topic 。</p>
<pre><code>bin/kafka-topics.sh --zookeeper 192.168.0.206:2181 --create --topic app-log-collection --partitions 1 --replication-factor 1
bin/kafka-topics.sh --zookeeper 192.168.0.206:2181 --create --topic error-log-collection --partitions 1 --replication-factor 1
</code></pre><p>启动 Filebeat 之后，如果配置正常，在 Kafka 的 logs 目录可以看到对应 topic 的日志。</p>
<h4 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h4><p>Lostash 作用是消费 Kafka 中的日志。下载解压之后修改配置文件 config/logstash.conf 。</p>
<pre><code># 输入，可以有多个
input {
  # Kafka 的配置
  kafka {
    topics_pattern =&gt; &quot;app-log-.*&quot;                 # Kafka 的 Topic 模式
    bootstrap_servers =&gt; &quot;192.168.0.206:9092&quot;    # Kafka broker 地址
    codec =&gt; json
    consumer_threads =&gt; 4
    decorate_events =&gt; true
    group_id =&gt; &quot;app-log-group&quot;
  }
  kafka {
    topics_pattern =&gt; &quot;error-log-.*&quot;
    bootstrap_servers =&gt; &quot;192.168.0.206:9092&quot;
    codec =&gt; json
    consumer_threads =&gt; 4
    decorate_events =&gt; true
    group_id =&gt; &quot;error-log-group&quot;
  }
}

filter {
  ruby {
    # 将本地时间赋给变量 index_time ，在 ES 中按天创建索引会用到
    # Logstash 使用的 UTC 时间，所以会比东八区晚 8 小时，这里进行时区转换
    code =&gt; &quot;event.set(&#39;index_time&#39;, event.timestamp.time.localtime.strftime(&#39;%Y.%m.%d&#39;))&quot;
  }

  if &quot;app-log&quot; in [fields][log_topic] {     # Filebeat 中的变量
    grok {
      # 针对日志格式进行解析，变量名字无所谓，位置需要对应
      match =&gt; [&quot;message&quot;, &quot;\[%{DATA:host}\] \[%{DATA:ip}\] \[%{DATA:appName}\] %{NOTSPACE:currentDateTime} %{NOTSPACE:level} %{NOTSPACE:pid} %{NOTSPACE:thread} %{NOTSPACE:class} - %{DATA:msgInfo} ##(\&#39;\&#39;|%{QUOTEDSTRING:throwable})&quot;]
    }
    # 还是时区的问题，ELK 缺省使用的是 UTC ，所以在这把时区加上，在 ES 和 Kibana 里就都按指定时区了
    mutate {
      gsub =&gt; [&quot;currentDateTime&quot;, &quot;[+]&quot;, &quot;T&quot;]
    } 
    mutate{
      replace =&gt; [&quot;currentDateTime&quot;,&quot;%{currentDateTime}+08:00&quot;]
    }
  }

  if &quot;error-log&quot; in [fields][log_topic] {
    grok {
      match =&gt; [&quot;message&quot;, &quot;\[%{DATA:host}\] \[%{DATA:ip}\] \[%{DATA:appName}\] %{NOTSPACE:currentDateTime} %{NOTSPACE:level} %{NOTSPACE:pid} %{NOTSPACE:thread} %{NOTSPACE:class} - %{DATA:msgInfo} ##(\&#39;\&#39;|%{QUOTEDSTRING:throwable})&quot;]
    }
    mutate {
      gsub =&gt; [&quot;currentDateTime&quot;, &quot;[+]&quot;, &quot;T&quot;]
    } 
    mutate{
      replace =&gt; [&quot;currentDateTime&quot;,&quot;%{currentDateTime}+08:00&quot;]
    }
  }
}

# 输出
output {
  # 输出到控制台
  stdout { 
    codec =&gt; rubydebug
  }
}

output {
  # 输出到 ES
  if &quot;app-log&quot; in [fields][log_topic] {
    elasticsearch {
      hosts =&gt; [&quot;192.168.0.201:9200&quot;]                        # ES 地址
      index =&gt; &quot;app-log-%{[fields][logbiz]}-%{index_time}&quot;    # ES 索引的名字，按天生成索引
      sniffing =&gt; true                                        # 嗅探模式
      template_overwrite =&gt; true                                  
    }
  }

  if &quot;error-log&quot; in [fields][log_topic] {
    elasticsearch {
      hosts =&gt; [&quot;192.168.0.201:9200&quot;]
      index =&gt; &quot;error-log-%{[fields][logbiz]}-%{index_time}&quot;
      sniffing =&gt; true
      template_overwrite =&gt; true      
    }
  }
}
</code></pre><p>配置完成后启动</p>
<pre><code>./bin/logstash -f ./config/logstash.conf
</code></pre><p>更多 Logstash 内容参考 <a href="http://doc.yonyoucloud.com/doc/logstash-best-practice-cn/index.html" target="_blank" rel="external">Logstash 最佳实践</a> 。</p>
<h4 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h4><p>Elasticsearch 集群搭建参考 <a href="../../../../2020/05/02/elasticsearch-quickstart/">Elasticsearch Quickstart</a> 。</p>
<h4 id="Kibana"><a href="#Kibana" class="headerlink" title="Kibana"></a>Kibana</h4><p>下载解压之后在 config/kibana.yml 中配置 ES 的地址就可以运行了。</p>
<pre><code>./bin/kibana
</code></pre><p>启动之后访问 <a href="http://locahost:5601" target="_blank" rel="external">http://locahost:5601</a> 。<br>先去 Management &gt; Kibana &gt; Advanced Settings 里修改时区为东八区，然后创建 Index Patterns 。<br><img src="https://s1.ax1x.com/2020/05/02/JvOVqH.png" alt="20200502183933" border="0"><br>在 Discover 中就可以看到日志了。</p>
<h4 id="错误告警"><a href="#错误告警" class="headerlink" title="错误告警"></a>错误告警</h4><p>通过 Elasticsearch Watcher 可以进行错误告警。Watcher 就是一个定时任务，通过 Watcher API 可以创建 Watcher ，比如创建一个 Watcher 每 10s 扫描一次 error-log 索引。</p>
<pre><code>PUT _xpack/watcher/watch/applog_error_watcher
{
  # 触发器
  &quot;trigger&quot;:{
    &quot;schedule&quot;:{
      &quot;interval&quot;:&quot;10s&quot;
    }
  },
  &quot;input&quot;:{
    &quot;search&quot;:{
      &quot;request&quot;:{
        &quot;indices&quot;:[
          &quot;error-log-*&quot;
        ],
        &quot;body&quot;:{
          &quot;size&quot;:0,
          &quot;query&quot;:{
            &quot;bool&quot;:{
              &quot;must&quot;:{
                &quot;term&quot;:{
                  &quot;level.keyword&quot;:&quot;ERROR&quot;
                }
              },
              &quot;filter&quot;:{
                &quot;range&quot;:{
                  &quot;currentDateTime&quot;:{
                    &quot;gt&quot;:&quot;now-30s&quot;,
                    &quot;lt&quot;:&quot;now&quot;
                  }
                }
              }
            }
          }
        }
      }
    }
  },
  # 条件：查询命中条数大于0触发
  &quot;condition&quot;:{
      &quot;compare&quot;:{
          &quot;ctx.payload.hits.total&quot;:{
              &quot;gt&quot;:0
          }
      }
  },
  # 查询数据
  &quot;transform&quot;:{
    &quot;search&quot;:{
      &quot;request&quot;:{
        &quot;indices&quot;:[
          &quot;error-log-*&quot;
        ],
        &quot;body&quot;:{
          &quot;size&quot;:10,
          &quot;query&quot;:{
            &quot;bool&quot;:{
              &quot;must&quot;:{
                &quot;term&quot;:{
                  &quot;level.keyword&quot;:&quot;ERROR&quot;
                }
              },
              &quot;filter&quot;:{
                &quot;range&quot;:{
                  &quot;currentDateTime&quot;:{
                    &quot;gt&quot;:&quot;now-30s&quot;,
                    &quot;lt&quot;:&quot;now&quot;
                  }
                }
              }
            }
          }
        }
      }
    }
  },
  # 处理动作，这里是注册了一个webhook，然后进行回调
  &quot;actions&quot;:{
    &quot;test_error&quot;:{
      &quot;throttle_period&quot;:&quot;1m&quot;,
      &quot;webhook&quot;:{
        &quot;method&quot;:&quot;POST&quot;,
        &quot;url&quot;:&quot;http://192.168.0.106:8080/watch&quot;,
        &quot;body&quot;:&quot;watcher test&quot;
      }
    }
  }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Microservices </category>
            
        </categories>
        
        
        <tags>
            
            <tag> ELK </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[rabbitmq cluster]]></title>
      <url>/2020/04/27/rabbitmq-cluster/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> uncategory </category>
            
        </categories>
        
        
        <tags>
            
            <tag> untag </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[RabbitMQ Management GUI]]></title>
      <url>/2020/04/27/rabbitmq-management-gui/</url>
      <content type="html"><![CDATA[<p>RabbitMQ 提供了一个管理图形界面，通过 <a href="http://localhost:15672/" target="_blank" rel="external">http://localhost:15672/</a> 可以访问，默认用户名密码是 guest/guest 。</p>
]]></content>
      
        <categories>
            
            <category> MQ </category>
            
        </categories>
        
        
        <tags>
            
            <tag> RabbitMQ </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[RabbitMQ Exchange Types]]></title>
      <url>/2020/04/25/rabbitmq-exchange-types/</url>
      <content type="html"><![CDATA[<p>RabbitMQ 中有 4 种不同的 Exchange ，分别是 Direct 、Topic 、Fanout 和 Headers 。</p>
<h4 id="Direct"><a href="#Direct" class="headerlink" title="Direct"></a>Direct</h4><p>RabbitMQ 默认的 Exchange Type 。使用此方式 Exchange 会比较 RoutingKey 和 BindingKey ，两个相等才会将消息路由到 Queue ，如果没有和 RoutingKey 相等的 BindingKey ，消息就会被丢弃。</p>
<p><img src="https://s1.ax1x.com/2020/04/25/JyHBWt.png" alt="JyHBWt.png" border="0" style="width:700px"></p>
<p>有两个 Queue 绑定到 Exchange ，分别是 hello.queue 和 hello2.queue 。Producer 向 Exchange 发送消息，RoutingKey 作为参数存放在消息的 header 。Exchange 会将消息路由到 hello.queue 的队列中，因为 RoutingKey 和 BindingKey 完全相等。</p>
<h4 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h4><p>使用此方式 Exchange 会通过模式匹配的方式进行路由，RoutingKey 可以使用 “.” 、“#” 、“<em>” ，例如 order.create.</em> ，order.# ，”*“ 匹配 0 或 1 个，”#“ 匹配 0 或 n 个。Consumer 可以订阅任何感兴趣的 Topic ，Exchange 会将消息路由到所有符合模式的队列中。</p>
<p><img src="https://s1.ax1x.com/2020/04/25/Jyv2jI.png" alt="Jyv2jI.png" border="0" style="width:700px"></p>
<p>Consumer1 订阅了 order.# ，Consumer2 订阅了 order.del.# ，Consumer3 订阅了 order.create.<em> 。Producer 向 Exchange 发送了一条消息，RoutingKey 为 order.create.test ，order.create.</em> 、order.# 都可以匹配 order.create.test ，因此 Consumer1 和 Consumer3 都会收到消息， order.del.# 无法匹配，则 Consumer2 不会收到消息。</p>
<h4 id="Fonout"><a href="#Fonout" class="headerlink" title="Fonout"></a>Fonout</h4><p>使用此方式 Exchange 会消息复制多份，并路由到所有与 Exchange 绑定的队列，此时将不再关心 RoutingKey 。这种模式通常在需要对相同的消息采取不同的处理时使用。</p>
<p><img src="https://s1.ax1x.com/2020/04/25/J6SzUf.png" alt="J6SzUf.png" border="0" style="width:700px"></p>
<h4 id="Headers"><a href="#Headers" class="headerlink" title="Headers"></a>Headers</h4><p>使用此方式 Exchange 在绑定 Queue 时会增加一个特殊参数 x-match ，x-match 有两个值，分别是 any 和 all ，默认是 all 。Exchange 在路由匹配时，通过消息的 Header 进行匹配，而不是 RoutingKey 。<br><img src="https://s1.ax1x.com/2020/04/25/J6kuPx.png" alt="J6kuPx.png" border="0" style="width:700px"><br>Consumer1 订阅了 type:order format:xml ，Consumer2 订阅了 type:pay format:binary ，Consumer3 订阅了 type:pay format:json 。Producer1 发送的消息 headers 为 type:order format:json ，Exchange 没有与其匹配的 Queue ，所以消息会被丢弃。Producer2 发送的消息 headers 为 type:pay format:text x-match:any ，Exchange 会将消息路由给 Queue2 和 Queue3 。Producer3 发送的消息 headers 为 type:pay format:json ，Exchange 会将消息路由到 Queue3 。</p>
]]></content>
      
        <categories>
            
            <category> MQ </category>
            
        </categories>
        
        
        <tags>
            
            <tag> RabbitMQ </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[RabbitMQ-Concepts-and-Glossary]]></title>
      <url>/2020/04/25/rabbitmq-concepts-and-glossary/</url>
      <content type="html"><![CDATA[<h4 id="概念和术语"><a href="#概念和术语" class="headerlink" title="概念和术语"></a>概念和术语</h4><p>在学习 RabbitMQ 之前，先了解一下 RabbitMQ 的术语和基本概念。</p>
<ol>
<li>AMQP<br>高级消息队列协议 (Advanced Message Queuing Protocol, AMQP) 是一个应用层协议的开放标准。RabbitMQ 实现了 AMQP 协议。</li>
<li>Publisher<br>向 MQ 发送消息的程序。</li>
<li>Message<br>Publisher 通过 MQ 传递给 Consumer 的数据。</li>
<li>Consumer<br>从 MQ 接收消息的程序。</li>
<li>Connection<br>应用程序和 RabbitMQ Broker 之间建立的 TCP 连接。</li>
<li>Queue<br>存放消息的队列。</li>
<li>Confirm<br>Publisher 向 RabbitMQ 发送 Message ，RabbitMQ 收到 Message 之后给 Publisher 的回执，用来标识 RabbitMQ 收到 Message 。</li>
<li>Message acknowledgment<br>消息回执，简称 ack 。Message 被 Consumer 消费之后，Consumer 向 MQ Server 发送一个 ack ，MQ Server 收到 ack 后会将 Message 删除。如果没有收到 ack 并且 Consumer 和 MQ Server  断开连接，MQ Server 会将 Message 发送给其他的 Consumer 处理。</li>
<li>Message durability<br>消息持久化，用来保证 MQ Server 在异常宕机时消息不丢失。</li>
<li>Prefetch count</li>
<li>Exchange<br>在 RabbitMQ 中，Publisher 不会直接将消息发送到 Queue ，而是将消息发送到 Exchange ，再由 Exchange 将消息路由给 Queue 。</li>
<li>RoutingKey<br>发送消息时携带的 key 。</li>
<li>Binding<br>绑定就是将 Exchange 和 Queue 进行关联。 </li>
<li>BindingKey<br>BindingKey 是在 Exchange 和 Queue 绑定时指定的。BindingKey 并不是实际存在，而是为了和 RoutingKey 进行区分，实际和 RoutingKey 是一个东西。Exchange 在路由消息时，会将 RoutingKey 和 BindingKey 进行比较，如果相等或匹配，Exchange 就会将消息路由到对应的 Queue 。</li>
<li>Exchange Types<br>路由规则，有 4 种：fanuot 、direct 、topic 和 headers 。</li>
</ol>
<h4 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h4><p>了解了基本概念，再来看看 MQ 的执行过程。<br><img src="https://s1.ax1x.com/2020/04/25/JyRABt.png" alt="JyRABt.png" border="0" style="width:700px"></p>
<ol>
<li>RabbitMQ 已经运行，并且 Exchange 和 Queue 已经绑定。</li>
<li>Producer 连接到 RabbitMQ ，并发送一条消息，这个消息上带着一个 RoutingKey 。</li>
<li>RabbitMQ 接收到消息，并给 Producer 发送了 Confirm 消息。</li>
<li>Exchange 根据 RoutingKey 将消息路由到 Queue 。</li>
<li>Consumer 从 RabbitMQ 接收一条消息，处理完成后向 RabbitMQ 发送一条 Ack 。</li>
<li>RabbitMQ 收到 Ack 后删除消息，整个流程结束。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> MQ </category>
            
        </categories>
        
        
        <tags>
            
            <tag> RabbitMQ </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Introducing Nacos]]></title>
      <url>/2020/04/19/introducing-nacos/</url>
      <content type="html"><![CDATA[<p>Nacos 是一个用于构建微服务的基础设施，提供服务发现、服务配置、元数据和流量管理功能。</p>
<h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>目前推荐版本是 1.1.4 ，可以去 github 下载。直接下载二进制包速度太慢，可以使用源代码编译。</p>
<pre><code>git clone https://github.com/alibaba/nacos.git
cd nacos/
mvn -Prelease-nacos -Dmaven.test.skip=true clean install -U
</code></pre><p>编译完成，在 <code>distribution/target/</code> 中有编译好的二进制包，解压之后就可以使用命令启动。启动有单机和集群两种方式。</p>
<pre><code>sh startup.sh -m standalone
</code></pre><p>不带参数为集群方式。</p>
<p>单机模式不需要什么配置，直接启动就可以。集群方式需要先修改 <code>conf/cluster.conf</code> 。</p>
<pre><code>192.168.100.101:8848
192.168.100.102:8848
192.168.100.103:8848
</code></pre><p>集群至少需要 3 个节点。</p>
<p>启动之后访问 <a href="http://localhost:8848/nacos/index.html" target="_blank" rel="external">http://localhost:8848/nacos/index.html</a> 可以看到界面，默认用户名密码为：nacos/nacos 。</p>
<h4 id="添加获取配置"><a href="#添加获取配置" class="headerlink" title="添加获取配置"></a>添加获取配置</h4><p>Nacos 通过 Namespace 、Group 、DataId 三元组来确定配置，Namespace 对应环境如 dev 、test 、prod ，Group 可以对应项目或工程，DataId 对应配置文件。Nacos 有多种方式，界面、OpenAPI 、SDK 。界面点点就好了，下面来说说另外两种方式。</p>
<h5 id="OpenAPI-方式"><a href="#OpenAPI-方式" class="headerlink" title="OpenAPI 方式"></a>OpenAPI 方式</h5><p>发布</p>
<pre><code>curl -XPOST &quot;http://localhost:8848/nacos/v1/cs/configs&quot; \
-H &quot;Content-Type: application/x-www-form-urlencoded; charset=utf-8&quot; \
--data-urlencode &quot;dataId=application.properties&quot; \
--data-urlencode &quot;group=spring-cloud-alibaba-nacos&quot; \
--data-urlencode &quot;tenant=e400be7d-039f-460a-bbb9-d2a2752fcb9e&quot; \
--data-urlencode &quot;content=application.name=nacos&quot;
</code></pre><blockquote>
<p>这里有一点需要注意，tenant 为 Namespace ，不能写名字，需要写 ID 。</p>
</blockquote>
<p>获取</p>
<pre><code>curl -XGET &quot;http://localhost:8848/nacos/v1/cs/configs?dataId=application.properties&amp;group=spring-cloud-alibaba-nacos&amp;tenant=e400be7d-039f-460a-bbb9-d2a2752fcb9e&quot;
</code></pre><p>监听</p>
<pre><code>curl -XPOST &quot;http://localhost:8848/nacos/v1/cs/configs/listener&quot; -H &quot;Long-Pulling-Timeout: 30000&quot; -d &quot;Listening-Configs=application.properties^2spring-cloud-alibaba-nacos^6db060a43bdf54674e916e7b3acca7fa^2e400be7d-039f-460a-bbb9-d2a2752fcb9e^1&quot;
</code></pre><h5 id="SDK"><a href="#SDK" class="headerlink" title="SDK"></a>SDK</h5><pre><code>public class NacosSDK {
    public static void main(String[] args) throws NacosException, InterruptedException {
        String serverAddr = &quot;localhost:8848&quot;;
        String dataId = &quot;application.properties&quot;;
        String group = &quot;spring-cloud-alibaba-nacos&quot;;
        String tenant = &quot;e400be7d-039f-460a-bbb9-d2a2752fcb9e&quot;;
        Properties properties = new Properties();
        properties.put(PropertyKeyConst.SERVER_ADDR, serverAddr);
        properties.put(PropertyKeyConst.NAMESPACE, tenant);
        ConfigService configService = NacosFactory.createConfigService(properties);
        String content = configService.getConfig(dataId, group, 5000);
        System.out.println(&quot;配置为：&quot; + content);
        configService.addListener(dataId, group, new Listener() {
            @Override
            public void receiveConfigInfo(String configInfo) {
                System.out.println(&quot;监听器-配置更新了：&quot; + configInfo);
            }

            @Override
            public Executor getExecutor() {
                return null;
            }
        });

        boolean isPublishOk = configService.publishConfig(dataId, group, &quot;application.name=nacos&quot;);
        System.out.println(&quot;发布了配置：&quot; + isPublishOk);

        Thread.sleep(3000);
        content = configService.getConfig(dataId, group, 5000);
        System.out.println(&quot;配置为：&quot; + content);

        Thread.sleep(3000);
        boolean isPublishOk1 = configService.publishConfig(dataId, group, &quot;application.name=nacos1&quot;);
        System.out.println(&quot;更新了配置：&quot; + isPublishOk1);

        Thread.sleep(3000);
        content = configService.getConfig(dataId, group, 5000);
        System.out.println(&quot;更新后配置为：&quot; + content);

        Thread.sleep(3000);
        boolean isRemoveOk = configService.removeConfig(dataId, group);
        System.out.println(&quot;删除了配置：&quot; + isRemoveOk);

        Thread.sleep(3000);
        content = configService.getConfig(dataId, group, 5000);
        System.out.println(&quot;删除后配置为：&quot; + content);
        Thread.sleep(300000);
    }
}
</code></pre><h4 id="使用-MySQL-数据源"><a href="#使用-MySQL-数据源" class="headerlink" title="使用 MySQL 数据源"></a>使用 MySQL 数据源</h4><p>Nacos 默认使用嵌入式数据库存储配置信息，数据源支持换成 MySQL 。<br>首先使用 conf/nacos-mysql.sql 创建数据库。第二步将数据库配置加入 conf/application.properties 中。</p>
<pre><code>spring.datasource.platform=mysql

db.num=1
db.url.0=jdbc:mysql://localhost:3306/nacos_config?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true
db.user=root
db.password=123456
</code></pre><h4 id="管理多环境配置文件"><a href="#管理多环境配置文件" class="headerlink" title="管理多环境配置文件"></a>管理多环境配置文件</h4><p>通常会有 3 个环境 dev 、test 、prod ，三个环境的配置文件在 nacos 中进行管理。在项目中只存放 nacos config 相关的配置。通过 profiles 来区分不同环境的配置。</p>
<pre><code># dev 配置
spring:
  profiles: dev
nacos:
  config:
    server-addr: 127.0.0.1:8848
    namespace: af40020e-9c75-4174-be5b-796622544bae

---
#test 配置
spring:
  profiles: test
nacos:
  config:
    server-addr: 127.0.0.1:8848
    namespace: 33d746ec-529e-472c-a6d1-302ee741e6cf

---
# prod 配置
spring:
  profiles: prod
nacos:
  config:
    server-addr: 127.0.0.1:8848
    namespace: d8038098-05b5-4a9a-9d55-a274eecf1e3a
---


management:
  endpoints:
    web:
      exposure:
        include: &#39;*&#39;
  endpoint:
    health:
      show-details: always

spring:
  application:
    name: spring-boot-nacos-example
</code></pre><p>启动时通过 <code>java -jar xxx.jar --spring.profiles.active=dev</code> 来指定运行环境。</p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
            <category> Microservices </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[The Basic Principles of Design]]></title>
      <url>/2020/04/05/the-basic-principles-of-design/</url>
      <content type="html"><![CDATA[<h4 id="1-单一职责原则-Single-Resposibility-Principle-SRP"><a href="#1-单一职责原则-Single-Resposibility-Principle-SRP" class="headerlink" title="1. 单一职责原则 (Single Resposibility Principle, SRP)"></a><strong>1. 单一职责原则 (Single Resposibility Principle, SRP)</strong></h4><p>通常我们设计一个类，比如 UserInfo ，会像这样。<br><img src="https://s1.ax1x.com/2020/04/05/G0vs61.png" alt="20200405002557" border="0" style="width:250px;"><br>这样做非常简单，相信大多数人也都是这样做的，但是这并不符合单一职责原则。<strong>单一职责原则是说有且只有一种原因会引起变更。</strong>在 UserInfo 中，<code>void setUserId(Integer userId);</code> ，<code>void setUserName(String userName);</code> ，<code>void setPassword(String password);</code> 是用户的属性，<code>void changePassword(String password);</code> 是用户的行为，所以它不符合单一职责原则。我们对它进行修改以符合单一职责原则。<br><img src="https://s1.ax1x.com/2020/04/05/G0vrlR.png" alt="20200405002919" border="0" style="width:350px;"><br>现在用户属性在 IUserBO 中，用户的行为在 IUserBiz 中，这样就符合单一职责原则了。<br>单一职责原则</p>
<ul>
<li>优点：每个类的复杂度降低，定义清晰明确，易于维护和扩展。</li>
<li>缺点：类之间的耦合增高，数量增多，增加了设计的复杂度。</li>
</ul>
<p>在实际中，单一原则有时很难使用，主要是因为职责是不可度量也不是一成不变的。但是我们还是应该尽可能应用它，不管是接口，类，还是方法。设计尽量要让使用的人清楚类或方法是干什么的，而不要让人猜他是怎么用的。</p>
<h4 id="2-里氏替换原则-Liskov-Substitution-Principle-LSP"><a href="#2-里氏替换原则-Liskov-Substitution-Principle-LSP" class="headerlink" title="2. 里氏替换原则 (Liskov Substitution Principle, LSP)"></a><strong>2. 里氏替换原则 (Liskov Substitution Principle, LSP)</strong></h4><p>通俗的讲，<strong>所有使用父类的地方都可以换成子类，且不会出现错误，反之则不行，这就是里氏替换原则</strong>。<br><img src="https://s1.ax1x.com/2020/04/05/GrYNQS.png" alt="GrYNQS.png" border="0" style="width:350px;"></p>
<pre><code>public class Client {
    public static void main(String[] args) {
        Person alice = new Person();
        Dog dog = new Dog();
        alice.set(dog);
        alice.play();
    }
}
</code></pre><p><code>void set(Animal animal)</code> 可以换成子类，满足里氏替换原则。<br>里氏替换原则的优点：增强程序的健壮性和可扩展性。</p>
<h4 id="3-依赖倒置原则-Dependence-Inversion-Principle-DIP"><a href="#3-依赖倒置原则-Dependence-Inversion-Principle-DIP" class="headerlink" title="3. 依赖倒置原则 (Dependence Inversion Principle, DIP)"></a><strong>3. 依赖倒置原则 (Dependence Inversion Principle, DIP)</strong></h4><p><strong>依赖倒置原则的意思是上层不依赖下层，抽象不依赖细节，而细节应该依赖抽象，通俗的说就是面向接口编程。</strong><br><img src="https://s1.ax1x.com/2020/04/05/GrdhPs.png" alt="GrdhPs.png" border="0" style="width:350px;"><br>Benz 是细节，ICar 是抽象，如果把 Benz 换成 BMW 不应该影响 ICar 。</p>
<pre><code>public class Client {
    public static void main(String[] args) {
        IDriver tom = new Driver();
        tom.drive(new Benz());
    }
}
</code></pre><p>Client 调用 Benz ，所以 Client 是上层，Benz 是下层，将 Benz 换成 BMW ，Client 其他细节不需要改变。<br>依赖倒置原则的优点：减少因需求变化导致的变更，程序易于扩展和维护。</p>
<h4 id="4-接口隔离原则-Interface-Segregation-Principle-ISP"><a href="#4-接口隔离原则-Interface-Segregation-Principle-ISP" class="headerlink" title="4. 接口隔离原则 (Interface Segregation Principle, ISP)"></a><strong>4. 接口隔离原则 (Interface Segregation Principle, ISP)</strong></h4><p>接口隔离原则是说接口应该细化，接口中的方法也应尽可能少。接口隔离原则和单一职责有点类似，也有些冲突，需要灵活应用。接口隔离原则目的是提高内聚，增加灵活性。</p>
<h4 id="5-迪米特法则-Law-of-Demeter-LoD"><a href="#5-迪米特法则-Law-of-Demeter-LoD" class="headerlink" title="5. 迪米特法则 (Law of Demeter, LoD)"></a><strong>5. 迪米特法则 (Law of Demeter, LoD)</strong></h4><p><strong>迪米特法则也叫最少知识原则，简单来说就是一个类对需要调用的类知道的越少越好。</strong>比如我们设计一个软件安装引导程序，我们可以这样设计。<br><img src="https://s1.ax1x.com/2020/04/06/GyKGxH.png" alt="20200406170228" border="0" style="width:200px;"><br>这样设计，Wizard 暴露了太多的方法给 SoftwareInstaller ，耦合性太高，按照迪米特法则进行优化。<br><img src="https://s1.ax1x.com/2020/04/06/GyKYMd.png" alt="20200406170346" border="0" style="width:200px;"><br>修改完后，Wizard 只暴露了一个方法给 SoftwareInstaller ，Wizard 中的 private 方法的修改不会影响到 SoftwareInstaller 。</p>
<h4 id="6-开闭原则-Open-Closed-Principle-OCP"><a href="#6-开闭原则-Open-Closed-Principle-OCP" class="headerlink" title="6. 开闭原则 (Open Closed Principle, OCP)"></a><strong>6. 开闭原则 (Open Closed Principle, OCP)</strong></h4><p><strong>开闭原则是说对扩展开放，对修改关闭。简单来说，我们的程序应该通过扩展功能来实现新的功能，而不应该通过修改已有的代码来实现新的功能。</strong>假设我们已经开发好了商品模块，现在需要进行促销，我们应该怎么做呢？有 3 种方法。</p>
<ol>
<li>在接口种增加打折方法。不建议，接口不应该经常发生变化，如果接口变了，所有的实现都需要改变。</li>
<li>将实现类中的价格改成折扣价格。容易造成业务上的混乱，分不清是折扣还是原价。</li>
<li>通过新增折扣商品的方式实现功能。<br><img src="https://s1.ax1x.com/2020/04/06/GymBiF.png" alt="GymBiF.png" border="0" style="width:400px;"></li>
</ol>
<p>开闭原则的优点：</p>
<ol>
<li>易于进行单元测试。</li>
<li>提高了复用性。</li>
<li>提高了可靠性。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Design Pattern </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Understanding MySQL Explain]]></title>
      <url>/2020/04/01/understanding-mysql-explain/</url>
      <content type="html"><![CDATA[<p>Explain 会展示 MySQL 优化器关于语句执行计划的信息，也就是说会解释 MySQL 将如何处理语句。<br>我们先来试一下。</p>
<pre><code>mysql&gt; explain select * from t_user where name=&#39;tom&#39;;
+----+-------------+--------+------------+------+---------------+--------+---------+-------+------+----------+-------+
| id | select_type | table  | partitions | type | possible_keys | key    | key_len | ref   | rows | filtered | Extra |
+----+-------------+--------+------------+------+---------------+--------+---------+-------+------+----------+-------+
|  1 | SIMPLE      | t_user | NULL       | ref  | i_name        | i_name | 202     | const |    1 |   100.00 | NULL  |
+----+-------------+--------+------------+------+---------------+--------+---------+-------+------+----------+-------+
</code></pre><p>Explain 结果显示了 12 列（黑体是我们需要重点关注的列）。</p>
<p><table style="font-size:12px;color:#333333;border-width: 1px;border-color: #666666;border-collapse: collapse;"><tr><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">列</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">说明</th></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">id</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">序号</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><strong>select_type</strong></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">select 的类型</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">table</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">表名</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">partitions</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">匹配的分区</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><strong>type</strong></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">查找的类型</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">possible_keys</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">可能选择的索引</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">key</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">实际选择的索引</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">key_len</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">实际使用的索引的长度</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><strong>ref</strong></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">与索引比较的列</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">rows</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">读取的行数</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">filtered</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">按条件过滤后的行数占比</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><strong>Extra</strong></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">附加信息</td></tr></table><br></p>
<h5 id="select-type"><a href="#select-type" class="headerlink" title="select_type"></a><strong>select_type</strong></h5><p>select_type 有以下一些值：</p>
<ol>
<li>SIMPLE：简单 SELECT（不使用 UNION 或子查询）。<pre><code>mysql&gt; explain select * from t_user;
+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------+
| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |
+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------+
|  1 | SIMPLE      | t_user | NULL       | ALL  | NULL          | NULL | NULL    | NULL |  100 |   100.00 | NULL  |
+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------+
</code></pre></li>
<li>PRIMARY：最外层 SELECT 。<pre><code>mysql&gt; explain select t1.* from t_user t1 where t1.id =(select id from t_user t2 where t2.name=&#39;user1&#39;);
+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------------+
| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra       |
+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------------+
|  1 | PRIMARY     | t1    | NULL       | const | PRIMARY       | PRIMARY | 4       | const |    1 |   100.00 | NULL        |
|  2 | SUBQUERY    | t2    | NULL       | ref   | i_name        | i_name  | 202     | const |    1 |   100.00 | Using index |
+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------------+
</code></pre></li>
<li>UNION：UNION 中第二个及以后的 SELECT 语句。<pre><code>mysql&gt; explain select * from t_user t1 where t1.id=1 union select * from t_user t2 where t2.id=2;
+----+--------------+------------+------------+-------+---------------+---------+---------+-------+------+----------+-----------------+
| id | select_type  | table      | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra           |
+----+--------------+------------+------------+-------+---------------+---------+---------+-------+------+----------+-----------------+
|  1 | PRIMARY      | t1         | NULL       | const | PRIMARY       | PRIMARY | 4       | const |    1 |   100.00 | NULL            |
|  2 | UNION        | t2         | NULL       | const | PRIMARY       | PRIMARY | 4       | const |    1 |   100.00 | NULL            |
| NULL | UNION RESULT | &lt;union1,2&gt; | NULL       | ALL   | NULL          | NULL    | NULL    | NULL  | NULL |     NULL | Using temporary |
+----+--------------+------------+------------+-------+---------------+---------+---------+-------+------+----------+-----------------+
</code></pre>union 的结果 UNION RESULT 放在临时表 <union1,2> 中，所以 id 为 NULL 。union 要对结果去重，所以需要临时表，union all 不需要去重，所以不需要临时表。<pre><code>mysql&gt; explain select * from t_user t1 where t1.id=1 union all select * from t_user t2 where t2.id=2;
+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+
| id | select_type | table | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra |
+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+
|  1 | PRIMARY     | t1    | NULL       | const | PRIMARY       | PRIMARY | 4       | const |    1 |   100.00 | NULL  |
|  2 | UNION       | t2    | NULL       | const | PRIMARY       | PRIMARY | 4       | const |    1 |   100.00 | NULL  |
+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+
</code></pre></union1,2></li>
<li>DEPENDENT UNION：UNION 中的第二个及以后的 SELECT 语句，依赖外层查询。<pre><code>mysql&gt; explain select t1.* from t_user t1 where t1.id in (select id from t_user t2 union select id from t_user t3);
+----+--------------------+------------+------------+--------+---------------+---------+---------+------+------+----------+-----------------+
| id | select_type        | table      | partitions | type   | possible_keys | key     | key_len | ref  | rows | filtered | Extra           |
+----+--------------------+------------+------------+--------+---------------+---------+---------+------+------+----------+-----------------+
|  1 | PRIMARY            | t1         | NULL       | ALL    | NULL          | NULL    | NULL    | NULL |  100 |   100.00 | Using where     |
|  2 | DEPENDENT SUBQUERY | t2         | NULL       | eq_ref | PRIMARY       | PRIMARY | 4       | func |    1 |   100.00 | Using index     |
|  3 | DEPENDENT UNION    | t3         | NULL       | eq_ref | PRIMARY       | PRIMARY | 4       | func |    1 |   100.00 | Using index     |
| NULL | UNION RESULT       | &lt;union2,3&gt; | NULL       | ALL    | NULL          | NULL    | NULL    | NULL | NULL |     NULL | Using temporary |
+----+--------------------+------------+------------+--------+---------------+---------+---------+------+------+----------+-----------------+
</code></pre></li>
<li>UNION RESULT：UNION 的结果。</li>
<li>SUBQUERY：子查询中第一个 SELECT 语句。</li>
<li>DEPENDENT SUBQUERY：子查询中第一个 SELECT 语句，依赖外部查询。</li>
<li>DERIVED：derived 表<pre><code>mysql&gt; explain select * from (select id from t_user group by id) A;
+----+-------------+------------+------------+-------+------------------------+---------+---------+------+------+----------+-------------+
| id | select_type | table      | partitions | type  | possible_keys          | key     | key_len | ref  | rows | filtered | Extra       |
+----+-------------+------------+------------+-------+------------------------+---------+---------+------+------+----------+-------------+
|  1 | PRIMARY     | &lt;derived2&gt; | NULL       | ALL   | NULL                   | NULL    | NULL    | NULL |  100 |   100.00 | NULL        |
|  2 | DERIVED     | t_user     | NULL       | index | PRIMARY,i_name,i_skill | PRIMARY | 4       | NULL |  100 |   100.00 | Using index |
+----+-------------+------------+------------+-------+------------------------+---------+---------+------+------+----------+-------------+
</code></pre></li>
<li>MATERIALIZED：</li>
<li>UNCACHEABLE SUBQUERY：子查询结果无法缓存，必须针对外部查询的每一行重新进行评估。</li>
<li>UNCACHEABLE UNION：UNION 中的第二个及以后的 SELETE 语句，并且这个 UNION 属于 UNCACHEABLE SUBQUERY 。</li>
</ol>
<h5 id="table"><a href="#table" class="headerlink" title="table"></a><strong>table</strong></h5><p>table 对应的是表名，比如 t1 ，或者是临时表的名字。将查询的结果保存到临时表叫做物化。如果是物化的方式，则显示为 <code>&lt;derivedN&gt;</code> ，表示需要依赖 id 为 N 的查询。当使用 union 时显示 <code>&lt;union1,2&gt;</code> 。 </p>
<h5 id="type"><a href="#type" class="headerlink" title="type"></a><strong>type</strong></h5><ol>
<li>system：该表只有一行记录。system 是 const 的特例。</li>
<li>const：全表最多只有一行匹配。<pre><code>mysql&gt; explain select * from t_user where id=1;
+----+-------------+--------+------------+-------+---------------+---------+---------+-------+------+----------+-------+
| id | select_type | table  | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtered | Extra |
+----+-------------+--------+------------+-------+---------------+---------+---------+-------+------+----------+-------+
|  1 | SIMPLE      | t_user | NULL       | const | PRIMARY       | PRIMARY | 4       | const |    1 |   100.00 | NULL  |
+----+-------------+--------+------------+-------+---------------+---------+---------+-------+------+----------+-------+
</code></pre></li>
<li>eq_ref：A 连接 B ，B 的连接字段是主键或唯一索引。<pre><code>mysql&gt; explain select * from t_dept join t_employee on t_dept.dept_id=t_employee.id;
+----+-------------+------------+------------+--------+---------------+---------+---------+---------------------+------+----------+-------+
| id | select_type | table      | partitions | type   | possible_keys | key     | key_len | ref                 | rows | filtered | Extra |
+----+-------------+------------+------------+--------+---------------+---------+---------+---------------------+------+----------+-------+
|  1 | SIMPLE      | t_dept     | NULL       | ALL    | PRIMARY       | NULL    | NULL    | NULL                |    1 |   100.00 | NULL  |
|  1 | SIMPLE      | t_employee | NULL       | eq_ref | PRIMARY       | PRIMARY | 4       | test.t_dept.dept_id |    1 |   100.00 | NULL  |
+----+-------------+------------+------------+--------+---------------+---------+---------+---------------------+------+----------+-------+
</code></pre></li>
<li>ref：A 连接 B ，B 的连接字段是普通索引。<pre><code>mysql&gt; explain select * from t_dept join t_employee on t_dept.dept_id=t_employee.dept_id;
+----+-------------+------------+------------+------+---------------+-----------+---------+---------------------+------+----------+-------+
| id | select_type | table      | partitions | type | possible_keys | key       | key_len | ref                 | rows | filtered | Extra |
+----+-------------+------------+------------+------+---------------+-----------+---------+---------------------+------+----------+-------+
|  1 | SIMPLE      | t_dept     | NULL       | ALL  | PRIMARY       | NULL      | NULL    | NULL                |    1 |   100.00 | NULL  |
|  1 | SIMPLE      | t_employee | NULL       | ref  | i_dept_id     | i_dept_id | 5       | test.t_dept.dept_id |    1 |   100.00 | NULL  |
+----+-------------+------------+------------+------+---------------+-----------+---------+---------------------+------+----------+-------+
</code></pre></li>
<li>fulltext：使用 fulltext 索引进行连接。</li>
<li>ref_or_null：类似 ref ，但是还会搜索包含 NULL 的行。<pre><code>mysql&gt; explain select * from t_user where skill=&#39;aaa&#39; or skill is null;
+----+-------------+--------+------------+-------------+---------------+---------+---------+-------+------+----------+-----------------------+
| id | select_type | table  | partitions | type        | possible_keys | key     | key_len | ref   | rows | filtered | Extra                 |
+----+-------------+--------+------------+-------------+---------------+---------+---------+-------+------+----------+-----------------------+
|  1 | SIMPLE      | t_user | NULL       | ref_or_null | i_skill       | i_skill | 43      | const |    2 |   100.00 | Using index condition |
+----+-------------+--------+------------+-------------+---------------+---------+---------+-------+------+----------+-----------------------+
</code></pre></li>
<li>index_merge：<pre><code>mysql&gt; explain select * from t_user where name=&#39;user1&#39; or skill is null;
+----+-------------+--------+------------+-------------+----------------+----------------+---------+------+------+----------+------------------------------------------+
| id | select_type | table  | partitions | type        | possible_keys  | key            | key_len | ref  | rows | filtered | Extra                                    |
+----+-------------+--------+------------+-------------+----------------+----------------+---------+------+------+----------+------------------------------------------+
|  1 | SIMPLE      | t_user | NULL       | index_merge | i_name,i_skill | i_name,i_skill | 202,43  | NULL |    2 |   100.00 | Using union(i_name,i_skill); Using where |
+----+-------------+--------+------------+-------------+----------------+----------------+---------+------+------+----------+------------------------------------------+
</code></pre></li>
<li>unique_subquery：</li>
<li>index_subquery：</li>
<li>range：<pre><code>mysql&gt; explain select * from t_user where id&gt;10;
+----+-------------+--------+------------+-------+---------------+---------+---------+------+------+----------+-------------+
| id | select_type | table  | partitions | type  | possible_keys | key     | key_len | ref  | rows | filtered | Extra       |
+----+-------------+--------+------------+-------+---------------+---------+---------+------+------+----------+-------------+
|  1 | SIMPLE      | t_user | NULL       | range | PRIMARY       | PRIMARY | 4       | NULL |   90 |   100.00 | Using where |
+----+-------------+--------+------------+-------+---------------+---------+---------+------+------+----------+-------------+
</code></pre></li>
<li>index：全表扫描，查询字段全都有索引。<pre><code>mysql&gt; explain select name from t_user;
+----+-------------+--------+------------+-------+---------------+--------+---------+------+------+----------+-------------+
| id | select_type | table  | partitions | type  | possible_keys | key    | key_len | ref  | rows | filtered | Extra       |
+----+-------------+--------+------------+-------+---------------+--------+---------+------+------+----------+-------------+
|  1 | SIMPLE      | t_user | NULL       | index | NULL          | i_name | 202     | NULL |  100 |   100.00 | Using index |
+----+-------------+--------+------------+-------+---------------+--------+---------+------+------+----------+-------------+
</code></pre></li>
<li>ALL：全表扫描，查询的字段不全都有索引。<pre><code>mysql&gt; explain select * from t_user;
+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------+
| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra |
+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------+
|  1 | SIMPLE      | t_user | NULL       | ALL  | NULL          | NULL | NULL    | NULL |  100 |   100.00 | NULL  |
+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-------+
</code></pre></li>
</ol>
<h5 id="possible-keys"><a href="#possible-keys" class="headerlink" title="possible_keys"></a><strong>possible_keys</strong></h5><p>如果查询没有使用索引，则为 NULL ，可以在 where 中添加一些条件来使用索引。</p>
<h5 id="key-len"><a href="#key-len" class="headerlink" title="key_len"></a><strong>key_len</strong></h5><p>key_len 是实际使用的 key 的长度，tinyint 是 1 字节 ，smallint 是 2 字节，int 是 4 字节，bigint 是 8 字节，timestamp 是 3 字节，datetime 是 8 字节 ，char(n) 是 n 字节，varchar(n) 是 x*n + 2 字节，x 根据字符集而定。</p>
<h5 id="rows"><a href="#rows" class="headerlink" title="rows"></a><strong>rows</strong></h5><p>rows 是查询计划预估的记录数，不是真正的结果行数。如果没有走索引，是全表扫描的行数，如果走索引，是预估的索引扫描行数。</p>
<h5 id="filtered"><a href="#filtered" class="headerlink" title="filtered"></a><strong>filtered</strong></h5><p>filtered 主要用于表连接。</p>
<pre><code>mysql&gt; explain select * from t_employee,t_dept where t_employee.dept_id=t_dept.dept_id;
+----+-------------+------------+------------+------+---------------+-----------+---------+---------------------+------+----------+-------+
| id | select_type | table      | partitions | type | possible_keys | key       | key_len | ref                 | rows | filtered | Extra |
+----+-------------+------------+------------+------+---------------+-----------+---------+---------------------+------+----------+-------+
|  1 | SIMPLE      | t_dept     | NULL       | ALL  | PRIMARY       | NULL      | NULL    | NULL                |    1 |   100.00 | NULL  |
|  1 | SIMPLE      | t_employee | NULL       | ref  | i_dept_id     | i_dept_id | 5       | test.t_dept.dept_id |    1 |   100.00 | NULL  |
+----+-------------+------------+------------+------+---------------+-----------+---------+---------------------+------+----------+-------+
</code></pre><p>在使用表连接时，如果是 A left join B ，则 A 是驱动表，B 是被驱动表。如果是 A right join B ，则 B 是驱动表，A 是被驱动表。如果是 <code>select * from A,B</code>  ，则小表是驱动表，大表是被驱动表。上边的例子，t_dept 是驱动表，t_employee 是被驱动表，t_employee 的连接行数 = 1 行 (t_dept rows * t_dept filtered=1 * 100% = 1) 。</p>
<h5 id="Extra"><a href="#Extra" class="headerlink" title="Extra"></a>Extra</h5><ol>
<li>NULL：查询的列没有被索引覆盖，必须通过回表进行查询。<pre><code>mysql&gt; explain select * from t_user where name=&#39;tom&#39;;
+----+-------------+--------+------------+------+---------------+--------+---------+-------+------+----------+-------+
| id | select_type | table  | partitions | type | possible_keys | key    | key_len | ref   | rows | filtered | Extra |
+----+-------------+--------+------------+------+---------------+--------+---------+-------+------+----------+-------+
|  1 | SIMPLE      | t_user | NULL       | ref  | i_name        | i_name | 202     | const |    1 |   100.00 | NULL  |
+----+-------------+--------+------------+------+---------------+--------+---------+-------+------+----------+-------+
</code></pre></li>
<li>Using index：只使用索引查询列的信息，这种情况一般都是使用了索引覆盖。<pre><code>mysql&gt; explain select name from t_user where name=&#39;tom&#39;;
+----+-------------+--------+------------+------+---------------+--------+---------+-------+------+----------+-------------+
| id | select_type | table  | partitions | type | possible_keys | key    | key_len | ref   | rows | filtered | Extra       |
+----+-------------+--------+------------+------+---------------+--------+---------+-------+------+----------+-------------+
|  1 | SIMPLE      | t_user | NULL       | ref  | i_name        | i_name | 202     | const |    1 |   100.00 | Using index |
+----+-------------+--------+------------+------+---------------+--------+---------+-------+------+----------+-------------+
</code></pre></li>
<li>Using where：where 条件是索引之一。<pre><code>mysql&gt; explain select name from t_user where name=&#39;tom&#39; and age=10;
+----+-------------+--------+------------+------+---------------+--------+---------+-------+------+----------+-------------+
| id | select_type | table  | partitions | type | possible_keys | key    | key_len | ref   | rows | filtered | Extra       |
+----+-------------+--------+------------+------+---------------+--------+---------+-------+------+----------+-------------+
|  1 | SIMPLE      | t_user | NULL       | ref  | i_name        | i_name | 202     | const |    1 |    10.00 | Using where |
+----+-------------+--------+------------+------+---------------+--------+---------+-------+------+----------+-------------+
</code></pre></li>
<li>Using index condition：使用了索引下推优化。</li>
<li>Using temporary：查询使用了临时表，临时表创建和维护成本很高，所以一般需要考虑优化。</li>
<li>Using filesort：filesort 耗时，一般需要考虑优化成索引排序。</li>
<li>Using join buffer：连接条件没有使用索引，需要优化。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> MySQL </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Deep in Overload and Override]]></title>
      <url>/2020/03/29/deep-in-overload-and-override/</url>
      <content type="html"><![CDATA[<p>封装，继承，多态是面向对象的 3 个特征。多态又可以分为静态多态 (overload) 和动态多态 (override) 。</p>
<h4 id="Overload"><a href="#Overload" class="headerlink" title="Overload"></a>Overload</h4><p>Overload 通过参数类型来选择方法，我们通过一个例子来感受以下。</p>
<pre><code>public class OverloadExample {

    public void sayHello(Human guy) {
        System.out.println(&quot;hello, guy&quot;);
    }

    public void sayHello(Man guy) {
        System.out.println(&quot;hello, gentleman&quot;);
    }

    public void sayHello(Woman guy) {
        System.out.println(&quot;hello, lady&quot;);
    }

    public static void main(String[] args) {
        Human man = new Man(); // 静态类型是Human，动态类型是Man
        Human woman = new Woman();
        OverloadExample oe = new OverloadExample();
        /*
            重载是根据静态类型来判断的
         */
        oe.sayHello(man);
        oe.sayHello(woman);
    }

    static class Human {
    }

    static class Man extends Human {
    }

    static class Woman extends Human {
    }
}

运行结果：
hello, guy
hello, guy
hello, gentleman
hello, lady
</code></pre><p>接下来我们来分析以下为什么。<code>Human man = new Man();</code> Human 是静态类型，Man 是实际类型，变量本身的静态类型不会被改变，所以是编译期可知的，而实际类型是在运行时确定的。编译器在重载时是通过参数的静态类型来判断的。通过 javap 可以看到编译的字节码。</p>
<pre><code> #13 = Methodref          #11.#57        // com/rolex/microlabs/jvm/OverloadExample.sayHello:(Lcom/rolex/microlabs/jvm/OverloadExample$Human;)V

 26: invokevirtual #13                 // Method sayHello:(Lcom/rolex/microlabs/jvm/OverloadExample$Human;)V
 29: aload_3
 30: aload_2
 31: invokevirtual #13                 // Method sayHello:(Lcom/rolex/microlabs/jvm/OverloadExample$Human;)V
</code></pre><p>这种通过静态类型来寻找方法的方式叫做<strong>静态分派</strong>，Overload 就是典型场景。静态类型可能会匹配多个方法，这时编译器会选择一个最合适。比如下面这个例子。</p>
<pre><code>public class OverloadExample1 {
    public static void sayHello(char arg) {
        System.out.println(&quot;hello char&quot;);
    }

    public static void sayHello(int arg) {
        System.out.println(&quot;hello int&quot;);
    }

    public static void sayHello(long arg) {
        System.out.println(&quot;hello long&quot;);
    }

    public static void sayHello(float arg) {
        System.out.println(&quot;hello float&quot;);
    }

    public static void sayHello(double arg) {
        System.out.println(&quot;hello double&quot;);
    }

    public static void sayHello(Character arg) {
        System.out.println(&quot;hello Character&quot;);
    }

    public static void sayHello(Serializable arg) {
        System.out.println(&quot;hello Serializable&quot;);
    }

    public static void sayHello(Comparable arg) {
        System.out.println(&quot;hello Comparable&quot;);
    }

    public static void sayHello(Object arg) {
        System.out.println(&quot;hello Object&quot;);
    }

    public static void sayHello(char... arg) {
        System.out.println(&quot;hello char...&quot;);
    }

    public static void sayHello(int... arg) {
        System.out.println(&quot;hello int...&quot;);
    }

    public static void main(String[] args) {
        sayHello(&#39;a&#39;);
    }
}
</code></pre><p>根据 <code>&#39;a&#39;</code> 的类型，最匹配的当然是 char 。如果没有 char ，则会匹配 int ，因为 char 通过类型转化，也可以用 int 表示。如果 int 也没有，则再进行一次类型转化，来匹配 long 。依次类推，可以依次匹配 float 和 double 。如果 float 和 double 都没有，则会匹配 Character ，因为 Character 是 char 的包装类，通过自动装箱可以进行类型转化。如果 Character 也么有，则会匹配 Serializable 和 Comparable ，因为 Character 实现了 Serializable 和 Comparable ，它们的优先级是相同的，编译器就不知道该如何匹配了，会报编译错误。如果没有 Serializable 和 Comparable ，则会继续匹配 Object 因为 Object 是 Character 的父类。最后如果 Object 也没有，就会作为一个可变参数进行匹配。</p>
<h4 id="Override"><a href="#Override" class="headerlink" title="Override"></a>Override</h4><pre><code>public class OverrideExample {
    public static void main(String[] args) {
        Human man = new Man();
        Human woman = new Woman();
        Man man1 = new Man();
        Woman woman1 = new Woman();
        man.sayHello();
        woman.sayHello();
        man1.sayHello();
        woman1.sayHello();
    }

    static class Human {
        public void sayHello() {
            System.out.println(&quot;hello, guy&quot;);
        }
    }

    static class Man extends Human {
        public void sayHello() {
            System.out.println(&quot;hello, gentleman&quot;);
        }
    }

    static class Woman extends Human {
        public void sayHello() {
            System.out.println(&quot;hello, lady&quot;);
        }
    }
}

执行结果：
hello, gentleman
hello, lady
hello, gentleman
hello, lady
</code></pre><p>在编译 <code>man.sayHello()</code> 时，编译器并不知道最终是调用 Man 的 sayHello() ，我们可以通过 javap 查看。</p>
<pre><code>#6 = Methodref          #14.#39        // com/rolex/microlabs/jvm/OverrideExample$Human.sayHello:()V
#7 = Methodref          #2.#39         // com/rolex/microlabs/jvm/OverrideExample$Man.sayHello:()V
#8 = Methodref          #4.#39         // com/rolex/microlabs/jvm/OverrideExample$Woman.sayHello:()V

34: invokevirtual #6                  // Method com/rolex/microlabs/jvm/OverrideExample$Human.sayHello:()V
37: aload_2
38: invokevirtual #6                  // Method com/rolex/microlabs/jvm/OverrideExample$Human.sayHello:()V
41: aload_3
42: invokevirtual #7                  // Method com/rolex/microlabs/jvm/OverrideExample$Man.sayHello:()V
45: aload         4
47: invokevirtual #8                  // Method com/rolex/microlabs/jvm/OverrideExample$Woman.sayHello:()V
</code></pre><p>编译的指令是相同的，但是最终执行的结果却不一样。这和 invokevirtual 指令的执行过程有关。invokevirtual 指令会首先从操作数栈顶对象开始找，如果找到匹配的方法，则返回。如果没有找到，则继续按照继承关系从下往上依次查找，直到找到为止。这种根据运行时实际类型进行方法匹配叫做<strong>动态分派</strong>。</p>
<blockquote>
<p>由于查找是在运行时进行的，为了性能考虑，JVM 并不会按照这种方式进行查找，而是通过虚方法表的方式进行查找。</p>
</blockquote>
<p>不论是静态分派还是动态分派，Java 在进行方法匹配时可检查的不外乎对象的类型和方法的参数，这叫做方法的<strong>宗量</strong>。通过宗量的数量，又可以分为单分派和多分派。在 Overload 中，编译器需要看方法参数的静态类型，还要看调用的是哪个对象的方法，所以 Overload 是<strong>静态多分派</strong>。在 Override 中，方法的参数是固定的，只需要看匹配的是哪个对象中的方法，所以 Override 是<strong>动态单分派</strong>。</p>
]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Escape Analysis]]></title>
      <url>/2020/03/27/escape-analysis/</url>
      <content type="html"><![CDATA[<p>什么是逃逸分析<br>逃逸分析是 JVM 中使用的一种优化技术。逃逸分析算法是利用连通图来构建对象和引用对象之间的可达性，以此进行数据流分析的方法，在论文 Escape Analysis for Java 中有介绍。</p>
<p>逃逸的种类<br>逃逸分析针对的对象的分析，对象的逃逸状态有 3 种：</p>
<ol>
<li>GlobalEscape ，全局逃逸<br>当对象符合以下条件，认为是全局逃逸：<br> 1）对象作为方法的返回结果。<br> 2）存储在全局变量或静态变量中的对象。<br> 3）重写了 finalize() 方法的对象。</li>
<li>ArgEscape ，参数逃逸<br>对象作为参数传递或被参数引用，但是没有发生全局逃逸。</li>
<li>NoEscape 没有逃逸</li>
</ol>
<p>利用逃逸分析，JVM 可以对代码进行优化：</p>
<ol>
<li>栈上分配<br>如果对象没有逃逸，可以将对象分配在方法的栈上而不用在堆中创建对象，这样当方法执行完，栈帧弹出，对象就自动被回收，可以加快内存回收，减少 GC 。</li>
<li>锁消除<br>当 JVM 认为一个对象只在当前线程内部使用，那么就会优化掉对象的同步锁。<pre><code>public static void m1() {
 synchronized (new Object()) {
     System.out.println(&quot;m1&quot;);
 }
}
public static void optimizedM1() {
 System.out.println(&quot;m1&quot;);
}
</code></pre>上边的例子只是为了说明，因为实际中我们应该不会对 new Object() 进行加锁。实际中最常见的还有在一个方法内部使用 StringBuffer.append() ，StringBuffer 的方法是 synchronized ，如果对象没有逃逸，JVM 会帮我们优化掉 synchronized 。</li>
<li>标量替换<br>标量不能再拆分，比如基本类型，聚合量可以被拆分，比如对象。将对象分解成标量，使用标量代替对象就叫做标量替换。如果对象没有逃逸，就可以用标量代替，变量只存储在栈上，就不用在堆中创建对象，既减少了内存占用又提高了运行速度。<pre><code>class Point {
 int x;
 int y;
}
public void optimizedShow() {
 int x = 1;
 int y = 2;
 System.out.println(&quot;point=(&quot; + x + &quot;, &quot; + y + &quot;)&quot;);
}
public void show() {
 Point point = new Point();
 point.x = 1;
 point.y = 2;
 System.out.println(&quot;point=(&quot; + point.x + &quot;, &quot; + point.y + &quot;)&quot;);
}
</code></pre></li>
<li><p>锁粗化<br>加锁操作是很消耗资源的，如果在循环内部进行多次，会将锁的范围扩大到循环外。</p>
<pre><code>public static void m1() {
 for (int i = 0; i &lt; 5_000_000; i++) {
     synchronized (new Object()) {

     }
 }
}
public static void optimizedM1() {
 synchronized (new Object()) {
     for (int i = 0; i &lt; 5_000_000; i++) {

     }
 }
}
</code></pre></li>
</ol>
]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[JIT at a Glance]]></title>
      <url>/2020/03/26/jit-at-a-glance/</url>
      <content type="html"><![CDATA[<h4 id="JIT-是什么？"><a href="#JIT-是什么？" class="headerlink" title="JIT 是什么？"></a>JIT 是什么？</h4><p>JIT(Just-In-Time Compilation) 即时编译，是一段代码在第一次将要被执行之前，进行的编译。属于动态编译（运行时编译）的范畴，与之相对的是 AOT(ahead-of-time Compilation)  也叫静态编译。</p>
<p>java 文件经过 javac 编译成字节码文件，再由 JVM 的解释器 interpreter 解释执行。当 JVM 发现某段代码执行地非常频繁，就会认为这段代码是热点代码 (hot spot code) 。JVM 就会将这些代码编译成机器指令，这样就可以直接调用机器指令执行，而不用再进行解释执行。这个将热点代码编译成机器指令的过程就是 JIT 编译，是通过 JIT 编译器来完成的。</p>
<p>什么样的代码算热点代码?</p>
<ol>
<li>被多次调用的代码，如果调用次数到达阈值，就会被加入到编译队列中等待编译，这种编译叫标准编译。</li>
<li>循环体，如果方法中有很长的循环，当计数器到达阈值，整个方法也会被编译，这种编译叫栈上替换 (On Stack Replacement, OSR) 。</li>
</ol>
<p>为什么 JIT 不是针对所有代码，而只是热点代码？<br>因为 JIT 也是有成本的。</p>
<ol>
<li>首先是时间成本，JIT 编译可能非常耗时，并且不是 100% 能够获取运行速度提升，即便获得运行速度提升，也不一定能抵消 JIT 编译的时间消耗，而且有些代码可能就只执行一次，所以相对来说还是解释执行的成本更低。</li>
<li>其次是空间成本，将字节码编译成机器码会占用更多的空间。</li>
</ol>
<p>所以只有热点代码才值得进行 JIT 编译。</p>
<h4 id="JIT-编译器"><a href="#JIT-编译器" class="headerlink" title="JIT 编译器"></a>JIT 编译器</h4><p>HotSpotVM 中，解释器和 JIT 编译器都属于执行引擎。JIT 编译器有两种，一个是 Client Compiler ，简称 C1 ，另一个是 Server Compiler ，简称 C2 。JVM 会根据运行模式选择 C1 或 C2 搭配解释器一起使用。默认使用的是 Server Compiler ，通过 <code>-client</code> 或 <code>-server</code> 选项可以指定使用哪种编译器。C1 编译器主要针对客户端程序设计，优化程度小，启动速度快。C2 编译器主要针对长时间执行的程序，更加关注代码的执行时间，所以会对代码进行更大程度的优化，因此启动时间比 C1 长。为了利用各自的优势，达到启动时间和执行效率之间的平衡，从 jdk1.6 开始引入了分层编译 (tiered compilation) ，并在 jdk1.7 作为默认策略。<br>分层编译是如何分层的？</p>
<ol>
<li>第 0 层，解释器解释执行。可以触发第 1 层编译。</li>
<li>第 1 层，C1 编译，进行简单的优化，将字节码编译成机器码。可以触发第 2 层编译。</li>
<li>第 2 层及以上，C2 编译，进行耗时较长的优化，可能会进行激进的优化。</li>
</ol>
<p>解释器和 JIT 是如何配合工作的？<br>HotSpotVM 为每个方法准备了两个计数器：Invocation Counter 和 Back Edge Counter 。解释器首先解释执行字节码，每执行一次某个方法，对应的计数器加 1 ，当达到阈值，触发 C1 编译，C1 将字节码编译成机器指令，只进行简单的优化。随着执行次数增多，优化会升级，触发 C2 编译，在 C2 编译过程中 JVM 可能会进行一些激进优化（大多数情况下能够提升运行速度的优化），但不一定成功。当出现罕见陷阱 (Uncommon Trap) 即优化失败时，通过逆优化 (deopimization) 进行回退，继续由解释器解释执行。编译过程需要花费时间，程序在运行期间不会等待编译完成，编译是异步进行的，编译完成后会替换代码，再下一次执行时使用。</p>
<p>Java 为什么要有 JIT ，为什么不在 javac 阶段就进行优化?<br>这是由于 javac 本身就是这么设计的，至于为什么这么设计，一是因为 Java 有一些动态特性导致在 javac  阶段进行优化难度很大，所以干脆不进行优化。举个例子：<br>有一个类 Foo 有两个方法 m1 和 m2  。</p>
<pre><code>class Foo {
    public String m1() {
        return m2();
    }
    public String m2() {
        return null;
    }
}

Foo foo = new Foo();
foo.m1();
</code></pre><p>对于这样的类，我们能不能在 javac 编译时将 m1 优化成 return null 呢？不能。<br>因为我们无法确定会不会在其他时刻会出现一个 Bar 类。</p>
<pre><code>class Bar extends Foo {
    public String m2(){
        return &quot;bar&quot;
    }
}

Foo foo = new Bar();
foo.m1();
</code></pre><p>此时 <code>m1()</code> 就不应该为 null 了。显然在 javac 编译时想要确定这个问题是十分困难的。二是将优化放在 JIT ，可以让其他运行在 JVM 上的其他语言也可以享受到优化的收益。</p>
<p>有 JIT 比没有 JIT 要快么?<br>其实不一定，还要具体问题具体分析。如果没有 JIT ，那么执行过程是 <code>字节码-&gt;解释器解释执行-&gt;结果</code>，有 JIT 的过程是 <code>字节码-&gt;JIT 编译-&gt;执行编译后的代码-&gt;结果</code>。经过 JIT 编译之后的代码执行要比解释器解释执行要快，但是 JIT 编译也是需要耗时的，并不一定 JIT 编译的时间要肯定小于解释执行的时间。</p>
<p>JIT 进行了哪些优化？</p>
<ol>
<li>公共子表达式消除<br>如果一个表达式 E 已经计算得到结果 R ，并且再后续再次出现 E 时它的参数没有发生变化，则可以直接使用 R 代替 E 。</li>
<li>方法内联<br>方法内联是在编译过程中遇到方法调用时，将目标方法的方法体纳入编译范围之中，并取代原方法调用的优化手段。比如 getter/setter 方法，如果没有内联，在调用 getter/setter 方法时，程序需要保存当前方法的执行位置，并创建 getter/setter 的栈帧入栈，执行完调用后再出栈，恢复到当前方法继续执行。如果有内联，会将方法调用优化成字段访问，从而提高程序运行速度。内联发生在 C2 阶段，由 jit compiler 解析字节码生成 IR 图，并在 IR 图上进行优化，如果进行方法内联，就将 IR 图中的对应节点替换成目标方法的 IR 图，然后对新的 IR 图进行进一步优化。 </li>
<li><a href="../../../../2020/03/27/escape-analysis/">逃逸分析</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Gazing at Hystrix]]></title>
      <url>/2020/03/25/gazing-at-hystrix/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Gazing at Zuul]]></title>
      <url>/2020/03/24/gazing-at-zuul/</url>
      <content type="html"><![CDATA[<p>ZuulServlet 在 service 中顺序执行 preRoute() ，route() ，postRoute() 。具体的 route 动作是通过聚合 ZuulRunner ，在 ZuulRunner 中使用 FilterProcessor 来执行。<br>首先执行的是 pre 类型的 filter 。默认的 preFilter 有 5 个：</p>
<ol>
<li>ServletDetectionFilter ，第一个 preFilter ，order 是 -3 ，用来判断 isDispatcherServletRequest 。</li>
<li>Servlet30WrapperFilter ，第二个 preFilter ，order 是 -2 ，用来包装 request 请求。</li>
<li>FormBodyWrapperFilter ，第三个 preFilter ，order 是 -1 ，用来对请求进行 FormBodyRequestWrapper 包装，以便后续的 filter 能够拿到流的信息。</li>
<li>DebugFilter ，第四个 preFilter ，order 是 1 ，用于 debug 开启时设置 debug 开关，打印 debug 信息。开启 bebug 之后，debug 信息会放在 X-Zuul-Debug-Header 中。</li>
<li>PreDecorationFilter ，第五个 preFilter ，order 是 5 ，用来做一些预处理，比如 set requestURI ，比如添加一些 request header 信息。</li>
</ol>
<p>然后会执行 route 类型的 filter 。默认的 routeFilter 有 3 个：</p>
<ol>
<li>RibbonRoutingFilter ，第一个 routeFilter ，order 是 10 ，针对通过 serviceId 进行路由的请求。</li>
<li>SimpleHostRoutingFilter ，第二个 routeFilter ，order 是 100 ，针对通过 url 进行路由的请求。</li>
<li>SendForwardFilter ，第三个 routeFilter ，order 是 500 ，用来处理 request.getRequestDispatcher() 的请求。</li>
</ol>
<p>最后执行 post 类型的 filter 。默认的 postFilter 有 1 个：</p>
<ol>
<li>SendResponseFilter ，第一个 postFilter ，order 是 1000 ，当头信息不为空，或有响应流信息，或有响应体的时候对 response 进行处理，将数据发回客户端。</li>
</ol>
<p>正常情况下不会执行 error 类型的 filter 。</p>
<blockquote>
<p>filter 的 order 表示 filter 的执行顺序，越小越早执行。需要注意，如果顺序错了，可能导致结果有问题，比如我们如果要在 preFilter 中重写 url ，应该放在 PreDecorationFilter 之后，因为 PreDecorationFilter 中会 set request 信息，如果我们在此之前 rewrite 了 url ，在这一步又会被覆盖成原始的。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Gazing at Feign]]></title>
      <url>/2020/03/24/gazing-at-feign/</url>
      <content type="html"><![CDATA[<p>Feign 的工作流程：</p>
<ol>
<li>启动时 ReflectiveFeign 通过 jdk 动态代理方式生成 FeignClient 的代理。<br><img src="https://s1.ax1x.com/2020/03/24/8qynjP.png" alt="8qynjP.png" border="0" style="width:700px"></li>
<li>调用 invoke() 时，生成 RequestTemplate 封装了 uri ，请求参数等信息。<br><img src="https://s1.ax1x.com/2020/03/24/8qw3tI.png" alt="20200324150653" border="0" style="width:600px"></li>
<li>在 executeAndDecode() 中用 RequestTemplate 构造出 Request 对象。<br><img src="https://s1.ax1x.com/2020/03/24/8qwnXD.png" alt="20200324150745" border="0" style="width:700px"></li>
<li>调用 LoadBalancerFeignClient.execute() 去发送 http 请求。<br><img src="https://s1.ax1x.com/2020/03/24/8qwQ7d.png" alt="20200324151551" border="0" style="width:700px"></li>
<li>获得 response 之后，根据 code 来进行 decode 将报文组装成对象。<br><img src="https://s1.ax1x.com/2020/03/24/8qwm6O.png" alt="20200324151750" border="0" style="width:650px"></li>
</ol>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Gazing at Ribbon]]></title>
      <url>/2020/03/23/gazing-at-ribbon/</url>
      <content type="html"><![CDATA[<p>通过自动装配扫描 spring.factories 中的 LoadBalancerAutoConfiguration 用来构造 LoadBalancerInterceptor 实例。在进行 http 调用的时候进行拦截。如果 server 有多个，会根据 IRule 来选择 server 。默认使用 aroundRobin ，server 存在 ArrayList 中，有一个计数器记录 nextIndex，用 nextIndex 对 server 数量取余来获取 server 的 index 。拿到 server 的 ip 和 port后，在 RibbonLoadBalancerClient 的 reconstructURI 中将服务名替换成 ip 和 port ，构造成新的 url ，通过 LoadBalancerRequest.apply() 发起真正的 http 调用。</p>
<p>Ribbon 在 RibbonClientConfiguration 中进行了默认配置。有 3 个配置：</p>
<ol>
<li>IRule ，负载均衡的规则，默认 ZoneAvoidanceRule 。获取所有可用的 zone ，如果当前 zone 可用，就使用当前 zone 中的 server ，不再看其他的 zone 。如果 server 有多个默认使用 aroundRobin 来选择 server 。</li>
<li>IPing ，向服务发起 Ping 操作，默认 DummyPing 什么都不做。</li>
<li>ILoadBalancer ，使用 IRule 和 IPing 配置进行 loadbalance 。默认使用 ZoneAwareLoadBalancer 。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Building Eureka Server with Region and Zone]]></title>
      <url>/2020/03/22/building-eureka-server-with-region-and-zone/</url>
      <content type="html"><![CDATA[<p>Eureka Region 和 Zone 的架构参考 <a href="../../../../2018/08/29/eureka-region-and-zone/">Eureka Region and Zone</a> 。</p>
<p>按照 Region 和 Zone 的架构来构建，有一个 Region us-east-1 ，us-east-1 下有 3 个 Zone ：us-east-1c ，us-east-1d ，us-east-1e 。各个 Zone 下有一个 Eureka Server 和 Application Service ，另外在 us-east-1c 下还有一个 Application Client 。Application Client 和 Application Service 都会注册到 Eureka Server 上，Application Client 会调用 Application Service 。当服务正常时，Application Client 会优先调用相同 us-east-1c 下的 Application Service ，当 us-east-1c 下的 Application Service 下线，Application Client 会调用 us-east-1d 和 us-east-1e 中的 Application Service 。<br>配置文件比之前多了 Region 和 Zone 的信息。<br>eureka-server-01</p>
<pre><code>server:
  port: 8761
spring:
  application:
    name: eureka-server-01
eureka:
  instance:
    hostname: ${spring.application.name}
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
    lease-renewal-interval-in-seconds: 1 #心跳间隔
    lease-expiration-duration-in-seconds: 3 #3秒没收到心跳就失效
    metadata-map:
      zone: us-east-1c #服务属于哪个zone
  client:
    region: us-east-1
    availability-zones:
      us-east-1: us-east-1c,us-east-1d,us-east-1e #将自己的zone写在前边
    serviceUrl:
      us-east-1c: http://eureka-server-01:8761/eureka/
      us-east-1d: http://eureka-server-02:8762/eureka/
      us-east-1e: http://eureka-server-03:8763/eureka/
    prefer-same-zone-eureka: true #优先使用相同zone的服务
  server:
    enable-self-preservation: false
    eviction-interval-timer-in-ms: 1000 #剔除时间间隔
</code></pre><p>eureka-server-02</p>
<pre><code>server:
  port: 8762
spring:
  application:
    name: eureka-server-02
eureka:
  instance:
    hostname: ${spring.application.name}
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
    lease-renewal-interval-in-seconds: 1 #心跳间隔
    lease-expiration-duration-in-seconds: 3 #3秒没收到心跳就失效
    metadata-map:
      zone: us-east-1d #服务属于哪个zone
  client:
    region: us-east-1
    availability-zones:
      us-east-1: us-east-1d,us-east-1c,us-east-1e #将自己的zone写在前边
    serviceUrl:
      us-east-1c: http://eureka-server-01:8761/eureka/
      us-east-1d: http://eureka-server-02:8762/eureka/
      us-east-1e: http://eureka-server-03:8763/eureka/
    prefer-same-zone-eureka: true #优先使用相同zone的服务
  server:
    enable-self-preservation: false
    eviction-interval-timer-in-ms: 1000 #剔除时间间隔
</code></pre><p>eureka-server-03</p>
<pre><code>server:
  port: 8763
spring:
  application:
    name: eureka-server-03
eureka:
  instance:
    hostname: ${spring.application.name}
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
    lease-renewal-interval-in-seconds: 1 #心跳间隔
    lease-expiration-duration-in-seconds: 3 #3秒没收到心跳就失效
    metadata-map:
      zone: us-east-1e #服务属于哪个zone
  client:
    region: us-east-1
    availability-zones:
      us-east-1: us-east-1e,us-east-1c,us-east-1d #将自己的zone写在前边
    serviceUrl:
      us-east-1c: http://eureka-server-01:8761/eureka/
      us-east-1d: http://eureka-server-02:8762/eureka/
      us-east-1e: http://eureka-server-03:8763/eureka/
    prefer-same-zone-eureka: true #优先使用相同zone的服务
  server:
    enable-self-preservation: false
    eviction-interval-timer-in-ms: 1000 #剔除时间间隔
</code></pre><p>application-service-01</p>
<pre><code>server:
  port: 10003
spring:
  application:
    name: application-service
eureka:
  instance:
    prefer-ip-address: true
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
    lease-renewal-interval-in-seconds: 1 #心跳间隔
    lease-expiration-duration-in-seconds: 3 #3秒没收到心跳就剔除服务
    metadata-map:
      zone: us-east-1c #服务属于哪个zone
  client:
    region: us-east-1
    availability-zones:
      us-east-1: us-east-1c,us-east-1d,us-east-1e #将自己的zone写在前边
    serviceUrl:
      us-east-1c: http://eureka-server-01:8761/eureka/
      us-east-1d: http://eureka-server-02:8762/eureka/
      us-east-1e: http://eureka-server-03:8763/eureka/
    prefer-same-zone-eureka: true #优先使用相同zone的服务
</code></pre><p>application-service-02</p>
<pre><code>server:
  port: 10004
spring:
  application:
    name: application-service
eureka:
  instance:
    prefer-ip-address: true
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
    lease-renewal-interval-in-seconds: 1 #心跳间隔
    lease-expiration-duration-in-seconds: 3 #3秒没收到心跳就剔除服务
    metadata-map:
      zone: us-east-1d #服务属于哪个zone
  client:
    region: us-east-1
    availability-zones:
      us-east-1: us-east-1d,us-east-1c,us-east-1e #将自己的zone写在前边
    serviceUrl:
      us-east-1c: http://eureka-server-01:8761/eureka/
      us-east-1d: http://eureka-server-02:8762/eureka/
      us-east-1e: http://eureka-server-03:8763/eureka/
    prefer-same-zone-eureka: true #优先使用相同zone的服务
</code></pre><p>application-service-03</p>
<pre><code>server:
  port: 10005
spring:
  application:
    name: application-service
eureka:
  instance:
    prefer-ip-address: true
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
    lease-renewal-interval-in-seconds: 1 #心跳间隔
    lease-expiration-duration-in-seconds: 3 #3秒没收到心跳就剔除服务
    metadata-map:
      zone: us-east-1e #服务属于哪个zone
  client:
    region: us-east-1
    availability-zones:
      us-east-1: us-east-1e,us-east-1c,us-east-1d #将自己的zone写在前边
    serviceUrl:
      us-east-1c: http://eureka-server-01:8761/eureka/
      us-east-1d: http://eureka-server-02:8762/eureka/
      us-east-1e: http://eureka-server-03:8763/eureka/
    prefer-same-zone-eureka: true #优先使用相同zone的服务
</code></pre><p>application-client-01</p>
<pre><code>server:
  port: 8081
spring:
  application:
    name: application-client
eureka:
  instance:
    prefer-ip-address: true
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
    lease-renewal-interval-in-seconds: 1 #心跳间隔
    lease-expiration-duration-in-seconds: 3 #3秒没收到心跳就剔除服务
    metadata-map:
      zone: us-east-1c #服务属于哪个zone
  client:
    region: us-east-1
    availability-zones:
      us-east-1: us-east-1c,us-east-1d,us-east-1e #将自己的zone写在前边
    serviceUrl:
      us-east-1c: http://eureka-server-01:8761/eureka/
      us-east-1d: http://eureka-server-02:8762/eureka/
      us-east-1e: http://eureka-server-03:8763/eureka/
    prefer-same-zone-eureka: true #优先使用相同zone的服务
</code></pre><p>通过 metadata-map.zone 标识服务属于哪个 Zone ，<code>prefer-same-zone-eureka: true</code> 会优先调用相同 Zone 的服务。availability-zones 的 Zone 列表应优先将自己 Zone 写在前边，因为 Eureka 在查找服务时是按顺序找的。</p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Building Eureka Server with Peer Awareness]]></title>
      <url>/2020/03/22/building-eureka-server-with-peer-awareness/</url>
      <content type="html"><![CDATA[<p>构建一个 Eureka Server Standalone 非常简单，可以参考 <a href="../../../../2018/06/16/service-registration-and-discovery/">Service Registration and Discovery</a> 。<br>Eureka Server 也支持部署多个节点，步骤和单节点类似，只是配置文件略有修改。如果我们有 3 个对等的节点，配置文件是这样的：<br>eureka01</p>
<pre><code>server:
  port: 8761
spring:
  application:
    name: eureka01
eureka:
  instance:
    prefer-ip-address: true
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
  client:
    serviceUrl:
      defaultZone: http://eureka01:8761/eureka/,http://eureka02:8762/eureka/,http://eureka03:8763/eureka/
  server:
    enable-self-preservation: false
</code></pre><p>eureka02</p>
<pre><code>server:
  port: 8762
spring:
  application:
    name: eureka02
eureka:
  instance:
    prefer-ip-address: true
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
  client:
    serviceUrl:
      defaultZone: http://eureka01:8761/eureka/,http://eureka02:8762/eureka/,http://eureka03:8763/eureka/
</code></pre><p>eureka03</p>
<pre><code>server:
  port: 8763
spring:
  application:
    name: eureka03
eureka:
  instance:
    prefer-ip-address: true
    instance-id: ${spring.cloud.client.ip-address}:${server.port}
  client:
    serviceUrl:
      defaultZone: http://eureka01:8761/eureka/,http://eureka02:8762/eureka/,http://eureka03:8763/eureka/
</code></pre><p>Eureka Server 之间是对等的，所以可以将自己作为 Client 注册到其他的 Eureka Server 上，defaultZone 可以不用区分，启动的时候会过滤掉自己。</p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL Log]]></title>
      <url>/2020/03/21/mysql-log/</url>
      <content type="html"><![CDATA[<h4 id="Bin-Log"><a href="#Bin-Log" class="headerlink" title="Bin Log"></a>Bin Log</h4><p>Bin Log 是 MySQL Server 层的一种日志，用来保存数据库的更改（表的更改和数据的更改）事件。Bin Log 不会记录 select 操作。Bin Log 的作用主要用来做复制。<br>Bin Log 有 3 种格式：</p>
<ol>
<li>statement ，记录每一条会修改数据的 sql 。日志量少，但是需要额外保存 sql 执行时的信息。</li>
<li>row ，记录修改的记录。日志量大，每一行数据的修改都会保存。</li>
<li>mixed 。</li>
</ol>
<p>可以通过命令查看 MySQL 的 Bin Log 格式：</p>
<pre><code>mysql&gt; show global variables like &#39;%binlog_format&#39;;
+---------------+-------+
| Variable_name | Value |
+---------------+-------+
| binlog_format | ROW   |
+---------------+-------+
</code></pre><p>Bin Log 为什么不合适做异常恢复？<br>Bin Log 是通过 Bin Log 文件来恢复数据，这些数据是持久化到磁盘的，而异常掉电时，内存中的数据是没有写到磁盘的，所以内存中的这些数据是无法通过 Bin Log 来恢复的，会造成数据丢失。<br>Redo Log 记录的是内存中还没有写到磁盘的数据，所以 Redo Log 用来做异常恢复不会造成内存中的数据丢失。</p>
<h4 id="Redo-Log"><a href="#Redo-Log" class="headerlink" title="Redo Log"></a>Redo Log</h4><p>Redo Log 是一种基于磁盘的数据结构，用来保证崩溃恢复期间未提交事务数据的正确性。Redo Log 包括两部分：Redo Log Buffer 和 Redo Log File 。事务日志先写到 Redo Log Buffer ，再刷到 Redo Log File 。有 3 种方式：</p>
<ol>
<li>每次提交都会将 Redo Log Buffer 中的数据写到 OS Buffer 并写入 Redo Log File 。默认。</li>
<li>每次提交日志会写入 Redo Log Buffer，每秒从 Redo Log Buffer 刷到 OS Buffer 并写入 Redo Log File 。</li>
<li>每次提交日志会写入 OS Buffer ，每秒从 OS Buffer 写入 Redo Log File 。</li>
</ol>
<p>Redo Log 是以 block 为存储单位，包括 block header ，block tailer 和 block body 。</p>
<p>Redo Log 和 Bin Log 的区别</p>
<ol>
<li>Bin Log 是 Server 层的日志，Redo Log 是 InnoDb 引擎的日志。</li>
<li>Bin Log 是逻辑日志，Redo Log 是物理日志。</li>
<li>Bin Log 是每次提交写入，Redo Log 是先写入 Redo Log Buffer ，然后再写入。</li>
<li>Bin Log 是追加写，Redo Log 是循环写。</li>
</ol>
<h4 id="Undo-Log"><a href="#Undo-Log" class="headerlink" title="Undo Log"></a>Undo Log</h4><p>Undo Log 是 Undo Log Record 的集合。Undo Log Record 包含事务回滚到最近一次修改的信息。每个事务有独立的 Undo Log 。Undo Log 存在于 Undo Log Segment ，Undo Log Segment 存在于 rollback segments 。<br>当事务提交时，Undo Log 不会立刻删除，会放在删除列表中，通过 purge 删除。<br>MySQL 利用 Undo Log 和 MVCC 来实现 RC 和 RR 隔离级别。</p>
]]></content>
      
        <categories>
            
            <category> MySQL </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MVCC]]></title>
      <url>/2020/03/19/mvcc/</url>
      <content type="html"><![CDATA[<p>数据库有 4 种隔离级别，RU 、RC 、RR 和 Serializable ，MySQL 默认为 Repeatable Read 。t1 表有两条记录，如果有两个事务并发操作 t1 表如下： </p>
<p><img src="http://bsyonline.gitee.io/pic/20200502/20200929221226.png" alt="20200929221405" border="0" style="width:500px"></p>
<p>Client1 开启事务，将记录 2 的 name 修改为 C 。Client2 也开启事务，查询 t1 。不管 Client1 的事务是否提交，Client2 查询的结果和 Client1 开启事务之前是相同的，等 Client2 提交之后才能看到 Client1 修改的内容。<br>如果将 MySQL 的隔离级别改成 Read Commited ，效果又会有不同。<br><img src="http://bsyonline.gitee.io/pic/20200502/20200929221405.png" alt="20200929221405" border="0" style="width:500px"></p>
<p>这就是不可重复读的现象。</p>
<p>为什么当数据库的隔离级别为 RC 时，会出现不可重复读，通过修改隔离级别为 RR ，可以避免不可重复读呢？答案是因为在 MySQL 中，RC 和 RR 隔离级别是通过 MVCC 实现的。MVCC (Multi-Version Concurrency Control) 是 InnoDB 使用的一种并发控制协议，作用于 RC RR 两个级别。</p>
<h4 id="MVCC-的作用"><a href="#MVCC-的作用" class="headerlink" title="MVCC 的作用"></a>MVCC 的作用</h4><p>你一定想问，MVCC 有什么用呢？我们知道如果要实现并发，第一个想到的就是加锁。如果加锁，那么当 Client1 开启了事务，Client2 就无法获得锁，就会阻塞，这样性能就会很差。MVCC 并不会加锁，而是允许 Client2 在 Client1 事务期间依旧是可读的，这样就提高了读写的并发度。</p>
<h4 id="MVCC-是如何实现的"><a href="#MVCC-是如何实现的" class="headerlink" title="MVCC 是如何实现的"></a>MVCC 是如何实现的</h4><p>对于 t1 表，我们看到的是这样的：</p>
<pre><code>mysql&gt; desc t1;
+-------+-------------+------+-----+---------+-------+
| Field | Type        | Null | Key | Default | Extra |
+-------+-------------+------+-----+---------+-------+
| id    | int(4)      | NO   | PRI | NULL    |       |
| name  | varchar(10) | YES  |     | NULL    |       |
+-------+-------------+------+-----+---------+-------+
</code></pre><p>实际在 MySQL 中的样子这样的：</p>
<p><img src="https://s1.ax1x.com/2020/03/20/86OpNR.png" alt="20200320100637" border="0" style="width:500px"></p>
<p>MySQL 会增加 3 个隐藏列：</p>
<ol>
<li>DB_TRX_ID：表示插入或更新的的最后一个事务 id 。</li>
<li>DB_ROLL_PTR：回滚指针，指向 Undo Log 的记录。</li>
<li>DB_ROW_ID：行 id ，单调递增。</li>
</ol>
<p>每次开启事务，都会生成对应的 Undo Log 。在事务中做的任何修改都会在 Undo Log 中保存下来，类似链表。然后在 select 的时候会生成对应查询视图 ReadView 。<strong>ReadView 由当前未提交的事务 id 列表和最大事务 id 组成</strong>。用 select 的结果的 DB_TRX_ID 和 ReadView 比较来判断事务的状态，从而确定返回的结果集。比较规则如下：</p>
<ol>
<li>当 DB_TRX_ID 小于 ReadView 的最小 ID ，则说明事务已经提交，则数据是可见的。</li>
<li>当 DB_TRX_ID 大于等于 ReadView 的最小 ID 小于等于 ReadView 的最大 ID 时，<br> 2.1) 如果 DB_TRX_ID 等于当前的 DB_TRX_ID ，说明是自己的事务，则数据可见。<br> 2.2) 如果 DB_TRX_ID 在 ReadView 的未完成事务列表中，说明事务未提交，则数据不可见。如果不在，则说明事务已提交，数据可见。</li>
</ol>
<p><strong>在 RR 隔离级别下，ReadView 会延用事务第一次生成的 ReadView ，而 RC 隔离级别下，每次查询会生成新的 ReadView </strong>。<br>有了上边的概念，我们来分析一下前边的例子，假设 t1 表中有 2 条记录，是由 DB_TRX_ID=100 的事务插入的，事务已经提交。</p>
<p><img src="http://bsyonline.gitee.io/pic/20200502/20200929230446.png" alt="20200929230446" border="0" style="width:500px"></p>
<h5 id="首先看-RR-级别："><a href="#首先看-RR-级别：" class="headerlink" title="首先看 RR 级别："></a>首先看 RR 级别：</h5><p>&ensp;&ensp;1)  Client1 开启了事务，假设它的 DB_TRX_ID=200 。Client1 修改了 id=12 的 name 为 C ，MySQL 会将 id=12 这条记录拷贝到 Undo Log 中，然后将 DB_ROLL_PTR 指向 Undo Log 中的这条记录，然后将 name 修改成 C ，这样就形成一个版本链。</p>
<p><img src="http://bsyonline.gitee.io/pic/20200502/20200929230614.png" alt="20200929230446" border="0" style="width:700px"></p>
<p>&ensp;&ensp;2)  当 Client1 查询时，会生成查询视图 ReadView([200],200) 。id=11 这条记录的 DB_TRX_ID=100 ，小于最小的未提交 DB_TRX_ID ，所以 id=11 这条记录是可见的。id=12 这条记录的 DB_TRX_ID=200 ，等于最大的未提交 DB_TRX_ID 说明是自己的事务，所以也是可见的。所以查到的结果就是 A 和 C 。<br>&ensp;&ensp;3)  当 Client2 开启了事务，假设它的 DB_TRX_ID=300 ，生成对应的查询视图 ReadView([200],300) 。Client2 执行查询时，id=11 这条记录的 DB_TRX_ID=100 ，小于最小的未提交 DB_TRX_ID ，所以 id=11 这条记录是可见的。id=12 这条记录的 DB_TRX_ID=200 ，在未提交列表中，所以需要去 Undo Log 中找历史版本 DB_TRX_ID=100 ，最终查到的结果是 A 和 B 。<br>&ensp;&ensp;4)  当 Client1 提交后，Client2 再次查询，ReadView 还是 ([200],300) ，所以查到的结果还是 A 和 B 。</p>
<h5 id="与此类似，我们再来看看-RC-级别："><a href="#与此类似，我们再来看看-RC-级别：" class="headerlink" title="与此类似，我们再来看看 RC 级别："></a>与此类似，我们再来看看 RC 级别：</h5><p>&ensp;&ensp;1) 、 2） 、3）和上边是相同的。<br>&ensp;&ensp;4)  当 Client1 提交后，Client2 再次查询，此时 ReadView 是新生成的 ([300],300) ，DB_TRX_ID=200 已经提交，所以 C 是可见的，最终查到的结果是 A 和 C 。</p>
<blockquote>
<p>MVCC 只作用于 RC 和 RR ，那 RU 和 Serializable 是如何实现的？<br>RU 每次都读最新记录。<br>Serializable 通过互斥锁。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[One Question One Answer for Redis]]></title>
      <url>/2020/03/17/one-question-one-answer-for-redis/</url>
      <content type="html"><![CDATA[<p>Q: Redis 有哪些数据类型，及应用场景。<br>A: 数据类型有 8 种：</p>
<ol>
<li><p>string，简单的 KV 缓存，比如单值缓存，再比如文章的阅读量。</p>
<pre><code>127.0.0.1:6379&gt; incr article:view:19 
127.0.0.1:6379&gt; incr article:view:19 
127.0.0.1:6379&gt; incr article:view:19
127.0.0.1:6379&gt; get article:view:19 
&quot;3&quot;
</code></pre></li>
<li><p>list，list 使用场景很多，可以存储列表类型的数据，比如消息列表。</p>
<pre><code>127.0.0.1:6379&gt; lpush 12:msg 101
127.0.0.1:6379&gt; lpush 12:msg 104
127.0.0.1:6379&gt; lrange 12:msg 0 5
1) &quot;104&quot;
2) &quot;101&quot;
</code></pre><p>再比如查询历史。</p>
<pre><code>127.0.0.1:6379&gt; lpush history &quot;select * from user where id=1&quot;
127.0.0.1:6379&gt; lpush history &quot;select * from dept where dept_name=&#39;sales&#39;&quot;
127.0.0.1:6379&gt; lrange history 0 5
1) &quot;select * from dept where dept_name=&#39;sales&#39;&quot;
2) &quot;select * from user where id=1&quot;
</code></pre><p>可以用来分页。</p>
<pre><code>127.0.0.1:6379&gt; lrange list 0 9
</code></pre><p>可以用来实现队列： lpush + rpop 。实现栈：lpush + lpop 。</p>
</li>
<li><p>set，应用场景需要没有重复的元素，比如将歌曲从歌曲库加到我喜欢的歌曲列表。</p>
<pre><code>127.0.0.1:6379&gt; smove songs my_favourite &quot;yestoday once more&quot;
(integer) 1
</code></pre><p>再比如抽奖</p>
<pre><code>127.0.0.1:6379&gt; srandmember lottery_draw 1    #不移除
or
127.0.0.1:6379&gt; spop lottery_draw 1           #移除
</code></pre><p>再比如点赞</p>
<pre><code>127.0.0.1:6379&gt; sadd like:123 19         #点赞
127.0.0.1:6379&gt; srem like:123 19         #取消点赞
127.0.0.1:6379&gt; sismember like:123 19    #是否点过赞
127.0.0.1:6379&gt; smembers like:123        #点赞用户列表
127.0.0.1:6379&gt; scard like:123           #点赞数
</code></pre><p>再比如关注</p>
<pre><code>127.0.0.1:6379&gt; sadd tom:follow 101 102 199 
127.0.0.1:6379&gt; sadd alice:follow 102 103 199 
127.0.0.1:6379&gt; sinter tom:follow alice:follow       #tom和alice共同关注
1) &quot;102&quot;
2) &quot;199&quot;
127.0.0.1:6379&gt; sdiff alice:follow tom:follow        #alice还关注了哪些人
1) &quot;103&quot;
</code></pre></li>
<li><p>zset，无重复且有序。比如排行榜。</p>
<pre><code>127.0.0.1:6379&gt; zincrby music:month:1:week:1 1 &quot;yestoday once more&quot;
127.0.0.1:6379&gt; zincrby music:month:1:week:1 1 &quot;yestoday once more&quot;
127.0.0.1:6379&gt; zincrby music:month:1:week:1 1 &quot;hotel california&quot;
127.0.0.1:6379&gt; zrevrange music:month:1:week:1 0 9 withscores     #周排行
1) &quot;yestoday once more&quot;
2) &quot;2&quot;
3) &quot;hotel california&quot;
4) &quot;1&quot;
127.0.0.1:6379&gt; zincrby music:month:1:week:2 1 &quot;yestoday once more&quot;
127.0.0.1:6379&gt; zincrby music:month:1:week:3 1 &quot;hotel california&quot;
127.0.0.1:6379&gt; zincrby music:month:1:week:4 1 &quot;hotel california&quot;
127.0.0.1:6379&gt; zunionstore music:month:1 4 music:month:1:week:1 music:month:1:week:2 music:month:1:week:3 music:month:1:week:4 
127.0.0.1:6379&gt; zrevrange music:month:1 0 9 withscores    #月排行
1) &quot;yestoday once more&quot;
2) &quot;8&quot;
3) &quot;hotel california&quot;
4) &quot;5&quot;
</code></pre></li>
<li><p>hash，可以用来存储简单对象。比如数据库表 user 是这样的：<br>| id   | name  | age  |<br>| —- | —– | —- |<br>| 1    | Tom   | 20   |<br>| 2    | Alice | 19   |<br>用 redis hash 可以这样表示：</p>
<pre><code class="shell">127.0.0.1:6379&gt; hmset user 1:name Tome 1:age 20
127.0.0.1:6379&gt; hmset user 2:name Alice 2:age 19
127.0.0.1:6379&gt; hmget user 1:name 1:age
1) &quot;Tome&quot;
2) &quot;20&quot;
</code></pre>
<p>如果表记录很多，可以进行分段，防止 big value 导致执行缓慢。<br>再比如购物车，</p>
<pre><code># 用户 id 为 12 商品 id 为 1099
127.0.0.1:6379&gt; hset cart:12 1099 1         #添加商品
127.0.0.1:6379&gt; hincrby cart:12 1099 1      #增加数量
127.0.0.1:6379&gt; hlen cart:12                #购物车中商品种类数量
127.0.0.1:6379&gt; hdel cart:12 1099           #删除商品
127.0.0.1:6379&gt; hgetall cart:12             #购物车中全部商品
</code></pre></li>
<li><p>bitmap，可以用来实现 bloomfilter 。</p>
</li>
<li><p>hyperloglog，可以用来进行大数据量统计，比如 UV 。但是不精确。</p>
</li>
<li><p>geo，可以用来进行地理信息计算。</p>
</li>
</ol>
<p>还有一些功能也列一下：</p>
<ol>
<li>pub/sub，可以用来实现消息队列。</li>
<li>lua，利用它的原子性。</li>
<li>Pipeline，一次提交多条命令，一次返回多个结果，减少交互次数。</li>
<li>transaction，使用 multi ，exec ， discard 和 watch 实现。弱事务，可以保证全部执行，单不能同时成功，失败了不会回滚。</li>
</ol>
<p>Q: Redis 底层数据结构有哪些？<br>A: 可变字节数组 (simple dynamic string, SDS) ，链表 (list) ，双哈希表 (dict) ，跳跃表 (zskiplist) ，intset ，ziplist ，quicklist ，zipmap 。</p>
<p>Q: Redis 为什么快？<br>A:  </p>
<ol>
<li>单进程单线程模型，没有上下文切换。</li>
<li>使用多路复用无阻塞 I/O 模型。</li>
<li>内存计算。</li>
<li>数据结构简单，查找和操作的时间复杂度都是 O(1) 。</li>
</ol>
<p>Q: Redis 是怎么样持久化的？<br>A: Redis 有两种持久化方式：</p>
<ol>
<li>RDB，全量镜像方式，通过 fork 和 copy on write 方式实现，备份时间长，恢复速度快，可以分成多个文件存储，时间间隔长。</li>
<li>AOF，增量日志方式，对每条命令都生成日志，以 append-on 方式写文件，写入速度快，数据量大，频率高。</li>
</ol>
<p>Q: Redis 的高可用是怎么做的？<br>A: 通过哨兵模式，只少 3 个节点，如果 master 挂了，slave 会被提升为 master 。哨兵模式只能保证高可用，不能保证数据不丢。</p>
<p>Q: Redis 主从之间是如何进行数据同步的？<br>A: 如果新加一个 slave 节点到集群，master 会生成一个 RDB 的镜像快照，将 RDB 发给 slave ，slave 将 RDB 保存到本地，然后加载到内存。如果在数据同步期间有增量数据，等 slave 通过 RDB 恢复了再把增量的部分发给 slave 。如果网络断了，会自动重连，网络恢复之后会重发。</p>
<p>Q: 哨兵模式 master 挂了如何进行选主？<br>A: 先看优先级，优先级相同，看复制偏移量，及数据完整性，偏移量相同，取 id 最小的。</p>
<p>Q: Redis key 的过期的 key 是怎么删除的？<br>A: 如果 redis 中的 key 过期了，就会返回 nil 。但是这个 key 并没有被立刻删除。Redis 的失效的 key 的删除策略有 2 种：</p>
<ol>
<li>被动删除(passive)：当再次访问这个 key 时发现它已经过期，则删除。</li>
<li>主动删除(active)：有些 key 失效之后可能再也不会被访问，所以无法被动删除，只能主动删除。Redis 会从过期的集合中随机挑一些 key 删除，如果失效 key 大于 25% ，主动删除会一直进行。如果还删不掉，就只能等 LRU 了。</li>
</ol>
<p>Q: 内存淘汰策略是怎样的？<br>A: noeviction，allkeys-LRU，volatile-LRU，allkeys-Random，volatile-Random，volatile-ttl 。</p>
<p>Q: 主从模式，哨兵模式，集群模式的区别。<br>A: 主从是备份关系，如果主挂了，从可以接替主继续工作，但是切换需要人工。哨兵是在主挂了之后由程序自动将从提成主，保证高可用，哨兵最少 3 台。集群是将数据自动分配到 hash slot 中，多台机器同时工作，提高并发，集群最少 6 台，3 主 3 从。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Proxy Pattern]]></title>
      <url>/2020/03/14/proxy-pattern/</url>
      <content type="html"><![CDATA[<p>代理模式属于结构模式。代理模式的作用是可以在调用 target 时扩展 target 的功能。</p>
<h4 id="静态代理"><a href="#静态代理" class="headerlink" title="静态代理"></a>静态代理</h4><p>有一个接口 Image 及它的实现。</p>
<pre><code>public interface Image {
    void display();
}

public class JPEGImage implements Image {
    String imageFilePath;

    public JPEGImage(String imageFilePath) {
        this.imageFilePath = imageFilePath;
    }

    @Override
    public void display() {
        System.out.println(&quot;display image&quot; + imageFilePath);
    }
}
</code></pre><p>我们可以在通过代理 JPEGImage 在调用 display() 的时候扩展一些功能。</p>
<pre><code>public class ImageProxy implements Image {

    private JPEGImage target;

    public ImageProxy(String imageFilePath) {
        this.target = new JPEGImage(imageFilePath);
    }

    @Override
    public void display() {
        System.out.println(&quot;proxy start&quot;);
        target.display();
        System.out.println(&quot;proxy end&quot;);
    }
}

public class ImageViewer {
    public static void main(String[] args) {
        ImageProxy imageProxy1 = new ImageProxy(&quot;sample/photo1.jpeg&quot;);
        imageProxy1.display();
    }
}
</code></pre><p><img src="https://s1.ax1x.com/2020/03/14/8QEoid.png" alt="static proxy" border="0" style="width:200px"><br>静态代理的缺点是，一个对象对应有一个代理对象，如果对象很多，对应和代理对象也就有很多。</p>
<h4 id="动态代理"><a href="#动态代理" class="headerlink" title="动态代理"></a>动态代理</h4><p>动态代理分为 jdk 动态代理和 cglib 代理。</p>
<h5 id="jdk-动态代理"><a href="#jdk-动态代理" class="headerlink" title="jdk 动态代理"></a>jdk 动态代理</h5><p>jdk 动态代理利用 Java 反射通过 InvocationHandler 实现。</p>
<pre><code>public class ImageProxy {

    Image target;

    public ImageProxy(Image target) {
        this.target = target;
    }

    public Object getProxyInstance() {
        return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), new InvocationHandler() {
            @Override
            public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
                System.out.println(&quot;proxy start&quot;);
                Object obj = method.invoke(target, args);
                System.out.println(&quot;proxy end&quot;);
                return obj;
            }
        });
    }
}

public class ImageViewer {
    public static void main(String[] args) {
        Image jpegImage1 = new PNGImage(&quot;sample/photo1.png&quot;);
        Image imageProxy1 = (Image) new ImageProxy(jpegImage1).getProxyInstance();
        imageProxy1.display();
    }
}
</code></pre><p><img src="https://s1.ax1x.com/2020/03/14/8QE4de.png" alt="dynamic proxy" border="0" style="width:300px"><br>jdk 动态代理特点：需要实现接口，通过 Java 反射实现。</p>
<h5 id="cglib-代理"><a href="#cglib-代理" class="headerlink" title="cglib 代理"></a>cglib 代理</h5><p>加入 cglib 依赖。</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;cglib&lt;/groupId&gt;
    &lt;artifactId&gt;cglib&lt;/artifactId&gt;
    &lt;version&gt;3.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><pre><code>public class ImageProxy implements MethodInterceptor {

    GIFImage target;

    public ImageProxy(GIFImage target) {
        this.target = target;
    }

    public Object getProxyInstance() {
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(target.getClass());
        enhancer.setCallback(this);
        return enhancer.create(new Class[]{String.class}, new Object[]{target.imageFilePath});
    }

    @Override
    public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable {
        System.out.println(&quot;proxy start&quot;);
        Object obj = methodProxy.invokeSuper(o, args);
        System.out.println(&quot;proxy end&quot;);
        return obj;
    }
}
</code></pre><p><img src="https://s1.ax1x.com/2020/03/14/8Q3RyQ.png" alt="8Q3RyQ.png" border="0" style="width:500px"><br>cglib 特点：不需要接口，利用继承，被代理的类和方法不能是 final ，利用字节码技术 asm 实现。</p>
]]></content>
      
        <categories>
            
            <category> Design Pattern </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Cache]]></title>
      <url>/2020/03/11/cache/</url>
      <content type="html"><![CDATA[<h4 id="哪些地方可以使用缓存？"><a href="#哪些地方可以使用缓存？" class="headerlink" title="哪些地方可以使用缓存？"></a>哪些地方可以使用缓存？</h4><ol>
<li>数据库缓存<br>在数据库内部也是支持缓存的，比如 MySQL 。不过这种方式并不是太好，首先缓存涉及到更新，会消耗数据库的性能，另一方面，查询是按照 sql 语句作为 key ，缓存的命中率不高，也失去了缓存的意义，所以在 MySQL5.7.20 之后就弃用缓存了。</li>
<li>本地缓存<br>本地缓存是速度非常快的，可以利用一些本地缓存技术实现，如 Caffeine，GuavaCache，EhCache 等，也可以结合一些 ORM 框架使用 。但是本地缓存只能单机使用，多台机器之间不能共享。在某些场景下会有缓存不一致的问题，比如 <a href="../../../../2020/02/01/mybatis-cache/">MyBitas 的二级缓存</a>。</li>
<li>分布式缓存<br>分布式缓存是用的最多的一种方案，利用独立的中间件来缓存数据，和应用程序以及数据库都是独立的。常用的技术有 redis ，Memcached 。</li>
<li>Nginx 缓存<br>Nginx 可以缓存用户请求过的 url 对应的 response 响应，当用户再次请求，可以直接返回缓存内容。</li>
<li>页面缓存<br>比如静态化，ajax 等。</li>
</ol>
<h4 id="缓存更新的方式"><a href="#缓存更新的方式" class="headerlink" title="缓存更新的方式"></a>缓存更新的方式</h4><ol>
<li>Cache Aside ，同时更新缓存和数据库。<br>应用程序先从 cache 取数据，没有得到，则从数据库中取数据，成功后放到缓存中。如果需要更新数据，先更新数据库，成功后再让缓存失效。简单，但是同时操作 cache 和数据库，可能会有数据不一致。推荐先操作数据库，再删除缓存。</li>
<li>Read/Write Through ，先更新缓存，缓存负责同步更新数据库。<br>只操作缓存，但是实现比较复杂。</li>
<li>Write Behind Caching ，先更新缓存，缓存定时异步更新数据库。<br>异步操作，可能会造成数据丢失。</li>
</ol>
<h4 id="缓存常见问题"><a href="#缓存常见问题" class="headerlink" title="缓存常见问题"></a>缓存常见问题</h4><ol>
<li>缓存击穿<br>热点 key 失效后，大量的请求查询热点 key，导致数据库压力增大。</li>
<li>缓存穿透<br>查询一个不存在的 key ，导致总会查询数据库。</li>
<li>缓存雪崩<br>大量缓存设置了相同的失效时间，同一时间失效。</li>
</ol>
<p>解决缓存问题的方案有很多种，可以综合使用：</p>
<ol>
<li>随机设置缓存失效时间。</li>
<li>热点 key 永久不失效。</li>
<li>使用锁，保证并发时只有获得锁的请求可以访问数据库并重建缓存。</li>
<li>使用分段锁，保证不会有大量的线程阻塞。</li>
<li>缓存没查询到时返回默认提示。</li>
<li>查询备份缓存。 </li>
</ol>
]]></content>
      
        <categories>
            
            <category> Architecture </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Understanding happens-before]]></title>
      <url>/2020/03/10/happens-before/</url>
      <content type="html"><![CDATA[<p>在学习 java.util.concurrent 的过程中，经常看到一个词就是 happens-before 。happens-before 表示了两个操作之间的顺序关系， A happens-before B 就是说 A 在 B 之前执行，则 A 的执行结果对 B 是可见的。为了方便 A happens-before B 可以用 hb(A,B) 表示。</p>
<h5 id="为什么需要-happens-before"><a href="#为什么需要-happens-before" class="headerlink" title="为什么需要 happens-before"></a><strong>为什么需要 happens-before</strong></h5><p>了解过 JMM 模型都知道，线程在操作主内存中的变量时并不会直接在主内存中修改，而是将主内存中的数据拷贝到自己的工作内存，在多线程环境下就会面临可见性的问题。还有就是我们的代码在编译的时候编译器会对代码进行指令优化，有可能改变指令的顺序，从而导致结果和预期不一致。这些问题是非常复杂的，并且没有办法枚举出每一种情况，面对这样的情况，于是提出了一些通用的规则，这就是 happens-before 。</p>
<h5 id="happens-before-规则"><a href="#happens-before-规则" class="headerlink" title=" happens-before 规则"></a><strong> happens-before 规则</strong></h5><ol>
<li>如果线程 t1 对 A 解锁之后，线程 t2 又对 A 加锁，那么 t1 对 A 的操作对 t2 都是可见的。</li>
<li>对于一个 volatile 变量 A ，如果线程 t1 修改了 A 之后，线程 t2 读取了 A ，那么 t1 的修改对 t2 是可见的。</li>
<li>线程的 start() 在其他方法之前执行。</li>
<li>如果线程 t1 成功执行 t1.join() 之后执行线程 t2 那么 t1 中的操作对 t2 都是可见的。</li>
<li>如果线程 t1 执行了两个操作 A 和 B ，那么 A 中的操作对 B 都是可见的。 </li>
<li>happens-before 具有传递性，如果 hb(A,B) , hb(B,C) , 那么可以得到 hb(A,C) 。 </li>
</ol>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Future]]></title>
      <url>/2020/03/09/future/</url>
      <content type="html"><![CDATA[<p>Future 是一个可终止的异步计算接口，它提供了一种异步计算方式。Future 代表了异步计算的结果，当计算没有完成，获取结果会被阻塞，直到计算完成。FutureTask 是 Future 接口的实现，可以接收 Runnable 和 Callable 对象，也可以使用 Executor.submit() 执行。</p>
<pre><code>public class FutureExample {
    public static void main(String[] args) throws ExecutionException, InterruptedException {
        long start = System.currentTimeMillis();
        FutureTask&lt;Integer&gt; f1 = new FutureTask((Callable&lt;Integer&gt;) () -&gt; {
            Thread.sleep(2000);
            return 10;
        });
        FutureTask&lt;Integer&gt; f2 = new FutureTask((Callable&lt;Integer&gt;) () -&gt; {
            Thread.sleep(3000);
            return 20;
        });
        FutureTask&lt;Integer&gt; f3 = new FutureTask((Callable&lt;Integer&gt;) () -&gt; {
            Thread.sleep(5000);
            return 20;
        });
        new Thread(f1).start();
        new Thread(f2).start();        
        new Thread(f3).start();
        foo();
        f3.cancel(true);
        System.out.println(&quot;--&quot;);
        while (!f1.isDone() || !f2.isDone()) {
            System.out.println(&quot;f1&quot; + (f1.isDone() ? &quot;完成，&quot; : &quot;未完成，&quot;) + &quot;f2&quot; + (f2.isDone() ? &quot;完成&quot; : &quot;未完成&quot;));
            Thread.sleep(300);
        }
        System.out.println(&quot;f1&quot; + (f1.isDone() ? &quot;完成，&quot; : &quot;未完成，&quot;) + &quot;f2&quot; + (f2.isDone() ? &quot;完成&quot; : &quot;未完成&quot;));
        int result = f1.get() + f2.get();
        System.out.println(&quot;f3 cancelled state: &quot;+f3.isCancelled());
        System.out.println(&quot;result=&quot; + result + &quot;, costs &quot; + (System.currentTimeMillis() - start) + &quot;ms&quot;);
    }

    static void foo() throws InterruptedException {
        System.out.println(&quot;同步执行foo&quot;);
        Thread.sleep(1000);
        System.out.println(&quot;foo done&quot;);
    }
}
</code></pre><p>执行结果</p>
<pre><code>同步执行foo
foo done
--
f1未完成，f2未完成
f1未完成，f2未完成
f1未完成，f2未完成
f1未完成，f2未完成
f1完成，f2未完成
f1完成，f2未完成
f1完成，f2未完成
f1完成，f2完成
f3 cancelled state: true
result=30, costs 3146ms
</code></pre><p>在上面的例子就是 FutureTask 的用法。主线程执行 foo() ，f1 ，f2 f3 是三个异步任务，执行完成后通过 future.get() 获取直接结果，如果 f1 或 f2 没有执行完，future.get() 会阻塞，直到任务完成。通过 future.isDone() 可以查看任务是否完成。在 f3 任务之前完成之前可以通过 future.cancel() 终止任务，任务完成后则无法终止。<br>接下来我们来分析一下 Future 是如何工作的。<br>首先看看 FutureTask 中定义的属性和构造器。<br><img src="https://s2.ax1x.com/2020/03/09/8Cif4x.png" alt="8Cif4x.png" border="0" style="width:300px"><br>FutureTask 有两个构造器，一个接收 Callable 一个接收 Runnable 。<br><img src="https://s2.ax1x.com/2020/03/09/8Ci58K.png" alt="8Ci58K.png" border="0" style="width:450px"><br>Runnable 最终通过 RunnableAdapter 构造成为 Callable 。<br><img src="https://s2.ax1x.com/2020/03/09/8Ck9W6.png" alt="8Ck9W6.png" border="0" style="width:600px"><br>由于 FutureTask 实现了 Runnable 接口，所以任务启动后首先会执行 run() 方法。在 run() 方法中，任务的初始状态为 NEW ，通过 CAS 将当前线程赋值为 runner 。然后在 run() 方法中执行 callable.call() 。<br><img src="https://s2.ax1x.com/2020/03/09/8CEKsS.png" alt="8CEKsS.png" border="0" style="width:600px"><br>不管是成功还是异常，都会通过 CAS 更新状态，将结果或异常交给 outcome 。<br><img src="https://s2.ax1x.com/2020/03/09/8CE2QK.png" alt="8CE2QK.png" border="0" style="width:600px"><br>再来看如何获取结果。根据状态，如果完成就直接获取结果，如果没有完成，则执行 awaitDone() 。<br><img src="https://s2.ax1x.com/2020/03/10/8CmgtH.png" alt="8CmgtH.png" border="0" style="width:600px"><br>如果一个任务没有执行完，在第一次循环中将构造一个包含当前线程的 WaitNode ，第二次循环将 WaitNode 加入到队列，第三次循环才 park 线程。当任务执行完成后，调用 finishCompletion() 唤醒线程，再重新获取结果。<br>cancel() 操作就比较简单了，更新状态，唤醒线程而已。<br><img src="https://s2.ax1x.com/2020/03/10/8CncrV.png" alt="8CncrV.png" border="0" style="width:600px"></p>
<p>总结一下：FutureTask 实现了 Runnable 接口，在 run() 方法中调用 callable.call() ，将结果保存到 outcome 。通过 get() 获取结果，如果任务没有执行完，则通过自旋将当前线程加入到 waiter 队列的头部，然后 park 线程。等到任务执行完成，通过 finishCompletion() 唤醒 waiter 队列中的线程，再次获取结果。</p>
<blockquote>
<p>我们注意到，在 FutureTask 中声明的 outcome 并没有用 volatile 修饰，那是如何保证在多线程环境下修改了 outcome 立刻对其他线程可见的呢？<br>这实际是利用了 <a href="../../../../2020/03/10/happens-before/">happens-before</a> 规则。通过刚才的分析我们可以知道:</p>
<ol>
<li>state 是 volatile 的。</li>
<li><code>outcome = v</code> happens-before <code>state == NORMAL</code> 。</li>
<li><code>state == NORMAL</code> happens-before <code>get outcome</code> 。</li>
</ol>
<p>所以利用 happens-before 的传递性可以保证 <code>outcome = v</code> happens-before <code>get outcome</code> 。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlockingQueue]]></title>
      <url>/2020/03/07/blockingqueue/</url>
      <content type="html"><![CDATA[<p>BlockingQueue 是 java.util.concurrent 包中的接口，实现了 Collection 和 Queue 接口，提供了 3 类操作。<br>BlockingQueue 操作</p>
<p><table style="font-size:12px;color:#333333;border-width: 1px;border-color: #666666;border-collapse: collapse;"><tr><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;"></th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">Throws exception</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">Special value</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">Blocks</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">Times out</th></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Insert</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;">add(e)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;">offer(e)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;">put(e)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;">offer(e, time, unit)</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Remove</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;">remove()</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;">poll()</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;">take()</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;">poll(time, unit)</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Examine</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;">element()</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;">peek()</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;">not applicable</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;">not applicable</td></tr></table><br>和普通的 queue 相比，BlockingQueue 满时 put 元素和 BlockingQueue 为空时 take 元素都会阻塞。下面我们就以 LinkedBlockingQueue 为例来看看具体实现。<br>首先在 LinkedBlockingQueue 中定义了一些属性。<br><img src="https://s2.ax1x.com/2020/03/07/3jTjvd.png" alt="3jTjvd.png" border="0" style="width:400px"><br>通过这些属性定义，我们大概可以猜到元素在是以 Node 的形式保存在队列中，并且入队和出队操作都会用锁，元素个数也是通过 AtomicInteger 来保存，所以 LinkedBlockingQueue 是一个线程安全的队列。<br>接下来我们主要看看两个 block 操作：</p>
<ol>
<li>put(e)<br><img src="https://s2.ax1x.com/2020/03/07/3jqyM4.png" alt="3jqyM4.png" border="0" style="width:500px"><br>put() 中有 3 处判断:<br>1) 当元素个数小于 capacity 则继续执行，如果等于 capacity 则执行阻塞 notFull 线程。<br>2) 添加完元素之后，如果元素个数小于 capacity 则唤醒 notFull 线程。<br>3) 释放锁之前元素个数为 c+1 ，如果 c==0 那么说明队列中有一个元素，所以唤醒 notEmpty 线程。</li>
<li>take()<br><img src="https://s2.ax1x.com/2020/03/07/3jjU6U.png" alt="3jjU6U.png" border="0" style="width:350px"><br>和 put(e) 类似，take() 方法也是有 2 处判断：<br>1) 当元素个数等于 0 ，则阻塞 notEmpty 线程。<br>2) 当元素个数大于 0 ，则唤醒 notEmpty 线程。<br>3) take 元素个数会减少，在释放锁之前做了 take 操作，所以释放锁之后队列实际是小于 capacity 的，所以唤醒 notFull 线程。</li>
</ol>
<p>总结一下：</p>
<ol>
<li><strong>LinkedBlockingQueue 有两把锁 putLock 和 takeLock ，有两个 condition 条件 notFull 和 notEmpty 。</strong></li>
<li><strong>元素添加或删除操作先获取锁，再操作链表。</strong></li>
<li><strong>如果队列满时阻塞 notFull 线程，反之则唤醒 notFull 线程。</strong></li>
<li><strong>如果队列中没有元素时，阻塞 notEmpty 线程，反之则唤醒 notEmpty 线程。</strong></li>
</ol>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[LockSupport]]></title>
      <url>/2020/03/06/locksupport/</url>
      <content type="html"><![CDATA[<p>在 java.util.concurrent 中大量使用了 LockSuport 来阻塞和唤醒线程。LockSupport 的 park/unpark 都是通过 Unsafe 类来实现的。</p>
<pre><code>// 用于 debug 
public static void park(Object blocker) {
    Thread t = Thread.currentThread();
    setBlocker(t, blocker);
    UNSAFE.park(false, 0L);
    setBlocker(t, null);
}

public static void park() {
    UNSAFE.park(false, 0L);
}

public static void unpark(Thread thread) {
    if (thread != null)
        UNSAFE.unpark(thread);
}
</code></pre><p>LockSupport 有一个 permit 的概念，park 时，permit 置为 0 ，unpark 或 interrupt 时，permit 置为 1 。</p>
<pre><code>public class LockSupportExample {
    public static void main(String[] args) throws InterruptedException {
        Thread t1 = new Thread(() -&gt; {
            LockSupport.park();
            LockSupport.park();
            LockSupport.park();
        });
        t1.start();
        Thread.sleep(3000);
        LockSupport.unpark(t1);
        Thread.sleep(3000);
        Thread.interrupted();
    }
}
</code></pre><p>如果同一个线程调用多次 park() 第一次执行完线程会阻塞，第二次不会执行，直到 unpark() 或 interrupt 之后 permit 恢复，才会执行后续的 park() 。</p>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CountDownLatch]]></title>
      <url>/2020/03/06/countdownlatch/</url>
      <content type="html"><![CDATA[<p>CountDownLatch 是 java.util.concurrent 包中提供的一个倒计时器工具类。基本用法如下：</p>
<pre><code>public class CountDownLatchTest {
    public static void main(String[] args) throws InterruptedException {
        CountDownLatch latch = new CountDownLatch(3);
        for (int i = 0; i &lt; 3; i++) {
            new Thread(() -&gt; {
                System.out.println(Thread.currentThread().getName() + &quot; task done&quot;);
                latch.countDown();
            }, &quot;t&quot; + i).start();
        }
        latch.await();
        System.out.println(&quot;all thread wake up&quot;);
    }
}
</code></pre><p>接下来我们来看看每一步都做了什么。</p>
<ol>
<li>初始化 CountDownLatch 。<pre><code>public CountDownLatch(int count) {
 if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;);
 this.sync = new Sync(count);
}
//
Sync(int count) {
 setState(count);
}
</code></pre>可以看到我们创建的计数 count 通过 setState 保存到 AQS 的 state 中。</li>
<li>await()<br>首先判断 state ，因为是倒计数器，所以是判断 state 是不是等于 0 。如果不为 0 ，将包含主线程信息的 node 节点加入到 AQS 队列，然后再进行循环。第一次循环会再判断一下计数器是否到 0 了，如果还没有到 0 ，说明任务还没有就绪，那就将 node 的 waitStatus 标记为需要 signal 来唤醒。然后进行第二次循环，如果还没有到 0 ，则 park 主线程。</li>
<li>countDown()<br>每执行一次 countDown() 方法，会通过 CAS 将 state-1 ，直到 state=0 才执行 doReleaseShared() 。当最后一次 countDown() 执行，AQS 队列中有两个节点，一个是虚拟的 node 节点 head ，另一个是包含主线程信息的 node 节点。取出 head 节点，并且由于 waitStatus 是 signal ，会执行 unparkSuccessor() 。在 unparkSuccessor 中会 unpark head.next 即包含主线程信息的节点。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Condition]]></title>
      <url>/2020/03/05/condition/</url>
      <content type="html"><![CDATA[<p>Condition 是 java.util.concurrent 包中提供的接口，Condition 可以用来阻塞和唤醒线程，如果有多个线程，还可以指定唤醒某个线程。具体用法我们可以看一个例子：</p>
<pre><code>public class ConditionTest {

    public static void main(String[] args) throws InterruptedException {
        ReentrantLock reentrantLock = new ReentrantLock();
        Condition condition = reentrantLock.newCondition();
        Thread t1 = new Thread(() -&gt; {
            reentrantLock.lock();
            try {
                condition.await();
                System.out.println(Thread.currentThread().getName() + &quot; wake up&quot;);
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                reentrantLock.unlock();
            }
        }, &quot;t1&quot;);
        t1.start();
        Thread.sleep(1000);
        Thread t2 = new Thread(() -&gt; {
            reentrantLock.lock();
            try {
                condition.await();
                System.out.println(Thread.currentThread().getName() + &quot; wake up&quot;);
            } catch (InterruptedException e) {
                e.printStackTrace();
            } finally {
                reentrantLock.unlock();
            }
        }, &quot;t2&quot;);
        t2.start();
        Thread.sleep(1000);
        new Thread(() -&gt; {
            reentrantLock.lock();
            condition.signalAll();
            reentrantLock.unlock();
        }, &quot;t5&quot;).start();
    }
}
</code></pre><p>这个例子展示了 Condition 的用法，我们来看一下每一步都做了什么。</p>
<ol>
<li>首先 lock.newCondition() 返回的是 sync.newCondition() sync 继承自 AQS ，最终创建了一个 AQS 的 ConditionObject() 对象。ConditionObject 中包含了两个引用 firstWaiter 和 lastWaiter ，其类型是 AbstractQueuedSynchronizer.Node ，Node 中又包含了一个指针 nextWaiter ，这样就可以来构建一个链表。</li>
<li>当调用 await() 方法时，先创建一个包含当前线程的 node 节点 n1 ，然后如果 condition queue 的 lastWaiter 节点 t 为空，说明condition queue 中没有节点，就将 firstWaiter 节点指向 n1 ，否则就将 lastWaiter.nextWaiter 指向 n1 。<br><img src="https://s2.ax1x.com/2020/03/06/3bd2sf.png" alt="20200306102035" border="0" style="width:500px"></li>
<li>当调用 signal() 方法时，从 condition queue 中取出 firstWaiter 节点 n1 执行 doSignal() 。在 doSignal() 中，先将 firstWaiter 指向 n1.next 节点，如果 n1.next 为空，就将 lastWaiter 置空。然后将 condition queue 的节点 n1 取出来，加入到 AQS 队列中。<br><img src="https://s2.ax1x.com/2020/03/06/3bdRL8.png" alt="20200306101634" border="0" style="width:500px"></li>
<li>当执行 unlock() 方法，就可以从 AQS 队列中执行出队操作，从而 unpark 线程。</li>
</ol>
<blockquote>
<p>signal() 和 signalAll() 的区别：<br>signal() 方法是从 condition queue 中取出 firstWaiter 节点执行 transferForSignal() 操作。signalAll() 方法是遍历 condition queue 执行 transferForSignal() 直到 firstWaiter 为空。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[ReentrantLock]]></title>
      <url>/2020/03/03/reentrantlock/</url>
      <content type="html"><![CDATA[<p>ReentrantLock 可以创建公平锁和非公平锁，默认是非公平锁。公平锁由 FairSync 实现，非公平锁由 NonfairSync 实现，它们都是 Sync 的子类，Sync 又是 AbstractQueuedSynchronizer 的子类。ReentrantLock 的基本用法如下：</p>
<pre><code>ReentrantLock reentrantLock = new ReentrantLock();
reentrantLock.lock();
try {
    // todo
} finally {
    reentrantLock.unlock();
}
</code></pre><p>下面我们就来分析一下每一步都做了什么。</p>
<h5 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a><strong>加锁</strong></h5><p><img src="https://s2.ax1x.com/2020/03/05/3Hhs4x.png" alt="3Hhs4x.png" border="0"><br>从代码来看，公平锁和非公平锁的 lock 都是执行 acquire() 方法，区别在于非公平锁在 acquire() 前先进行一次 CAS 操作，成功了就不执行 acquire() ， 不成功才执行 acquire() 。这个 acquire() 是父类 AbstractQueuedSynchronizer 中的方法。<br><img src="https://s2.ax1x.com/2020/03/05/3H4Uit.png" alt="3H4Uit.png" border="0" style="width:350px"><br>公平锁和非公平锁的 tryAcquire() 分别有各自的实现。<br><img src="https://s2.ax1x.com/2020/03/05/3HRjbR.png" alt="3HRjbR.png" border="0"><br>比较两个 tryAcquire() 方法发现，公平锁多了一个 hasQueuedPredecessors() 的判断。在公平锁中，当线程执行 tryAcquire() 时，如果可以进行加锁时，先执行 !hasQueuedPredecessors() 的判断。<br><img src="https://s2.ax1x.com/2020/03/05/3HW3rj.png" alt="3HW3rj.png" border="0" style="width:450px"><br>如果当前线程之前有排队的线程则返回 true ，如果队列为空或队列的 head 就是当前线程则返回 false 。这是一个取反判断，所以当队列中有排队的线程，那么就不再执行 compareAndSetState() 操作了。换句话说就是如果有线程在排队，那么就不执行加锁的操作，直接判定加锁失败。这样就回到 AbstractQueuedSynchronizer 的 acquire() 中，继续执行 acquireQueued() 操作，即加入到 AQS 队列中。<br>相对于公平锁来说，非公平锁没有执行 hasQueuedPredecessors() 判断，如果可以进行加锁，则直接进行加锁，加锁成功返回 true ，加锁失败返回 false ，再执行 acquireQueued() 入队操作。<br>总结一下，<strong>非公平锁比公平锁多了两次获取锁的机会</strong>。</p>
<h5 id="入队"><a href="#入队" class="headerlink" title="入队"></a><strong>入队</strong></h5><p>入队操作包含两步：</p>
<ol>
<li>addWaiter()<br>首先将当前线程封装成 Node 节点 n ，如果队列没有初始化，则通过 enq() 方法来初始化队列，会进行两次循环，第一次循环初始化一个空节点 t ，将 head 和 tail 都指向该 t ，第二次循环将 tail 指向 n ，将 t.next 指向 n ，这样就将线程加入到 AQS 队列中。<br><img src="https://s2.ax1x.com/2020/03/05/3HjMWQ.png" alt="3HjMWQ.png" border="0" style="width:600px"></li>
<li>acquireQueued()<br>这个方法会判断线程是否会阻塞。判断逻辑放在 acquireQueued() 方法的死循环中。当线程加入到 AQS 队列中后，并不会马上阻塞，会在第一次循环中 再次尝试获取锁，如果获取锁失败，就将线程的 waitStatus 条件标记为需要 signal 来唤醒。第二次循环，还是获取锁失败之后，才真正 park 该线程，然后跳出循环。<br><img src="https://s2.ax1x.com/2020/03/05/3HX0qP.png" alt="3HX0qP.png" border="0"></li>
</ol>
<h5 id="解锁"><a href="#解锁" class="headerlink" title="解锁"></a><strong>解锁</strong></h5><p>解锁就很简单了，从 AQS 对列中获取 head.next 然后 unpark 。</p>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[AQS]]></title>
      <url>/2020/03/03/aqs/</url>
      <content type="html"><![CDATA[<p>AQS(AbstractQueuedSynchronizer) 是 java.util.concurrent.locks 包中提供的同步框架。AQS 是一个抽象类，java.util.concurrent 中很多并发工具类都是基于 AQS 实现的。AQS 比较复杂，但是我们可以先比较概括的来描述一下 AQS 。简单来说，AQS 维护了一个 state 属性和一个由双向链表构成的同步队列。线程通过 CAS 操作 state 获取锁，获取锁失败的线程被构造成 Node 放到同步队列中阻塞。当锁被释放，再将队列中的线程唤醒来重新获取锁。AQS 中提供了很多获取和释放资源的操作，子类继承和扩展这些方法来完成具体的功能，AQS 比较抽象和难以理解，我们可以通过学习具体场景的类来学习 AQS 。</p>
<p><a href="../../../../2020/03/03/reentrantlock/">ReentrantLock</a><br><a href="../../../../2020/03/05/condition/">Condition</a><br><a href="../../../../2020/03/06/countdownlatch/">CountDownLatch</a></p>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CAS]]></title>
      <url>/2020/03/02/cas/</url>
      <content type="html"><![CDATA[<p>在 Java 并发编程中，为了保证并发安全，一种方式是使用锁，另一种方式是使用 CAS（compare and swap） 。CAS 有 3 个参数，内存地址 V ，旧的预期值 A ，要修改的新值 B ，更新一个变量的时候，只有当变量的预期值 A 和内存地址 V 当中的实际值相同时，才会将内存地址 V 对应的值修改为 B ，如果和预期不相等则更新失败。</p>
<h4 id="CAS-是如何实现的？"><a href="#CAS-是如何实现的？" class="headerlink" title="CAS 是如何实现的？"></a>CAS 是如何实现的？</h4><p>Unsafe 类中有 3 个 cas 方法：</p>
<pre><code>public final native boolean compareAndSwapObject(Object var1, long var2, Object var4, Object var5);

public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);

public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6);
</code></pre><p>它们都是本地方法，在 x86 架构的系统中，是 Unsafe 类通过来调用 <strong>cmpxchg</strong> 指令来完成 CAS 操作的。</p>
<blockquote>
<p>compareAndSwapInt() 方法 4 个参数含义：<br>Object var1 需要操作的对象。<br>long var2    需要操作的属性的内存偏移量。<br>int var4    期望值。<br>int var5    更新值。</p>
</blockquote>
<h4 id="如何使用-Unsafe"><a href="#如何使用-Unsafe" class="headerlink" title="如何使用 Unsafe"></a>如何使用 Unsafe</h4><p>Unsafe 是 sun.misc 包下的类，如果我们使用 Unsafe.getUnsafe() 来创建实例，则会报 java.lang.SecurityException: Unsafe 。原因是因为 Unsafe 类是 Java 的底层类，必须由 bootstrap classloader 加载，我们的应用是通过 application classloader 加载的，所以会报异常。</p>
<pre><code>@CallerSensitive
public static Unsafe getUnsafe() {
    Class var0 = Reflection.getCallerClass();
    if (!VM.isSystemDomainLoader(var0.getClassLoader())) {
        throw new SecurityException(&quot;Unsafe&quot;);
    } else {
        return theUnsafe;
    }
}
</code></pre><p>既然不能直接使用，那就只能换一种方式，借鉴 java.util.concurrent.atomic.AtomicInteger ，利用反射来获取 Unsafe 。</p>
<pre><code>public class UnsafeExample {

    private static Unsafe unsafe;
    private static long valueOffset;
    private volatile int value;

    static {
        try {
            Field theUnsafeField = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);
            theUnsafeField.setAccessible(true);
            unsafe = (Unsafe) theUnsafeField.get(null);
            valueOffset = unsafe.objectFieldOffset(UnsafeExample.class.getDeclaredField(&quot;value&quot;));
        } catch (NoSuchFieldException | IllegalAccessException e) {
            e.printStackTrace();
        }
    }

    public static void main(String[] args) {
        //Unsafe unsafe = Unsafe.getUnsafe();
        System.out.println(unsafe);
        System.out.println(valueOffset);
    }
}
</code></pre><h4 id="CAS-的优点与问题"><a href="#CAS-的优点与问题" class="headerlink" title="CAS 的优点与问题"></a>CAS 的优点与问题</h4><p>和 Java 的锁相比，CAS 不会阻塞线程，也不会有线程间通信带来的线程切换和唤醒的消耗，在性能上会好于 Java 的锁。但是 CAS 也有一些问题：</p>
<ol>
<li>线程自旋造成的 CPU 占用高。</li>
<li>ABA 问题。</li>
<li>只能保证单个属性的线程安全，多个属性的线程安全无法使用 CAS 。</li>
</ol>
<h4 id="ABA-问题"><a href="#ABA-问题" class="headerlink" title="ABA 问题"></a>ABA 问题</h4><p>CAS 没有加锁，而是通过比较内存地址的值是否和预期相等来判断是否能更新成功。举个例子，比如一个栈中有 ABC 三个元素，栈顶元素是 C ，如果进行 2 次出栈操作，在将 C 入栈，此时栈顶元素还是 C ，但是栈中只有 A 和 C 了。为了避免这种情况，可以使用 <code>AtomicStampedReference&lt;V&gt;</code> 或 <code>AtomicMarkableReference&lt;V&gt;</code> 通过每次操作都添加一个标签来，虽然值相同但是不同的操作标签已经改变，从而避免 ABA 问题。</p>
<blockquote>
<p><code>AtomicStampedReference&lt;V&gt;</code> 和 <code>AtomicMarkableReference&lt;V&gt;</code> 内部都维护了一个 pair ，AtomicStampedReference 中的 pair 是 (reference, int) ，AtomicMarkableReference 中的 pair 是 (reference, boolean) 。AtomicMarkableReference 只是标识是否有修改。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spring Boot Starters]]></title>
      <url>/2020/02/25/spring-boot-starters/</url>
      <content type="html"><![CDATA[<p>Spring Boot Starters 是什么？实际上就是一组依赖描述合集。以 spring-boot-starter-web 为例，工程只有一个 pom 文件，其中就是几个依赖。</p>
<pre><code>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-json&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;
        &lt;exclusions&gt;
            &lt;exclusion&gt;
                &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;
                &lt;artifactId&gt;tomcat-embed-el&lt;/artifactId&gt;
            &lt;/exclusion&gt;
        &lt;/exclusions&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework&lt;/groupId&gt;
        &lt;artifactId&gt;spring-web&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework&lt;/groupId&gt;
        &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre><p>Spring Boot Starts 的作用就是<strong>减少手动来管理 pom 依赖，提高 pom 的可管理性，减少项目的整体配置的时间</strong>。 </p>
]]></content>
      
        <categories>
            
            <category> Spring Boot </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Learning About Spring Boot Auto Configuration]]></title>
      <url>/2020/02/25/learning-about-spring-boot-auto-configuration/</url>
      <content type="html"><![CDATA[<p>Spring Boot 自动配置主要依靠注解来实现。</p>
<pre><code>@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@AutoConfigurationPackage
@Import(AutoConfigurationImportSelector.class)
public @interface EnableAutoConfiguration {
}
</code></pre><p>@EnableAutoConfiguration 通过 @Import 引入了 AutoConfigurationImportSelector ，我们需要重点关注一下 getAutoConfigurationEntry() 方法。<br><img src="https://s2.ax1x.com/2020/02/25/3tCwt0.png" alt="3tCwt0.png" border="0"><br>这个方法通过 SpringFactoriesLoader 加载 META-INF/spring.factories 中的配置，在 spring-boot-autoconfigure 中 auto configuration 配置了 100+ 个类的全名，通过排除，过滤最终剩下需要自动配置的 29 个类。有了类的全名，在 doCreateBean() 方法中通过 beanFactory 创建类的实例。<br>自动配置除了上边的加载过程，还有一个重要的环节就是条件注解。我们看到在 spring.factories 中配置的类都是 xxxAutoConfiguration 这样的配置类，这些类有一个共同的特点就是都会带一些条件注解，以  JdbcTemplateAutoConfiguration 为例。</p>
<pre><code>@Configuration(proxyBeanMethods = false)
@ConditionalOnClass({ DataSource.class, JdbcTemplate.class }) //当类路径下有指定类的条件下
@ConditionalOnSingleCandidate(DataSource.class)              //当指定Bean在容器中只有一个，或者虽然有多个但是指定首选Bean    
@AutoConfigureAfter(DataSourceAutoConfiguration.class)      //自动配置必须在指定类之后进行
@EnableConfigurationProperties(JdbcProperties.class)
@Import({ JdbcTemplateConfiguration.class, NamedParameterJdbcTemplateConfiguration.class })
public class JdbcTemplateAutoConfiguration {

}
</code></pre><p>可以看到，有很多 @ConditionalOnXXX 的注解，这就是条件注解。条件注解的作用就是给 bean 的创建加上一些限制条件，以保证在自动实例化和注入时正确执行。<br>综上所述，Spring Boot 的自动配置就是通过 @EnableAutoConfiguration + 条件注解实现的。</p>
<blockquote>
<p>常见的一些条件注解：<br>@ConditionalOnBean：当容器里有指定Bean的条件下<br>@ConditionalOnClass：当类路径下有指定类的条件下<br>@ConditionalOnExpression：基于SpEL表达式作为判断条件<br>@ConditionalOnJava：基于JV版本作为判断条件<br>@ConditionalOnMissingBean：当容器里没有指定Bean的情况下<br>@ConditionalOnMissingClass：当类路径下没有指定类的条件下<br>@ConditionalOnProperty：指定的属性是否有指定的值<br>@ConditionalOnResource：类路径是否有指定的值<br>@ConditionalOnSingleCandidate：当指定Bean在容器中只有一个，或者虽然有多个但是指定首选Bean</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Spring Boot </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Learning About Spring Boot Launcher]]></title>
      <url>/2020/02/25/learning-about-spring-boot-launcher/</url>
      <content type="html"><![CDATA[<p>Spring Boot 是如何通过 java -jar 方式运行的？为了搞清楚其中缘由，我们需要先构建一个 Spring Boot 工程。</p>
<p>通过 mvn package 将 Spring Boot 项目打包，然后解压缩，我们可以看到 jar 中的结构。这是一个 fat-jar ，其中主要有 3 部分：</p>
<ol>
<li>BOOT-INF，用来存放应用的 class 文件和 Spring BOOT 依赖的 jar 。</li>
<li>META-INF，用来存放 MANIFEST.MF 文件。</li>
<li>spring-boot-loader 的 class 文件。</li>
</ol>
<p>打开 MANIFEST.MF 文件我们会发现有两个信息：</p>
<pre><code>Main-Class: org.springframework.boot.loader.JarLauncher
Start-Class: com.rolex.springbootlearning.SpringBootLearningApplication
</code></pre><p>我们知道，如果我们需要打一个可执行的 jar ，那么 Main-Class 就是这个 jar 的入口。但是我们工程实际的程序入口是 Start-Class 对应的类，所以我们可以大胆猜测 Spring Boot 是通过 JarLauncher 来引导执行应用程序的入口类的。<br>接下来我们就要 debug 一下 JarLauncher 的执行过程。正常构建 Spring Boot 工程不需要加 spring-boot-loader 依赖，Spring Boot 会通过插件自动加入。由于我们需要通过 JarLauncher 启动 debug ，所以加入 spring-boot-loader 依赖。</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-loader&lt;/artifactId&gt;
    &lt;scope&gt;provided&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre><p>然后配置运行配置。<br><img src="https://s2.ax1x.com/2020/02/25/3JcSvn.png" alt="3JcSvn.png" border="0"><br>最后在 JarLauncher 中打上断点就可以启动调试了。</p>
<ol>
<li>首先获取文件路径，加载 fat-jar 中所有的 jar 的 URL path 。<br><img src="https://s2.ax1x.com/2020/02/25/3JR4dP.png" alt="20200225103627" border="0"></li>
<li>然后加载 Manifest 信息，读取 Start-Class 。<br><img src="https://s2.ax1x.com/2020/02/25/3JR5If.png" alt="20200225102947" border="0"></li>
<li>最后通过反射 invoke 应用程序的 main 方法。<br><img src="https://s2.ax1x.com/2020/02/25/3JRhZt.png" alt="20200225103200" border="0"></li>
</ol>
<p>通过以上 3 步就实现了通过 java -jar 方式启动 Spring Boot 应用程序。</p>
]]></content>
      
        <categories>
            
            <category> Spring Boot </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CMS Garbage Collector]]></title>
      <url>/2020/02/23/cms-garbage-collector/</url>
      <content type="html"><![CDATA[<p>CMS 收集器执行过程分为 5 个阶段：</p>
<ol>
<li>Initial Mark(Stop the World Event)<br>暂停较短时间，标记可达对象。</li>
<li>Concurrent Marking<br>应用不暂停，从 GC root 开始标记可达对象。</li>
<li>Remark(Stop the World Event)<br>查找在并发标记过程中遗漏的对象。</li>
<li>Concurrent Sweep<br>应用不暂停，清除不可达对象。</li>
<li>Resetting<br>为下一次收集做准备。</li>
</ol>
<p>最初堆中 eden，survivor，old 都是空的。<br><img src="https://s2.ax1x.com/2020/02/23/3l4vPe.png" alt="20200223122552" border="0" style="width:300px"><br>当 young GC 触发，存活的对象将从 eden 和 survivor 拷贝到另一个 survivor ，到达年龄阈值的对象晋升到 old 。</p>
<p><img src="https://s2.ax1x.com/2020/02/23/3l4x8H.png" alt="20200223122351" border="0" style="width:500px"></p>
<p>young GC 完成后，eden 和一个 survivor 被清空。</p>
<p><img src="https://s2.ax1x.com/2020/02/23/3l4z2d.png" alt="20200223125905" border="0" style="width:500px"><br>当 old 到达一定容量触发 CMS 。<br>1） 首先进行 <strong>Initial Mark</strong> 阶段，标记出可达对象。<br>2） 短暂暂停之后，进入 <strong>Concurrent Marking</strong> 阶段，应用程序继续执行，CMS 同时找到可达的对象。<br>3） 在 <strong>Remark</strong> 阶段，找到并发标记期间丢失的对象。<br>4） 进入 <strong>Concurrent Sweep</strong> 阶段，释放掉未被标记的对象。<br>5） 释放之后，进入 <strong>Resetting</strong> 阶段，一次 CMS GC 完成。</p>
<p><img src="https://s2.ax1x.com/2020/02/23/3l4X5D.png" alt="20200223125952" border="0" style="width:500px"></p>
]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
            <tag> GC </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[G1 Garbage Collector]]></title>
      <url>/2020/02/23/g1-garbage-collector/</url>
      <content type="html"><![CDATA[<p><a href="https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/index.html" target="_blank" rel="external">https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/index.html</a></p>
<p>Garbage-First (G1) 垃圾收集器是服务器端的垃圾收集器，适用于大内存多处理器的服务器。G1 的目标是替代 CMS ，和 CMS 相比，G1 具有 2 个优势：<br>1） G1 是压缩的垃圾收集器，可以避免内存碎片。<br>2） G1 支持垃圾收集暂停时间预测，时间可以由用户设置。</p>
<h5 id="内存结构"><a href="#内存结构" class="headerlink" title="内存结构"></a>内存结构</h5><p>和之前的垃圾收集器架构不同，G1 使用了另一种架构。</p>
<p><img src="https://s2.ax1x.com/2020/02/23/3l6Bad.png" alt="3l6Bad.png" border="0" style="width:500px"></p>
<p>堆内存被分成若干大小相等的 region ，大小 1-32Mb 不等，数量大约 2000 个，每个 region 中都有 eden，survivor ，old ，humogous 和 unused 。G1 的内存分配是一种逻辑划分，不一定是连续的。</p>
<h5 id="GC-过程"><a href="#GC-过程" class="headerlink" title="GC 过程"></a>GC 过程</h5><ol>
<li>Initial Mark(Stop the World Event)<br>应用暂停，标记 survivor region （root region），这些 region 可能含有 old gen 的引用。</li>
<li>Root Region Scanning<br>应用不暂停，扫描 root region 获取 old 的引用。</li>
<li>Concurrent Marking<br>查找存活的对象。</li>
<li>Remark(Stop the World Event)<br>完成存活对象的标记，使用的是 snapshot-at-the-beginning(SATB) 算法。</li>
<li>Cleanup(Stop the World Event and Concurrent)<br>5.1 统计存活对象和完全空闲的 region (Stop the World Event) 。<br>5.2 清除记录的区域 (Stop the World Event) 。<br>5.3 将空白的 region 重置，然后加入到空闲列表 (Concurrent) 。</li>
<li>Copying(Stop the World Event)<br>将存活的对象拷贝到 unused region 。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Garbage Collection Steps]]></title>
      <url>/2020/02/23/garbage-collection-steps/</url>
      <content type="html"><![CDATA[<p><a href="https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html" target="_blank" rel="external">https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html</a></p>
<p>堆被分成若干部分：YoungGen ，OldGen ，parmGen 。<br><img src="https://s2.ax1x.com/2020/02/23/3l3SPA.png" alt="20200223093804" border="0" style="width:400px"><br>上图是 hotspot 的示意图，oracle 为了整合多种 jvm 产品，在 java8 中使用 metaspace 替代了 PerGen 。</p>
<h4 id="GC的过程"><a href="#GC的过程" class="headerlink" title="GC的过程"></a>GC的过程</h4><ol>
<li>最初 eden 、form 、to 都是空的，新创建的对象首先放到 eden 。<br><img src="https://s2.ax1x.com/2020/02/23/3l1vUH.png" alt="20200223093404" border="0" style="width:400px"></li>
<li>对象不断放入 eden ，当 eden 满时触发 minor GC 。<br><img src="https://s2.ax1x.com/2020/02/23/3l1jVe.png" alt="20200223093458" border="0" style="width:400px"><br>将 eden 中的对象移动到 s0 ，然后清空 eden 。<br><img src="https://s2.ax1x.com/2020/02/23/3l1ObD.png" alt="20200223093528" border="0" style="width:400px"></li>
<li>新创建的对象继续放到 eden ，当 eden 满时触发第二次 miner GC 。将 eden 中的对象移动到 s1 ，同时将 s0 中的对象也移动到 s1 ，同时对象年龄 +1 ，最后将 eden 和 s0 清空。<br><img src="https://s2.ax1x.com/2020/02/23/3l1LDO.png" alt="20200223093551" border="0" style="width:400px"></li>
<li>当第三次 minor GC 时，eden 和 s1 中的对象会被移动到 s0 并且对象年龄 +1 ，同时将清空 eden 和 s1 ，如此往复。<br><img src="https://s2.ax1x.com/2020/02/23/3l1qKK.png" alt="20200223093611" border="0" style="width:400px"></li>
<li>当若干次 minor GC 之后，当对象的年龄到达阈值时，会移动到 OldGen 。<br><img src="https://s2.ax1x.com/2020/02/23/3l1x5d.png" alt="20200223093639" border="0" style="width:400px"></li>
<li>对象不断晋升到 OldGen ，当 OldGen 满时会触发 major GC 来清理 OldGen。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Monitoring Linux Performence]]></title>
      <url>/2020/02/22/monitoring-linux-performence/</url>
      <content type="html"><![CDATA[<p>程序在 Linux 服务器上运行，我们需要对程序的运行状态和系统健康状况进行监控，那么如何做呢？下面一组命令可以帮助到我们。</p>
<ol>
<li><strong>top</strong>，监控 CPU 。<br><img src="https://s2.ax1x.com/2020/02/27/3wTtfg.png" alt="3wTtfg.png" border="0" style="width:550px"><br>这里我们主要关注两个地方：<br>1) 是右上角的 load average ，load average 有 3 个值，分别表示系统 1m ，5m ，15m 的平均负载值，<code>(1m+5m+15m)/3*100%</code> 可以作为衡量系统负载的指标，一般不要超过 60% 。<br>2) 是 %CPU 。可以看出 CPU 占用情况和对应的的进程 id 。</li>
<li><strong>vmstat</strong>，也可以用来监控 CPU 资源。<br><img src="https://s2.ax1x.com/2020/02/27/3wqi9O.png" alt="3wqi9O.png" border="0" style="width:550px"><br>也是关注两块：<br>1) procs，如果 r 的平均值大于系统 CPU 核数的 2 倍说明负载过高。<br> r 表示进行 CPU 处理的进程数。<br> b 表示进行 I/O 处理的进程数。<br>2) cpu，如果 us + sy 大于 80% 说明 CPU 资源不足。<br> us 表示用户进程消耗 CPU 时间百分比。<br> sy 表示内核进程消耗 CPU 时间百分比。</li>
<li><strong>pidstat</strong>，可以监控具体进程的 CPU 资源。<br><img src="https://s2.ax1x.com/2020/02/27/3wj0oR.png" alt="3wj0oR.png" border="0" style="width:500px"><br>也可以监控内存资源。<br><img src="https://s2.ax1x.com/2020/02/27/3wvyAs.png" alt="3wvyAs.png" border="0" style="width:500px"></li>
<li><strong>free</strong>，可以监控内存。<br><img src="https://s2.ax1x.com/2020/02/27/3wxebQ.png" alt="3wxebQ.png" border="0" style="width:600px"><br>一般 free 小于 20% 说明内存不足。</li>
<li><strong>df</strong>，可以查看磁盘占用情况。<br><img src="https://s2.ax1x.com/2020/02/27/3wxvR0.png" alt="3wxvR0.png" border="0" style="width:400px"></li>
<li><strong>iostat</strong>，可以监控磁盘 I/O 。<br><img src="https://s2.ax1x.com/2020/02/27/30Sdc6.png" alt="30Sdc6.png" border="0"><br>util 表示磁盘 I/O 带宽占用百分比。</li>
<li><strong>ifstat</strong>，可以查看网络 I/O 。<br><img src="https://s2.ax1x.com/2020/02/27/30pGKf.png" alt="30pGKf.png" border="0" style="width:200px"></li>
<li><strong>netstat</strong>，可以查看协议相关的信息。</li>
</ol>
<p>了解了常用的系统监控命令，再结合 java 的命令，就可以定位程序问题了。举个例子。</p>
<pre><code>public class CPUTest {
    public static void main(String[] args) {
        new Thread(()-&gt;{
            try {
                Thread.sleep(Integer.MAX_VALUE);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();

        new Thread(()-&gt;{
            while (true) {
                int i = new Random().nextInt();
            }
        }).start();
        System.out.println(&quot;program started...&quot;);
    }
}
</code></pre><p>这个程序有 2 个线程，其中一个休眠，一个一直进行 cpu 操作。在服务器上运行，在使用系统监控命令，可以看到系统的资源情况。<br><img src="https://s2.ax1x.com/2020/02/27/30F6US.png" alt="30F6US.png" border="0" style="width:700px"><br>进程 id=330 的 Java 程序 CPU 已经 100% 。<br><img src="https://s2.ax1x.com/2020/02/27/30knVf.png" alt="30knVf.png" border="0" style="width:500px"><br>我们使用 ps 可以查看 CPU 占用 100% 是由 id=343 的线程造成的。接下来我们将 343 转成 16 进制。<br><img src="https://s2.ax1x.com/2020/02/27/30Apyn.png" alt="30Apyn.png" border="0" style="width:400px"><br>接下来我们就可以使用 jstack 来查看堆栈信息了。<br><img src="https://s2.ax1x.com/2020/02/27/30Asfg.png" alt="30Asfg.png" border="0"><br>找到对应的 nid 即可找到有问题的代码了。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[GC Details]]></title>
      <url>/2020/02/21/gc-details/</url>
      <content type="html"><![CDATA[<p>规律就是： GC前内存大小-&gt;GC后内存大小(总内存大小)</p>
<p><img src="https://s2.ax1x.com/2020/02/21/3uzCuQ.png" alt="20200221210744" border="0"></p>
<p><img src="https://s2.ax1x.com/2020/02/21/3uzPBj.png" alt="20200221210808" border="0"></p>
]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[JVM Options]]></title>
      <url>/2020/02/21/jvm-options/</url>
      <content type="html"><![CDATA[<p>JVM 的选项有 3 种：</p>
<ol>
<li>基本选项，如 -version。</li>
<li>非基本选项，即 -X 选项，如 -Xmx，-Xms，-Xmn 等。</li>
<li>高级选项，即 -XX 选项。高级选项有两种类型，一种是 boolean 类型的，用 -XX:+ 或 -XX:- 表示，如 -XX:+PrintGCDetails ，另一种是值类型，如 -XX:ParallelGCThreads=2 。</li>
</ol>
<p>高级选项比较常用重要的有以下几个：</p>
<ol>
<li>-XX:InitialHeapSize，初始堆内存大小，等价于 -Xms 。</li>
<li>-XX:MaxHeapSize，最大堆内存大小，等价于 -Xmx 。</li>
<li>-XX:NewSize，新生代初始内存，等价于 -Xmn 。</li>
<li>-XX:MaxNewSize，新生代最大内存。</li>
<li>-XX:ThreadStackSize，线程栈的内存大小，等价于 -Xss 。</li>
<li>-XX:SurvivorRatio=ratio，eden 和 survivor 的比例，默认为 8 ，即 eden:s0:s1 = 8:1:1 。</li>
<li>-XX:NewRatio=ratio，young 和 old 的比例，默认为 2 ，即 young 占 1/3 。</li>
<li>-XX:MaxTenuringThreshold=threshold，经过多少次 young GC 才能到 ParOldGen ，默认是 15 ，可以设置范围 0-15 。</li>
<li>-XX:+UseParallelGC，使用 ParallelGC 垃圾收集器。</li>
<li>-XX:+PrintCommandLineFlags，输出 JVM 选项。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Default JVM Options]]></title>
      <url>/2020/02/21/default-jvm-options/</url>
      <content type="html"><![CDATA[<p>在进行 JVM 调优之前首先需要确定当前环境 JVM 各项参数的值是什么。我们可以用以下几种方式查看 JVM 的参数配置。</p>
<ol>
<li><strong>使用 jinfo</strong><br>查看某个具体的参数<pre><code>D:\Dev\IdeaProjects\microlabs\effictive-java&gt;jinfo -flag MaxHeapSize 19280
-XX:MaxHeapSize=4267704320
</code></pre>查看所有的参数<pre><code>&gt;jinfo -flags 19280
Attaching to process ID 19280, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 25.221-b11
Non-default VM flags: -XX:CICompilerCount=4 -XX:InitialHeapSize=268435456 -XX:MaxHeapSize=4267704320 -XX:MaxNewSize=1422393344 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=89128960 -XX:OldSize=179306496 -
XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGC
Command line:  -XX:+PrintCommandLineFlags -javaagent:D:\Program Files\JetBrains\IntelliJ IDEA 2019.2\lib\idea_rt.jar=5195:D:\Program Files\JetBrains\IntelliJ IDEA 2019.2\bin -Dfile.encoding=UTF-8
</code></pre></li>
<li><strong>使用 -XX:+PrintCommandLineFlags</strong><pre><code>&gt;java -XX:+PrintCommandLineFlags -version
-XX:G1ConcRefinementThreads=8 -XX:GCDrainStackTargetSize=64 -XX:InitialHeapSize=266639552 -XX:MaxHeapSize=4266232832 -XX:+PrintCommandLineFlags -XX:ReservedCodeCacheSize=251658240 -XX:+SegmentedCodeCa
che -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC -XX:-UseLargePagesIndividualAllocation
openjdk version &quot;11.0.3&quot; 2019-04-16
OpenJDK Runtime Environment (build 11.0.3+12-b304.10)
OpenJDK 64-Bit Server VM (build 11.0.3+12-b304.10, mixed mode, sharing)
</code></pre></li>
<li><strong>使用 -XX:+PrintFlagsInitial 或 -XX:+PrintFlagsFinal</strong><pre><code>&gt;java -XX:+PrintFlagsInitial -version
[Global flags]
ccstrlist AOTLibrary                               =                                           {product} {default}
   int ActiveProcessorCount                     = -1                                        {product} {default}
 uintx AdaptiveSizeDecrementScaleFactor         = 4                                         {product} {default}
 uintx AdaptiveSizeMajorGCDecayTimeScale        = 10                                        {product} {default}
 uintx AdaptiveSizePolicyCollectionCostMargin   = 50                                        {product} {default}
 …
</code></pre>-XX:+PrintFlagsInitial 显示的是初始值，-XX:+PrintFlagsFinal 显示的是最终的值，:= 表示修改过。<pre><code>$ java -XX:+PrintFlagsInitial -version | grep UseParallelGC
  bool UseParallelGC                             = false                               {product}
$ java -XX:+PrintFlagsFinal -version | grep UseParallelGC
  bool UseParallelGC                            := true                                {product}
java version &quot;1.8.0_221&quot;
Java(TM) SE Runtime Environment (build 1.8.0_221-b11)
Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode)
</code></pre></li>
</ol>
<p>JVM 的参数配置不是固定的，默认值也会随机器，操作系统不同而不同，所以还是通过以上几种方式来查看比较好。</p>
]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Lock]]></title>
      <url>/2020/02/20/lock/</url>
      <content type="html"><![CDATA[<p>Java 锁的种类：</p>
<ol>
<li><strong>公平锁</strong>：多个线程按照申请锁的顺序获得锁，效率不高，通过 new ReentrantLock(true) 可以创建公平锁。</li>
<li><strong>非公平锁</strong>：多个线程不是申请锁的顺序获得锁，后申请的有可能先获得锁。性能比公平锁高，会有优先级低的线程长时间无法获得锁的情况。synchornized 是非公平锁，ReentrantLock 默认也是非公平锁。</li>
<li><strong>可重入锁/递归锁</strong>：如果一个线程获得了锁，那么该方法内部调用的其他方法可以直接获得该对象的锁，不需要重新申请锁。</li>
<li><strong>自旋锁</strong>：线程获取锁失败后不会阻塞，而是通过循环再次尝试获取锁。自旋可以减少线程上下文切换，但是会消耗 CPU 资源，典型的用法如 CAS 。</li>
<li><strong>读锁/写锁</strong>：读读可以共存，读写、写写互斥。</li>
<li><strong>共享锁</strong>：一个锁可以被多个线程占有。</li>
<li><strong>独占锁</strong>：一个锁只能被一个线程占有，synchornized 和 ReentrantLock 都是独占锁。</li>
<li><strong>悲观锁</strong>：认为在一个线程操作数据的时候，其他线程也会同时进行操作，如果不加锁就一定会出问题，Java 中的锁就是悲观锁。</li>
<li><strong>乐观锁</strong>：认为在一个线程操作数据的时候，其他线程不一定会同时进行操作，从而先尝试进行操作，失败则进行重试，典型的就是 CAS 。</li>
<li><strong>分段锁</strong>：为提高性能，将数据分成若干部分，每部分分别加锁，典型如 concurrentHashMap 。</li>
<li><strong>偏向锁/轻量级锁/重量级锁</strong>：如果一段代码被一个线程多次访问，该线程会自动获得锁，这就是偏向锁。如果又有一个线程来访问这段代码，偏向锁就升级成轻量级锁，没有获得锁得锁的线程则自旋。如果自旋次数到达阈值则阻塞，轻量级锁会升级成重量级锁。</li>
</ol>
<h5 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a><strong>ReentrantLock</strong></h5><p>ReentrantLock 是 J.U.C.locks 包 Lock 接口的实现类，基本用法如下：</p>
<pre><code>public ReentrantLock lock = new ReentrantLock();

lock.lock();
try{
    // dosomething
} catch(Exception e) {

} finally {
    lock.unlock();
}
</code></pre><p>ReentrantLock 具有如下特点：</p>
<ol>
<li><strong>可重入</strong>，和 synchornized 相同。</li>
<li><strong>可中断</strong>，普通的 lock.lock() 是不能响应中断的，lock.lockInterruptibly() 能够响应中断。</li>
<li><strong>可限时</strong>，lock.tryLock(5, TimeUnit.SECONDS) 超时不能获得锁，就返回 false ，不会永久等待构成死锁。</li>
<li><strong>支持公平锁</strong>，默认是非公平锁，通过 new ReentrantLock(true) 可以创建公平锁。</li>
<li><strong>支持精确唤醒线程</strong>，在使用 notify/notifyAll 时，只能随机唤醒线程，ReentrantLock 可以通过 Condition 精确唤醒线程。</li>
</ol>
<pre><code>Lock lock = new ReentrantLock();
Condition c1 = lock.newCondition();
Condition c2 = lock.newCondition();
Condition c3 = lock.newCondition();

public void print1() {
    lock.lock();
    try {
        while (count % 3 != 0) {
            c1.await();
        }
        System.out.println(Thread.currentThread().getName() + &quot; print &quot; + count);
        count++;
        c2.signal();
    } catch (InterruptedException e) {
        e.printStackTrace();
    } finally {
        lock.unlock();
    }
}

public void print2() {
    lock.lock();
    try {
        while (count % 3 != 1) {
            c2.await();
        }
        System.out.println(Thread.currentThread().getName() + &quot; print &quot; + count);
        count++;
        c3.signal();
    } catch (InterruptedException e) {
        e.printStackTrace();
    } finally {
        lock.unlock();
    }
}

public void print3() {
    lock.lock();
    try {
        while (count % 3 != 2) {
            c3.await();
        }
        System.out.println(Thread.currentThread().getName() + &quot; print &quot; + count);
        count++;
        c1.signal();
    } catch (InterruptedException e) {
        e.printStackTrace();
    } finally {
        lock.unlock();
    }
}
</code></pre><p>使用 ReentrantLock 需要注意：</p>
<ol>
<li>由于 Lock 需要手动 lock/unlock ，所以需要注意 lock 之后一定要 unlock 以避免死锁。</li>
<li>lock/unlock 多个嵌套是可以的。</li>
</ol>
<h5 id="ReadWriteLock"><a href="#ReadWriteLock" class="headerlink" title="ReadWriteLock"></a><strong>ReadWriteLock</strong></h5><p>ReentrantReadWriteLock 是 ReadWriteLock 接口的实现类，基本用法如下：</p>
<pre><code>public class ReadWriteLockExample {

    public static void main(String[] args) {
        Cache cache = new ReadWriteLockExample().new Cache();
        for (int i = 0; i &lt; 5; i++) {
            int finalI = i;
            new Thread(() -&gt; {
                cache.put(&quot;key-&quot; + finalI, finalI);
            }).start();
        }

        for (int i = 0; i &lt; 5; i++) {
            int finalI = i;
            new Thread(() -&gt; {
                System.out.println(cache.get(&quot;key-&quot; + finalI));
            }).start();
        }
    }

    class Cache {
        volatile HashMap map = new HashMap();
        ReadWriteLock lock = new ReentrantReadWriteLock();

        public void put(String key, Object val) {
            lock.writeLock().lock();
            try {
                System.out.println(Thread.currentThread().getName() + &quot; write begin&quot;);
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                map.put(key, val);
                System.out.println(Thread.currentThread().getName() + &quot; write finish&quot;);
            } finally {
                lock.writeLock().unlock();
            }
        }

        public Object get(String key) {
            lock.readLock().lock();
            try {
                System.out.println(Thread.currentThread().getName() + &quot; read begin&quot;);
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
                Object obj = map.get(key);
                System.out.println(Thread.currentThread().getName() + &quot; read finish&quot;);
                return obj;
            } finally {
                lock.readLock().unlock();
            }
        }
    }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[synchronized]]></title>
      <url>/2020/02/20/synchronized/</url>
      <content type="html"><![CDATA[<p>synchronized 是 java 关键字，是最常见多线程同步方式，可以作用于方法和代码块。</p>
<pre><code>// 同步方法
synchronized void method(){

}

// 同步代码块
synchronized (this) {

}
</code></pre><p>不论是同步方法还是同步代码块，在 JVM 中都是通过管程 (Monitor) 来支持的。同步方法是隐式的，通过 ACC_SYNCHRONIZED 访问标识来声明。同步代码则是在 javac 编译器在字节码中添加 monitorenter 和 monitorexit 指令来实现的。无论正常退出还是异常结束， monitorenter 都必须有 monitorexit 与之对应。<br>synchronized 具有以下特点：</p>
<ol>
<li><strong>非公平锁</strong></li>
<li><strong>可重入</strong>：是指在如果一个线程获得了锁进入了 synchronized 方法，那么该方法内部调用的其他方法可以直接获得该对象的锁。</li>
<li><strong>不可中断</strong>：是指一旦一个线程获得了锁，只有执行完成或抛出异常才能释放，执行过程中其他线程只能等待，直到获得锁的线程释放锁之后其他线程才能获取锁。</li>
</ol>
<p>synchronized 使用使用时需要注意以下几点：</p>
<ol>
<li>synchronized 代码块的作用的对象不能为空。因为 synchronized 的信息是保存在对象的头信息中，所以作用的对象必须进行实例化。</li>
<li>synchronized 虽然简单，但是效率不高，所以在使用是尽可能保证 synchronized 的作用域不能过大。</li>
<li>要注意避免死锁</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[huffman tree and huffman code]]></title>
      <url>/2020/02/14/huffman-tree-and-huffman-code/</url>
      <content type="html"><![CDATA[<p>哈夫曼树的定义为假设有 m 个权值｛w1,w2,w3,…,wn｝，可以构造一棵含有 n 个叶子结点的二叉树，每个叶子结点的权为 wi ，则其中<strong>带权路径长度 WPL </strong>最小的二叉树称做最优二叉树或哈夫曼树。如图有 4 个节点 a b c d ，其权值分别为 wa = 7 ，wb = 5 ，wc = 2 ，wd = 4 ，它们可以构造出不同的二叉树，从根节点到每一个节点的路径长度和节点权值的乘积之和为 <strong>带权路径长度 WPL </strong>，WPL 最小的树即为哈夫曼树。</p>
<p><img src="https://s2.ax1x.com/2020/02/14/1XEpL9.png" alt="1XEpL9.png" border="0" style="width:500px"></p>
<p>从上图可以看出，要构造一颗哈夫曼树，权值越大，路径越短，则 WPL 越小。所以，如果我们需要构造一棵哈夫曼树，可以使用如下步骤：</p>
<ol>
<li>先将节点按照权值升序排列，将前 2 个节点取出，作为树的叶子节点， 2 个叶子节点的权值之和记为父节点的权值。</li>
<li>将父节点加入到节点列表中，重新排序，再重复步骤 1 ，直到最后一个节点。</li>
</ol>
<p>利用哈夫曼树可以生成哈夫曼编码，哈夫曼树是一种变长编码，主要用于数据的压缩和解压场景。利用哈夫曼树生成哈夫曼编码的方法很简单，将左子树路径记为 0 ，右子树路径记为 1 即可。</p>
<p><img src="https://s2.ax1x.com/2020/02/14/1X11xI.png" alt="1X11xI.png" border="0" style="width:300px"></p>
<pre><code>public class HuffmanTreeExample {

    public static void main(String[] args) {
        Node node1 = new Node(7, &#39;a&#39;);
        Node node2 = new Node(5, &#39;b&#39;);
        Node node3 = new Node(2, &#39;c&#39;);
        Node node4 = new Node(4, &#39;d&#39;);
        List&lt;Node&gt; list = new ArrayList&lt;&gt;();
        list.add(node1);
        list.add(node2);
        list.add(node3);
        list.add(node4);
        HuffmanTree huffmanTree = new HuffmanTree();
        Node root = huffmanTree.create(list);
        huffmanTree.preOrder(root);
        System.out.println(&quot;--&quot;);
        Map&lt;Character, String&gt; huffmanCode = huffmanTree.createHuffmanCode(root);
        System.out.println(huffmanCode);
    }
}

class HuffmanTree {

    public void preOrder(Node root) {
        System.out.println(root);
        if (root.left != null) {
            preOrder(root.left);
        }
        if (root.right != null) {
            preOrder(root.right);
        }
    }

    public Map createHuffmanCode(Node node) {
        HashMap codeMap = new HashMap();
        return createHuffmanCode(node, &quot;&quot;, new StringBuffer(), codeMap);
    }

    /**
     * 将左子树的 pathNo 记为 0， 又子树的 pathNo 记为 1
     *
     * @param node
     * @param pathNo
     * @param code
     * @param map
     * @return
     */
    public Map createHuffmanCode(Node node, String pathNo, StringBuffer code, Map&lt;Character, String&gt; map) {
        StringBuffer sb = new StringBuffer(code);
        if (node != null) {
            sb.append(pathNo);
            if (node.value == null) {
                createHuffmanCode(node.left, &quot;0&quot;, sb, map);
                createHuffmanCode(node.right, &quot;1&quot;, sb, map);
            } else {
                map.put(node.value, sb.toString());
            }
        }
        return map;
    }

    public Node create(List&lt;Node&gt; nodes) {
        while (nodes.size() &gt; 1) {
            Collections.sort(nodes);
            Node node0 = nodes.get(0);
            Node node1 = nodes.get(1);
            Node parentNode = new Node(node0.weight + node1.weight, null);
            parentNode.left = node0;
            parentNode.right = node1;
            nodes.remove(node0);
            nodes.remove(node1);
            nodes.add(parentNode);
        }
        return nodes.get(0);
    }
}

class Node implements Comparable&lt;Node&gt; {
    int weight;
    Character value;
    Node left;
    Node right;

    public Node(int weight, Character value) {
        this.weight = weight;
        this.value = value;
    }

    public int getWeight() {
        return weight;
    }

    public void setWeight(int weight) {
        this.weight = weight;
    }

    public Character getValue() {
        return value;
    }

    public void setValue(Character value) {
        this.value = value;
    }

    public Node getLeft() {
        return left;
    }

    public void setLeft(Node left) {
        this.left = left;
    }

    public Node getRight() {
        return right;
    }

    public void setRight(Node right) {
        this.right = right;
    }

    @Override
    public int compareTo(Node o) {
        return this.weight - o.weight;
    }

    @Override
    public String toString() {
        return &quot;Node{&quot; +
                &quot;weight=&quot; + weight +
                &quot;, value=&quot; + value +
                &#39;}&#39;;
    }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Data Structure </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[KMP Search]]></title>
      <url>/2020/02/12/kmp-search/</url>
      <content type="html"><![CDATA[<p>和 BF 算法不同，KMP 算法按照前缀和后缀找到公共前后缀，构造出一个 prefix table，然后在匹配失败的时候，不是回溯到开头的位置，而是按照 prefix table 的索引位置进行回溯，从而减少回溯次数。</p>
<p>我们来看看 KMP 的查找过程：<br>目标字符串为 text ，索引记为 i ，需要匹配的字符串为 pattern ，索引记为 j 。根据 pattern 先生成 prefix table 。然后从第一个元素开始匹配。第一个位置匹配， i 和 j 都后移一位。<br><img src="https://s2.ax1x.com/2020/02/12/1bG0IJ.png" alt="20200212213949" border="0" style="width:500px"><br>当第二个位置不匹配，根据 prefix table ，将 pattern 的 0 位置对齐到 text 的 i 位置。<br><img src="https://s2.ax1x.com/2020/02/12/1bGdZF.png" alt="20200212214027" border="0" style="width:500px"><br>然后重新开始匹配，pattern 第一个位置就不匹配，根据 prefix table ，j = -1 ，所以 pattern 整体后移一位。<br><img src="https://s2.ax1x.com/2020/02/12/1bGNrT.png" alt="20200212214046" border="0" style="width:500px"><br>当匹配到 pattern 最后一个位置不匹配，根据 prefix table ，将 pattern 的 0 位置对齐到 text 的 i 位置。<br><img src="https://s2.ax1x.com/2020/02/12/1bGUqU.png" alt="20200212214106" border="0" style="width:500px"><br>pattern 最后一个位置不匹配，根据 prefix table，pattern 的 0 位置对齐到 text 的 i 的位置。<br><img src="https://s2.ax1x.com/2020/02/12/1bGJx0.png" alt="20200212214129" border="0" style="width:500px"><br>继续匹配，当匹配到 pattern 的最后一个位置符合，则找到一个匹配的字符串。<br><img src="https://s2.ax1x.com/2020/02/12/1bGDi9.png" alt="20200212214201" border="0" style="width:500px"><br>继续向后找，找出数组长度则退出，查找完成。</p>
<pre><code>public class KMPExample {
    public static void main(String[] args) {
        String s1 = &quot;ABAABCDAABAB&quot;;
        String pattern = &quot;AABA&quot;;
        int[] next = next(pattern);
        int[] prefix = prefixTable(next);
        System.out.println(Arrays.toString(next));
        System.out.println(Arrays.toString(prefix));
        kmpSearch(s1, pattern);
    }

    /**
     * @param s1
     * @param pattern
     */
    public static void kmpSearch(String s1, String pattern) {
        int[] next = next(pattern);
        int[] prefixTable = prefixTable(next);
        int i = 0;
        int j = 0;
        boolean found = false;
        while (i &lt; s1.length()) {
            // j 等于 pattern.length 并且 pattern 最后一位置和 s1 的 i 位置匹配，说明整体匹配，即找到
            if (j == pattern.length() - 1 &amp;&amp; s1.charAt(i) == pattern.charAt(j)) {
                System.out.println(&quot;found at &quot; + (i - j));
                found = true;
                // 如果需要继续找，则从 前缀表的 j 位置继续匹配
                j = prefixTable[j];
            }
            if (s1.charAt(i) == pattern.charAt(j)) {
                i++;
                j++;
            } else {
                // 如果不匹配，则从前缀表的 j 位置开始重新匹配
                j = prefixTable[j];
                // 如果第一个位置都不匹配，则整体后移一位
                if (j == -1) {
                    i++;
                    j++;
                }
            }
        }
        if (!found) {
            System.out.println(&quot;not found&quot;);
        }
    }

    /**
     * 构造 prefix table， next 数组整体后移 1 位，第一个位置置为 -1
     *
     * @param next
     * @return
     */
    private static int[] prefixTable(int[] next) {
        int[] prefix = new int[next.length];
        prefix[0] = -1;
        for (int i = 0; i &lt; next.length - 1; i++) {
            prefix[i + 1] = next[i];
        }
        return prefix;
    }

    /**
     * 前缀表
     *
     * @param pattern
     * @return
     */
    private static int[] next(String pattern) {
        int[] next = new int[pattern.length()];
        next[0] = 0;
        for (int i = 1, j = 0; i &lt; pattern.length(); i++) {
            while (j &gt; 0 &amp;&amp; pattern.charAt(i) != pattern.charAt(j)) {
                j = next[j - 1];
            }
            // 如果
            if (pattern.charAt(i) == pattern.charAt(j)) {
                j++;
            }
            next[i] = j;
        }
        return next;
    }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Bucket Sort]]></title>
      <url>/2020/02/08/bucket-sort/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Heapsort]]></title>
      <url>/2020/02/08/heapsort/</url>
      <content type="html"><![CDATA[<p>堆排序（heapsort） 用到了一种数据结构叫做<strong>堆</strong>。堆由一颗<strong>完全二叉树</strong>构成，且完全二叉树的每一个父节点都大于或小于叶子节点。如果父节点大于叶子节点，就叫做最大堆，反之就叫做最小堆。排序按照升序或降序需要对应用到最大堆或最小堆。</p>
<blockquote>
<p>完全二叉树具有一个特点，就是树的生成顺序是自上至下，从左到右。</p>
</blockquote>
<p>由于完全二叉树的特点，元素是连续，所以完全二叉树可以用数组来表示。</p>
<p><img src="https://s2.ax1x.com/2020/02/10/152KRe.png" alt="152KRe.png" border="0" style="width:600px"></p>
<p>由上图可以看到，完全二叉树种的任意一个节点都可以通过计算得到：如果 i 是索引位置，那么 parent = (i - 1) / 2 , c1 = i <em> 2 + 1， c2 = i </em> 2 + 2 。</p>
<p>如果我们需要利用堆来对数组进行排序，那么就需要用数组构造出一个最大堆或最小堆。而我们当前的数组并不是一个最大堆，所以首先需要将完全二叉树调整成堆，这个步骤叫做 heapify ，其过程如下：<br>从 root 节点开始，找到 parent ，c1，c2 三个元素，parent 和 c1 比较，如果 parent 小于 c1 ，则将 parent 和 c1 互换。将所有的子树都按照这个过程再做一次，直到满足堆的特性。<br>有了这个基础，我们就可以利用堆来进行数组排序了。步骤为：</p>
<ol>
<li>从树的 h-1 层的最左节点开始做 heapify 直到构造一个堆。</li>
<li>然后将 root 和最后一个节点，也就是数组的第一个元素和最后一个元素交换，然后将堆的最后一个元素删除。</li>
<li>由于交换破坏了堆，所以再重复1，2步，依次类推，最终就得到了一个有序的数组。</li>
</ol>
<p><img src="https://s2.ax1x.com/2020/02/10/152MxH.png" alt="152MxH.png" border="0"><br><img src="https://s2.ax1x.com/2020/02/10/152GZt.png" alt="152GZt.png" border="0"><br><img src="https://s2.ax1x.com/2020/02/10/152YIf.png" alt="152YIf.png" border="0"><br><img src="https://s2.ax1x.com/2020/02/10/15W3UP.png" alt="20200210180057" border="0"><br><img src="https://s2.ax1x.com/2020/02/10/152aRg.png" alt="152aRg.png" border="0"></p>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Shell Sort]]></title>
      <url>/2020/02/08/shell-sort/</url>
      <content type="html"><![CDATA[<p>将数分成 n 组，每组分别进行比较，将结果在分成 n/2 组，每组粉笔进行比较，直到分组为 0<br>时间复杂度为 O(n*logn)</p>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[radix sort]]></title>
      <url>/2020/02/08/radix-sort/</url>
      <content type="html"><![CDATA[<p>将数按 个位 十位 百位 … 分布到 10 个桶中<br>时间复杂度为 O(n <em> logn)<br>空间换时间， n 个数需要 (n </em> 11 * 4) 字节的空间</p>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mergesort]]></title>
      <url>/2020/02/08/mergesort/</url>
      <content type="html"><![CDATA[<p>归并排序（mergesort）是采用分治法的一种排序算法。它的操作步骤分为两个阶段：拆分和归并。<br>拆分阶段，先将数组分成左右两段，再将左边再分成左右两段，依此执行直到左右两段只有 1 个元素（1 个元素即认为有序）。右边也执行相同操作。<br>归并阶段，从左边开始依次合并直到成为一个完成数组。归并具体步骤如下：</p>
<ol>
<li>假如有两个数组 a1 和 a2 ，先从 a1 和 a2 各取出第一个元素进行比较，a1 的元素较小，则放到临时数组，然后再从 a1 取出下一个元素，继续比较。</li>
<li>如果 a2 元素全都放到临时数组，a1 还有元素，则按顺序加入到临时数组。</li>
</ol>
<p><img src="https://s2.ax1x.com/2020/02/11/1Tbq2j.png" alt="1Tbq2j.png" border="0"></p>
<p>了解了归并的操作之后，将两个阶段合起来就可以完成排序了，n 个数的排序需要合并 n-1 次。</p>
<p><img src="https://s2.ax1x.com/2020/02/11/1TRCPP.png" alt="1TRCPP.png" border="0"></p>
<p>归并排序是稳定排序，它的时间复杂度为 O(n * logn)。</p>
<pre><code>public class MergesortExample {
    public static void main(String[] args) {
        int[] arr = {6, 2, 4, 7, 1};
        mergesort(arr, 0, arr.length - 1);
        System.out.println(Arrays.toString(arr));
    }

    /**
     * 1. n 个数需要合并 n-1 次
     * 2. 时间复杂度为 O(n * logn)
     *
     * @param arr
     * @param left
     * @param right
     */
    public static void mergesort(int[] arr, int left, int right) {
        if (left == right) {
            return;
        }
        int middle = (left + right) / 2;
        mergesort(arr, left, middle);
        mergesort(arr, middle + 1, right);
        merge(arr, left, middle, right);
    }

    private static void merge(int[] arr, int left, int middle, int right) {
        System.out.printf(&quot;left=%d,right=%d\n&quot;, left, right);
        int[] tmp = new int[right - left + 1];
        int t = 0;
        int i = left;
        int j = middle + 1;
        //从左右两端开始比较，较小的数放到临时数组
        while (i &lt;= middle &amp;&amp; j &lt;= right) {
            tmp[t++] = arr[i] &lt; arr[j] ? arr[i++] : arr[j++];
        }
        //如果左边或右边还有剩余，就依次拷贝到临时数组
        while (i &lt;= middle) {
            tmp[t++] = arr[i++];
        }
        while (j &lt;= right) {
            tmp[t++] = arr[j++];
        }
        //将临时数组拷贝回原数组
        for (int k = 0; k &lt; t; k++) {
            arr[left + k] = tmp[k];
        }
    }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Selection Sort]]></title>
      <url>/2020/02/08/selection-sort/</url>
      <content type="html"><![CDATA[<p>n 个数需要循环 n-1 次<br>默认选择第一个数，假定其最小，从下一个数开始依次向后比较，如果有更小的数，记录下值和索引<br>如果第一个数和选定的数不是同一个数，将第一个位置的数与选定的数交换<br>时间复杂度为 O(n^2)</p>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Insertion Sort]]></title>
      <url>/2020/02/08/insertion-sort/</url>
      <content type="html"><![CDATA[<p>将数组分成 2 组，一组有序一组无序<br>将无序组中的数依次取出来，从有序组中的最后一个数开始，依次比较，确定位置后插入有序组<br>n 个数需要执行 n-1 次<br>时间复杂度为 O(n^2)</p>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Sparse Array]]></title>
      <url>/2020/02/03/sparse-array/</url>
      <content type="html"><![CDATA[<p>稀疏数组(sparse array)是大多数位置都没有值或是值相同的多维数组。稀疏数组可以应用于压缩场景，便于节省空间。</p>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mybatis Execution Flow]]></title>
      <url>/2020/02/03/mybatis-execution-flow/</url>
      <content type="html"><![CDATA[<ol>
<li>实例化 org.mybatis.spring.SqlSessionFactoryBean 。</li>
<li>解析 xml 构造 Configuration 和 Context 。<br> 2.1 将 statement ，resultMap 等信息加入到 context 。<br> 2.2 将 sql 进行绑定到 SqlSource 。<br> 2.3 将 statement 信息构造成 MappedStatement ，放到 Configuration 。</li>
<li>创建查询接口 mapper 的代理对象 org.apache.ibatis.binding.MapperProxy ，通过“包名+类名+方法名”从 Map 中取出对应的 sql 语句执行。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Formatting Git Log Graph]]></title>
      <url>/2020/02/02/formatting-git-log-graph/</url>
      <content type="html"><![CDATA[<p>git log 命令可以查看 git 的提交历史，–graph 参数是将 git log 信息图形化显示。可以同过定制 format 格式来优化显示。<br>在 git 的安装目录下找到 etc\profile.d\aliases.sh ，加入 alias 配置。</p>
<pre><code>alias glog=&quot;git log --graph --pretty=format:&#39;%C(red)%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)&lt;%an&gt;%Creset&#39; --abbrev-commit&quot;
</code></pre><p>重启终端，使用 glog 命令就可以查看定制格式的 git log 信息了。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Git </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mybatis Result Mapping]]></title>
      <url>/2020/02/01/mybatis-result-mapping/</url>
      <content type="html"><![CDATA[<p>对于查询结果，mybatis 通过 resultType 或是 resultMap 来进行映射。简单的类型使用 resultType ，比如基本类型或是结构简单的对象类型。对于一些复杂的结构，可以通过 resultMap 来组装，比如聚合查询的结果。</p>
<pre><code>&lt;resultMap id=&quot;groupByColumnResultMap&quot; type=&quot;java.util.Map&quot;&gt;
    &lt;result property=&quot;age&quot; column=&quot;age&quot;&gt;&lt;/result&gt;
    &lt;result property=&quot;count&quot; column=&quot;count&quot;&gt;&lt;/result&gt;
&lt;/resultMap&gt;

&lt;select id=&quot;groupByColumn&quot; parameterType=&quot;java.lang.String&quot; resultMap=&quot;groupByColumnResultMap&quot;&gt;
    select age, count(*) as count from t_user group by ${columnName}
&lt;/select&gt;
</code></pre><p>关联查询结果使用 &lt;association&gt; 和 &lt;collection&gt; 组装也是这种用法。</p>
<blockquote>
<p>在进行结果映射时，如果 column 和 property 名称相同，mybatis 会自动映射，如果不同，则不会自动映射。可以使用别名同一字段名称，或是使用 resultMap 。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mybatis Parameter Mapping]]></title>
      <url>/2020/02/01/mybatis-parameter-mapping/</url>
      <content type="html"><![CDATA[<p>通常我们在查询的时候会需要传递参数，参数的类型可以通过 parameterType 指定。</p>
<pre><code>&lt;select id=&quot;findByAge&quot; parameterType=&quot;java.lang.Integer&quot; resultType=&quot;com.rolex.microlabs.model.User&quot;&gt;
    select * from t_user where age=#{age}
&lt;/select&gt;
</code></pre><p>非简单类型的参数也是一样的。</p>
<pre><code>&lt;select id=&quot;findByAnyCondition&quot; parameterType=&quot;com.rolex.microlabs.model.User&quot;
            resultType=&quot;com.rolex.microlabs.model.User&quot;&gt;
        select id, name, age, gender, skill from t_user
&lt;/select&gt;
</code></pre><p>parameterType 如果不指定，mybatis 会自动推断参数的类型。<br>在参数赋值时，如果查询接口的参数名字和 sql 中使用的占位符名称一样，会自动完成赋值。如果不一样，可以通过 @Param 指定。</p>
<pre><code>List&lt;User&gt; findByNameAndAge(@Param(&quot;name&quot;) String arg1, @Param(&quot;age&quot;) Integer arg2);
</code></pre><p>大多数情况下，参数赋值都是使用 #{} 方式，这种方式类似 jdbc 中 PrepareStatement 的 ? 占位符。还有一种占位符是 ${} ，它只会进行字符串替换，不会进行预处理，只有在一些特殊场景才会用到。例如通过参数控制对哪一列进行 group by 。</p>
<pre><code>&lt;select id=&quot;groupByColumn&quot; parameterType=&quot;java.lang.String&quot; resultMap=&quot;groupByColumnResultMap&quot;&gt;
    select age, count(*) as count from t_user group by ${columnName}
&lt;/select&gt;
</code></pre><p>使用 ${} 占位符，mybatis 无法通过名字进行绑定，需要通过 @Param 来指定。</p>
<pre><code>List&lt;Map&lt;Integer,Integer&gt;&gt; groupByColumn(@Param(&quot;columnName&quot;) String columnName);
</code></pre>]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mybatis One to Many Mapping]]></title>
      <url>/2020/02/01/mybatis-one-to-many-mapping/</url>
      <content type="html"><![CDATA[<p>mybatis 一对多映射通过 <collection> 标签来实现。</collection></p>
<pre><code>&lt;mapper namespace=&quot;com.rolex.microlabs.dao.DepartmentDao&quot;&gt;

    &lt;resultMap id=&quot;deptResultMap&quot; type=&quot;com.rolex.microlabs.model.Department&quot;&gt;
        &lt;id column=&quot;dept_id&quot; property=&quot;deptId&quot;&gt;&lt;/id&gt;
        &lt;result column=&quot;dept_name&quot; property=&quot;deptName&quot;&gt;&lt;/result&gt;
        &lt;collection property=&quot;employees&quot; ofType=&quot;com.rolex.microlabs.model.Employee&quot;&gt;
            &lt;id column=&quot;id&quot; property=&quot;id&quot;&gt;&lt;/id&gt;
            &lt;result column=&quot;name&quot; property=&quot;name&quot;&gt;&lt;/result&gt;
        &lt;/collection&gt;

    &lt;/resultMap&gt;

    &lt;select id=&quot;findAll&quot; resultMap=&quot;deptResultMap&quot;&gt;
        select e.id, e.name, d.dept_id, d.dept_name from t_employee e, t_dept d where e.dept_id=d.dept_id
    &lt;/select&gt;

&lt;/mapper&gt;
</code></pre>]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mybatis One to One Mapping]]></title>
      <url>/2020/02/01/mybatis-one-to-one-mapping/</url>
      <content type="html"><![CDATA[<p>mybatis 一对一映射通过 <association> 标签实现。</association></p>
<pre><code>&lt;mapper namespace=&quot;com.rolex.microlabs.dao.EmployeeDao&quot;&gt;

    &lt;resultMap id=&quot;employeeResultMap&quot; type=&quot;com.rolex.microlabs.model.Employee&quot;&gt;
        &lt;id column=&quot;id&quot; property=&quot;id&quot;&gt;&lt;/id&gt;
        &lt;result column=&quot;name&quot; property=&quot;name&quot;&gt;&lt;/result&gt;
        &lt;association property=&quot;department&quot; javaType=&quot;com.rolex.microlabs.model.Department&quot;&gt;
            &lt;id column=&quot;dept_id&quot; property=&quot;deptId&quot;&gt;&lt;/id&gt;
            &lt;result column=&quot;dept_name&quot; property=&quot;deptName&quot;&gt;&lt;/result&gt;
        &lt;/association&gt;

    &lt;/resultMap&gt;

    &lt;select id=&quot;findAll&quot; resultMap=&quot;employeeResultMap&quot;&gt;
        select e.id, e.name, d.dept_id, d.dept_name from t_employee e, t_dept d where e.dept_id=d.dept_id
    &lt;/select&gt;

&lt;/mapper&gt;
</code></pre>]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mybatis Cache]]></title>
      <url>/2020/02/01/mybatis-cache/</url>
      <content type="html"><![CDATA[<p>mybatis 有一级缓存和二级缓存，通过 mybatis 官方文档我们知道默认情况下，mybatis 的一级缓存是默认开启的。如果我们在 springboot 中集成 mybatis ，我们在同一方法中使用两次查询，会发现 mybatis 会执行两次查询。</p>
<pre><code>@Test
public void testCache(){
    List&lt;User&gt; users = userDao.findAll();
    System.out.println(users);
    List&lt;User&gt; users1 = userDao.findAll();
    System.out.println(users1);
}
</code></pre><p>打印 sql 。</p>
<pre><code>2020-02-01 11:57:17.958 DEBUG 2680 --- [           main] com.rolex.microlabs.dao.UserDao.findAll  : ==&gt;  Preparing: select id, name, age, gender, skill from t_user 
2020-02-01 11:57:18.012 DEBUG 2680 --- [           main] com.rolex.microlabs.dao.UserDao.findAll  : ==&gt; Parameters: 
2020-02-01 11:57:18.049 DEBUG 2680 --- [           main] com.rolex.microlabs.dao.UserDao.findAll  : &lt;==      Total: 4
[User(id=3, name=alice, age=29, gender=Female, skill=Java), User(id=4, name=jim, age=29, gender=Male, skill=CPP), User(id=5, name=alice, age=19, gender=Female, skill=Java), User(id=6, name=jim, age=20, gender=Male, skill=CPP)]
2020-02-01 11:57:18.052 DEBUG 2680 --- [           main] com.rolex.microlabs.dao.UserDao.findAll  : ==&gt;  Preparing: select id, name, age, gender, skill from t_user 
2020-02-01 11:57:18.053 DEBUG 2680 --- [           main] com.rolex.microlabs.dao.UserDao.findAll  : ==&gt; Parameters: 
2020-02-01 11:57:18.056 DEBUG 2680 --- [           main] com.rolex.microlabs.dao.UserDao.findAll  : &lt;==      Total: 4
[User(id=3, name=alice, age=29, gender=Female, skill=Java), User(id=4, name=jim, age=29, gender=Male, skill=CPP), User(id=5, name=alice, age=19, gender=Female, skill=Java), User(id=6, name=jim, age=20, gender=Male, skill=CPP)]
</code></pre><p>很显然一级缓存失效了。<br>我们来分析一下缓存失效的原因。我们在使用 springboot 集成 mybatis 时，从始至终都没有发现 mybatis 的一个重要的对象 SqlSession 。原因是因为 spring 在集成 mybatis 时，将 SqlSession 进行了封装，而在使用时通过代理对象创建。所以我们没有办法直接操作 SqlSession 。<strong>正是因为 SqlSession 完全由 spring 容器管理，所以 spring 在 SqlSessionTemplate.SqlSessionInterceptor.invoke() 方法中每次执行完 invoke() 方法后，都在 finally 中将 SqlSession 关闭了，所以一级缓存就失效了。</strong></p>
<p>不过我们还可以通过配置使用二级缓存。在 UserMapper.xml 中加入 <cache> 配置，我们会发现第二次查询使用了缓存。</cache></p>
<pre><code>2020-02-01 12:35:35.413 DEBUG 20624 --- [           main] com.rolex.microlabs.dao.UserDao.findAll  : ==&gt;  Preparing: select id, name, age, gender, skill from t_user 
2020-02-01 12:35:35.463 DEBUG 20624 --- [           main] com.rolex.microlabs.dao.UserDao.findAll  : ==&gt; Parameters: 
2020-02-01 12:35:35.517 DEBUG 20624 --- [           main] com.rolex.microlabs.dao.UserDao.findAll  : &lt;==      Total: 4
[User(id=3, name=alice, age=29, gender=Female, skill=Java), User(id=4, name=jim, age=29, gender=Male, skill=CPP), User(id=5, name=alice, age=19, gender=Female, skill=Java), User(id=6, name=jim, age=20, gender=Male, skill=CPP)]
2020-02-01 12:35:35.536 DEBUG 20624 --- [           main] com.rolex.microlabs.dao.UserDao          : Cache Hit Ratio [com.rolex.microlabs.dao.UserDao]: 0.5
[User(id=3, name=alice, age=29, gender=Female, skill=Java), User(id=4, name=jim, age=29, gender=Male, skill=CPP), User(id=5, name=alice, age=19, gender=Female, skill=Java), User(id=6, name=jim, age=20, gender=Male, skill=CPP)]
</code></pre><blockquote>
<p>缓存对象还需要实现序列化接口。</p>
</blockquote>
<p>mybatis 的二级缓存是 namespace 级别的缓存，同时在进行增删改操作之后会自动更新缓存。但是由于有 namespace 的限制，在一个 namespaceA 中修改了另一个 namespaceB 中的对象，那 namespaB 中的缓存是不会自动更新的，这就导致数据不一致，在多表操作时应该注意。</p>
<blockquote>
<p>除非能够确定对象不会被别的 namespace 修改，否则不要使用二级缓存。通常情况下，应禁用 mybatis 的缓存，可以使用 redis 这样的外部缓存。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Working with Mybatis Plugin Pagehelper]]></title>
      <url>/2020/02/01/working-with-mybatis-plugin-pagehelper/</url>
      <content type="html"><![CDATA[<p>mybatis 分页插件 PageHelper 可以非常方便的进行物理分页。<br>添加 spring-boot-starter 依赖。</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;
    &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;1.2.13&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>UserMapper.xml 不需要额外修改。</p>
<pre><code>&lt;select id=&quot;listForPage&quot; resultType=&quot;com.rolex.microlabs.model.User&quot;&gt;
    select * from t_user
&lt;/select&gt;
</code></pre><p>在需要分页的查询前加入分页代码。</p>
<pre><code>@Test
public void listForPage(){
    PageHelper.startPage(2, 5);
    List&lt;User&gt; list = userDao.listForPage();
    PageInfo page = new PageInfo(list);
    //测试PageInfo全部属性
    //PageInfo包含了非常全面的分页属性
    assertEquals(2, page.getPageNum());
    assertEquals(5, page.getPageSize());
    assertEquals(6, page.getStartRow());
    assertEquals(10, page.getEndRow());
    assertEquals(100, page.getTotal());
    assertEquals(20, page.getPages());
    assertEquals(true, page.isHasPreviousPage());
    assertEquals(true, page.isHasNextPage());
    System.out.println(page.getList());
}
</code></pre><p>使用 sprin boot + mybatis + PageHelper 如果有特殊需求，可以在配置文件中进行配置，比如分页合理化参数。</p>
<pre><code>pagehelper:
  reasonable: true # 合理化参数
</code></pre>]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Printing Mybatis SQL]]></title>
      <url>/2020/01/31/printing-mybatis-sql/</url>
      <content type="html"><![CDATA[<p>打印出的 sql 可以帮助调试程序。需要在配置文件添加日志配置。</p>
<pre><code>logging:
  level:
    com.rolex.microlabs.dao: debug # 查询接口的包名
</code></pre><p>打印 sql 信息如下：</p>
<pre><code>==&gt;  Preparing: select id, name, age, gender, skill from t_user WHERE age=? and gender=? 
==&gt; Parameters: 20(Integer), 1(Integer)
&lt;==      Total: 1
</code></pre>]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mybatis Dynamic SQL]]></title>
      <url>/2020/01/31/mybatis-dynamic-sql/</url>
      <content type="html"><![CDATA[<p>通常在通过组合若干条件进行数据库操作时，需要根据条件组装 sql ，可以使用 &lt;if&gt; 标签。</p>
<pre><code>&lt;select id=&quot;findByCondition&quot; parameterType=&quot;com.rolex.microlabs.model.User&quot;
            resultType=&quot;com.rolex.microlabs.model.User&quot;&gt;
    select id, name, age, gender, skill from t_user
    &lt;where&gt;
        &lt;if test=&quot;name != null&quot;&gt;and name=#{name}&lt;/if&gt;
        &lt;if test=&quot;age != null&quot;&gt;and age=#{age}&lt;/if&gt;
        &lt;if test=&quot;gender != null&quot;&gt;and gender=#{gender}&lt;/if&gt;
    &lt;/where&gt;
&lt;/select&gt;
</code></pre><p>还有一种类似 switch 功能的标签。</p>
<pre><code>&lt;select id=&quot;findByAnyCondition&quot; parameterType=&quot;com.rolex.microlabs.model.User&quot;
            resultType=&quot;com.rolex.microlabs.model.User&quot;&gt;
    select id, name, age, gender, skill from t_user
    &lt;where&gt;
        &lt;choose&gt;
            &lt;when test=&quot;name != null&quot;&gt;and name=#{name}&lt;/when&gt;
            &lt;when test=&quot;age != null&quot;&gt;and age=#{age}&lt;/when&gt;
            &lt;when test=&quot;gender != null&quot;&gt;and gender=#{gender}&lt;/when&gt;
        &lt;/choose&gt;
    &lt;/where&gt;
&lt;/select&gt;
</code></pre><p>更新操作也可以使用 &lt;if&gt; 标签，可用于更新有值的字段。</p>
<pre><code>&lt;update id=&quot;update&quot; parameterType=&quot;com.rolex.microlabs.model.User&quot;&gt;
    update t_user
    &lt;set&gt;
        &lt;if test=&quot;name != null&quot;&gt;name=#{name},&lt;/if&gt;
        &lt;if test=&quot;age != null&quot;&gt;age=#{age},&lt;/if&gt;
        &lt;if test=&quot;gender != null&quot;&gt;gender=#{gender}&lt;/if&gt;
    &lt;/set&gt;
    where id=#{id}
&lt;/update&gt;
</code></pre><p>批量操作时可以使用 &lt;foreach&gt; 标签。</p>
<pre><code>&lt;insert id=&quot;batchSave&quot;&gt;
    insert into t_user
    (name, age, gender, skill)
    values
    &lt;foreach collection=&quot;list&quot; item=&quot;user&quot; index=&quot;index&quot; separator=&quot;,&quot;&gt;
        (#{user.name}, #{user.age}, #{user.gender}, #{user.skill} )
    &lt;/foreach&gt;
&lt;/insert&gt;
&lt;select id=&quot;batchQuery&quot; resultType=&quot;com.rolex.microlabs.model.User&quot;&gt;
    select name, age, gender, skill from t_user
    where id in
    &lt;foreach collection=&quot;list&quot; item=&quot;id&quot; index=&quot;index&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt;
        #{id}
    &lt;/foreach&gt;
&lt;/select&gt;
&lt;delete id=&quot;batchDelete&quot;&gt;
    delete from t_user where id in
    &lt;foreach collection=&quot;list&quot; item=&quot;id&quot; index=&quot;index&quot; open=&quot;(&quot; close=&quot;)&quot; separator=&quot;,&quot;&gt;
        #{id}
    &lt;/foreach&gt;
&lt;/delete&gt;
&lt;update id=&quot;batchUpdate&quot;&gt;
    &lt;foreach collection=&quot;list&quot; item=&quot;user&quot; index=&quot;index&quot; separator=&quot;;&quot;&gt;
        update t_user
        &lt;set&gt;
            &lt;if test=&quot;user.name != null&quot;&gt;name=#{user.name},&lt;/if&gt;
            &lt;if test=&quot;user.age != null&quot;&gt;age=#{user.age},&lt;/if&gt;
            &lt;if test=&quot;user.gender != null&quot;&gt;gender=#{user.gender}&lt;/if&gt;
        &lt;/set&gt;
        where id=#{user.id}
    &lt;/foreach&gt;
&lt;/update&gt;
</code></pre>]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mybatis Annotation]]></title>
      <url>/2020/01/30/mybatis-annotation/</url>
      <content type="html"><![CDATA[<p>除了使用 mapper 文件之外，还可以使用注解来写 sql 。</p>
<pre><code>@Mapper // 和@MapperScan二选一
public interface UserDao {

    @Insert(&quot;insert into t_user (name, age, gender, skill) values (#{name}, #{age}, #{gender}, #{skill})&quot;)
    int save(User user);

    @Select(&quot;select id, name, age, gender, skill from t_user&quot;)
    List&lt;User&gt; findAll();

}
</code></pre><p>使用注解就可以不用 xml 的相关配置了。</p>
]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mapping Enum Type]]></title>
      <url>/2020/01/30/mapping-enum-type/</url>
      <content type="html"><![CDATA[<p>我们可以使用自定义 typeHandler 来处理 enum 类型的映射。在实体 User 中有两个 enum 类型的属性。</p>
<pre><code>public class User {

    private int id;
    private String name;
    private int age;
    private Gender gender;
    private Skill skill;
    // getter and setter
}
</code></pre><p>数据库中分别为 tinyint 类型和 varchar ，我们可以通过 typeHandler 来进行映射。</p>
<ol>
<li><p>创建 enum 类型的 typeHandler。<br>有两种方式来创建自定义的 typeHandler ，实现 TypeHandler<t> 和继承 BaseTypeHandler<t> 。</t></t></p>
<pre><code>@MappedTypes({Gender.class})
public class GenderHandler implements TypeHandler&lt;Gender&gt; {
 @Override
 public void setParameter(PreparedStatement preparedStatement, int i, Gender gender, JdbcType jdbcType) throws SQLException {
     preparedStatement.setInt(i, gender.getValue());
 }

 @Override
 public Gender getResult(ResultSet resultSet, String s) throws SQLException {
     return Gender.nameOf(resultSet.getInt(s));
 }

 @Override
 public Gender getResult(ResultSet resultSet, int i) throws SQLException {
     return Gender.nameOf(resultSet.getInt(i));
 }

 @Override
 public Gender getResult(CallableStatement callableStatement, int i) throws SQLException {
     return Gender.nameOf(callableStatement.getInt(i));
 }
}
</code></pre><pre><code>@MappedTypes({Skill.class})
public class SkillHandler extends BaseTypeHandler&lt;Skill&gt; {

 @Override
 public void setNonNullParameter(PreparedStatement preparedStatement, int i, Skill skill, JdbcType jdbcType) throws SQLException {
     preparedStatement.setString(i, skill.getValue());
 }

 @Override
 public Skill getNullableResult(ResultSet resultSet, String s) throws SQLException {
     return Skill.nameOf(resultSet.getString(s));
 }

 @Override
 public Skill getNullableResult(ResultSet resultSet, int i) throws SQLException {
     return Skill.nameOf(resultSet.getString(i));
 }

 @Override
 public Skill getNullableResult(CallableStatement callableStatement, int i) throws SQLException {
     return Skill.nameOf(callableStatement.getString(i));
 }
}
</code></pre><p>自定义 typeHandler 上要加上 @MappedTypes 。</p>
</li>
<li>在配置文件中加入 typeHandler 的配置。<pre><code>mybatis:
type-handlers-package: com.rolex.microlabs.handler
</code></pre>这样就可以在 insert 和 select 的时候完成 enum 类型的映射了。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Working with Mybatis Generator Maven Plugin]]></title>
      <url>/2020/01/29/working-with-mybatis-generator-maven-plugin/</url>
      <content type="html"><![CDATA[<p>除了自己写实体类，接口和映射之外，还可以使用 mybatis-generator-maven-plugin 来自动生成。</p>
<ol>
<li>添加 maven plugin 配置。<pre><code>&lt;build&gt;
 &lt;plugins&gt;
     &lt;plugin&gt;
         &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;
         &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt;
         &lt;version&gt;1.3.5&lt;/version&gt;
         &lt;dependencies&gt;
             &lt;dependency&gt;
                 &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt;
                 &lt;artifactId&gt;mybatis-generator-core&lt;/artifactId&gt;
                 &lt;version&gt;1.3.5&lt;/version&gt;
             &lt;/dependency&gt;
             &lt;dependency&gt;
                 &lt;groupId&gt;mysql&lt;/groupId&gt;
                 &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
                 &lt;version&gt;5.1.34&lt;/version&gt;
             &lt;/dependency&gt;
         &lt;/dependencies&gt;
         &lt;executions&gt;
             &lt;execution&gt;
                 &lt;id&gt;mybatis-generator&lt;/id&gt;
                 &lt;phase&gt;package&lt;/phase&gt;
                 &lt;goals&gt;
                     &lt;goal&gt;generate&lt;/goal&gt;
                 &lt;/goals&gt;
             &lt;/execution&gt;
         &lt;/executions&gt;
         &lt;configuration&gt;
             &lt;!-- 允许移动生成的文件 --&gt;
             &lt;verbose&gt;true&lt;/verbose&gt;
             &lt;!-- 允许覆盖，生产环境应设置成false --&gt;
             &lt;overwrite&gt;true&lt;/overwrite&gt;
             &lt;configurationFile&gt;
                 src/main/resources/mybatis-generator.xml
             &lt;/configurationFile&gt;
         &lt;/configuration&gt;
     &lt;/plugin&gt;
 &lt;/plugins&gt;
&lt;/build&gt;
</code></pre></li>
<li><p>修改 src/main/resources/mybatis-generator.xml 。</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE generatorConfiguration
     PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot;
     &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;
&lt;generatorConfiguration&gt;
 &lt;context id=&quot;DB2Tables&quot; targetRuntime=&quot;MyBatis3&quot;&gt;
     &lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot;
                     connectionURL=&quot;jdbc:mysql://localhost:3306/test&quot;
                     userId=&quot;root&quot;
                     password=&quot;123456&quot;&gt;
     &lt;/jdbcConnection&gt;

     &lt;javaTypeResolver&gt;
         &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot;/&gt;
     &lt;/javaTypeResolver&gt;
     &lt;!--实体类配置--&gt;
     &lt;javaModelGenerator targetPackage=&quot;generator.model&quot; targetProject=&quot;src/main/java&quot;&gt;
         &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt;
         &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot;/&gt;
     &lt;/javaModelGenerator&gt;
     &lt;!--查询接口配置--&gt;
     &lt;sqlMapGenerator targetPackage=&quot;mapper&quot; targetProject=&quot;src/main/java/generator&quot;&gt;
         &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt;
     &lt;/sqlMapGenerator&gt;
     &lt;!--mapper映射配置--&gt;
     &lt;javaClientGenerator type=&quot;XMLMAPPER&quot; targetPackage=&quot;generator.dao&quot; targetProject=&quot;src/main/java&quot;&gt;
         &lt;property name=&quot;enableSubPackages&quot; value=&quot;true&quot;/&gt;
     &lt;/javaClientGenerator&gt;
     &lt;!--数据库表和实体映射配置--&gt;
     &lt;table schema=&quot;test&quot; tableName=&quot;t_user&quot; domainObjectName=&quot;User&quot;
            enableCountByExample=&quot;true&quot;
            enableUpdateByExample=&quot;true&quot;
            enableDeleteByExample=&quot;true&quot;
            enableSelectByExample=&quot;true&quot;
            selectByExampleQueryId=&quot;true&quot;&gt;
     &lt;/table&gt;
 &lt;/context&gt;
&lt;/generatorConfiguration&gt;
</code></pre></li>
<li>运行插件。<br>执行命令 mvn mybatis-generator:generate 即可在对应目录生成相应文件。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Working with Mybatis]]></title>
      <url>/2020/01/29/working-with-mybatis/</url>
      <content type="html"><![CDATA[<p>集成 spring boot 和 Mybatis 非常简单，只需要 6 步即可完成。</p>
<ol>
<li><p>添加 maven 依赖</p>
<pre><code>&lt;dependency&gt;
 &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
 &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
 &lt;version&gt;1.3.0&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
 &lt;groupId&gt;mysql&lt;/groupId&gt;
 &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre></li>
<li><p>按照数据库结构创建对象。<br>假设我们有一张用户表。</p>
<pre><code>create table t_user
(
 id   int auto_increment primary key,
 name varchar(50) not null,
 age  int         null
);
</code></pre><p>对应的实体对象 com.rolex.microlabs.model.User 。</p>
<pre><code>public class User {
 private int id;
 private String name;
 private int age;
 //getter and setter
}
</code></pre></li>
<li>添加查询接口 com.rolex.microlabs.dao.UserDao 。<pre><code>@Mapper // 和@MapperScan二选一
public interface UserDao {
 int save(User user);
}
</code></pre></li>
<li>编写对应的 mapper 映射。<br>创建 resources/mapper/UserMapper.xml 文件，添加如下内容。<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot; &gt;
&lt;mapper namespace=&quot;com.rolex.microlabs.dao.UserDao&quot;&gt;
 &lt;insert id=&quot;save&quot; parameterType=&quot;com.rolex.microlabs.model.User&quot;&gt;
     insert into t_user
       (name, age)
     values
       (#{name}, #{age})
 &lt;/insert&gt;
&lt;/mapper&gt;
</code></pre></li>
<li>修改配置文件。<br>在 application.yml 中添加 mybatis 配置信息。<pre><code>spring:
datasource:
 url: jdbc:mysql://localhost:3306/test
 username: root
 password: 123456
 driver-class-name: com.mysql.jdbc.Driver
mybatis:
mapper-locations: classpath:mapper/*.xml  #注意：一定要对应mapper映射xml文件的所在路径
</code></pre></li>
<li>配置 spring boot 启动类。<pre><code>@SpringBootApplication
@MapperScan(&quot;com.rolex.microlabs.dao&quot;) // 和@Mapper二选一
public class MyBatisApplication {
 public static void main(String[] args) {
     SpringApplication.run(MyBatisApplication.class, args);
 }
}
</code></pre></li>
</ol>
<p>完成以上配置就可以使用 JUnit 进行测试了。</p>
]]></content>
      
        <categories>
            
            <category> MyBatis </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MyBatis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker Network]]></title>
      <url>/2020/01/21/docker-network/</url>
      <content type="html"><![CDATA[<p>Linux 内核支持 6 中命名空间：UTS，User，PID，IPC，Mount，Network 。</p>
<p>docker 默认创建有 3 种网络，使用命令可以查看。</p>
<pre><code>$ docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
c9277adb7c8b        bridge              bridge              local
705c67c36bba        host                host                local
fd36f2cec0f3        none                null                local
</code></pre><p>当我们启动一个容器，默认使用 bridge 网络。</p>
<pre><code>$ docker run --name busybox1 -it --rm busybox:latest
/ # ifconfig
eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:02
          inet addr:172.17.0.2  Bcast:172.17.255.255  Mask:255.255.0.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:13 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:998 (998.0 B)  TX bytes:0 (0.0 B)

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1
          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)
</code></pre><p>进入容器使用 ifconfig 可以看到 eth0 是 172.17 网段。这种网络是 docker 使用了一个虚拟网络设备，将容器内部网络和宿主机网络连接起来，从而可以实现容器和宿主机之间通信，并且可以将宿主机当作 dns 服务器和外部通信。</p>
<pre><code>/ # nslookup -type=A www.baidu.com
Server:         192.168.65.1
Address:        192.168.65.1:53

Non-authoritative answer:
www.baidu.com   canonical name = www.a.shifen.com
Name:   www.a.shifen.com
Address: 61.135.169.125
Name:   www.a.shifen.com
Address: 61.135.169.121
</code></pre><p>当然可以指定 dns 服务器。</p>
<pre><code>$ docker run -it --rm --dns 8.8.8.8 --name busybox1 busybox
/ # nslookup -type=A www.baidu.com
Server:         8.8.8.8
Address:        8.8.8.8:53

Non-authoritative answer:
www.baidu.com   canonical name = www.a.shifen.com
Name:   www.a.shifen.com
Address: 61.135.169.121
Name:   www.a.shifen.com
Address: 61.135.169.125
</code></pre><p>如果我们使用 - -network 指定容器启动的网络为 bridge ，效果是一样的。</p>
<p>如果我们指定使用 none 网络，那么就只有 lo 网络，是一种封闭式容器。</p>
<pre><code>$ docker run --name busybox1 -it --rm --network none busybox:latest
/ # ifconfig                                                       
lo        Link encap:Local Loopback                                
          inet addr:127.0.0.1  Mask:255.0.0.0                      
          UP LOOPBACK RUNNING  MTU:65536  Metric:1                 
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0       
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0     
          collisions:0 txqueuelen:1                                
          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)
</code></pre><p>我们还可以指定 network 为 host 。</p>
<pre><code>$ docker run -it --rm --network host --name busybox1 busybox               
/ # ifconfig                                                               
docker0   Link encap:Ethernet  HWaddr 02:42:98:75:6B:44                    
          inet addr:172.17.0.1  Bcast:172.17.255.255  Mask:255.255.0.0     
          inet6 addr: fe80::42:98ff:fe75:6b44/64 Scope:Link                
          UP BROADCAST MULTICAST  MTU:1500  Metric:1                       
          RX packets:77548 errors:0 dropped:0 overruns:0 frame:0           
          TX packets:174258 errors:0 dropped:0 overruns:0 carrier:0        
          collisions:0 txqueuelen:0                                        
          RX bytes:3130282 (2.9 MiB)  TX bytes:250653674 (239.0 MiB)       

eth0      Link encap:Ethernet  HWaddr 02:50:00:00:00:01                    
          inet addr:192.168.65.3  Bcast:192.168.65.15  Mask:255.255.255.240
          inet6 addr: fe80::50:ff:fe00:1/64 Scope:Link                     
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1               
          RX packets:174978 errors:0 dropped:0 overruns:0 frame:0          
          TX packets:78102 errors:0 dropped:0 overruns:0 carrier:0         
          collisions:0 txqueuelen:1000                                     
          RX bytes:251511916 (239.8 MiB)  TX bytes:4265623 (4.0 MiB)       

hvint0    Link encap:Ethernet  HWaddr 00:15:5D:00:67:17                    
          inet addr:10.0.75.2  Bcast:0.0.0.0  Mask:255.255.255.240         
          inet6 addr: fe80::215:5dff:fe00:6717/64 Scope:Link               
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1               
          RX packets:57690 errors:0 dropped:1 overruns:0 frame:0           
          TX packets:29914 errors:0 dropped:0 overruns:0 carrier:0         
          collisions:0 txqueuelen:1000                                     
          RX bytes:7303259 (6.9 MiB)  TX bytes:2630900 (2.5 MiB)           

lo        Link encap:Local Loopback                                        
          inet addr:127.0.0.1  Mask:255.0.0.0                              
          inet6 addr: ::1/128 Scope:Host                                   
          UP LOOPBACK RUNNING  MTU:65536  Metric:1                         
          RX packets:18 errors:0 dropped:0 overruns:0 frame:0              
          TX packets:18 errors:0 dropped:0 overruns:0 carrier:0            
          collisions:0 txqueuelen:1                                        
          RX bytes:1484 (1.4 KiB)  TX bytes:1484 (1.4 KiB)
</code></pre><p>可以看到容器的 IP 地址就是宿主机的 IP 地址，说明容器共享了宿主机的 network 命名空间。</p>
<p>当我们启动多个容器的时候，如果我们使用 bridge ，多个容器的 ip 地址是不同的。</p>
<pre><code>$ docker run -it --rm --network bridge --name busybox1 busybox
/ # ifconfig
eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:02
          inet addr:172.17.0.2  Bcast:172.17.255.255  Mask:255.255.0.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:8 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:688 (688.0 B)  TX bytes:0 (0.0 B)

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1
          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)
</code></pre><pre><code>$ docker run -it --rm --network bridge --name busybox2 busybox
/ # ifconfig
eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:02
          inet addr:172.17.0.2  Bcast:172.17.255.255  Mask:255.255.0.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:8 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:688 (688.0 B)  TX bytes:0 (0.0 B)

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1
          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)
</code></pre><p>如果我们修改一下 busybox2 的 network 为 –network container:busybox1 。</p>
<pre><code>$ docker run -it --rm --network container:busybox1 --name busybox2 busybox   
/ # ifconfig                                                                 
eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:02                      
          inet addr:172.17.0.2  Bcast:172.17.255.255  Mask:255.255.0.0       
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1                 
          RX packets:13 errors:0 dropped:0 overruns:0 frame:0                
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0               
          collisions:0 txqueuelen:0                                          
          RX bytes:1038 (1.0 KiB)  TX bytes:0 (0.0 B)                        

lo        Link encap:Local Loopback                                          
          inet addr:127.0.0.1  Mask:255.0.0.0                                
          UP LOOPBACK RUNNING  MTU:65536  Metric:1                           
          RX packets:0 errors:0 dropped:0 overruns:0 frame:0                 
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0               
          collisions:0 txqueuelen:1                                          
          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)
</code></pre><p>这时，两个容器的 IP 是相同的，这种网络模式叫做联盟式网络。联盟式网络的容器共享同一个 network 命名空间，可以彼此之间进行通信，类似同一个主机上的两个进程。</p>
<p>以上就是 docker 支持的 4 种内置的网络模式。<br>除此之外，docker 还可以创建自定义的网络。通过 docker info 可以查看 docker 支持的网络类型。</p>
<pre><code>$ docker info
Client:
 Debug Mode: false

Server:
 ...
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
  ...
</code></pre><p>通过插件，可以支持多种网络。使用命令可创建自定义网络。</p>
<pre><code>$ docker network create --driver bridge mynet
</code></pre><pre><code>$ docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
c9277adb7c8b        bridge              bridge              local
705c67c36bba        host                host                local
798d854b9d67        mynet               bridge              local
fd36f2cec0f3        none                null                local
</code></pre><p>我们自己创建的 bridge 网络和默认的 bridge 网络是类似，适合规模较小的网络。如果需要创建较大规模的网络，可以使用 overlay 网络。</p>
]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Netty Websocket Long Connection]]></title>
      <url>/2020/01/04/netty-websocket-long-connection/</url>
      <content type="html"><![CDATA[<p><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Scalable IO in Java<br>Doug Lea<br>State University of New York at Oswego<br>dl@cs.oswego.edu<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Outline<br>“ Scalable network services<br>“ Event-driven processing<br>“ Reactor pattern<br>Basic version<br>Multithreaded versions<br>Other variants<br>“ Walkthrough of java.nio nonblocking IO APIs<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Network Services<br>“ Web services, Distributed Objects, etc<br>“ Most have same basic structure:<br>Read request<br>Decode request<br>Process service<br>Encode reply<br>Send reply<br>“ But differ in nature and cost of each step<br>XML parsing, File transfer, Web page<br>generation, computational services, …<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Classic Service Designs<br>client<br>client<br>client<br>Server<br>read decode compute encode send<br>read decode compute encode send<br>handler<br>handler<br>read decode compute encode send<br>handler<br>Each handler may be started in its own thread<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Classic ServerSocket Loop<br> class Server implements Runnable {<br> public void run() {<br> try {<br> ServerSocket ss = new ServerSocket(PORT);<br> while (!Thread.interrupted())<br> new Thread(new Handler(ss.accept())).start();<br> // or, single-threaded, or a thread pool<br> } catch (IOException ex) { /<em> … </em>/ }<br> }<br> static class Handler implements Runnable {<br> final Socket socket;<br> Handler(Socket s) { socket = s; }<br> public void run() {<br> try {<br> byte[] input = new byte[MAX_INPUT];<br> socket.getInputStream().read(input);<br> byte[] output = process(input);<br> socket.getOutputStream().write(output);<br> } catch (IOException ex) { /<em> … </em>/ }<br> }<br> private byte[] process(byte[] cmd) { /<em> … </em>/ }<br> }<br>}<br>Note: most exception handling elided from code examples<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Scalability Goals<br>“ Graceful degradation under increasing load<br>(more clients)<br>“ Continuous improvement with increasing<br>resources (CPU, memory, disk, bandwidth)<br>“ Also meet availability and performance goals<br>Short latencies<br>Meeting peak demand<br>Tunable quality of service<br>“ Divide-and-conquer is usually the best<br>approach for achieving any scalability goal<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Divide and Conquer<br>“ Divide processing into small tasks<br>Each task performs an action without blocking<br>“ Execute each task when it is enabled<br>Here, an IO event usually serves as trigger<br>“ Basic mechanisms supported in java.nio<br>Non-blocking reads and writes<br>Dispatch tasks associated with sensed IO events<br>“ Endless variation possible<br>A family of event-driven designs<br>read decode compute encode send<br>handler<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Event-driven Designs<br>“ Usually more efficient than alternatives<br>Fewer resources<br>“ Don’t usually need a thread per client<br>Less overhead<br>“ Less context switching, often less locking<br>But dispatching can be slower<br>“ Must manually bind actions to events<br>“ Usually harder to program<br>Must break up into simple non-blocking actions<br>“ Similar to GUI event-driven actions<br>“ Cannot eliminate all blocking: GC, page faults, etc<br>Must keep track of logical state of service<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Background: Events in AWT<br>Event<br>Event<br>Button<br>public void actionPerformed(…) {<br> doSomething();<br>}<br>ActionListener<br>AWT thread<br>AWT Event Queue<br>Event-driven IO uses similar ideas but in different designs<br>…<br>click!<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Reactor Pattern<br>“ Reactor responds to IO events by dispatching<br>the appropriate handler<br>Similar to AWT thread<br>“ Handlers perform non-blocking actions<br>Similar to AWT ActionListeners<br>“ Manage by binding handlers to events<br>Similar to AWT addActionListener<br>“ See Schmidt et al, Pattern-Oriented Software<br>Architecture, Volume 2 (POSA2)<br>Also Richard Stevens’s networking books, Matt<br>Welsh’s SEDA framework, etc<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Basic Reactor Design<br>client<br>client<br>client<br>read decode compute encode send<br>read decode compute encode send<br>read decode compute encode send<br>Reactor<br>acceptor<br>dispatch<br>Single threaded version<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>java.nio Support<br>“ Channels<br>Connections to files, sockets etc that support<br>non-blocking reads<br>“ Buffers<br>Array-like objects that can be directly read or<br>written by Channels<br>“ Selectors<br>Tell which of a set of Channels have IO events<br>“ SelectionKeys<br>Maintain IO event status and bindings<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Reactor 1: Setup<br> class Reactor implements Runnable {<br>final Selector selector;<br>final ServerSocketChannel serverSocket;<br>Reactor(int port) throws IOException {<br>selector = Selector.open();<br>serverSocket = ServerSocketChannel.open();<br>serverSocket.socket().bind(<br>new InetSocketAddress(port));<br>serverSocket.configureBlocking(false);<br>SelectionKey sk =<br>serverSocket.register(selector,<br>SelectionKey.OP_ACCEPT);<br>sk.attach(new Acceptor());<br>}<br>/<em><br>Alternatively, use explicit SPI provider:<br>SelectorProvider p = SelectorProvider.provider();<br>selector = p.openSelector();<br>serverSocket = p.openServerSocketChannel();
</em>/<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Reactor 2: Dispatch Loop<br> // class Reactor continued<br>public void run() { // normally in a new<br>Thread<br>try {<br>while (!Thread.interrupted()) {<br>selector.select();<br>Set selected = selector.selectedKeys();<br>Iterator it = selected.iterator();<br>while (it.hasNext())<br>dispatch((SelectionKey)(it.next());<br>selected.clear();<br>}<br>} catch (IOException ex) { /<em> … </em>/ }<br>}<br>void dispatch(SelectionKey k) {<br>Runnable r = (Runnable)(k.attachment());<br>if (r != null)<br>r.run();<br>}<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Reactor 3: Acceptor<br> // class Reactor continued<br>class Acceptor implements Runnable { // inner<br>public void run() {<br>try {<br>SocketChannel c = serverSocket.accept();<br>if (c != null)<br>new Handler(selector, c);<br>}<br>catch(IOException ex) { /<em> … </em>/ }<br>}<br>}<br>}<br>client<br>client<br>client<br>read decode compute encode send<br>read decode compute encode send<br>read decode compute encode send<br>Reactor<br>acceptor<br>dispatch<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Reactor 4: Handler setup<br>final class Handler implements Runnable {<br>final SocketChannel socket;<br>final SelectionKey sk;<br>ByteBuffer input = ByteBuffer.allocate(MAXIN);<br>ByteBuffer output = ByteBuffer.allocate(MAXOUT);<br>static final int READING = 0, SENDING = 1;<br>int state = READING;<br>Handler(Selector sel, SocketChannel c)<br>throws IOException {<br>socket = c; c.configureBlocking(false);<br>// Optionally try first read now<br>sk = socket.register(sel, 0);<br>sk.attach(this);<br>sk.interestOps(SelectionKey.OP_READ);<br>sel.wakeup();<br>}<br>boolean inputIsComplete() { /<em> … </em>/ }<br>boolean outputIsComplete() { /<em> … </em>/ }<br>void process() { /<em> … </em>/ }<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Reactor 5: Request handling<br> // class Handler continued<br>public void run() {<br>try {<br>if (state == READING) read();<br>else if (state == SENDING) send();<br>} catch (IOException ex) { /<em> … </em>/ }<br>}<br>void read() throws IOException {<br>socket.read(input);<br>if (inputIsComplete()) {<br>process();<br>state = SENDING;<br>// Normally also do first write now<br>sk.interestOps(SelectionKey.OP_WRITE);<br>}<br>}<br>void send() throws IOException {<br>socket.write(output);<br>if (outputIsComplete()) sk.cancel();<br>}<br>}<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Per-State Handlers<br>“ A simple use of GoF State-Object pattern<br>Rebind appropriate handler as attachment<br>class Handler { // …<br>public void run() { // initial state is reader<br>socket.read(input);<br>if (inputIsComplete()) {<br>process();<br>sk.attach(new Sender());<br>sk.interest(SelectionKey.OP_WRITE);<br>sk.selector().wakeup();<br>}<br>}<br>class Sender implements Runnable {<br>public void run(){ // …<br>socket.write(output);<br>if (outputIsComplete()) sk.cancel();<br>}<br>}<br>}<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Multithreaded Designs<br>“ Strategically add threads for scalability<br>Mainly applicable to multiprocessors<br>“ Worker Threads<br>Reactors should quickly trigger handlers<br>“ Handler processing slows down Reactor<br>Offload non-IO processing to other threads<br>“ Multiple Reactor Threads<br>Reactor threads can saturate doing IO<br>Distribute load to other reactors<br>“ Load-balance to match CPU and IO rates<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Worker Threads<br>“ Offload non-IO processing to speed up<br>Reactor thread<br>Similar to POSA2 Proactor designs<br>“ Simpler than reworking compute-bound<br>processing into event-driven form<br>Should still be pure nonblocking computation<br>“ Enough processing to outweigh overhead<br>“ But harder to overlap processing with IO<br>Best when can first read all input into a buffer<br>“ Use thread pool so can tune and control<br>Normally need many fewer threads than clients<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Worker Thread Pools<br>client<br>client<br>client<br>read<br>decode compute encode<br>send<br>read<br>decode compute encode<br>send<br>read<br>decode compute encode<br>send<br>Reactor<br>Thread<br>Pool<br>worker<br>threads<br>acceptor<br>queued tasks<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Handler with Thread Pool<br> class Handler implements Runnable {<br> // uses util.concurrent thread pool<br> static PooledExecutor pool = new PooledExecutor(…);<br> static final int PROCESSING = 3;<br> // …<br> synchronized void read() { // …<br> socket.read(input);<br> if (inputIsComplete()) {<br> state = PROCESSING;<br> pool.execute(new Processer());<br> }<br> }<br> synchronized void processAndHandOff() {<br> process();<br> state = SENDING; // or rebind attachment<br> sk.interest(SelectionKey.OP_WRITE);<br> }<br> class Processer implements Runnable {<br> public void run() { processAndHandOff(); }<br> }<br>}<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Coordinating Tasks<br>“ Handoffs<br>Each task enables, triggers, or calls next one<br>Usually fastest but can be brittle<br>“ Callbacks to per-handler dispatcher<br>Sets state, attachment, etc<br>A variant of GoF Mediator pattern<br>“ Queues<br>For example, passing buffers across stages<br>“ Futures<br>When each task produces a result<br>Coordination layered on top of join or wait/notify<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Using PooledExecutor<br>“ A tunable worker thread pool<br>“ Main method execute(Runnable r)<br>“ Controls for:<br>The kind of task queue (any Channel)<br>Maximum number of threads<br>Minimum number of threads<br>“Warm” versus on-demand threads<br>Keep-alive interval until idle threads die<br>“ to be later replaced by new ones if necessary<br>Saturation policy<br>“ block, drop, producer-runs, etc<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Multiple Reactor Threads<br>“ Using Reactor Pools<br>Use to match CPU and IO rates<br>Static or dynamic construction<br>“ Each with own Selector, Thread, dispatch loop<br>Main acceptor distributes to other reactors<br>Selector[] selectors; // also create threads<br>int next = 0;<br>class Acceptor { // …<br>public synchronized void run() { …<br>Socket connection = serverSocket.accept();<br>if (connection != null)<br>new Handler(selectors[next], connection);<br>if (++next == selectors.length) next = 0;<br>}<br>}<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Using Multiple Reactors<br>client<br>client<br>client<br>read<br>decode compute encode<br>send<br>read<br>decode compute encode<br>send<br>read<br>decode compute encode<br>send<br>mainReactor<br>Thread<br>Pool<br>worker<br>threads<br>acceptor<br>queued tasks<br>subReactor<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Using other java.nio features<br>“ Multiple Selectors per Reactor<br>To bind different handlers to different IO events<br>May need careful synchronization to coordinate<br>“ File transfer<br>Automated file-to-net or net-to-file copying<br>“ Memory-mapped files<br>Access files via buffers<br>“ Direct buffers<br>Can sometimes achieve zero-copy transfer<br>But have setup and finalization overhead<br>Best for applications with long-lived connections<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Connection-Based Extensions<br>“ Instead of a single service request,<br>Client connects<br>Client sends a series of messages/requests<br>Client disconnects<br>“ Examples<br>Databases and Transaction monitors<br>Multi-participant games, chat, etc<br>“ Can extend basic network service patterns<br>Handle many relatively long-lived clients<br>Track client and session state (including drops)<br>Distribute services across multiple hosts<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>API Walkthrough<br>“ Buffer<br>“ ByteBuffer<br>(CharBuffer, LongBuffer, etc not shown.)<br>“ Channel<br>“ SelectableChannel<br>“ SocketChannel<br>“ ServerSocketChannel<br>“ FileChannel<br>“ Selector<br>“ SelectionKey<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Buffer<br> abstract class Buffer {<br> int capacity();<br> int position();<br> Buffer position(int newPosition);<br> int limit();<br> Buffer limit(int newLimit);<br> Buffer mark();<br> Buffer reset();<br> Buffer clear();<br> Buffer flip();<br> Buffer rewind();<br> int remaining();<br> boolean hasRemaining();<br> boolean isReadOnly();<br>}<br>position limit capacity<br>mark<br>a b c<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>ByteBuffer (1)<br> abstract class ByteBuffer extends Buffer {<br> static ByteBuffer allocateDirect(int capacity);<br> static ByteBuffer allocate(int capacity);<br> static ByteBuffer wrap(byte[] src, int offset, int len);<br> static ByteBuffer wrap(byte[] src);<br> boolean isDirect();<br> ByteOrder order();<br> ByteBuffer order(ByteOrder bo);<br> ByteBuffer slice();<br> ByteBuffer duplicate();<br> ByteBuffer compact();<br> ByteBuffer asReadOnlyBuffer();<br> byte get();<br> byte get(int index);<br> ByteBuffer get(byte[] dst, int offset, int length);<br> ByteBuffer get(byte[] dst);<br> ByteBuffer put(byte b);<br> ByteBuffer put(int index, byte b);<br> ByteBuffer put(byte[] src, int offset, int length);<br> ByteBuffer put(ByteBuffer src);<br> ByteBuffer put(byte[] src);<br> char getChar();<br> char getChar(int index);<br> ByteBuffer putChar(char value);<br> ByteBuffer putChar(int index, char value);<br> CharBuffer asCharBuffer();<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>ByteBuffer (2)<br> short getShort();<br> short getShort(int index);<br> ByteBuffer putShort(short value);<br> ByteBuffer putShort(int index, short value);<br> ShortBuffer asShortBuffer();<br> int getInt();<br> int getInt(int index);<br> ByteBuffer putInt(int value);<br> ByteBuffer putInt(int index, int value);<br> IntBuffer asIntBuffer();<br> long getLong();<br> long getLong(int index);<br> ByteBuffer putLong(long value);<br> ByteBuffer putLong(int index, long value);<br> LongBuffer asLongBuffer();<br> float getFloat();<br> float getFloat(int index);<br> ByteBuffer putFloat(float value);<br> ByteBuffer putFloat(int index, float value);<br> FloatBuffer asFloatBuffer();<br> double getDouble();<br> double getDouble(int index);<br> ByteBuffer putDouble(double value);<br> ByteBuffer putDouble(int index, double value);<br> DoubleBuffer asDoubleBuffer();<br>}<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Channel<br> interface Channel {<br> boolean isOpen();<br> void close() throws IOException;<br>}<br>interface ReadableByteChannel extends Channel {<br> int read(ByteBuffer dst) throws IOException;<br>}<br>interface WritableByteChannel extends Channel {<br> int write(ByteBuffer src) throws IOException;<br>}<br>interface ScatteringByteChannel extends ReadableByteChannel {<br> int read(ByteBuffer[] dsts, int offset, int length)<br> throws IOException;<br> int read(ByteBuffer[] dsts) throws IOException;<br>}<br>interface GatheringByteChannel extends WritableByteChannel {<br> int write(ByteBuffer[] srcs, int offset, int length)<br> throws IOException;<br> int write(ByteBuffer[] srcs) throws IOException;<br>}<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>SelectableChannel</p>
<p>abstract class SelectableChannel implements Channel {<br> int validOps();<br> boolean isRegistered();<br> SelectionKey keyFor(Selector sel);<br> SelectionKey register(Selector sel, int ops)<br> throws ClosedChannelException;<br> void configureBlocking(boolean block)<br> throws IOException;<br> boolean isBlocking();<br> Object blockingLock();<br>}<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>SocketChannel<br> abstract class SocketChannel implements ByteChannel … {<br> static SocketChannel open() throws IOException;<br> Socket socket();<br> int validOps();<br> boolean isConnected();<br> boolean isConnectionPending();<br> boolean isInputOpen();<br> boolean isOutputOpen();<br> boolean connect(SocketAddress remote) throws IOException;<br> boolean finishConnect() throws IOException;<br> void shutdownInput() throws IOException;<br> void shutdownOutput() throws IOException;<br> int read(ByteBuffer dst) throws IOException;<br> int read(ByteBuffer[] dsts, int offset, int length)<br> throws IOException;<br> int read(ByteBuffer[] dsts) throws IOException;<br> int write(ByteBuffer src) throws IOException;<br> int write(ByteBuffer[] srcs, int offset, int length)<br> throws IOException;<br> int write(ByteBuffer[] srcs) throws IOException;<br>}<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>ServerSocketChannel</p>
<p>abstract class ServerSocketChannel extends … {<br> static ServerSocketChannel open() throws IOException;<br> int validOps();<br> ServerSocket socket();<br> SocketChannel accept() throws IOException;<br>}<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>FileChannel<br> abstract class FileChannel implements … {<br> int read(ByteBuffer dst);<br> int read(ByteBuffer dst, long position);<br> int read(ByteBuffer[] dsts, int offset, int length);<br> int read(ByteBuffer[] dsts);<br> int write(ByteBuffer src);<br> int write(ByteBuffer src, long position);<br> int write(ByteBuffer[] srcs, int offset, int length);<br> int write(ByteBuffer[] srcs);<br> long position();<br> void position(long newPosition);<br> long size();<br> void truncate(long size);<br> void force(boolean flushMetaDataToo);<br> int transferTo(long position, int count,<br> WritableByteChannel dst);<br> int transferFrom(ReadableByteChannel src,<br> long position, int count);<br> FileLock lock(long position, long size, boolean shared);<br> FileLock lock();<br> FileLock tryLock(long pos, long size, boolean shared);<br> FileLock tryLock();<br> static final int MAP_RO, MAP_RW, MAP_COW;<br> MappedByteBuffer map(int mode, long position, int size);<br>}<br>NOTE: ALL methods throw IOException<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>Selector<br> abstract class Selector {<br> static Selector open() throws IOException;<br> Set keys();<br> Set selectedKeys();<br> int selectNow() throws IOException;<br> int select(long timeout) throws IOException;<br> int select() throws IOException;<br> void wakeup();<br> void close() throws IOException;<br>}<br><a href="http://gee.cs.oswego.edu" target="_blank" rel="external">http://gee.cs.oswego.edu</a><br>SelectionKey<br> abstract class SelectionKey {<br> static final int OP_READ, OP_WRITE,<br> OP_CONNECT, OP_ACCEPT;<br> SelectableChannel channel();<br> Selector selector();<br> boolean isValid();<br> void cancel();<br> int interestOps();<br> void interestOps(int ops);<br> int readyOps();<br> boolean isReadable();<br> boolean isWritable();<br> boolean isConnectable();<br> boolean isAcceptable();<br> Object attach(Object ob);<br> Object attachment();<br>}</p>
]]></content>
      
        <categories>
            
            <category> Netty </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Netty </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Netty Handler Chain]]></title>
      <url>/2020/01/04/netty-handler-chain/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Netty </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Netty </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Netty Encoder and Decoder]]></title>
      <url>/2020/01/04/netty-encoder-and-decoder/</url>
      <content type="html"><![CDATA[<p>我们在网络编程时，数据在网络中通常都是以字节码的形式传输的，而到了应用程序，需要将字节码转化成业务能够理解的形式，这个过程就是编解码。Netty 作为一个通用的网络编程框架，也提供了一些通用的抽象来帮助我们实现编解码工作。<br>编解码是编码和解码的统称，我们在发送数据之前，需要将数据进行编码，在收到数据后，在按照对应的方式解码。我们可以通过一个例子来了解 Netty 中的编解码器。<br>客户端和服务器之间通过 channel 进行通信，数据发送到 channel 叫做出站，从 channel 取出数据叫做入站。因此，首先客户端发送一个 Long 类型的数据，出将 Long 类型转换成 ByteBuf ，这个过程是编码，入站从 channel 中读取 ByteBuf 转换成 Long 这个过程是解码。我们需要实现一个 Long 到 ByteBuf 的编码器和一个 ByteBuf 到 Long 的解码器。<br>编码器比较简单，直接使用 ByteBuf 的 writeLong 发送数据。</p>
<pre><code>public class MyLongToByteEncoder extends MessageToByteEncoder&lt;Long&gt; {
    @Override
    protected void encode(ChannelHandlerContext ctx, Long msg, ByteBuf out) throws Exception {
        System.out.println(&quot;MyLongToByteEncoder的encode方法执行，将&quot; + msg + &quot;(Long)转成Byte&quot;);
        out.writeLong(msg);
    }
}
</code></pre><p>入站解码的时候需要按照 Long 类型的格式来读取数据，所以首先需要判断数据是否够 8 个字节，如果够 8 个字节，才能正确处理。</p>
<pre><code>public class MyByteToLongDecoder extends ByteToMessageDecoder {
    @Override
    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception {
        System.out.println(&quot;MyByteToLongDecoder的decode执行，将Byte转成Long&quot;);
        if (in.readableBytes() &gt;= 8) {
            out.add(in.readLong());
        }
    }
}
</code></pre><p>写完之后在将编码器加入到客户端的 pipeline 中，将解码器加入到服务端的 pipeline 中。<br>由于 Netty 提供了一些抽象类，我们只需要实现这些类来重写我们自己实现，就可以完成相应的功能，所以整个过程编码相当简单。正如我们看到的，我们自己的 Encoder 继承 MessageToByteEncoder ，这是一个 Netty 提供的抽象类。</p>
<pre><code>public abstract class MessageToByteEncoder&lt;I&gt; extends ChannelOutboundHandlerAdapter {
}
</code></pre><p>它继承了 ChannelOutboundHandlerAdapter ，对应 bind、connect、read、write 等操作都已经实现好了，我们只需要根据自己的需要重写 encode 方法即可。根据名字我们可以知道，通过 encode 方法可以将 message 转成 byte 。encode 方法有三个参数，ChannelHandlerContext ctx 是上下文，I msg 是需要 encode 的数据， ByteBuf out 是转换之后的 ByteBuf 对象。MessageToByteEncoder 接收一个泛型用于指定将什么类型的数据转成 byte 。</p>
<p>同样的道理，Decoder 继承了另一个抽象类 ByteToMessageDecoder 。ByteToMessageDecoder 又继承了 ChannelInboundHandlerAdapter</p>
<pre><code>public abstract class ByteToMessageDecoder extends ChannelInboundHandlerAdapter {
}
</code></pre><p>重写 decode 方法可以将 byte 转换成我们需要的格式，比如例子中的 Long 。decode 方法也有三个参数，ChannelHandlerContext ctx 是上下文， ByteBuf in 是读取的 ByteBuf 对象，List<object> out 用来存放解码处理后的数据，比如我们发送了两个 Long 类型的消息，那么就会每次读取 8 个长度的 byte 转成 Long 然后放到集合中，最终集合中放的就是 2 个 Long 类型的数据，这些数据会被传递给 pipeline 的下一个 handler 进行处理。</object></p>
<p>上边的示例中，我们使用 ByteToMessageDecoder 的 decode 方法时需要按照数据的长度进行判断，以保证数据解析正确，这样还是有一些麻烦，Netty 还提供了另外一个类可以帮助我们简化这个操作。</p>
<pre><code>public class MyByteToLongDecoder extends ReplayingDecoder&lt;Void&gt; {
    @Override
    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception {
        System.out.println(&quot;MyByteToLongDecoder的decode执行，将Byte转成Long&quot;);
        out.add(in.readLong());
    }
}
</code></pre><p>ReplayingDecoder 继承自 ByteToMessageDecoder，可以帮我们在读取缓冲区的数据之前需要检查缓冲区是否有足够的字节，而不用我们自己检查。</p>
<pre><code>public abstract class ReplayingDecoder&lt;S&gt; extends ByteToMessageDecoder {
</code></pre><p>简单来看，继承 ByteToMessageDecoder 和继承 ReplayingDecoder 除了用户自己判断数据长度之外，其他操作都是一样的。但是使用 ReplayingDecoder 还是要注意，比如下面这个例子。</p>
<pre><code>public class MyDecoder extends ReplayingDecoder&lt;Void&gt; {

    private final Queue&lt;Integer&gt; values = new LinkedList&lt;Integer&gt;();

    @Override
    public void decode(ChannelHandlerContext ctx, ByteBuf buf, List&lt;Object&gt; out) throws Exception {

        // A message contains 2 integers.
        values.offer(buf.readInt());
        values.offer(buf.readInt());

        // This assertion will fail intermittently since values.offer()
        // can be called more than two times!
        assert values.size() == 2;
        out.add(values.poll() + values.poll());
    }

}
</code></pre><p>这个 Decoder 的作用是先读取两个 int 放到队列中，如果读到 2 个 int 再将 2 个 int 都取出来相加，将结果交给下一个 handler 处理。看上去很简单，但是实际上是无法正确执行的。这和 ReplayingDecoder 的处理机制有关。简单来说 ReplayingDecoder 就是不断的读取 ByteBuf ，如果没有读到想要的数据，就抛出异常，然后捕获异常，重置位置后重新再次读取。所以上边的示例中，当第二次读取不够 int 长度时，会再次调用 decode 重新读取，直到读取了两个 int ，但是由于之前第一个 int 已经读到并加入到 Queue<integer> 中了，当第二次读取到 2 个 int 时，Queue<integer> 中已经有 3 个 int 了，assert values.size() == 2; 的断言就永远无法成功，所以需要在第一次读取之前先清空之前的数据才能保证程序正确执行。</integer></integer></p>
<p>除了上边的几种编解码器之外，Netty 还提供了一组编解码器 MessageToMessageEncoder 和 MessageToMessageDecoder 用于格式之间转换，使用方法和其他编解码器类似。</p>
]]></content>
      
        <categories>
            
            <category> Netty </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Netty </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[packet sticking and unpacking]]></title>
      <url>/2020/01/04/packet-sticking-and-unpacking/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Netty </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Netty </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Netty Core Concepts]]></title>
      <url>/2020/01/04/netty-core-concepts/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Netty </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Netty </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Netty Asynchronous Task]]></title>
      <url>/2020/01/04/netty-asynchronous-task/</url>
      <content type="html"><![CDATA[<p>Netty 的 handler 在处理消息时，如果业务比较耗时，响应会阻塞直到业务处理完成。在这样的场景下，通常会将业务处理提交到任务队列异步执行，而让 handler 可以快速返回。<br>比如可以将业务提交到 EventLoop 中的 taskQueue 。</p>
<pre><code>public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
    ByteBuf byteBuf = (ByteBuf) msg;
    System.out.println(&quot;收到客户端请求：&quot; + byteBuf.toString(CharsetUtil.UTF_8));
    // 提交到eventLoop的tackQueue
    ctx.channel().eventLoop().execute(new Runnable() {
        @Override
        public void run() {
            myTask1();
        }
    });
}
</code></pre><p>还可以提交到定时任务队列中。</p>
<pre><code>public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {
    ByteBuf byteBuf = (ByteBuf) msg;
    System.out.println(&quot;收到客户端请求：&quot; + byteBuf.toString(CharsetUtil.UTF_8));
    // 提交到eventLoop的scheduledTaskQueue
    ctx.channel().eventLoop().schedule(new Runnable() {
        @Override
        public void run() {
            myTask2();
        }
    }, 0, TimeUnit.SECONDS);
}
</code></pre><p>任务可以提交多个，如果提交了多个任务，那么任务会在队列中排队，顺序执行。如果同时提交了 taskQueue 和 scheduledTaskQueue ，任务不会并行执行。</p>
]]></content>
      
        <categories>
            
            <category> Netty </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Netty </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Netty Introduction]]></title>
      <url>/2020/01/04/netty-introduction/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Netty </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Netty </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Netty IO Model]]></title>
      <url>/2020/01/04/netty-io-model/</url>
      <content type="html"><![CDATA[<p>在传统的 JavaIO 网络编程中，我们使用的是阻塞 IO 模型，即一个线程只对应一个客户端，单个线程负责客户端的连接及读写事件。</p>
<p><img src="https://s2.ax1x.com/2020/02/27/3axaVA.png" alt="3axaVA.png" border="0" style="width:700px"></p>
<p>显而易见，阻塞 IO 模型具有诸多缺点：</p>
<ol>
<li>每个客户端都需要有一个线程，并且没有 IO 操作也不能释放，导致消耗大量的服务器资源；</li>
<li>服务器资源有限，无法承载大量的客户端请求；</li>
<li>线程间等待、唤醒，切换上下文会严重的消耗 cpu 资源。 </li>
</ol>
<p>所以，针对阻塞问题，Java NIO 引入了事件驱动模型。</p>
<p><img src="https://s2.ax1x.com/2020/02/27/3axdUI.png" alt="3axdUI.png" border="0" style="width:750px"></p>
<p>在 NIO 模型中，使用 selector 来维护客户端和服务器之间的通道 channel ，当有事件触发，selector 根据 selectKey 找到对应的通道进行处理，这样解决了线程阻塞的问题，但是这个模型相对复杂，编程难度比较高。</p>
<p>Reactor 模式是事件驱动的一种实现，它包含两个部分：reactor 和 handler 。reactor 使用单线程循环监听连接事件，并将请求分发给相应的 handler 进行处理，处理完成通过回调程序返回结果。下图就是<strong>基本 reactor 模型</strong>。</p>
<p><img src="https://s2.ax1x.com/2020/02/27/3axWan.png" alt="3axWan.png" border="0" style="width:750px"></p>
<p>和 NIO 模型类似，Reactor 模型让多个客户端复用一个 acceptor ，减少了阻塞造成的线程资源浪费。在没有连接事件时，线程可以进行 handler 处理。 处理完成后，线程不用销毁，可以处理新的分发任务，提高系统的处理能力。虽然减少了线程连接时的阻塞消耗，但是一个线程无法同时处理 accept 和 handler ，所以这种基本模型不适合 handler 业务比较耗时的场景。<br>为了能够充分的利用系统资源，又对 reactor 模型进行了改进，这就是<strong>单 reactor 多线程模型</strong>，如下图所示。</p>
<p><img src="https://s2.ax1x.com/2020/02/27/3ax6Kg.png" alt="3ax6Kg.png" border="0" style="width:800px"></p>
<p>在多线程模式中，handler 只负责响应事件，收到事件后将任务分配给线程池中的工作线程，这样任务处理是异步的，处理完成后由回调函数返回结果，不会影响线程处理新的 accept 事件，这样就进一步减少了线程阻塞。但是在单 reactor 多线程模型中，由于 reactor 是既要处理连接，又要将请求分发给 handler ，所以请求量大时，会有性能瓶颈，因此对进一步改进出现了<strong>主从 reactor 模型</strong>。</p>
<p><img src="https://s2.ax1x.com/2020/02/27/3axD8f.png" alt="3axD8f.png" border="0" style="width:800px"></p>
<p>主从 reactor 模型是在单 reactor 多线程模型基础上，对 reactor 进行了功能区分，主 reactor 只负责处理 accept 事件，接收到请求后将连接分配给子 reactor 。 子 reactor 负责将事件分发给 handler，handler 再将事件分发给 worker 线程池中的线程来处理，处理结果由回调方法返回，这样就进一步提高了服务器的处理能力。</p>
<p>Netty 模型是在主从 reactor 模型的基础上演化而来的，如下图所示。</p>
<p><img src="https://s2.ax1x.com/2020/02/27/3axgbj.png" alt="3axgbj.png" border="0" style="width:550px"></p>
<p>BossGroup 相当于主 reactor， WorkerGroup 相当于子 reactor 。每个 group 中都有多个不断循环处理事件的线程 NioEventLoop 。BossGroup 只处理 accept 事件，将 WorkerGroup 中的 NioEventLoop 注册到 selector 。WorkerGroup 中的 NioEventLoop 负责处理读写事件。每个 NioEventLoop 中都维护了一个 pipeline ，用来维护 handler 。 </p>
]]></content>
      
        <categories>
            
            <category> Netty </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Zero Copy]]></title>
      <url>/2020/01/04/zero-copy/</url>
      <content type="html"><![CDATA[<p>零拷贝是网络 IO 的一个概念。在了解零拷贝之前，我们先来看一个简单的问题。我们经常会遇到需要将硬盘中的一个文件拷贝到另外的地方去，这是一个非常简单而且常见的场景，使用 JavaIO 很容易就可以实现。我们知道，Java 程序最终也是调用操作系统的 read() 和 write() 方法来实现的。虽然看起来很简单，但是这两步操作却经历了 4 次拷贝和 4 次上下文切换。</p>
<p><img src="https://s2.ax1x.com/2020/02/27/3azRyD.png" alt="20200115132437" border="0" style="width:600px;"></p>
<p>如上图所示，第一步，用户程序调用系统的 read() 方法，上下文从用户模式切换到内核模式，系统通过DMA拷贝，将文件内容从磁盘上读取出来，写到内核缓冲区。<br>第二步，数据从内核缓冲区通过 cpu 拷贝复制到用户缓冲区，然后 read() 方法返回，上下文从内核模式切换到用户模式。<br>第三步，调用系统的 write() 方法，上下文从用户模式切换到内核模式，同时通过 cpu 拷贝将数据放到套接字关联的缓冲区中。<br>第四步，系统通过 DMA 拷贝将数据写到协议栈中，write() 方法返回，上下文从内核模式切换到用户模式。</p>
<blockquote>
<p>cpu 拷贝：计算机中内存的读写操作需要 cpu 来协调数据总线、地址总线和控制总线共同完成。所以在发生读写操作的时候，cpu 往往需要停下来，协助内存协调总线资源，因此叫做 cpu 拷贝。<br>DMA 拷贝：Direct Memory Access ，在计算机中，当需要和外设进行数据交换时，cpu 需要进行初始化，再外设和内存之间传输不需要 cpu 参与。<br>上下文切换：操作系统为了保护系统不被破坏，为操作系统设置了两种状态：用户状态和内核状态。当用户需要访问系统资源时，需要通过系统调用，从用户状态进入到内核状态，调用完成后再由内核状态回到用户状态，两种状态的转换就是所说的上下文切换。</p>
</blockquote>
<p>可以看到，一个简单的文件复制，实际也是经历复杂 cpu 和内存操作。为了能够节省系统资源和提高性能，Linux 系统进行了 mmap 优化。</p>
<p><img src="https://s2.ax1x.com/2020/02/27/3azgSK.png" alt="20200115132526" border="0" style="width:600px;"></p>
<p>如上图所示，第一步，用户程序调用系统的 read() 方法，上下文从用户模式切换到内核模式，系统通过 DMA 拷贝，将文件内容从磁盘上读取出来，写到内核缓冲区。然后与用户进程共享该缓冲区，而不需要进行 CPU 拷贝，read() 方法返回，上下文从内核模式切换到用户模式。<br>第二步，调用系统的 write() 方法，上下文从用户模式切换到内核模式，同时将数据放到套接字关联的缓冲区中。<br>第三步，系统通过 DMA 拷贝将数据写到协议栈中，write() 方法返回，上下文从内核模式切换到用户模式。</p>
<p>通过 mmap 优化，减少了一次 cpu 拷贝，但是还是有 3 次拷贝和 4 次上下文切换。<br>在 Linux 内核 2.1 版本中又进一步优化，引入了 sendfile 。</p>
<p><img src="https://s2.ax1x.com/2020/02/27/3azBw9.png" alt="20200115132644" border="0" style="width:600px;"></p>
<p>如上图所示，第一步，用户程序调用系统的 sendfile 操作，使用 DMA 拷贝将文件内容从磁盘复制到内核缓冲区。<br>第二步，通过 cpu 拷贝将数据从内核缓冲区复制到套接字关联的缓冲区。<br>第三步，通过 DMA 拷贝将数据从套接字缓冲区放到协议栈中，然后上下文从内核模式切换到用户模式。</p>
<p>到目前位置，整个过程还是经历了 2 次 DMA 拷贝和 1 次 cpu 拷贝，以及 2 次上下文切换。<br>到了内核 2.4 版本中，Linux 对套接字缓冲区描述符进行了修改，不再将内核缓冲区中的数据拷贝到套接字缓冲区中，而只是将数据的长度等信息添加到套接字缓冲区中，这些信息大小几乎可以忽略不记，从而又减少了一次 cpu 拷贝，如下图所示。</p>
<p><img src="https://s2.ax1x.com/2020/02/27/3azsF1.png" alt="20200115132723" border="0" style="width:600px;"></p>
<p>第一步，用户程序调用系统的 sendfile 操作，使用 DMA 拷贝将文件内容从磁盘复制到内核缓冲区，将数据的长度等信息写到套接字缓冲区。<br>第二步，通过 DMA 拷贝将数据从套接字缓冲区放到协议栈中，然后上下文从内核模式切换到用户模式。</p>
<p>最终，整个过程只进行了 2 次 DMA 拷贝，没有 cpu 拷贝，这就是我们所说的零拷贝。因此我们看到，零拷贝并不是整个系统没有拷贝的操作，而是整个过程没有消耗 cpu 资源的拷贝操作。</p>
]]></content>
      
        <categories>
            
            <category> Netty </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
            <tag> NIO </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[How to Set Up MySQL Master Slave Replication in Docker]]></title>
      <url>/2019/12/03/how-to-set-up-mysql-master-slave-replication-in-docker/</url>
      <content type="html"><![CDATA[<p>使用 docker 可以快速的搭建 mysql 主从复制环境，便于我们快速开发。接下来就让我们看看如何操作。</p>
<h4 id="1-准备-my-cnf-文件"><a href="#1-准备-my-cnf-文件" class="headerlink" title="1. 准备 my.cnf 文件"></a>1. 准备 my.cnf 文件</h4><p>准备两份 my.cnf 文件，这样做的好处是我们可以在启动 docker 镜像的时候挂载而不用登录到 docker 镜像内部去修改 my.cnf 文件，而且镜像删除配置信息也不会丢失。<br>master:</p>
<pre><code>[mysqld]
server_id = 1
log-bin= mysql-bin
read-only=0

replicate-ignore-db=mysql
replicate-ignore-db=sys
replicate-ignore-db=information_schema
replicate-ignore-db=performance_schema

!includedir /etc/mysql/conf.d/
!includedir /etc/mysql/mysql.conf.d/
</code></pre><p>slave:</p>
<pre><code>[mysqld]
server_id = 2
log-bin= mysql-bin
read-only=1

replicate-ignore-db=mysql
replicate-ignore-db=sys
replicate-ignore-db=information_schema
replicate-ignore-db=performance_schema

!includedir /etc/mysql/conf.d/
!includedir /etc/mysql/mysql.conf.d/
</code></pre><h4 id="2-创建镜像"><a href="#2-创建镜像" class="headerlink" title="2. 创建镜像"></a>2. 创建镜像</h4><pre><code>docker run --name mysql-master -d -p 3307:3306 -e MYSQL_ROOT_PASSWORD=123456 -v D:/Dev/mysql/master/data:/var/lib/mysql -v D:/Dev/mysql/master/conf/my.cnf:/etc/mysql/my.cnf mysql:5.7
</code></pre><pre><code>docker run --name mysql-slave -d -p 3308:3306 -e MYSQL_ROOT_PASSWORD=123456 -v D:/Dev/mysql/slave/data:/var/lib/mysql -v D:/Dev/mysql/slave/conf/my.cnf:/etc/mysql/my.cnf mysql:5.7
</code></pre><p>如果本地没有镜像，docker 会先下载。</p>
<h4 id="3-在-master-上创建主从复制用户"><a href="#3-在-master-上创建主从复制用户" class="headerlink" title="3. 在 master 上创建主从复制用户"></a>3. 在 master 上创建主从复制用户</h4><p>登录到 mysql-master </p>
<pre><code>docker exec -it mysql-master /bin/bash
</code></pre><p>登录到 mysql</p>
<pre><code>mysql -uroot -p123456
</code></pre><p>创建用户 slave 用来同步数据</p>
<pre><code>CREATE USER &#39;slave&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;;

GRANT REPLICATION SLAVE ON *.* to &#39;slave&#39;@&#39;%&#39; identified by &#39;123456&#39;;
</code></pre><p>查看 master 信息</p>
<pre><code>mysql&gt; show master status\G;
*************************** 1. row ***************************
             File: mysql-bin.000003
         Position: 684
     Binlog_Do_DB:
 Binlog_Ignore_DB:
Executed_Gtid_Set:
1 row in set (0.00 sec)
</code></pre><p>File 和 Position 的值需要记录下来，在配置 salve 的时候会用到。</p>
<h4 id="4-在-slave-上配置同步信息"><a href="#4-在-slave-上配置同步信息" class="headerlink" title="4. 在 slave 上配置同步信息"></a>4. 在 slave 上配置同步信息</h4><p>登录到 mysql-slave </p>
<pre><code>docker exec -it mysql-slave /bin/bash
</code></pre><p>登录 mysql</p>
<pre><code>mysql -uroot -p123456
</code></pre><p>设置同步配置</p>
<pre><code>change master to master_host=&#39;172.17.0.3&#39;,master_user=&#39;slave&#39;,master_password=&#39;123456&#39;,master_log_file=&#39;mysql-bin.000003&#39;,master_log_pos=684,master_port=3306;
</code></pre><blockquote>
<p>这里有几个点需要注意：</p>
<ol>
<li>master_host 是 mysql-master 的 IP ，可用 docker inspect –format=’{ { .NetworkSettings.IPAddress } }’ mysql-master 查看。</li>
<li>master_log_file 和 master_log_pos 要和 mysql-master 的信息一致。</li>
<li>master_port docker 镜像之间通信走的是 docker 内部的网络，所以端口是 3306 而不是 3307 。</li>
</ol>
</blockquote>
<p>启动主从同步</p>
<pre><code>start slave;
</code></pre><p>查看 slave 状态</p>
<pre><code>mysql&gt; show slave status\G;                                                            
*************************** 1. row ***************************                         
               Slave_IO_State: Waiting for master to send event                        
                  Master_Host: 172.17.0.3                   
                  Master_User: slave                         
                  Master_Port: 3306                         
                Connect_Retry: 60                           
              Master_Log_File: mysql-bin.000003             
          Read_Master_Log_Pos: 684                           
               Relay_Log_File: c491b3d4773f-relay-bin.000002 
                Relay_Log_Pos: 320                           
        Relay_Master_Log_File: mysql-bin.000003             
             Slave_IO_Running: Yes                           
            Slave_SQL_Running: Yes                           
              Replicate_Do_DB:                               
          Replicate_Ignore_DB: mysql,sys,information_schema,performance_schema         
           Replicate_Do_Table:                               
       Replicate_Ignore_Table:                               
      Replicate_Wild_Do_Table:                               
  Replicate_Wild_Ignore_Table:                               
                   Last_Errno: 0                             
                   Last_Error:                               
                 Skip_Counter: 0                             
          Exec_Master_Log_Pos: 684                           
              Relay_Log_Space: 534                           
              Until_Condition: None                         
               Until_Log_File:                               
                Until_Log_Pos: 0                             
           Master_SSL_Allowed: No                           
           Master_SSL_CA_File:                               
           Master_SSL_CA_Path:                               
              Master_SSL_Cert:                               
            Master_SSL_Cipher:                               
               Master_SSL_Key:                               
        Seconds_Behind_Master: 0                             
Master_SSL_Verify_Server_Cert: No                           
                Last_IO_Errno: 0                             
                Last_IO_Error:                               
               Last_SQL_Errno: 0                             
               Last_SQL_Error:                               
  Replicate_Ignore_Server_Ids:                               
             Master_Server_Id: 1                             
                  Master_UUID: fd482d37-146c-11ea-9944-0242ac110003                    
             Master_Info_File: /var/lib/mysql/master.info   
                    SQL_Delay: 0                             
          SQL_Remaining_Delay: NULL                         
      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates  
           Master_Retry_Count: 86400                         
                  Master_Bind:                               
      Last_IO_Error_Timestamp:                               
     Last_SQL_Error_Timestamp:                               
               Master_SSL_Crl:                               
           Master_SSL_Crlpath:                               
           Retrieved_Gtid_Set:                               
            Executed_Gtid_Set:                               
                Auto_Position: 0                             
         Replicate_Rewrite_DB:                               
                 Channel_Name:                               
           Master_TLS_Version:                               
1 row in set (0.00 sec)
</code></pre><p>Slave_IO_Running 和 Slave_SQL_Running 都为 YES 则配置成功。</p>
<blockquote>
<p>如果 Slave_IO_Running 为 connecting 可根据  Last_IO_Error 检查</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
            <tag> MySQL </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[springMVC 执行流程]]></title>
      <url>/2019/12/02/springmvc-execution-flow/</url>
      <content type="html"><![CDATA[<p><img src="https://s2.ax1x.com/2020/02/27/3dSjgK.png" alt="3dSjgK.png" border="0" style="width:600px"></p>
<p>SpringMVC 执行流程：</p>
<ol>
<li>请求发送到 DispatcherServlet 调用 HandlerMapping 根据 url-pattern 找到对应的处理器。</li>
<li>调用 HandlerAdepter 做类型转换。</li>
<li>调用 preHandle 。</li>
<li>Controller 处理完成返回 ModelAndView 对象。</li>
<li>调用 postHandle 。</li>
<li>由 ViewReslover 解析后返回 View 。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[About Threadlocal]]></title>
      <url>/2019/11/25/about-threadlocal/</url>
      <content type="html"><![CDATA[<p>ThreadLocal 是一个特殊的数据存储类，它为每个线程都提供了一份变量的副本，每个线程只能够获取到自己对应的存储数据，从而实现变量被多个线程共享，数据又彼此隔离。</p>
<h4 id="ThreadLocal-的使用场景"><a href="#ThreadLocal-的使用场景" class="headerlink" title="ThreadLocal 的使用场景"></a>ThreadLocal 的使用场景</h4><p>ThreadLocal 在什么场景下使用呢？</p>
<ol>
<li><p><strong>多个线程之间作用域相同并且需要不同的数据副本。</strong>比如我们在使用 redis 实现分布式锁时，一个线程获取锁，处理完成后要释放锁，并且要保证自己的锁只能由自己来释放，我们需要给每一把锁生成一个唯一 ID ，这个 ID 由线程自己持有，在释放锁的时候通过 ID 来进行操作，此时可以使用 ThreadLocal 来保存 ID 。</p>
</li>
<li><p><strong>对象传递。</strong>通常我们在方法调用的时候，如果逻辑复杂，可能入参会有多个或者无法获取到某些参数的情况，这时候就可以使用 ThreadLocal 来进行对象传递。典型的如 Spring AOP ，由于业务代码是定义好的，业务代码入参中并不强制包含切面处理的对象，所以 spring 将这些切面对象放在 ThreadLocal 中，这样就可以在线程内部获取到切面所需要的参数信息了。</p>
</li>
</ol>
<h4 id="ThreadLocal-的实现原理"><a href="#ThreadLocal-的实现原理" class="headerlink" title="ThreadLocal 的实现原理"></a>ThreadLocal 的实现原理</h4><p>通过查看 ThreadLocal 的源代码，我们可以看到在 ThreadLocal 内部有一个 ThreadLocalMap ，这个 ThreadLocalMap 就是 Thread 类中用来存放线程自己的数据的。我们主要关注 ThreadLocal 的这几个方法：</p>
<ol>
<li><p>set </p>
<pre><code>public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}
</code></pre><p>获取到当前线程的 ThreadLocalMap ，如果 map 不为空，就把对象 set 进去，如果 map 为空，就创建一个新的 ThreadLocalMap ，再把对象 set 进去。</p>
</li>
<li><p>get</p>
<pre><code>public T get() {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        ThreadLocalMap.Entry e = map.getEntry(this);
        if (e != null) {
            @SuppressWarnings(&quot;unchecked&quot;)
            T result = (T)e.value;
            return result;
        }
    }
    return setInitialValue();
}
</code></pre><p>get 操作也是一样，先获取当前线程的 ThreadLocalMap ，如果 map 不为空，则从 Map.Entry 中获取对象。如果 map 为空，则返回初始值 null ，并把 null 值 set 到当前线程的 ThreadLocalMap 中。</p>
</li>
<li><p>remove</p>
<pre><code>public void remove() {
    ThreadLocalMap m = getMap(Thread.currentThread());
    if (m != null)
        m.remove(this);
}
</code></pre><p>remove 就更简单了，获取当前线程的 ThreadLocalMap ，然后从 Map 中删除线程的数据。</p>
</li>
</ol>
<p>了解 ThreadLocal 的基本操作之后，我们还要再来看看 ThreadLocalMap 。ThreadLocal 提供的功能，本质上是由 ThreadLocalMap 实现的。刚才源码我们也看到了，在往 ThreadLocal 中 set 对象的时候，实际调用的是 ThreadLocalMap 的 set 方法。</p>
<pre><code>// 遍历map
for (Entry e = tab[i];
    e != null;
    e = tab[i = nextIndex(i, len)]) {
    ThreadLocal&lt;?&gt; k = e.get();
    // 如果Entry的key相同，则替换
    if (k == key) {
        e.value = value;
        return;
    }
    // 如果Entry的key是null，则set新值
    if (k == null) {
        replaceStaleEntry(key, value, i);
        return;
    }
}
// 如果没有相同的对象，则生成新的Entry添加到map中
tab[i] = new Entry(key, value);
// map的大小加1
int sz = ++size;
if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)
    // 如果清除map中Entry的key为null的Entry之后，map的size
    // 还大于阈值，则进行rehash
    rehash();
</code></pre><pre><code>private void rehash() {   
    // 清除过时的元素(Entry的key为空)
    expungeStaleEntries();
    // 如果清除之后，size 还是超过阈值，则扩容为原来的 2 倍
    if (size &gt;= threshold - threshold / 4)
        resize();
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[面试问题]]></title>
      <url>/2019/11/07/interview/</url>
      <content type="html"><![CDATA[<p>Q: 为什么使用微服务？</p>
<p>A: 1. 解耦，减少人员的冲突，提高开发和测试的效率。2. 更好地做CI/CD。</p>
<p>Q: 为什么用rabbitmq？</p>
<p>A: 主要对比 kafka。1. 使用场景可靠性更高。2. 延时消息。3. Kafka 优势是高吞吐，目前的业务使用rabbitmq可以满足。4. 社区活跃，资料多。5. 界面友好。</p>
<p>Q: 怎么保证rabbitmq消息不丢？</p>
<p>A: 1. 生产者一端，使用 ack 机制，同时mq开启事务消息，事务成功才返回 ack，事务失败则重试。2. rabbitmq 持久化，等落盘之后再返回ack。3. 消费端手动ack。</p>
<p>Q: 接口的幂等性是怎么设计的，怎么保证幂等？</p>
<p>A: 1. 请求幂等，将数据库增删改操作的相对值修改改为绝对值修改。2. 使用全局id。3. 业务上幂等，比如同一个用户在 10 分钟内不能多次添加相同名单。</p>
<p>Q: 用过哪些 linux 命令？</p>
<p>A: 常用的命令有：查看cpu情况 top，查看内存情况 free， 查看网络情况 netstat，查看磁盘 df ，还有一些 java 的命令，jps， jstat ，jinfo， jstack 。 </p>
<p>Q: Threadlocal 的使用场景</p>
<p>A: </p>
<p>Q: 如何设计一个系统</p>
<p>A: benchMark 对标：了解公司和业内的先进的解决方案，进行对标。</p>
<p>​     efficiency 效率：原型，可重用的系统或组件，自动化的工具等等。</p>
<p>​     architecture 架构：简单，合适，可演进。</p>
<p>​     function 功能：梳理需求，了解业务，整理出功能。</p>
<p>​     quality 质量：一方面功能要可用，可测试；另一方面要做好兜底方案，保证系统的稳定性。</p>
<p>​     performance 性能：根据业务场景进行设计和优化，常用的手段有无状态化有利于动态扩容缩容，串行改并行，单线程改多线程，同步改异步，读写分离，分库分表，sql优化，jvm参数优化等。</p>
<p>​     safety 安全：1. 权限控制；2. sql注入，各种网络攻击等；3. 协议或数据加密。</p>
<p>Q: 面试经典算法：二分查找，快速排序，反转链表，遍历二叉树，给定两束之和求下标，最近公共子节点，爬楼梯算法</p>
<p>A: </p>
<p>Q: linux 常用命令，awk，sed，sort，uniq，统计文本中出现次数最多的ip</p>
<p>A: </p>
<p>Q: 如何定位和排查问题</p>
<p>A: 1. 先从日志入手，判断是否是业务问题。2.是否是资源不足，可借助top，free，jstack等。3. 定位之后制定短期和长期解决方案。</p>
<p>Q: redis的数据结构</p>
<p>A: </p>
<p>Q: mysql update的执行过程</p>
<p>A: </p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spring Bean Life Cycle]]></title>
      <url>/2019/11/07/spring-bean-life-cycle/</url>
      <content type="html"><![CDATA[<p><img src="https://s1.ax1x.com/2020/04/04/GwMsOK.png" alt="GwMsOK.png" border="0" style="width:500px;"></p>
<p>Spring bean 的生命周期有 5 个阶段：</p>
<ol>
<li>Prepare 阶段</li>
<li>Instantation 阶段</li>
<li>PopulateBean 阶段</li>
<li>Initailization 阶段</li>
<li>Destory 阶段</li>
</ol>
<p>Instantation 之前会执行 postProcessBeforeInstantiation 。<br>Instantation 之后会执行 postProcessAfterInstantiation 和 postProcessProperties 。<br>Initailization 之前执行 postProcessBeforeInitialization 。<br>Initailization 之后执行 postProcessAfterInitialization 。</p>
]]></content>
      
        <categories>
            
            <category> Spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spring Boot Life Cycle]]></title>
      <url>/2019/11/07/spring-boot-life-cycle/</url>
      <content type="html"><![CDATA[<p>spring boot 启动流程</p>
<ol>
<li>实例化 SpringApplication<br> 1.1 扫描 ApplicationContextInitializer 的配置并实例化（通过 SpringFactoriesLoader 加载 spring.factories 中的配置）<br> 1.2 扫描 ApplicationListener 的配置并实例化（通过 SpringFactoriesLoader 加载 spring.factories 中的配置）</li>
<li>执行 SpringApplication.run() 方法<br> 2.1 创建并启动 stopwatch<br> 2.2 扫描 SpringApplicationRunListener 并将实例化后的 EventPublishingRunListener 加入到 RunListener 集合<br> 2.3 遍历 RunListener 集合，启动 runListener ，创建一个 <strong>SpringBootStartingEvent</strong> 加入到事件广播<br> 2.4 包装命令行的参数<br> 2.5 配置环境变量<br> &ensp;&ensp;&ensp;&ensp;2.5.1 根据 applicationType 获取环境变量<br> &ensp;&ensp;&ensp;&ensp;2.5.2 配置自定义环境变量，比如命令行的参数<br> 2.6 打印 banner<br> 2.7 根据 applicationType 实例化 ConfigurableApplicationContext 类<br> 2.8 扫描 SpringBootExceptionReporter 的配置并实例化，将 failureAnalyzer 加入到 exceptionReporter 集合<br> 2.9 准备 context<br> &ensp;&ensp;&ensp;&ensp;2.9.1 set 环境变量<br> &ensp;&ensp;&ensp;&ensp;2.9.2 做一些后置处理<br> &ensp;&ensp;&ensp;&ensp;2.9.3 遍历 Initializer 集合执行每个 initializer 的 initialize() 方法<br> &ensp;&ensp;&ensp;&ensp;2.9.4 创建一个 <strong>ApplicationContextInitializedEvent</strong> 加入到事件广播<br> &ensp;&ensp;&ensp;&ensp;2.9.5 创建 beanDefinitionLoader<br> &ensp;&ensp;&ensp;&ensp;2.9.6 ApplicationListener 和 Context 互相 set，然后创建一个 <strong>ApplicationPreparedEvent</strong> 加入到事件广播<br> 2.10 refreshContext<br> &ensp;&ensp;&ensp;&ensp;2.10.1 调用 super.refresh()<br> &ensp;&ensp;&ensp;&ensp;2.10.1.1 prepareRefresh<br> &ensp;&ensp;&ensp;&ensp;2.10.1.2 prepareBeanFactory<br> &ensp;&ensp;&ensp;&ensp;2.10.1.3 postProcessBeanFactory<br> &ensp;&ensp;&ensp;&ensp;2.10.1.4 invokeBeanFactoryPostProcessors<br> &ensp;&ensp;&ensp;&ensp;2.10.1.5 registerBeanPostProcessors<br> &ensp;&ensp;&ensp;&ensp;2.10.1.6 initApplicationEventMulticaster<br> &ensp;&ensp;&ensp;&ensp;2.10.1.7 onRefresh 创建 webserver<br> &ensp;&ensp;&ensp;&ensp;2.10.1.8 registerListeners<br> &ensp;&ensp;&ensp;&ensp;2.10.1.9 finishBeanFactoryInitialization<br> &ensp;&ensp;&ensp;&ensp;2.10.1.10 finishRefresh<br> &ensp;&ensp;&ensp;&ensp;2.10.1.10.1 启动 webserver<br> &ensp;&ensp;&ensp;&ensp;2.10.1.10.2 创建一个 <strong>ServletWebServerInitializedEvent</strong> 加入到事件广播<br> &ensp;&ensp;&ensp;&ensp;2.10.2 registerShutdownHook<br> 2.11 afterRefresh 什么都没有做<br> 2.12 创建一个 <strong>ApplicationStartedEvent</strong> 加入到事件广播<br> 2.13 创建一个 <strong>ApplicationReadyEvent</strong> 加入到事件广播  </li>
</ol>
]]></content>
      
        <categories>
            
            <category> Spring Boot </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Thread Pool]]></title>
      <url>/2019/11/07/thread-pool/</url>
      <content type="html"><![CDATA[<p>线程池可以重用线程资源，减少线程创建销毁的资源耗费。JDK 提供了 ThreadPoolExecutor 来创建线程池。</p>
<pre><code>public ThreadPoolExecutor(int corePoolSize,                  // 线程池初始大小
                          int maximumPoolSize,               // 线程池最大线程数
                          long keepAliveTime,                // 线程存活的时间
                          TimeUnit unit,                     // 时间单位
                          BlockingQueue&lt;Runnable&gt; workQueue, // 任务等待队列
                          ThreadFactory threadFactory,       // 线程工厂用来创建线程
                          RejectedExecutionHandler handler   // 线程数量超过线程池大小后的处理策略
                          ) {}
</code></pre><h4 id="线程池参数效果"><a href="#线程池参数效果" class="headerlink" title="线程池参数效果"></a>线程池参数效果</h4><p>我们要创建一个核心线程数 5 ，最大线程数 20 ，队列大小是 10 的一个线程池。</p>
<pre><code>ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 20,
            5, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(5), Executors.defaultThreadFactory(), defaultHandler);
</code></pre><p>如果我们提交 10 个任务，那么首先会将前 5 个任务交给 5 个线程执行，同时 5 个线程进入队列等待。这时队列有 5 个线程工作，5 个任务等待。</p>
<p>如果我们提交 15 个任务，那么首先会将前 5 个任务交给 5 个线程执行，同时 5 个线程进入队列等待，再新创建 5 个线程来执行 11-15 号任务。这时队列有 10 个线程工作，5 个任务等待。</p>
<p>如果我们提交 50 个任务，那么首先会将前 5 个任务交给 5 个线程执行，同时 5 个线程进入队列等待，再新创建 15 个线程来执行任务，剩下的 25 个任务会丢弃掉。这时队列有 20 个线程工作，5 个任务等待，等任务执行完，超过线程存活时间，线程会被销毁，剩下 5 个线程。</p>
<h4 id="jdk-提供的线程池"><a href="#jdk-提供的线程池" class="headerlink" title="jdk 提供的线程池"></a>jdk 提供的线程池</h4><p>除了使用 new ThreadPoolExecutor ，Executors 提供了一些静态方法用来创建线程池，如：</p>
<pre><code>Executor executor = Executors.newSingleThreadExecutor();
//new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));
</code></pre><pre><code>Executor executor = Executors.newFixedThreadPool(5);
//new ThreadPoolExecutor(5, 5, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());
</code></pre><pre><code>Executor executor = Executors.newCachedThreadPool();
//new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());
</code></pre><pre><code>Executor executor = Executors.newScheduledThreadPool();
</code></pre><p>本质上和我们自己 new 一个线程池是一样的。</p>
<p>LinkedBlockingQueue 是阻塞队列，会缓存任务。SynchronousQueue 不缓存任务，会将任务直接发给消费端执行。所以如果我们创建以下线程池：</p>
<pre><code>ThreadPoolExecutor executor = new ThreadPoolExecutor(10, 20, 20L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), new ThreadPoolExecutor.AbortPolicy());
</code></pre><p>当我们提交 50 个任务，那么只有 20 个任务能够执行，剩下 30 个线程会被丢弃。</p>
<p>虽然 JDK 提供了 Executors 几种创建线程的方式，但是实际使用中并不建议直接使用，因为 LinkedBlockingQueue 虽然是有界队列，但是队列大小默认是 Integer.MAX_VALUE ，如果任务很多会导致 OOM 。所以我们还是需要根据实际情况自己创建线程池。</p>
<blockquote>
<p>线程的数量需要根据实际情况设置，如果任务是 CPU 密集型，那么线程数和 CPU 核数相同，可以减少线程上下文切换，如果是 IO 密集型，线程数量可以是 CPU 核数的若干倍。这个数据只是经验值，实际多少最好需要压测。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[one question one answer for jvm]]></title>
      <url>/2019/11/04/one-question-one-answer-for-jvm/</url>
      <content type="html"><![CDATA[<p>Q: 写一段将目录中指定的.class文件加载到JVM的程序，并通过Class对象获取到完整类名等信息。</p>
<p>A: 通常会继承 URLClassLoader ，重写 findClass 方法，通过 ByteArrayOutputStream 读取文件，通过反射执行。也可以重新loadClass 方法，但是会破坏双亲委托机制。</p>
<p>Q: 一段展示代码，里面包含一个全局静态整型变量，问如果用两个ClassLoader加载此对象，执行这个整型变量++操作后结果会是怎么样的？</p>
<p>A:  </p>
<p>Q: 自己写一个 String 类能否替换掉 jdk 的 String 类？</p>
<p>A: String 类在 rt.jar 中，是由 BootstrapClassLoader 来加载的，所以即使我们自己写自定义加载器来加载 String 类，由于双亲委托机制，最后都会先交给 BootstrapClassLoader 来加载，所以自己写的 String 是无法加载的。（除非修改 BootstrapClassLoader 的源码，猜的。）</p>
<p>Q: A a=new A(); a.execute(); 和 IA a=new A(); a.execute(); 执行有什么不同?</p>
<p>A: 多态属性运行时绑定，会调用父类的方法。</p>
<p>Q: 反射的性能低的原因是？</p>
<p>A: </p>
<p>Q: 编写一段程序，动态的创建一个接口的实现，并加载到JVM中执行；（可以允许用BCEL等工具）</p>
<p>A:</p>
<p>Q: 经典的String比较程序题：<br>   String a=”a”;<br>   String b=”b”;<br>   String ab=”ab”;<br>   (a+b)==ab;  ??  (引深题，如何才能让(a+b)==ab）<br>   (“a”+”b”)==ab; ?? </p>
<p>A:</p>
<p>Q: 写一段程序，让其OutOfMemory，或频繁执行Minor GC，但又不触发Full GC，又或频繁执行Full GC，但不执行minor GC，而且不OutOfMemory，甚至可以是控制几次Minor GC后发生一次Full GC；</p>
<p>A: </p>
<p>Q: 详细讲解GC的实现，例如minor GC的时候导致是怎么回收对象内存的，Full GC的时候是怎么回收对象内存的。</p>
<p>A: </p>
<p>Q: i++的执行过程</p>
<p>A: </p>
<p>Q: 一个线程需要等待另外一个线程将某变量置为true才继续执行，如何编写这段程序，或者如何控制多个线程共同启动等；</p>
<p>A: </p>
<p>Q: 控制线程状态的转换的方法，或者给几个thread dump，分析下哪个线程有问题，问题出在哪。</p>
<p>A: </p>
<p>Q: static属性加锁、全局变量属性加锁、方法加锁的不同点？</p>
<p>A: </p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[GC]]></title>
      <url>/2019/11/04/GC/</url>
      <content type="html"><![CDATA[<p>-Xms41m<br>-Xmx41m<br>-Xmn10m<br>-XX:+UseParallelGC<br>-XX:+PrintGCDetails<br>-XX:+PrintGCTimeStamps</p>
<pre><code>public class GCTest {
    public static void main(String[] args) throws Exception {
        List caches = new ArrayList();
        for (int i = 0; i &lt; 7; i++) {
            System.out.println(&quot;次数：&quot; + (i + 1));
            caches.add(new byte[1024 * 1024 * 3]);
        }
        caches.clear();
        for (int i = 0; i &lt; 2; i++) {
            System.out.println(&quot;clear后次数：&quot; + (i + 1));
            caches.add(new byte[1024 * 1024 * 3]);
        }
    }
}
</code></pre><pre><code>java -jar GCTest -Xms30m -Xmx30m -Xmn10m -XX:+UseParallelGC -XX:+PrintGCDetails
</code></pre><p>每次放3M<br>1、在YGC执行前，min(目前 eden 已使用的大小,之前平均晋升到old的大小中的较小值) &gt; old剩余空间大小 ? 不执行YGC，直接执行Full GC : 执行YGC；<br>2、在YGC执行后，平均晋升到old的大小 &gt; old剩余空间大小 ? 触发Full GC ： 什么都不做。</p>
<table style="font-size:12px;color:#333333;border-width: 1px;border-color: #666666;border-collapse: collapse;"><tr><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;width: 50px;"></th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">eden</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">old</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">YGC</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">FGC</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">说明</th></tr><br><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">第1次</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">3</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"></td></tr><br><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">第2次</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">6</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"></td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">第3次</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">3</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">6</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">1</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">eden空间剩余2，小于需要的内存，min（eden已使用大小是6，平均进入old的大小是0）=0，小于old剩余的空间20，所以触发YGC，eden的对象进入old，old变成6，eden变成3。平均晋升到old的大小是6，小于old剩余的空间14，不触发FGC。</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">第4次</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">6</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">6</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"></td></tr><br><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">第5次</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">3</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">12</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">1</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">eden空间剩余2，小于需要的内存，min（eden已使用大小是6，平均进入old的大小是6）=6，小于old剩余的空间12，所以触发YGC，eden的对象进入old，old变成12，eden变成3。平均晋升到old的大小是6，小于old剩余的空间8，不触发FGC。</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">第6次</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">6</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">12</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"></td></tr><br><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">第7次</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">3</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">18</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">1</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">1</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">eden空间剩余2，小于需要的内存，min（eden已使用大小是6，平均进入old的大小是6）=6，小于old剩余的空间8，所以触发YGC，eden的对象进入old，old变成18，eden变成3。平均晋升到old的大小是6，大于old剩余的空间2，触发FGC。</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">第8次</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">6</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">18</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"></td></tr><br><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">第9次</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">3</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">18</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">0</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">1</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">eden空间剩余2，小于需要的内存，min（eden已使用大小是6，平均进入old的大小是6）=6，大于old剩余的空间2，直接触发FGC。</td></tr></table>    


]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Approaches to Architecture Development]]></title>
      <url>/2019/09/01/approaches-to-architecture-development/</url>
      <content type="html"><![CDATA[<p>架构是解决问题的过程和方案。架构不是一成不变的，一个问题可以用不同的架构来解决，但是肯定有一种架构是最合适的。所以架构没有好坏，只有是否合适。如果我们脱离了实际问题讨论架构，那将是空中楼阁。架构是经验的总结和提炼，经过不断的抽象，逐渐形成以下几种架构。</p>
<h4 id="Monolith-架构"><a href="#Monolith-架构" class="headerlink" title="Monolith 架构"></a>Monolith 架构</h4><p>Monolith 就是单体应用程序，即单个应用程序包含所有的功能，一个应用就是一个进程。<br><img src="https://s2.ax1x.com/2020/02/27/3dNjRs.png" alt="3dNjRs.png" border="0" style="width:550px"><br>单体架构是我们最熟悉的一种架构，它的优点很明显，易于开发，测试，部署和扩展。同时它的缺点也很明显，就是所有功能耦合在一起，修改任何一个功能，都需要对所有功能进行测试，不利于做持续集成和发布。所以如果我们的场景不需要持续集成持续发布，那么单体架构是非常不错的选择。</p>
<h4 id="分层架构"><a href="#分层架构" class="headerlink" title="分层架构"></a>分层架构</h4><p>在单体应用中，往往我们为了开发和维护方便，我们会将软件划分成多个层次，比如常见的 3 层架构：表现层，业务层和数据访问层。<br><img src="https://s2.ax1x.com/2020/02/27/3dUioF.png" alt="3dUioF.png" border="0" style="width:550px"><br>每一层都有清晰的角色和分工，层与层之间通过接口通信，如果多人协同开发，不同的人员负责不同的层，每一层都是相对独立的，可以单独进行测试和部署。这对于大型的公司或是多人协同开发是非常合适。这种水平分层架构解决了功能耦合的问题，但是增加了调试和定位问题的难度，同时也对部署的要求更高。</p>
<h4 id="SOA-架构"><a href="#SOA-架构" class="headerlink" title="SOA 架构"></a>SOA 架构</h4><p>SOA 即面向服务的架构，它和分层架构的思想类似。水平分层是从功能层面解耦，而 SOA 则是从业务层面进行解耦。<br><img src="https://s2.ax1x.com/2020/02/27/3dUYQI.png" alt="3dUYQI.png" border="0" style="width:500px"><br>优点是业务比较独立，服务之间通过接口通信，内部调整不会影响其他服务。但是我们同时也会看到对业务的划分比水平层次的划分更难。</p>
<h4 id="微服务架构"><a href="#微服务架构" class="headerlink" title="微服务架构"></a>微服务架构</h4><p>微服务架构，是在 2014 年由 James Lewis 和 Martin Fowler 提出的，更多信息可以参考 <a href="https://www.martinfowler.com/articles/microservices.html" target="_blank" rel="external">https://www.martinfowler.com/articles/microservices.html</a> 。简单来说微服务架构就是水平分层架构 + SOA 架构。<br><img src="https://s2.ax1x.com/2020/02/27/3dUwTS.png" alt="3dUwTS.png" border="0" style="width:550px"><br>水平分层架构有业务耦合，SOA 架构有功能耦合，微服务架构在垂直方向进行业务解耦，在水平方向进行功能解耦，完全解决了耦合性的问题。其优势在于各个服务之间耦合度低，具有很好的扩展性。每个服务可以单独开发，测试和部署，单个服务调整不会影响其他服务，利于做持续集成和发布。各个服务拆分开来，不用再囿于相同的语言和环境，各个团队可以根据自身的技术选择实现方式。凡事有两面，我们不能光看到微服务架构的优点，同时我们也应该清楚微服务架构的缺点。由于要解耦，服务会被拆分成大量的微服务，而服务之间需要进行通信这就导致系统的变得极为复杂。同时由于通信链路变多，微服务的性能和单体架构相比会有所损失。还有在服务被拆分之后，在分布式环境中，数据的一致性也变得难以保证，需要我们额外使用一些手段来保证数据一致性。在大量的微服务面前，也对运维提出了极高的要求，所以虽然微服务在当下十分流行，但是在架构选择的时候还要根据自身的情况进行衡量，不要盲目跟风。</p>
<h4 id="服务网格架构"><a href="#服务网格架构" class="headerlink" title="服务网格架构"></a>服务网格架构</h4><p>Service Mesh 服务网格架构是由 Linkerd 提出的一种微服务架构，伴随着微服务的流行，Service Mesh 也越来越被人们关注。在微服务时代，服务治理是微服务架构的首要难题和痛点。微服务通过水平拆分功能解耦，垂直拆分业务解耦，已经极大降低了耦合性。但是微服务之间要通信，那么每个微服务中又必须包含相关的通信组件。通信和业务耦合不利于业务快速迭代，同时也不利于通信组件的升级。所以在这种情况下，Service Mesh 就将通信从服务中剥离出来，从而提高业务的迭代速度和降低通信组件的维护难度。<br><img src="https://s2.ax1x.com/2020/02/27/3dUH61.png" alt="3dUH61.png" border="0" style="width:750px"></p>
]]></content>
      
        <categories>
            
            <category> Architecture </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Architecture </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Understanding High Availability]]></title>
      <url>/2019/09/01/understanding-high-availability/</url>
      <content type="html"><![CDATA[<h4 id="什么是高可用"><a href="#什么是高可用" class="headerlink" title="什么是高可用"></a>什么是高可用</h4><p>高可用（High Availability，HA）简单来说，就是用户在任何时间访问系统都能获得正确的结果。如果系统不具有高可用性，那么意味着在某一个时刻用户无法使用系统或服务，用户体验会不好，更有可能使公司丢掉商业机会，造成损失，所以企业对高可用系统的重要性越来越重视，同时也提出一系列衡量高可用系统的标准，比如：按停机时间计算。</p>
<blockquote>
<p>一年 365 天，如果系统能够在 99% 的时间里提供服务，那么意味着系统一年之中停机时间不能超过 87.6 小时。<br>如果要保证 3 个 9 可用，停机时间不能超过 8.76 小时。<br>如果是 4 个 9 则停机时间不能超过 53 分钟。<br>如果是 5 个 9 则停机不能超过 6 分钟。</p>
</blockquote>
<p>停机时间可以从一个方面反应出系统的可用性，但是在高峰期停机 6 分钟和在低峰期停机 6 分钟造成的影响是不一样的，所以我们又提出通过估算停机时的请求量/一年的总请求量的比值来进行评估。不管使用何种评估方式，我们都可以对我们系统的高可用性有一个大致的了解。如果想要提高系统的可用性，那么就需要在系统的架构设计中进行改进。</p>
<h4 id="如何实现高可用"><a href="#如何实现高可用" class="headerlink" title="如何实现高可用"></a>如何实现高可用</h4><h5 id="1-服务冗余"><a href="#1-服务冗余" class="headerlink" title="1.服务冗余"></a>1.服务冗余</h5><p>5 个 9 的服务可用性是非常具有挑战的，因为我们的系统是软件，这些软件会有 bug ，而软件又是运行在计算机硬件上的，硬件也会出现故障，所以单一系统出现问题是无法避免的。为了解决单点问题，就必须将我们的服务冗余，进行集群，从而保证集群中任何节点出现故障都不影响系统整体的可用性。</p>
<h5 id="2-负载均衡"><a href="#2-负载均衡" class="headerlink" title="2.负载均衡"></a>2.负载均衡</h5><p>服务冗余固然可以消除单点故障的影响，但是仅仅冗余部署是不够的，必须要有一套监控机制来保证。服务部署多份，那么如何将请求分配到不同的节点，保证不会出现某个节点接受请求过大而另一些节点请求过少，或者当一个节点故障之后不会再有请求被分配到故障节点，这就需要使用负载均衡技术。</p>
<h5 id="3-幂等"><a href="#3-幂等" class="headerlink" title="3.幂等"></a>3.幂等</h5><p>当一个节点的请求处理失败，负载均衡会将请求路游到另外的节点上进行重试，为了保证系统不会因为多次请求导致数据不一致，我们还需要保证幂等性。</p>
<h5 id="4-无状态及动态扩容缩容"><a href="#4-无状态及动态扩容缩容" class="headerlink" title="4.无状态及动态扩容缩容"></a>4.无状态及动态扩容缩容</h5><p>当请求不断增多，集群压力过大，如果有富裕的硬件资源，我们需要增加服务节点，当请求减少，我们需要减少服务节点，回收多余的硬件资源。为了能够动态的扩容和缩容，服务必须是无状态的，否则每个节点都是不一样的，那么处理起来就会非常困难。</p>
<h5 id="5-限流、降级、熔断"><a href="#5-限流、降级、熔断" class="headerlink" title="5.限流、降级、熔断"></a>5.限流、降级、熔断</h5><p>有时在很短的时间内我们的系统资源无法支撑海量的请求，为了保证系统可用，我们需要对系统进行限流，降级或熔断处理。<strong>限流</strong>就是当请求数量超过系统的处理能力时，丢弃一部分请求以保证一部分请求能够正常处理。<strong>降级</strong>就是当系统资源不足时，将一部分边缘服务使用默认处理或是停掉，以保证核心服务资源可用。<strong>熔断</strong>是当一个服务请求处理缓慢时，使用服务的默认行为，防止因为单个服务缓慢导致整个系统雪崩。</p>
<h5 id="6-服务拆分"><a href="#6-服务拆分" class="headerlink" title="6.服务拆分"></a>6.服务拆分</h5><p>将服务拆分，按照服务等级施行不同策略的保障措施。</p>
<h5 id="7-服务监控"><a href="#7-服务监控" class="headerlink" title="7.服务监控"></a>7.服务监控</h5><p>从平均响应延时或异常条数来进行实时监控，需要有对日志实时采集和分析的能力。</p>
<h5 id="8-热部署或热切换"><a href="#8-热部署或热切换" class="headerlink" title="8.热部署或热切换"></a>8.热部署或热切换</h5><p>在不停机的情况下进行服务更新或状态修改，比如使用配置中心。</p>
<h5 id="9-异地容灾"><a href="#9-异地容灾" class="headerlink" title="9.异地容灾"></a>9.异地容灾</h5><p>不管是应用还是数据，异地部署都是有效的手段。比如，同城不同机房，异地多个机房等。</p>
]]></content>
      
        <categories>
            
            <category> Architecture </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[one question one answer for springboot]]></title>
      <url>/2019/08/16/one-question-one-answer-for-springboot/</url>
      <content type="html"><![CDATA[<p>Q: 为什么 springboot 可以用 java -jar 方式启动？<br>A: </p>
<p>Q: spring-boot-starter-parent 和 spring-boot-dependencies 的区别<br>A: </p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mysql]]></title>
      <url>/2019/08/11/mysql/</url>
      <content type="html"><![CDATA[<p>mysql 架构<br>连接器（connectors）<br>系统管理和控制工具（services &amp; utilies）<br>连接池（connection pool）<br>sql接口（sql interface）<br>解析器（parser）</p>
<pre><code>1. 词法分析 分词，获取子句
2. 语法分析 检查是否符合sql92语法
形成语法树
</code></pre><p>查询优化器</p>
<pre><code>1. 索引优化
2. 多表关联 小表驱动大表
3. where条件，从左到右，选择过滤力度最大的条件先执行
</code></pre><p>查询缓存（cache buffer）<br>    执行的sql hash 作为key， 结果是value<br>    当数据改变，清除缓存<br>存储引擎<br>    5.6 默认 innoDB<br>    MyISAM 查询和插入速度快，但不支持事务，行锁，外键；<br>    InnoDB 支持事务，行锁，外键；</p>
<p>执行流程</p>
<pre><code>1. 连接管理模块
2. 连接进程模块
3. 用户模块
4. 命令分发器
5. 记录日志
6. 命令解析器
7. 查询优化器
8. 访问控制 grant
9. 表管理模块
10. 存储引擎接口
</code></pre><p>物理架构<br>    日志文件和索引文件 /var/lib/mysql<br>    日志用顺序IO方式存储，数据使用随机IO方式存储<br>    顺序IO和随机IO的优劣</p>
<pre><code>日志分类
    错误日志
    二进制日志（bin log）
        记录数据变化所有的ddl和dml，但不包括select。作用数据备份，恢复，同步
    通用查询日志，性能不高，生产中不开启
    慢查询日志，默认关闭。
        slow_query_log,slow_query_time,
    redo log
    undo log
    中继日志 relay log
    看日志开启情况 show variables like &#39;log_%&#39;
数据文件
    看数据文件 show variables like &#39;datadir%&#39;
    InnoDB
        .frm文件 表结构信息
        .ibd 独享表空间
        .ibdata 共享表空间
    MyISAM
        .frm文件 表结构信息
        .myd文件 存储表数据
        .myi文件 存储索引信息
</code></pre><p>索引<br>    优势<br>        查询快<br>        降低排序成本<br>    劣势<br>        增删改慢</p>
<p>索引使用场景</p>
<pre><code>1. 主键唯一索引
2. 频繁查询的字段
3. 关联查询，关联字段建索引
4. 排序字段要建索引
5. 索引覆盖
6. 分组统计
</code></pre><p>不需要索引的场景</p>
<pre><code>1. 记录太少
2. 频繁更新
</code></pre><p>组合索引<br>    优势：<br>        省空间<br>        容易形成索引覆盖<br>    最左前缀原则：索引从左向右直到遇到范围查询，索引中断</p>
<p>查看执行计划 explain </p>
<pre><code>1. id 大的先执行，相同的顺序执行
2. select_type 能够看出sql语句使用了什么结构
    premary
    subquery
    dependent subquery
    union
    dependent union 
    union result 
    derived 
3. type
    system  
    const 唯一索引或主键索引
    eq_ref 主键关联或唯一索引关联
    ref 非唯一索引
    range 范围索引，前缀索引
    all 没有索引
    index 索引覆盖
4. possible_keys
    可能用到的索引
5. key
    优化器使用的索引
6. 执行计划估算的扫描行数
7. extra
    null 表示索引使用的好
    using temporary 使用了临时表， distinct
    using filesort 文件排序
    using index 索引覆盖
    using where 没有使用索引，在server层过滤
    using index condition 索引下推ICP
</code></pre><p>索引失效<br>    索引上计算<br>    组合索引开始索引缺失<br>    使用!=<br>    主键判空<br>    like <code>%a</code><br>    字符串没有使用单引号<br>    or</p>
<p>锁<br>    悲观锁<br>        表锁<br>        元数据锁（meta data lock）<br>        意向锁<br>        行锁<br>            共享锁<br>            排他写锁<br>            锁定范围<br>                记录锁record locks 主键指定<br>                间隙锁 gap locks 锁定记录前 记录中 记录后的行<br>                next-key 记录锁+间隙锁<br>            功能<br>                共享读锁 lock in share mode<br>                排他写锁</p>
<pre><code>                1. dml 自动加
                2. for update
        两阶段锁：加锁阶段 解锁阶段
        没索引不支持行锁
        主键锁定一行，不产生间隙锁
        主键范围锁定，产生间隙锁

死锁
    互相等待对方资源
</code></pre><p>事务<br>    由存储引擎实现</p>
<p>innodb 架构<br>    buffer pool</p>
<pre><code>redo log

double write

check point
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Distributed Transations]]></title>
      <url>/2019/08/03/distributed-transations/</url>
      <content type="html"><![CDATA[<p>我们通常说的事务是指本地事务，即对一个数据库进行的操作，并且这些操作满足事务的 4 个特性。事务的 4 个特性分别是：<br>Aotmicity（原子性），Consistency（一致性），Isolation（隔离性），Durability（持久性）。在一个事务中的所有操作要么同时成功，要么同时失败，这是原子性，一旦执行成功 commit 或是执行失败 rollback 那么这个结果必须是持久的。在事务开始和结束之间，存在着中间状态，这些中间状态是对事务之外是隔离的，换句话说，在事务结束之前，对数据进行的任何修改对事务之外都是不可见的，这就是隔离性。在事务结束之后，数据必须是完整并且一致的。</p>
<p>在传统的架构体系中经常使用本地事务来保证数据一致性。但是随着分布式系统的发展，出现了越来越多的跨多个数据库进行操作的情况。在这种情况下，本地事务就无法保证数据一致性，分布式事务应运而生。分布式事务是针对本地事务来说的，它的目的就是解决在分布式环境下，跨多个数据库操作的数据一致性问题。分布式事务可分为刚性分布式事务和柔性分布式事务。</p>
<h4 id="刚性分布式事务"><a href="#刚性分布式事务" class="headerlink" title="刚性分布式事务"></a>刚性分布式事务</h4><p>刚性分布式事务是和本地事务一样，都满足 ACID 特性的，是强一致性的。提到刚性事务，最据代表性的就是X/Open 提出的一种分布式事务模型，DTP (<strong>D</strong>istributed <strong>T</strong>ransaction <strong>P</strong>rocessing Reference Model) 模型。</p>
<p><img src="http://www.ibm.com/developerworks/websphere/library/techarticles/0407_woolf/images/DTPModel.gif" alt="http://www.ibm.com/developerworks/websphere/library/techarticles/0407_woolf/images/DTPModel.gif"></p>
<p>DTP 模型有 3 个组成部分：</p>
<p>​    <strong>AP</strong>（Application Program）：即应用程序，定义事务边界</p>
<p>​    <strong>RM</strong>（Resource Manager）：即 RDBMS ，管理计算机共享资源</p>
<p>​    <strong>TM</strong>（Transation Manager）：负责全局事务，分配事务唯一id，监控事务的执行进度，负责事务的提交，回滚，失败恢复</p>
<p>TM 和 AP、TM 和 RM 之间通信遵守 XA 规范 (XA Specification) ，AP 和 RM 之间通过 Native API 通信。</p>
<h4 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h4><p>2PC（two phase commit）是基于 DTP 模型的一种实现。<br><img src="https://s2.ax1x.com/2020/03/11/8AVSxA.png" alt="8AVSxA.png" border="0" style="width:400px"><br>2PC 过程如下：</p>
<p>​    第一阶段，AP 发起事务 commit ，TM 发起 prepare 投票，当 RM 都同意后，进行第二阶段。</p>
<p>​    第二阶段，TM 最终执行 commit 。如果 commit 过程出现异常，则根据 recover 进行补偿。</p>
<p>刚性分布式事务的优点是强一致性，但是缺点也很明显，由于要保证数据一致性，那么 TM 要挨个询问 RM 收集投票结果，如果 RM 数量很多，那么在所有 RM 投票完成之前，RM 的资源都是被锁定的，所以会导致全局的资源锁定，处理的性能及其低下。</p>
<h4 id="柔性分布式事务"><a href="#柔性分布式事务" class="headerlink" title="柔性分布式事务"></a>柔性分布式事务</h4><p>为了提高可用性，出现了柔性分布式事务。柔性分布式事务和刚性分布式事务不同，其理论基础是 BASE 理论。BASE 是 <strong>B</strong>asically <strong>A</strong>vailable（基本可用），<strong>S</strong>oft state（软状态）和 <strong>E</strong>ventually consistent（最终一致性）的缩写，是由 CAP 定理演化而来。</p>
<p>​    <strong>基本可用</strong>是指在特殊情况下，系统可以在功能和性能上保证基本或部分可用，比如系统响应时间从 10ms 降低到 500ms 或者只保证核心服务可用，非核心服务暂时不可用。</p>
<p>​    <strong>软状态</strong>是指在多个服务之间数据存在中间状态，多个服务之间暂时地数据不一致不会影响整体可用。</p>
<p>​    <strong>最终一致性</strong>是指数据经过短暂的不一致，最终能够达到一致状态。</p>
<p>通常柔性分布式事务有以下几种实现：</p>
<h5 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a><strong>TCC</strong></h5><p>TCC 是 2PC 的一种变形，是 <strong>T</strong>ry-<strong>C</strong>onfirm-<strong>C</strong>ancel 的缩写。TCC 的执行过程和 2PC 类似，首先 try 阶段尝试执行业务，完成资源检查，预留资源。第二阶段，不用进行业务检查，直接进行 confirm ，执行成功，事务结束，如果 confirm 失败，则进行重试。如果在某一方的 try 失败了，则进行 cancel 来释放 try 阶段预留的资源。</p>
<p>我们通过一个简单的例子来感受一下。假设一个下订单-减库存-支付的场景，各业务方需要针对 TCC 进行改造，比如预留库存，在 try 阶段不能真正扣减库存，所以在数据库里需要增加一个预留库存的字段，再比如支付模块也需要增加字段来预存支付金额。如果 try 阶段预留资源都成功了，那么再将预留字段更新到实际扣减库存字段或扣减金额字段，并清空预留资源字段。一般经过 try 阶段的检查， confirm 基本上都能成功。如果 comfirm  不成功，可能是网络抖动，进行重试即可。如果支付模块在 try 阶段预减金额失败了，那么就进行 cancel ，库存模块按照 try 阶段预留的资源进行释放。通过举例，我们可以看出，TCC 很灵活，但是缺点是和业务耦合性高，因为 try-confirm-cancel 3 个阶段都交由业务方来实现。</p>
<h5 id="Saga"><a href="#Saga" class="headerlink" title="Saga"></a><strong>Saga</strong></h5><p>Saga 是另一种著名分布式事务模型。1987 年论文 sagas 讲述了一种长事务的处理方案，即 saga 模型。Saga 模型的主要思想就是把一个分布式事务拆分成多个本地事务，每个 saga 子事务 <code>T1,T2,...Tn</code> 都有对应的补偿模块 <code>C1,C2,...Cn-1</code> 。当所有子事务都执行成功，那么它的执行顺序是 <code>T1,T2,...Tn</code> 。如果 Tj 执行失败了，那么它的执行顺序是 <code>T1,T2,...Tj,Cj-1,...C2,C1,(0&lt;j&lt;n)</code> 。<br>由于 saga 模型没有 try 阶段，所以当执行失败，需要通过补偿模块进行恢复。Saga 定义了两种恢复方式：向前恢复和向后恢复。向前恢复就是认为事务一定会执行成功而进行重试。向后恢复就是执行回滚+补偿，实际当中使用较多的是向后恢复。<br>我们还是以下单-减库存-支付这一场景来进行说明。首先我们需要定义两张事务表，事务状态表和事务调用表，这两张表和业务 DB 是独立的。</p>
<p>事务状态表</p>
<p><table class="table table-bordered" style="width: 60px"><tr><td>tx_id</td><td>state</td><td>recover_step</td><td>timestamp</td></tr></table><br>事务调用表</p>
<p><table class="table table-bordered" style="width: 100px"><tr><td>tx_id</td><td>action_id</td><td>method</td><td>param_type</td><td>param_value</td></tr></table><br>saga 执行过程如下：</p>
<p>1.AP 发起事务后 TM 生成 txId， 向事务状态表存一条记录，状态是执行中 。</p>
<p><table class="table table-bordered" style="width: 60px"><tr><td>tx_id</td><td>state</td><td>recover_step</td><td>timestamp</td></tr><tr><td>1</td><td>0</td><td>0</td><td>1514736000</td></tr></table><br>2.AP 按顺序调用下单-减库存-支付操作，每调用一个操作之前向事务调用表插一条记录。</p>
<p><table class="table table-bordered" style="width: 100px"><tr><td>tx_id</td><td>action_id</td><td>recover_method</td><td>param_type</td><td>param_value</td></tr><tr><td>1</td><td>1</td><td>/recover_order</td><td>kv</td><td>orderid=12345</td></tr><tr><td>1</td><td>2</td><td>/recover_stock</td><td>kv</td><td>stock=1</td></tr><tr><td>1</td><td>3</td><td>/recover_payment</td><td>kv</td><td>pay=1000</td></tr></table><br>这些信息如何获取到呢，又是怎么写到表里的呢？ 假如我们有个方法 <code>reduceStock()</code> ，我们在调用方法的时候可以利用 AOP 或者动态代理，就可以获取到方法的参数类型和参数值。recoverMethod 的信息可以通过注解写在被调用的方法上，这样通过反射就可以获取到 recoverMethod 的信息了。得到这些信息之后，按位置插到事务调用表中就可以了。</p>
<p>3.如果下单-减库存-支付都执行成功，TM 将事务状态表中的记录更新成成功，事务结束。</p>
<p><table class="table table-bordered" style="width: 60px"><tr><td>tx_id</td><td>state</td><td>recover_step</td><td>timestamp</td></tr><tr><td>1</td><td>1</td><td>0</td><td>1514737000</td></tr></table><br>4.如果有一步执行失败，则将事务状态更新成失败，同时立刻通知客户端执行失败。</p>
<p><table class="table table-bordered" style="width: 60px"><tr><td>tx_id</td><td>state</td><td>recover_step</td><td>timestamp</td></tr><tr><td>1</td><td>2</td><td>0</td><td>1514737000</td></tr></table><br>补偿是异步的，所以不用等补偿执行完成再通知客户端。<br>5.TM 定时扫描事务状态表，如果有失败状态的记录，就按照事务调用表中对应的除最后一步调用记录之外的其他记录调补偿接口进行补偿。</p>
<p><table class="table table-bordered" style="width: 100px"><tr><td>tx_id</td><td>action_id</td><td>recover_method</td><td>param_type</td><td>param_value</td></tr><tr><td>1</td><td>1</td><td>/recover_order</td><td>kv</td><td>orderid=12345</td></tr><tr><td>1</td><td>2</td><td>/recover_stock</td><td>kv</td><td>stock=1</td></tr><tr><td>1</td><td>3</td><td>/recover_payment</td><td>kv</td><td>pay=1000</td></tr></table><br>如果表中有 3 条记录，说明前两条是执行成功的，第 3 条执行失败了。那么只需要执行前两步的补偿，第 3 步是不需要补偿的。那么接下来就按照事务调用表中记录的补偿接口的信息进行补偿。</p>
<ol>
<li>首先将事务状态置为 3 。</li>
<li>第二步调用 <code>/recover_stock?stock=1</code> 补偿库存，然后将 recover_step 改为 2，表示第二步补偿完成。</li>
<li>第三步调用 <code>/recover_order?orderid=12345&amp;state=2</code> 补偿订单，成功后将 recover_step 置为 1。</li>
</ol>
<p>补偿接口应该设计成幂等的，这样可以保证多次重试也不会产生垃圾数据。</p>
<p>6.补偿完成后将事务状态表的状态更新成补偿完成。</p>
<p><table class="table table-bordered" style="width: 60px"><tr><td>tx_id</td><td>state</td><td>timestamp</td></tr><tr><td>1</td><td>4</td><td>1514739000</td></tr></table><br>如果补偿接口出现问题，怎么办呢，我们需不需要再给补偿接口加一个分布式事务呢？一般情况下，经过测试并且有重试机制，补偿是可以成功。我们完全没有必要再加一个分布式事务来保证补偿，因为我们一旦给补偿加上分布式事务，那我们是不是也要对保证补偿的逻辑再加一个分布式事务来保证一致性呢，这样就无穷无尽了。所以简单的做法就是一旦真的补偿接口出错了，那么记录错误日志，告警，然后人工处理就好了。</p>
<h5 id="异步消息"><a href="#异步消息" class="headerlink" title="异步消息"></a><strong>异步消息</strong></h5><p>Saga 是一种同步串行的方式，接下来我们介绍异步消息的分布式事务实现。说到异步消息，自然少不了消息中间件。通过 MQ 进行消息传递，就需要有一套机制来保证消息可靠。<br>第一种方式是通过异步消息方式来实现：</p>
<p>1.先发送一个 prepare 消息给 MQ Server 。<br>2.MQ Server 收到消息返回一个 ack 。<br>3.执行本地事务。<br>4.本地事务成功向 MQ Server 发送一个 commit 消息。本地事务失败则向 MQ Server 发送一个 cancel 消息。<br>5.如果长时间没有收到 prepare 消息的确认，MQ Server 则需要向 Client 申请回查。<br>6.Client 收到回查申请后，调用本地服务的回查接口查看本地事务是否成功，如果成功，发送 commit 消息，如果本地消息失败，则发送 cancel 消息。</p>
<p>以上就是异步消息的操作步骤，这种方式其实也是 2PC 的变形。这种方式实现起来对 MQ 的要求较高，并且需要业务方提供回查接口，对业务入侵较大。</p>
<p>另一种方式是通过本地消息表来实现：<br>1.执行本地事务同时将消息先写到本地消息表中，由于执行本地操作和写消息在同一个事务中，所以可以保证同时成功或失败。<br>2.将消息从表中读出来，写到 MQ 。<br>3.MQ 收到消息，返回 confirm 。<br>4.收到 confirm 后删除本地消息。</p>
<p>这种方式对业务没有入侵并且实现简单，但是其中有一些细节需要注意。如果从消息表读出消息的服务部署了多个，那么都从消息表去读，就会产生大量的重复消息，所以可以使用分布式锁进行控制，获得锁的服务才能从消息表读，这样就可以避免重复消息。由于消息可能会产生重复，所以在消费端需要处理幂等。</p>
<p>通过上边的讲解，我们对分布式事务的几种实现方式有了简单的认识。在实际使用中，我们其实应该避免出现分布式事务，尽量让核心步骤先执行，不重要的步骤异步执行。如果实在无法避免，那么可以通过柔性分布式事务来处理，同步场景下使用 Saga ，异步场景下使用本地消息表。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Understanding Design with Idempotency]]></title>
      <url>/2019/07/31/understanding-design-with-idempotency/</url>
      <content type="html"><![CDATA[<p>幂等设计是架构设计中需要考虑的重要环节。幂等设计可以分两个层面考虑：接口定义和幂等实现方案。</p>
<h4 id="接口定义"><a href="#接口定义" class="headerlink" title="接口定义"></a>接口定义</h4><p>请求幂等是说请求一次和请求多次结果一样。其实这个说法有一点不准确，因为如果是看请求结果的话，那么在读请求在数据被修改之后，得到的结果也是不同的。所以准确的说应该是看请求是否有副作用，比如每次请求都会将数据修改成不一样的值。按照这个定义，读请求不会修改数据本身，所以读请求是幂等的。而写请求是会修改数据本身的，所以写请求不是幂等的。大多数情况下，我们接口的设计都是遵守 RESTful 规范。在 RESTful 中定义了 7 种方法：</p>
<ol>
<li>OPTIONS，获取服务器信息，幂等。</li>
<li>HEAD，请求资源的头信息，幂等。</li>
<li>GET，获取资源信息，幂等。</li>
<li>POST，新建资源，非幂等。</li>
<li>PUT，全量更新，幂等。</li>
<li>DELETE，删除资源，幂等。</li>
<li>PATCH，局部更新，非幂等。</li>
</ol>
<p>所以在设计接口的时候需要和 RESTful 的规范保持一致。</p>
<h4 id="幂等实现方案"><a href="#幂等实现方案" class="headerlink" title="幂等实现方案"></a>幂等实现方案</h4><p>在由于写请求不是天然幂等的，所以我们在架构设计的时候需要考虑幂等性。我们可以尝试通过如下几种思路来解决幂等性问题。<br>​</p>
<ol>
<li>利用数据库约束<br>由于请求最终都是操作数据库，所以最终都会反映到数据库的 CRUD 操作，所以我们可以利用数据库主键或唯一索引来保证唯一。</li>
<li>去重表<br>单独维护一张表保存去重字段，比如订单号，在业务操作之前先插入订单号，插入订单号和业务处理在同一个事务中，同时成功提交或者回滚。这种方案是第一种方式的变形，好处是业务无关，多个业务可以共享一张表。</li>
<li>乐观锁<br>在进行更新和删除操作时比较常用。可以利用 version 字段，如<pre><code>update t1 set age=age+1, version=version+1 where id=1 and version=1
</code></pre>也可以使用业务字段，如<pre><code>update t1 set age=age+1 where id=1 and age=19
</code></pre><blockquote>
<p>在进行更新和删除操作时，最好使用绝对值，不要使用相对值。</p>
</blockquote>
</li>
<li><p>使用全局唯一 ID</p>
</li>
<li><p>token 方式<br>1) 客户端首先向服务器发送请求获取 token ，服务器生成 token 存到缓存中，服务器返回 token 给客户端。<br>2) 客户端业务请求同时带着 token ，如果服务端存在 token 说明是第一次操作，可以进行业务处理，如果 token 不存在，说明业务已经执行过。<br>3) 业务执行完成删除 token 。<br>这种方式可以防止客户端重复提交，缺点是多了一次获取 token 的请求。</p>
</li>
<li><p>分布式锁</p>
</li>
<li><p>MQ 消息去重</p>
</li>
<li><p>状态机<br>状态机是有限状态自动机的简称，是现实事物运行规则抽象而成的一个数学模型。状态机有起始、终止、现态、次态（目标状态）、动作、条件 6 中元素。比如一个账号支付状态只能从未支付到支付，且只能进行一次。</p>
</li>
<li>通过资源条件保证幂等<br>比如，有一个资源总量是 10 ，进行增加操作，每次增加都先判断资源总量，如果没到 10 就增加，如果到 10 就退出，这样不管执行多少次都是不会改变事件整体的幂等性。</li>
</ol>
<p>虽然我们列出几种出里方式，但是并没有一种方式是完美的，需要根据业务和架构进行选择。</p>
]]></content>
      
        <categories>
            
            <category> Architecture </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[One Question One Answer for MySQL]]></title>
      <url>/2019/07/28/one-question-one-answer-for-mysql/</url>
      <content type="html"><![CDATA[<p>Q: 什么是索引</p>
<p>A: 索引是关系数据库中的一种存储数据结构，针对数据库表的一列或多列进行排序，从而快速定位，加速检索。</p>
<p>Q: MySQL 有哪些索引</p>
<p>A: 主键索引， 唯一索引，哈希索引，fulltext 索引。</p>
<p>Q: B+Tree 索引和Hash 索引的区别</p>
<p>A: B+Tree 索引可以用于列相等的比较，范围查找，Like 前半部分的比较，B+Tree 的任何最左前缀都可以用来查找。Hash 索引仅能用于相等的比较，不能用于范围查找，但是速度更快。</p>
<p>Q: 加了索引为什么没有生效</p>
<p>A: 索引是否生效，可以通过执行计划进行查看。</p>
<p>在一些情况下即使加了索引，也是不会生效的，比如：</p>
<ol>
<li>关联表使数据类型不相同或大小不同；</li>
<li>字符串进行比较时字符集不同；</li>
<li>数据类型不同的列，没有进行转换的情况下。</li>
</ol>
<p>最终是否使用索引，是由查询优化器决定的，会根据检索条件，全表扫描的代价，各种执行方案对比等最终选择一个优化器觉得成本最低的方案执行。</p>
<p>Q: B+Tree 数据结构都可以存储哪些内容</p>
<p>A: BTree 节点可以存放 key 和数据，B+Tree 的内节点只能存放 key ，数据只能存放在叶子节点。</p>
<p>Q: 为什么使用 B+Tree 而不使用二叉树或是红黑树</p>
<p>A: 和计算机处理数据的原理有关系。计算机会在两个地方存储数据，一个是内存，一个是磁盘。当我们使用的数据没有在内存中时，计算机就会报一个缺页异常，这时候内存和磁盘之间就会进行数据交换。计算机会在磁盘上找到数据存储的位置。由于磁盘在读取数据成本很高，为了提高性能，通常计算机会以这个位置为开始位置，向后预读页的整数倍大小数据，将这些数据加载到内存。如果使用二叉树或是红黑树，树的高度会很大，逻辑上很近的数值可能在物理上很远，预读的优势无法体现。BTree 相对来说，出度很大，树的高度相对较小，逻辑相邻的数据物理上也相距很近，可以充分发挥预读的优势。B+Tree 相对于 BTree 来说中间节点只存储 key ，占用空间更小，所以在相同大小的页中包含的节点就更多，一次 I/O 预读的数据就更多。</p>
<p>Q: 什么是聚集索引和非聚集索引，他们有什么区别</p>
<p>A: 在 InnoDB 存储引擎中，B+Tree 的叶子节点保存了完整的数据这种方式叫做聚集索引。MyISAM 存储引擎中 B+Tree 在叶子节点存储的是数据的地址信息，这种方式叫做非聚集索引（二级索引）。如果一个表有多个列使用非聚集索引，那么主键索引和非主键索引结构上是一致的。如果使用聚集索引，那么主键索引的叶子节点存储了完整的数据信息，非主键索引的叶子节点存储的是列信息和主键的信息。</p>
<p>Q: 什么是回表</p>
<p>A: 在使用非主键索引查询时，通过索引查到主键，然后在通过主键进行一次查询，这个过程叫做回表。使用非主键索引进行查询时，可以使用索引覆盖（covering index）来避免回表。</p>
<p>Q: 什么是索引下推</p>
<p>A: 不使用索引下推时，查询结果拿到 server 层，回表之后再根据 where 条件进行过滤。使用索引下推，在 innoDB 层就对查询结果进行过滤，过滤之后的结果返回到 server 层进行回表。使用索引下推优化可以减少回表的数量。</p>
<p>Q: InnoDB 和 MyISAM 的区别。</p>
<p>A: <table style="font-size:12px;color:#333333;border-width: 1px;border-color: #666666;border-collapse: collapse;"><tr><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;"></th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">InnoDB</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">MyISAM</th></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">支持事务</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">支持</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">不支持</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">锁</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">行级锁</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">表级锁</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">支持MVCC</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">支持</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">不支持</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">支持外键</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">支持</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">不支持</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">支持全文索引</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">不支持</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">支持</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">索引</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">聚簇索引</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">非聚簇索引</td></tr></table></p>
<p>Q: 什么情况下应该或不应该使用索引。</p>
<p>A: </p>
<ol>
<li>记录数较少，不用使用索引。</li>
<li>频繁写的表，不应该使用索引。</li>
<li>数据重复且分布平均，比如性别字段，不应该使用索引。</li>
</ol>
<p>Q: 隔离级别</p>
<p>A: 隔离级别有 4 种：</p>
<ol>
<li>Read Uncommitted: 最低级别，任何情况都无法保证。</li>
<li>Read Committed: 可避免脏读的发生。</li>
<li>Repeatable Read: 可避免脏读、不可重复读的发生。</li>
<li>Serializable: 可避免脏读、不可重复读、幻读的发生。</li>
</ol>
<p>Q: 什么是 MVCC ?</p>
<p>A: MVCC (Multi-Version Concurrency Control) 是 InnoDB 使用的一种并发控制协议。在 RC RR 两种隔离级别下，select 会查询版本链中的数据，从而实现读写并发。与之相对的是 LBCC (Lock-Based Concurrency Control) 。</p>
<p>Q: SQL语言包括哪几类？</p>
<p>A: DDL ，DCL ，DML ，DQL ，TPL 。</p>
<p>Q: 脏读、幻读、不可重复读</p>
<p>A: 脏读：事务 T1 将某一值修改，然后事务 T2 读取该值，然后 T1 回滚，导致 T2 所读取到的数据是无效的。<br>幻读：事务 T1 修改了全表数据，然后事务 T2 插入了一条新记录，对 T1 来说还有一条记录没有改。<br>不可重复读：事务 T1 查询一次，然后事务 T2 修改了一条记录，然后 T1 再次查询，两次查询得到的结果不一致。</p>
<p>Q: delete、drop、truncate 区别？</p>
<p>A: 删除表用 drop ，删除表中的全部数据用 truncate ，删除表的部分数据用 delete 。drop 和 truncate 是 DDL ，不能回滚，delete 是 DML ，可以回滚。</p>
<p>Q: MySQL 有哪些锁？</p>
<p>A: MySQL 锁分为 lock 和 latch 。lock 针对的是事务，用来锁定数据库中的对象，latch 针对的是线程，用来保证并发的正确性。latch 是一种轻量级锁，又分为互斥锁 (mutex) 和 读写锁 (rw-lock) 。lock 又分为 表锁，页锁，行锁。行锁里又分 record lock (行锁，锁定一行)，gap lock (间隙锁，锁定范围行) ，next-key lock (临键锁，record lock + gap lock) 。<br>按模式分成共享锁和独占锁。<br>按使用机制分成乐观锁和悲观锁。</p>
<p>Q: 什么是 ACID？</p>
<p>A: 事务要么同时成功要么同时失败，这是原子性 atomic 。成功了 commit 失败了 rollback ，不管 commit 还是 rollback ，一旦执行，结果就是不可变的，这是持久性 Durability 。在事务开始和结束之间，存在中间状态，这些中间状态对事务之外是不可见的，这是隔离性 isolation 。事务前后数据必须是完整一致的，不能存在中间状态，这是一致性 consistency 。</p>
<p>Q: 什么是 B+ 树？</p>
<p>A: B+ 树是一种出度很大，高度很小，已排序的 n 叉树。</p>
<p>Q: AUTO_INCREMENT 的原理？</p>
<p>A: 传统的方式，MySQL 会维护一个计数器来记录当前最大的 id 值，当新增一条记录时，先获取 AUTO-INC 锁直到语句结束。AUTO-INC 是一个表级锁，性能不好，所以有了改进方式。如果能确定插入行数，则使用轻量级的互斥锁，如果是批量插入，还是使用 AUTO-INC 锁。</p>
<p>Q: 组合索引和几个单个的索引有什么区别？</p>
<p>A: 组合索引在进行多个条件查询时可以根据最左前缀规则进行索引，单个索引在多个查询条件时，索引可能只会使用一个索引（实际还要看查询计划）。</p>
<p>Q: 临时表有什么用，什么时候删除？</p>
<p>A: 临时表用于保存临时数据，连接断开时会删除临时表。</p>
<p>Q: 数据库的3个范式是什么？</p>
<p>A: 第一范式：关系中的每个属性都不可再分。第二范式：要有主键。第三范式：消除冗余。</p>
<p>Q: MySQL 主从复制是怎么做的？</p>
<p>A: 当有从库连接到主库时，主库会创建一个线程将 Bin Log 发送到从库。从库创建线程接收 Bin Log 并回放 sql 。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
            <tag> MySQL </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Implementing RPC]]></title>
      <url>/2019/06/23/implementing-rpc/</url>
      <content type="html"><![CDATA[<p>在上一篇 <a href="../../../../2018/05/18/understanding-rpc/">Understanding Remote Procedure Call</a> 中，我们了解 rpc 的基本原理，本节我们通过实现一个 rpc 的 demo 来进一步理解 rpc 。</p>
<p>实现思路如下：</p>
<ol>
<li>首先我们有两个服务， OrderService 和 UserService 分别部署，OrderService 需要调用 UserService 。</li>
<li>rpc over tcp 。rpc 可以基于 http 也可以基于 tcp ，由于 http 是短链接，性能低于 tcp ，所以客户端和服务器通讯使用 tcp ，NIO 性能要优于 BIO ，但是直接使用 Java NIO 难度较大，所以通信框架可以使用 netty 。</li>
<li>客户端和服务器通信效率除了协议的差异，还有一个重要因素是序列化和反序列化的效率。Java 提供了序列化库，但是效率不高。除此以外还有很多性能优秀的序列化/反序列化库，比如 protobuf，json，t’hrift，kryo 等等。pb 的性能和空间占用都很优秀的，并且是跨平台的，如果是 Java 平台，可以使用 protostuff 。</li>
<li>注册中心。注册中心的作用是维护 service 和 地址映射，是一个 key/value，可以使用 redis 实现。单节点，不考虑高可用，探活，负载均衡等功能。</li>
<li>使用代理来完成方法调用。</li>
</ol>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20190624/rpc.png" alt=""></p>
<p>以上就是 rpc demo 的实现思路，代码详见 <a href="https://github.com/bsyonline/microlabs/tree/develop/rpc" target="_blank" rel="external">https://github.com/bsyonline/microlabs/tree/develop/rpc</a> 。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> RPC </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[JVM Lock and Distributed Lock]]></title>
      <url>/2019/06/14/jvm-lock-and-distributed-lock/</url>
      <content type="html"><![CDATA[<p>一个买票的场景：</p>
<pre><code>public void reduce(int num) {
    Jedis jedis = jedisPool.getResource();
    lock.lock();
    Integer tickets = Integer.parseInt(jedis.get(&quot;ticket&quot;));
    boolean buyTicket = false;
    if (tickets - num &gt;= 0) {
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        tickets = tickets - num;
        jedis.set(&quot;ticket&quot;, String.valueOf(tickets));
        log.info(&quot;用户{}买到1张票,还剩{}张票&quot;, Thread.currentThread().getId(), tickets);
        buyTicket = true;
    } else {
        log.info(&quot;余票不足,用户{}没有买到票&quot;, Thread.currentThread().getId());
    }
    if (buyTicket) {
        if (Thread.currentThread().getId() % 2 == 0) {
            // vip加500积分
            log.info(&quot;用户{}是VIP,获得500积分&quot;, Thread.currentThread().getId());
        }
    }
}
</code></pre><p>10 个人买 5 张票，正常只有 5 个人能够买到票，执行程序结果如下：</p>
<pre><code>用户9买到1张票,还剩-3张票
用户5买到1张票,还剩2张票
用户1买到1张票,还剩-2张票
用户7买到1张票,还剩-5张票
用户6买到1张票,还剩3张票
用户4买到1张票,还剩1张票
用户8买到1张票,还剩-4张票
用户4是VIP,获得500积分
用户6是VIP,获得500积分
用户0买到1张票, 还剩4张票
用户0是VIP,获得500积分
用户2买到1张票, 还剩-1张票
用户8是VIP,获得500积分
用户2是VIP,获得500积分
用户3买到1张票, 还剩0张票
</code></pre><p>10 个人都买到了票，说明出现了多线程并发安全问题。要解决多线程并发安全问题很容易想到 synchronized 关键字。在 reduce() 方法上加上 synchronized 就可以解决并发安全问题。</p>
<pre><code>public synchronized void reduce(int num) {}
</code></pre><p>但是，synchronized 加在方法上性能不高，所以我们就会想到另一种 synchronized 用法，只把竞态条件的代码用 synchronized 包起来。</p>
<pre><code>public void reduceWithSynchronized(int num) {
    Jedis jedis = jedisPool.getResource();
    boolean buyTicket = false;
    synchronized (this) {
        Integer tickets = Integer.parseInt(jedis.get(&quot;ticket&quot;));
        if (tickets - num &gt;= 0) {
            try {
                Thread.sleep(100);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            tickets = tickets - num;
            jedis.set(&quot;ticket&quot;, String.valueOf(tickets));
            log.info(&quot;用户{}买到1张票,还剩{}张票&quot;, Thread.currentThread().getId(), tickets);
            buyTicket = true;
        } else {
            log.info(&quot;余票不足,用户{}没有买到票&quot;, Thread.currentThread().getId());
        }
    }
    if (buyTicket) {
        if (Thread.currentThread().getId() % 2 == 0) {
            // vip加500积分
            log.info(&quot;用户{}是VIP,获得500积分&quot;, Thread.currentThread().getId());
        }
    }
}
</code></pre><p>还可以使用 Lock ，效果和 synchronized 相同。</p>
<pre><code>Lock lock = new ReentrantLock();

public void reduceWithLock(int num) {
    boolean buyTicket = false;
    try {
        Jedis jedis = jedisPool.getResource();
        lock.lock();
        Integer tickets = Integer.parseInt(jedis.get(&quot;ticket&quot;));
        if (tickets - num &gt;= 0) {
            try {
                Thread.sleep(100);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            tickets = tickets - num;
            jedis.set(&quot;ticket&quot;, String.valueOf(tickets));
            log.info(&quot;用户{}买到1张票,还剩{}张票&quot;, Thread.currentThread().getId(), tickets);
            buyTicket = true;
        } else {
            log.info(&quot;余票不足,用户{}没有买到票&quot;, Thread.currentThread().getId());
        }

    } finally {
        lock.unlock();
    }
    if (buyTicket) {
        if (Thread.currentThread().getId() % 2 == 0) {
            // vip加500积分
            log.info(&quot;用户{}是VIP,获得500积分&quot;, Thread.currentThread().getId());
        }
    }
}
</code></pre><p>不管是 synchronized 还是 Lock 都是 JVM 级别的锁，单体环境下没有问题，但是如果是在分布式环境下就不能保证并发安全了。</p>
<p>首先把单体应用改成分布式应用。</p>
<p>启动 2 个 Ticket 服务，端口分别为 8081 和 8082 。通过 nginx 来做负载均衡。</p>
<pre><code>http {
    upstream myticket{
        server 127.0.0.1:8081;
        server 127.0.0.1:8082;
    }
    server {
        listen 8888 ;
        charset utf-8;
        location /tickets{
            proxy_pass http://myticket;
        }
    }
}
</code></pre><p>然后还是单体一样，模拟并发来调用 http 接口。运行结果可以看到，虽然都加了 Lock ，但是还是出现了超卖的情况，说明 JVM 级别的锁在分布式环境下是不能解决并发安全问题的。所以我们需要使用分布式锁。</p>
<h5 id="基于-redis-实现分布式锁"><a href="#基于-redis-实现分布式锁" class="headerlink" title="基于 redis 实现分布式锁"></a>基于 redis 实现分布式锁</h5><pre><code>public void reduce(int num) {
    String lockKey = &quot;ticket_lock&quot;;
    String lockId = UUID.randomUUID().toString(); // 1
    Jedis jedis = jedisPool.getResource();
    try {
//            Long result = 0L;
//            while (0 == result) {
//                result = jedis.setnx(lockKey, lockId);
//                jedis.expire(lockKey, 10);
//            }
        String result = &quot;&quot;;
        while (!&quot;OK&quot;.equals(result)) {
            result = jedis.set(lockKey, lockId, &quot;NX&quot;, &quot;PX&quot;, 10000); // 2
            expireTimer = new Timer();
            expireTimer.schedule(new TimerTask() { // 3
                @Override
                public void run() {
                    jedis.expire(lockKey, expire);
                }
            }, 0, period);
        }
        boolean buyTicket = false;
        Integer tickets = Integer.parseInt(jedis.get(&quot;ticket&quot;));
        if (tickets - num &gt;= 0) {
            tickets = tickets - num;
            jedis.set(&quot;ticket&quot;, String.valueOf(tickets));
            log.info(&quot;用户{}买到1张票,还剩{}张票&quot;, Thread.currentThread().getId(), tickets);
            buyTicket = true;
        } else {
            log.info(&quot;余票不足,用户{}没有买到票&quot;, Thread.currentThread().getId());
        }
        if (buyTicket) {
            if (Thread.currentThread().getId() % 2 == 0) {
                // vip加500积分
                log.info(&quot;用户{}是VIP,获得500积分&quot;, Thread.currentThread().getId());
            }
        }
    } finally {
//            if (lockId.equals(jedis.get(lockKey))) {
//                jedis.del(lockKey);
//            }
        String script = &quot;if redis.call(&#39;get&#39;, KEYS[1]) == ARGV[1] then return redis.call(&#39;del&#39;, KEYS[1]) else return 0 end&quot;;
        Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(lockId)); // 4
    }
}
</code></pre><p>上边是基于 jedis 的 redis 分布式锁的实现示例，基本思想就是在 redis 里维护一个 key ，调用业务代码前先来设置 key ，如果设置成功就获得了锁，否则就等待重试。代码比较简单，但是有几个地方需要注意：</p>
<ol>
<li><p>lockId 的作用</p>
<p>每一把锁创建都会有一个唯一 id ，唯一 id 的作用就是防止自己的锁被别人删掉。</p>
</li>
<li><p>setnx</p>
<p>setnx 无法指定锁的失效时间，需要使用 expire 来设置锁失效时间，但是这两个操作不是原子操作，在高并发场景下会出现死锁。所以在高版本的 redis 中使用 set 指定参数的方式来将两个操作作为一个原子操作。</p>
</li>
<li><p>续租</p>
<p>redis 锁续租是一个比较麻烦的问题，通常我们可以根据业务来估算处理时间，锁的失效时间应该大于业务执行的时间。但是估算难免存在误差，所以为了保证在业务执行完之前锁不会因为超时而释放掉，我们可以通过后台线程来定时设置 lockKey 的失效时间，从而达到锁续租的目的。</p>
</li>
<li><p>释放锁</p>
<p>在锁用完之后需要通过删除 lockKey 来释放锁，所以释放锁的代码应该放在 finally 中保证一定会被执行。在执行删除时需要做判断，保证自己只能删除自己的锁。这里同样会有非原子性的问题，解决方法是使用 lua 脚本将操作变成原子操作。</p>
</li>
</ol>
<p>以上就是 redis 锁的实现，注意上边 3 点，基本就可以满足一些场景的锁的需求，虽然我们考虑了很多异常的场景，也针对这些场景进行预防，但是并没有解决一个根本问题，就是 redis 本身是没有一致性的概念的，并不是一个 CP 模型，而锁本身是一个 CP 的需求，所以从根本上来说两者是冲突的。但是这并不妨碍我们在一些一致性要求不高的场景下使用一个简单 redis 实现的分布式锁。</p>
<h5 id="基于-zookeeper-实现分布式锁"><a href="#基于-zookeeper-实现分布式锁" class="headerlink" title="基于 zookeeper 实现分布式锁"></a>基于 zookeeper 实现分布式锁</h5><h5 id="基于-etcd-实现分布式锁"><a href="#基于-etcd-实现分布式锁" class="headerlink" title="基于 etcd 实现分布式锁"></a>基于 etcd 实现分布式锁</h5>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[basic concepts of drools]]></title>
      <url>/2019/06/02/basic-concepts-of-drools/</url>
      <content type="html"><![CDATA[<h5 id="什么是-KIE"><a href="#什么是-KIE" class="headerlink" title="什么是 KIE"></a>什么是 KIE</h5><p>KIE 是 jboss 的一些通用组件的集合，包括 drools， jbpm 等。</p>
<h5 id="KieServices"><a href="#KieServices" class="headerlink" title="KieServices"></a>KieServices</h5><p>KieServices 是程序入口，通过 KieServices 来获取规则构建，管理，执行需要的对象。通过 KieServices 创建 KieContainer ，由 KieContainer 创建 KieSession ， </p>
<h5 id="KieContainer"><a href="#KieContainer" class="headerlink" title="KieContainer"></a>KieContainer</h5><p>由 KieServices 获得，是存放 KieBase 的容器。</p>
<h5 id="KieBase"><a href="#KieBase" class="headerlink" title="KieBase"></a>KieBase</h5><p>KieBase 是知识库，包含规则和方法。创建成本很高。</p>
<h5 id="KieSession"><a href="#KieSession" class="headerlink" title="KieSession"></a>KieSession</h5><p>由 KieBase 创建，KieBase 只有规则和方法，并不包含运行数据，KieSession 包含运行数据和事实（fact），负责数据按照规则进行运算。KieSession 是程序和规则引擎的会话，创建成本低，可反复创建。</p>
<h5 id="KieRepository"><a href="#KieRepository" class="headerlink" title="KieRepository"></a>KieRepository</h5><p>KieRepository 是存放 KieModule 的仓库，单例对象。</p>
<h5 id="KnowledgeBuilder"><a href="#KnowledgeBuilder" class="headerlink" title="KnowledgeBuilder"></a>KnowledgeBuilder</h5><p>用来在业务代码当中收集已经编写好的规则，然后对这些规则文件进行编译，最终产生一批编译好的规则包（KnowledgePackage）给其它的应用程序使用。</p>
<h5 id="KnowledgeBase"><a href="#KnowledgeBase" class="headerlink" title="KnowledgeBase"></a>KnowledgeBase</h5><p>收集应用当中 knowledge 定义的知识库对象，包含普通规则，规则流，函数定义，对象模型等。</p>
<h5 id="KnowledgeBaseConfiguration"><a href="#KnowledgeBaseConfiguration" class="headerlink" title="KnowledgeBaseConfiguration"></a>KnowledgeBaseConfiguration</h5><p>用来存放规则引擎运行的环境参数。</p>
<h5 id="Stateful-和-Stateless"><a href="#Stateful-和-Stateless" class="headerlink" title="Stateful 和 Stateless"></a>Stateful 和 Stateless</h5><p>Stateful 对象会和规则引擎建立一个持续的交互通道，多次触发同一数据集，使用完成要调用 <code>dispose()</code> 方法释放资源。<br>Stateless 对象内部处理 <code>dispose</code>， 不用用户处理。</p>
<h5 id="Fact"><a href="#Fact" class="headerlink" title="Fact"></a>Fact</h5><p>一个普通的 JavaBean 插入到规则的 WorkingMemory 当中后被称为 Fact 。Fact 是 JavaBean 的引用，规则引擎可以操作 Fact ，运行数据存放在 Fact 中。Fact 是规则引擎和应用的数据载体。</p>
<h5 id="Agenda"><a href="#Agenda" class="headerlink" title="Agenda"></a>Agenda</h5><p>规则和 fact 在调用 <code>fireAllRules()</code> 之前都存放在 Agenda 对象中，存放在 Agenda 的对象被称为 Activation 。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Drools </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[A Guide to MongoDB API and Java Driver]]></title>
      <url>/2019/05/25/a-guide-to-mongodb-api-and-java-driver/</url>
      <content type="html"><![CDATA[<p>查询所有</p>
<pre><code>db.getCollection(&#39;order&#39;).find()
</code></pre><p>查询 customerId=1 的记录</p>
<pre><code>db.getCollection(&#39;order&#39;).find({&quot;customerId&quot;:1})
</code></pre><p>查询 customerId=1 的记录，按 userId 降序排序</p>
<pre><code>db.getCollection(&#39;order&#39;).find({&quot;customerId&quot;:1}).sort({&quot;userId&quot;:-1})
</code></pre><p>按 userId 分组</p>
<pre><code>db.getCollection(&#39;order&#39;).aggregate([
  {$group:{_id:&quot;$userId&quot;,count:{&quot;$sum&quot;:1}}}
])
</code></pre><pre><code>/* 1 */
{
    &quot;_id&quot; : 6,
    &quot;count&quot; : 2.0
}
/* 2 */
{
    &quot;_id&quot; : 5,
    &quot;count&quot; : 2.0
}
/* 3 */
{
    &quot;_id&quot; : 2,
    &quot;count&quot; : 4.0
}
/* 4 */
{
    &quot;_id&quot; : 1,
    &quot;count&quot; : 3.0
}
/* 5 */
{
    &quot;_id&quot; : 3,
    &quot;count&quot; : 2.0
}
/* 6 */
{
    &quot;_id&quot; : 4,
    &quot;count&quot; : 2.0
}
</code></pre><p>使用 java driver</p>
<pre><code>public void groupByUserId() {
    MongoCollection&lt;Document&gt; col = mongoClient.getDatabase(database).getCollection(collection);
    MongoCursor&lt;Document&gt; cursor = col.aggregate(Lists.newArrayList(
            group(&quot;$userId&quot;, sum(&quot;count&quot;, new BsonInt32(1)))
    )).iterator();
    while (cursor.hasNext()) {
        Document document = cursor.next();
        System.out.println(new Gson().toJson(document));
    }
}
</code></pre><pre><code>{&quot;_id&quot;:6,&quot;count&quot;:2}
{&quot;_id&quot;:5,&quot;count&quot;:2}
{&quot;_id&quot;:2,&quot;count&quot;:4}
{&quot;_id&quot;:1,&quot;count&quot;:3}
{&quot;_id&quot;:3,&quot;count&quot;:2}
{&quot;_id&quot;:4,&quot;count&quot;:2}
</code></pre><p>按多个字段分组</p>
<pre><code>db.getCollection(&#39;order&#39;).aggregate([
  {$group:{_id:{customerId:&quot;$customerId&quot;,userId:&quot;$userId&quot;},count:{&quot;$sum&quot;:1}}}
])
</code></pre><pre><code>/* 1 */
{
    &quot;_id&quot; : {
        &quot;customerId&quot; : 4,
        &quot;userId&quot; : 4
    },
    &quot;count&quot; : 1.0
}
/* 2 */
{
    &quot;_id&quot; : {
        &quot;customerId&quot; : 3,
        &quot;userId&quot; : 2
    },
    &quot;count&quot; : 1.0
}
/* 3 */
{
    &quot;_id&quot; : {
        &quot;customerId&quot; : 2,
        &quot;userId&quot; : 1
    },
    &quot;count&quot; : 1.0
}
/* 4 */
{
    &quot;_id&quot; : {
        &quot;customerId&quot; : 1,
        &quot;userId&quot; : 6
    },
    &quot;count&quot; : 2.0
}
/* 5 */
{
    &quot;_id&quot; : {
        &quot;customerId&quot; : 1,
        &quot;userId&quot; : 2
    },
    &quot;count&quot; : 3.0
}
/* 6 */
{
    &quot;_id&quot; : {
        &quot;customerId&quot; : 1,
        &quot;userId&quot; : 5
    },
    &quot;count&quot; : 2.0
}
/* 7 */
{
    &quot;_id&quot; : {
        &quot;customerId&quot; : 1,
        &quot;userId&quot; : 1
    },
    &quot;count&quot; : 2.0
}
/* 8 */
{
    &quot;_id&quot; : {
        &quot;customerId&quot; : 1,
        &quot;userId&quot; : 3
    },
    &quot;count&quot; : 2.0
}
/* 9 */
{
    &quot;_id&quot; : {
        &quot;customerId&quot; : 1,
        &quot;userId&quot; : 4
    },
    &quot;count&quot; : 1.0
}
</code></pre><p>使用 java driver</p>
<pre><code>public void groupByCustomerAndUser() {
    MongoCollection&lt;Document&gt; col = mongoClient.getDatabase(database).getCollection(collection);
    MongoCursor&lt;Document&gt; cursor = col.aggregate(Lists.newArrayList(
            group(new BasicDBObject(&quot;customerId&quot;, &quot;$customerId&quot;).append(&quot;userId&quot;, &quot;$userId&quot;), sum(&quot;count&quot;, new BsonInt32(1)))
    )).iterator();
    while (cursor.hasNext()) {
        Document document = cursor.next();
        System.out.println(new Gson().toJson(document));
    }
}
</code></pre><pre><code>{&quot;_id&quot;:{&quot;customerId&quot;:4,&quot;userId&quot;:4},&quot;count&quot;:1}
{&quot;_id&quot;:{&quot;customerId&quot;:3,&quot;userId&quot;:2},&quot;count&quot;:1}
{&quot;_id&quot;:{&quot;customerId&quot;:2,&quot;userId&quot;:1},&quot;count&quot;:1}
{&quot;_id&quot;:{&quot;customerId&quot;:1,&quot;userId&quot;:6},&quot;count&quot;:2}
{&quot;_id&quot;:{&quot;customerId&quot;:1,&quot;userId&quot;:2},&quot;count&quot;:3}
{&quot;_id&quot;:{&quot;customerId&quot;:1,&quot;userId&quot;:5},&quot;count&quot;:2}
{&quot;_id&quot;:{&quot;customerId&quot;:1,&quot;userId&quot;:1},&quot;count&quot;:2}
{&quot;_id&quot;:{&quot;customerId&quot;:1,&quot;userId&quot;:3},&quot;count&quot;:2}
{&quot;_id&quot;:{&quot;customerId&quot;:1,&quot;userId&quot;:4},&quot;count&quot;:1}
</code></pre><p>使用 pipeline ，组合多个操作，按用户去重，查询客户id为1的订单数量</p>
<pre><code>db.getCollection(&#39;order&#39;).aggregate([
  {$match:{&quot;customerId&quot;: 1}},
  {$group:{_id:{customerId:&quot;$customerId&quot;,userId:&quot;$userId&quot;}}},
  {$group:{_id:&quot;$_id.customerId&quot;,count:{&quot;$sum&quot;:1}}}
])
</code></pre><pre><code>/* 1 */
{
    &quot;_id&quot; : 1,
    &quot;count&quot; : 6.0
}
</code></pre><p>使用 java driver</p>
<pre><code>public void findByCustomerDistinctByUser(Integer customerId) {
    MongoCollection&lt;Document&gt; col = mongoClient.getDatabase(database).getCollection(collection);
    MongoCursor&lt;Document&gt; cursor = col.aggregate(Lists.newArrayList(
            match(eq(&quot;customerId&quot;, customerId)),
            group(new BasicDBObject(&quot;customerId&quot;, &quot;$customerId&quot;).append(&quot;userId&quot;, &quot;$userId&quot;), sum(&quot;count&quot;, new BsonInt32(1))),
            group(&quot;$_id.customerId&quot;, sum(&quot;count&quot;, new BsonInt32(1)))
    )).iterator();
    while (cursor.hasNext()) {
        Document document = cursor.next();
        System.out.println(new Gson().toJson(document));
    }
}
</code></pre><pre><code>{&quot;_id&quot;:1,&quot;count&quot;:6}
</code></pre><p>也可以将查询语句转成 bson 对象，这样写</p>
<pre><code>public void findByCustomerDistinctByUser1() {
    MongoCollection&lt;Document&gt; col = mongoClient.getDatabase(database).getCollection(collection);
    String query1 = &quot;{$match:{\&quot;customerId\&quot;: 1}}&quot;;
    String query2 = &quot;{$group:{_id:{customerId:\&quot;$customerId\&quot;,userId:\&quot;$userId\&quot;}}}&quot;;
    String query3 = &quot;{$group:{_id:\&quot;$_id.customerId\&quot;,count:{\&quot;$sum\&quot;:1}}}&quot;;
    Bson bson1 = (Bson) JSON.parse(query1);
    Bson bson2 = (Bson) JSON.parse(query2);
    Bson bson3 = (Bson) JSON.parse(query3);
    MongoCursor&lt;Document&gt; cursor = col.aggregate(Lists.newArrayList(bson1, bson2, bson3)).iterator();
    while (cursor.hasNext()) {
        Document document = cursor.next();
        System.out.println(new Gson().toJson(document));
    }
}
</code></pre><p>小数据量分页使用 skip() 和 limit()</p>
<pre><code>MongoCursor&lt;Document&gt; cursor = col.find()
                .skip(page * pageSize)
                .limit(pageSize)
                .iterator();
</code></pre><p>简单，但是数据量大时有效率问题。因为会把所有记录查出来，从头变例，并且无法使用索引。</p>
<p>大数据量</p>
<pre><code>MongoCursor&lt;Document&gt; cursor = col.find(gt(&quot;_id&quot;, new ObjectId(head)))
                .batchSize(batchSize).limit(limit).iterator();
</code></pre><p>效率高，但是必须回传当前页的最后一条记录的 id，同理上一页，需要回传当前页的第一条记录id，find 条件需要改成 lt() 。还有一个缺点是不能跳页。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MongoDB </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[distributed lock]]></title>
      <url>/2019/05/19/distributed-lock/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[install gitlab using docker]]></title>
      <url>/2019/04/28/install-gitlab-using-docker/</url>
      <content type="html"><![CDATA[<h4 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h4><pre><code>docker pull gitlab/gitlab-ce
</code></pre><h4 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h4><pre><code>docker run -d --hostname gitlab --publish 443:443 --publish 80:80 --publish 22:22 --name gitlab --restart always --volume D:\data\gitlab\config:/etc/gitlab --volume D:\data\gitlab\logs:/var/log/gitlab --volume D:\data\gitlab\data:/var/opt/gitlab gitlab/gitlab-ce
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Facade Pattern]]></title>
      <url>/2019/03/12/facade-pattern/</url>
      <content type="html"><![CDATA[<p>门面模式（Facade Pattern）是一种常用的封装模式。门面模式为子系统提供了统一的接口，隐藏了子系统的复杂性，是系统易于使用。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20190312/1552403341010.png" alt="1552403113798"></p>
<p>以 slf4j 为例，slf4j(Simple Logging Facade for Java)是一个服务于各种日志框架（如log4j，logback，slf4j-impl 等）的日志门面，它并不包含日志的具体实现。slf4j 提供了统一的接口，在使用多种日志框架时只需要使用 slf4j 定义的接口，而不需要关心具体的日志框架使用，大大降低了使用日志框架的复杂度。</p>
<p>我们如果在项目中只加入 slf4j ，日志是不生效的。比如我们使用日志简单打印一条日志：</p>
<pre><code>public class Slf4jTest {

    static Logger logger = LoggerFactory.getLogger(Slf4jTest.class);
    public static void main(String[] args) {
        logger.info(&quot;today is {}, the air temperature is {} at {}.&quot;, &quot;Warmer Day&quot;, &quot;18 degrees&quot;, &quot;10:00&quot;);
    }

}
</code></pre><p>在 pom.xml 中加入依赖</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
    &lt;version&gt;1.7.25&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>执行会得到警告</p>
<pre><code>SLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.
SLF4J: Failed to load class &quot;org.slf4j.impl.StaticLoggerBinder&quot;.
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
</code></pre><p>由此可见只使用 slf4j 日志是不生效的。查看源码我们发现 sfl4j 会去加载 org/slf4j/impl/StaticLoggerBinder.class ，而我们没有加入任何 StaticLoggerBinder 的实现，所以自然也就不会打印出日志。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20190312/1552747908647.png"></p>
<p>如果我们想使用日志，那么加入任何一种日志框架即可，当然也包括自己实现的日志框架。</p>
<p>为了能够打印日志，我们可以自己加一个 StaticLoggerBinder 的简单实现。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20190312/1552748321761.png" style="width:350px"></p>
<p>首先是具体的日志实现 MyLogger ，我们只简单重写 info 方法。</p>
<pre><code>public class MyLogger implements Logger {
    ...
    @Override
    public void info(String format, Object... arguments) {
        format = format.replace(&quot;{}&quot;, &quot;%s&quot;);
        System.out.println(String.format(format, arguments));
    }
    ...
}
</code></pre><p>接着创建一个工厂。</p>
<pre><code>public class MyLoggerFactory implements ILoggerFactory {
    @Override
    public Logger getLogger(String name) {
        return new MyLogger();
    }
}
</code></pre><p>最后使用 StaticLoggerBinder 来告诉日志门面使用那个 Logger 。</p>
<pre><code>public class StaticLoggerBinder implements LoggerFactoryBinder {

    static StaticLoggerBinder SINGLETON = new StaticLoggerBinder();
    ILoggerFactory loggerFactory = new MyLoggerFactory();
    @Override
    public ILoggerFactory getLoggerFactory() {
        return loggerFactory;
    }

    @Override
    public String getLoggerFactoryClassStr() {
        return loggerFactory.getClass().getName();
    }

    public static StaticLoggerBinder getSingleton() {
        return SINGLETON;
    }
}
</code></pre><p>这样就可以正常输出日志了。使用了门面，我们可以自由的更换我们想要的日志实现，而对编程来说，只要 slf4j 的日志接口不变，代码完全不用修改，这提高了系统的灵活性，降低了复杂度。</p>
]]></content>
      
        <categories>
            
            <category> Design Pattern </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Building ShadowSocks on VPS]]></title>
      <url>/2018/12/13/building-ss-on-vps/</url>
      <content type="html"><![CDATA[<p>Shadowsocks 一种基于 Socks5 代理方式的加密传输协议，也可以指实现这个协议的各种开发包。Shadowsocks 分为服务器端和客户端。VPS（Virtual Private Server 虚拟专用服务器）是指将一台服务器分割成多个虚拟专享服务器提供服务的技术，我们这里的 VPS 是指 VPS 主机。本篇我们就来介绍一下如何将 Shadowsocks 服务端安装在 VPS 主机上。VPS 提供商有很多，这里以阿里云 ECS 主机为例。</p>
<h4 id="Shadowsock-Server-配置"><a href="#Shadowsock-Server-配置" class="headerlink" title="Shadowsock Server 配置"></a>Shadowsock Server 配置</h4><p>安装依赖包</p>
<pre><code># yum install wget curl curl-devel zlib-devel openssl-devel perl perl-devel cpio expat-devel gettext-devel git autoconf libtool gcc swig python-devel lsof
</code></pre><p>下载 setuptools</p>
<pre><code># cd /usr/local/src/
# wget --no-check-certificate  https://pypi.python.org/packages/source/s/setuptools/setuptools-19.6.tar.gz#md5=c607dd118eae682c44ed146367a17e26
# tar -zvxf setuptools-19.6.tar.gz
# cd setuptools-19.6
# python2.7 setup.py build
</code></pre><p>安装 pip</p>
<pre><code># yum -y install epel-release
# yum -y install pip python-pip
# pip install --upgrade pip
</code></pre><p>安装 shadowsocks</p>
<pre><code># pip install shadowsocks
</code></pre><p>安装加密的依赖包</p>
<pre><code># pip install M2Crypto
</code></pre><p>创建服务端配置文件 /etc/shadowsocks.json</p>
<pre><code>{
&quot;server&quot;: &quot;0.0.0.0&quot;,
&quot;server_port&quot;: 8388,
&quot;password&quot;: &quot;your ss password&quot;,
&quot;timeout&quot;: 300,
&quot;method&quot;: &quot;aes-256-cfb&quot;
}
</code></pre><p>创建 ss 服务并启动</p>
<p>修改 /etc/systemd/system/ssserver.service</p>
<pre><code>[Unit]
Description=ssserver
[Service]
TimeoutStartSec=0
ExecStart=/usr/bin/ssserver -c /etc/shadowsocks.json
[Install]
WantedBy=multi-user.target
</code></pre><p>启动服务</p>
<pre><code># systemctl enable ssserver
# systemctl start ssserver
</code></pre><p>检查服务状态</p>
<pre><code># systemctl status ssserver -l
● ssserver.service - ssserver
   Loaded: loaded (/etc/systemd/system/ssserver.service; enabled; vendor preset: disabled)
   Active: active (running) since Fri 2018-12-14 16:07:34 CST; 8s ago
 Main PID: 1338 (ssserver)
   CGroup: /system.slice/ssserver.service
           └─1338 /usr/bin/python2 /usr/bin/ssserver -c /etc/shadowsocks.json

Dec 14 16:07:34 izj6cgrp5ibxaav9i9x2t6z systemd[1]: Started ssserver.
Dec 14 16:07:34 izj6cgrp5ibxaav9i9x2t6z systemd[1]: Starting ssserver...
Dec 14 16:07:34 izj6cgrp5ibxaav9i9x2t6z ssserver[1338]: INFO: loading config from /etc/shadowsocks.json
Dec 14 16:07:34 izj6cgrp5ibxaav9i9x2t6z ssserver[1338]: 2018-12-14 16:07:34 INFO     loading libcrypto from libcrypto.so.10
Dec 14 16:07:34 izj6cgrp5ibxaav9i9x2t6z ssserver[1338]: 2018-12-14 16:07:34 INFO     starting server at 0.0.0.0:8388
</code></pre><pre><code># lsof -i:8388
COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
ssserver 1444 root    3u  IPv4  17138      0t0  TCP *:8388 (LISTEN)
ssserver 1444 root    4u  IPv4  17139      0t0  UDP *:8388
</code></pre><p>在配置好 ECS 主机之后，远程 telnet 主机的 8388 会发现无法连接，可能的原因是被防火墙拦截了，所以我们需要把防火墙关掉。</p>
<pre><code># systemctl stop firewalld.service
# systemctl disable firewalld.service
# firewall-cmd --state
not running
</code></pre><p>还要把 8388 端口开放出来。可以使用 iptables 来管理开放端口，首先需要安装 iptables 。</p>
<pre><code># yum install iptables-services
# systemctl restart iptables.service
# systemctl enable iptables.service
</code></pre><p>添加配置</p>
<pre><code># iptables -A INPUT -p tcp --dport 8388 -j ACCEPT
# iptables -A OUTPUT -p tcp --sport 8388 -j ACCEPT
</code></pre><p>保存配置</p>
<pre><code># service iptables save
iptables: Saving firewall rules to /etc/sysconfig/iptables:[  OK  ]
</code></pre><p>查看配置</p>
<pre><code># iptables -L -n
Chain INPUT (policy ACCEPT)
target     prot opt source               destination         
ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0            state RELATED,ESTABLISHED
ACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0           
ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            state NEW tcp dpt:22
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            state NEW tcp dpt:8388
REJECT     all  --  0.0.0.0/0            0.0.0.0/0            reject-with icmp-host-prohibited
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:8388

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination         
REJECT     all  --  0.0.0.0/0            0.0.0.0/0            reject-with icmp-host-prohibited

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            tcp spt:8388
</code></pre><p>如果防火墙已经关闭，端口也已经开放还是无法访问，就需要开启阿里云端口限制。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181213/233904777.png" alt="mark"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181213/233557059.png" alt="mark"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181213/233442475.png" style="width: 350px"></p>
<p>规则设置好后 telnet 一下，访问正常 Shadowsock Server 就配置好了。</p>
<h3 id="客户端配置"><a href="#客户端配置" class="headerlink" title="客户端配置"></a>客户端配置</h3><p>windows 上的配置比较简单，下载 Shadowsocks 客户端，配置服务器信息即可。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181213/235222900.png" style="width: 350px"><br>ubuntu 上也有类似的客户端 shadowsock-qt5 ，安装也很简单。</p>
<pre><code># sudo add-apt-repository ppa:hzwhuang/ss-qt5
# sudo apt-get update
# sudo apt-get install shadowsocks-qt5
</code></pre><p>配置好客户端还需要配合浏览器插件，firefox 和 chrome 都可以使用 SwitchyOmega 。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181213/20181214135728.png" alt="mark"><br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181213/20181214140036.png" alt="mark"></p>
]]></content>
      
        <categories>
            
            <category> Wiki </category>
            
        </categories>
        
        
        <tags>
            
            <tag> ShadowSocks </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Reactive programming]]></title>
      <url>/2018/11/04/reactive-programming/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Reactive </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[spring cloud dataflow architectrue]]></title>
      <url>/2018/10/19/spring-cloud-dataflow-architectrue/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Developing a Spring Cloud Dataflow App]]></title>
      <url>/2018/10/19/developing-a-spring-cloud-dataflow-app/</url>
      <content type="html"><![CDATA[<p>本节我们通过写程序完成一个小功能来了解如何开发 spring cloud dataflow app 。</p>
<p>方便起见，我们将通过 http 发送一个字符串，然后将字符串拆分并输出到文件。我们可以写一个 transform 来完成字符串拆分。</p>
<ol>
<li><p>首先创建一个 spring boot 程序并引入 spring-cloud-stream 的依赖</p>
<pre><code>&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
        &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;
        &lt;version&gt;${commons-lang3.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
        &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-stream-test-support&lt;/artifactId&gt;
        &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;

&lt;build&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;

&lt;distributionManagement&gt;
    &lt;repository&gt;
        &lt;id&gt;mylocal&lt;/id&gt;
        &lt;name&gt;Local Repository&lt;/name&gt;
        &lt;url&gt;http://localhost:8081/nexus/content/repositories/releases&lt;/url&gt;
    &lt;/repository&gt;
    &lt;snapshotRepository&gt;
        &lt;id&gt;mylocal&lt;/id&gt;
        &lt;name&gt;Local Repository&lt;/name&gt;
        &lt;url&gt;http://localhost:8081/nexus/content/repositories/snapshots&lt;/url&gt;
    &lt;/snapshotRepository&gt;
&lt;/distributionManagement&gt;
</code></pre><p>为了能将 jar 上传到 maven 仓库，我们加入了仓库的配置。</p>
</li>
<li><p>加一些注解</p>
<pre><code>import org.apache.commons.lang3.StringUtils;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.stream.annotation.EnableBinding;
import org.springframework.cloud.stream.annotation.StreamListener;
import org.springframework.cloud.stream.messaging.Processor;
import org.springframework.cloud.stream.messaging.Sink;
import org.springframework.messaging.handler.annotation.SendTo;

import java.util.Arrays;

@EnableBinding(Processor.class)
@SpringBootApplication
public class ProcessorApplication {

    public static void main(String[] args) {
        SpringApplication.run(ProcessorApplication.class, args);
    }

    @StreamListener(target = Sink.INPUT)
    @SendTo(Processor.OUTPUT)
    public String split(String s) {
        return StringUtils.join(s.split(&quot;,&quot;), &quot; &quot;);
    }
}
</code></pre><p>使用两个注解，除此之外不需要其他配置，spring cloud dataflow 会自动完成配置。</p>
</li>
<li><p>注册 app</p>
<pre><code>dataflow:&gt;app register --name split-processor --type processor --uri maven://com.rolex.microlabs:transform-app:1.0-SNAPSHOT
</code></pre><p>uri 的格式为：<code>maven://groupId:artifactId:version</code></p>
</li>
<li><p>创建和部署</p>
<p>注册成功后就可以使用 app 来完成 stream 创建了。</p>
<pre><code>stream create --name splittest --definition &quot;splitInput: http | splitTransform: split-processor | splitOutput: file --directory=/tmp --name=split.txt&quot; --deploy true
</code></pre><p>这时你会看到一个这样的错误：</p>
<pre><code>Command failed org.springframework.cloud.dataflow.rest.client.DataFlowClientException: Failed to resolve MavenResource: com.rolex.microlabs:transform-app:jar:1.0-SNAPSHOT. Configured remote repositories: : [springRepo],[repo1]
</code></pre><p>很简单 spring cloud dataflow server 找不到我们写的 trasnform 。因为我们的程序并没有在 maven 的中央仓库中，所以我们需要使用私有 maven 仓库，让 spring cloud dataflow server 从私有仓库中下载 transform 。</p>
<p>停止 spring cloud dataflow server ，加入 maven 仓库选项：</p>
<pre><code>--maven.localRepository=mylocal --maven.remote-repositories.repo1.url=http://localhost:8081/nexus/content/repositories/snapshots/
</code></pre><p>然后重新启动。我们将 transform 上传到 maven 仓库之后再重新部署就可以正常部署了。</p>
</li>
<li><p>部署成功后发一条测试数据</p>
<pre><code>dataflow:&gt;http post --target http://127.0.0.1:46858 --data &quot;spring,cloud,dataflow&quot;
&gt; POST (text/plain) http://127.0.0.1:46858 spring,cloud,dataflow
&gt; 202 ACCEPTED
</code></pre><p>然后查看 /tmp/split.txt 就可以看到 spring cloud dataflow 的信息了。</p>
</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Getting Start with Spring Cloud Dataflow]]></title>
      <url>/2018/10/19/getting-start-with-spring-cloud-dataflow/</url>
      <content type="html"><![CDATA[<h3 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a><strong>配置环境</strong></h3><ol>
<li><p>下载 spring cloud dataflow 的 jar 包</p>
<pre><code>#spring-cloud-dataflow-server-local
wget https://repo.spring.io/release/org/springframework/cloud/spring-cloud-dataflow-server-local/1.6.3.RELEASE/spring-cloud-dataflow-server-local-1.6.3.RELEASE.jar

#spring-cloud-dataflow-shell
wget https://repo.spring.io/release/org/springframework/cloud/spring-cloud-dataflow-shell/1.6.3.RELEASE/spring-cloud-dataflow-shell-1.6.3.RELEASE.jar
</code></pre></li>
<li><p>启动服务</p>
<p>启动 rabbitmq</p>
<pre><code>docker run --name dataflow-rabbit -p 15672:15672 -p 5672:5672 -d rabbitmq:3.7-management
</code></pre><p>启动 redis</p>
<pre><code>docker run --name dataflow-redis -p 6379:6379 -d redis:3.0
</code></pre><p>启动 mysql</p>
<pre><code>docker run --name mysql -e MYSQL_ROOT_PASSWORD=123456 -e MYSQL_DATABASE=scdf -p 3306:3306 -d mysql:5.7
</code></pre><p>启动 spring-cloud-dataflow-server-local</p>
<pre><code>java -jar spring-cloud-dataflow-server-local-1.6.3.RELEASE.jar --spring.datasource.url=jdbc:mysql://localhost:3306/scdf --spring.datasource.username=root --spring.datasource.password=123456 --spring.datasource.driver-class-name=org.mariadb.jdbc.Driver --spring.rabbitmq.host=127.0.0.1 --spring.rabbitmq.port=5672 --spring.rabbitmq.username=guest --spring.rabbitmq.password=guest
</code></pre></li>
<li><p>启动 spring-cloud-dataflow-shell</p>
<pre><code>$ java -jar spring-cloud-dataflow-shell-1.6.3.RELEASE.jar 
____                              ____ _                __
/ ___| _ __  _ __(_)_ __   __ _   / ___| | ___  _   _  __| |
\___ \| &#39;_ \| &#39;__| | &#39;_ \ / _` | | |   | |/ _ \| | | |/ _` |
___) | |_) | |  | | | | | (_| | | |___| | (_) | |_| | (_| |
|____/| .__/|_|  |_|_| |_|\__, |  \____|_|\___/ \__,_|\__,_|
____ |_|    _          __|___/                 __________
|  _ \  __ _| |_ __ _  |  ___| | _____      __  \ \ \ \ \ \
| | | |/ _` | __/ _` | | |_  | |/ _ \ \ /\ / /   \ \ \ \ \ \
| |_| | (_| | || (_| | |  _| | | (_) \ V  V /    / / / / / /
|____/ \__,_|\__\__,_| |_|   |_|\___/ \_/\_/    /_/_/_/_/_/

1.6.3.RELEASE

Welcome to the Spring Cloud Data Flow shell. For assistance hit TAB or type &quot;help&quot;.
dataflow:&gt;
</code></pre><p>如果出现 <code>dataflow-unknown:&gt;</code> 需要设置服务器</p>
<p><code>server-unknown:&amp;gt;dataflow config server http://localhost:9393
server-unknown:&gt;dataflow config server http://localhost:9393
Shell mode: classic, Server mode: classic
dataflow:&gt;</code></p>
</li>
</ol>
<h3 id="使用界面配置-UpperCaseStream"><a href="#使用界面配置-UpperCaseStream" class="headerlink" title="使用界面配置 UpperCaseStream"></a>使用界面配置 UpperCaseStream</h3><p>启动 server 后访问 dashboard <a href="http://localhost:9393/dashboard" target="_blank" rel="external">http://localhost:9393/dashboard</a> 。这时 dashboard 里还没什么内容，spring 提供了一些可用的 app ，我们需要先导入这些 app 。</p>
<p>可以使用 http 方式导入 <a href="http://bit.ly/Celsius-SR3-stream-applications-rabbit-maven" target="_blank" rel="external">bit.ly/Celsius-SR3-stream-applications-rabbit-maven</a> 。</p>
<p><img src="http://pgu17t3sd.bkt.clouddn.com/pic/20181021/131648605.png" alt="mark"></p>
<p>也可以使用文件导入。</p>
<p><img src="http://pgu17t3sd.bkt.clouddn.com/pic/20181021/131813750.png" alt="mark"></p>
<p>导入成功后就可以看到下面的内容。</p>
<p><img src="http://pgu17t3sd.bkt.clouddn.com/pic/20181021/131904382.png" alt="mark"></p>
<p>接下来就使用导入的 3 个 App 来完成第一个例子。</p>
<ol>
<li><p>先创建一个 stream</p>
<p><img src="http://pgu17t3sd.bkt.clouddn.com/pic/20181021/132043862.png" alt="mark"></p>
</li>
<li><p>将 http ，transform ，file 三个组件拖拽到面板</p>
<p><img src="http://pgu17t3sd.bkt.clouddn.com/pic/20181021/133611052.png" alt="mark"></p>
</li>
<li><p>配置 file 的信息</p>
<p><img src="http://pgu17t3sd.bkt.clouddn.com/pic/20181021/125512120.png" alt=""></p>
</li>
<li><p>配置 transform 的信息</p>
<p><img src="http://pgu17t3sd.bkt.clouddn.com/pic/20181021/125302026.png" alt=""></p>
</li>
<li><p>配置 file 的信息</p>
<p><img src="http://pgu17t3sd.bkt.clouddn.com/pic/20181021/125349123.png" alt=""></p>
</li>
<li><p>将 app 按顺序连接起来</p>
<p><img src="http://pgu17t3sd.bkt.clouddn.com/pic/20181021/125604831.png" alt=""></p>
</li>
<li><p>最后创建并部署</p>
<p><img src="http://pgu17t3sd.bkt.clouddn.com/pic/20181021/125711260.png" alt=""></p>
</li>
<li><p>部署完成在 Runtime 中可以看到 stream 的信息</p>
<p><img src="http://pgu17t3sd.bkt.clouddn.com/pic/20181021/131950197.png" alt="mark"></p>
</li>
<li><p>发送一个 http 请求，然后查看文件可看到结果</p>
<pre><code>dataflow:&gt;http post --target http://10.0.75.1:61068 --data &quot;hello world&quot;
&gt; POST (text/plain) http://10.0.75.1:61068 hello world
&gt; 202 ACCEPTED
</code></pre></li>
</ol>
<p><img src="http://pgu17t3sd.bkt.clouddn.com/pic/20181021/131010335.png" alt="mark"></p>
<h3 id="官方文档上的-httptest"><a href="#官方文档上的-httptest" class="headerlink" title="官方文档上的 httptest"></a><strong>官方文档上的 httptest</strong></h3><p>上边我们通过 dashboard 部署了一个 stream，接下来我们通过官方文档的 httptest 来看看如何使用 cli 部署 stream 。</p>
<ol>
<li><p>创建 stream</p>
<pre><code>stream create --name httptest --definition &quot;http | log&quot; --deploy
</code></pre></li>
<li><p>查看 stream</p>
<pre><code>dataflow:&gt;stream list
╔═══════════╤═════════════════╤═════════════════════════════════════════╗
║Stream Name│Stream Definition│                 Status                  ║
╠═══════════╪═════════════════╪═════════════════════════════════════════╣
║httptest   │http | log       │The stream has been successfully deployed║
╚═══════════╧═════════════════╧═════════════════════════════════════════╝
</code></pre></li>
<li><p>查看运行的 App 信息</p>
<pre><code>dataflow:&gt;runtime apps 
╔════════════════════╤═══════════╤════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
║App Id / Instance Id│Unit Status│                                       No. of Instances / Attributes                                        ║
╠════════════════════╪═══════════╪════════════════════════════════════════════════════════════════════════════════════════════════════════════╣
║httptest.http       │ deployed  │                                                     1                                                      ║
╟┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┼┈┈┈┈┈┈┈┈┈┈┈┼┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈╢
║                    │           │       guid = 54544                                                                                         ║
║                    │           │        pid = 2424                                                                                          ║
║                    │           │       port = 54544                                                                                         ║
║httptest.http-0     │ deployed  │     stderr = /tmp/spring-cloud-deployer-69437306715667832/httptest-1539933007655/httptest.http/stderr_0.log║
║                    │           │     stdout = /tmp/spring-cloud-deployer-69437306715667832/httptest-1539933007655/httptest.http/stdout_0.log║
║                    │           │        url = http://127.0.0.1:54544                                                                        ║
║                    │           │working.dir = /tmp/spring-cloud-deployer-69437306715667832/httptest-1539933007655/httptest.http             ║
╟────────────────────┼───────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────╢
║httptest.log        │ deployed  │                                                     1                                                      ║
╟┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┼┈┈┈┈┈┈┈┈┈┈┈┼┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈┈╢
║                    │           │       guid = 17251                                                                                         ║
║                    │           │        pid = 2406                                                                                          ║
║                    │           │       port = 17251                                                                                         ║
║httptest.log-0      │ deployed  │     stderr = /tmp/spring-cloud-deployer-69437306715667832/httptest-1539933007348/httptest.log/stderr_0.log ║
║                    │           │     stdout = /tmp/spring-cloud-deployer-69437306715667832/httptest-1539933007348/httptest.log/stdout_0.log ║
║                    │           │        url = http://127.0.0.1:17251                                                                        ║
║                    │           │working.dir = /tmp/spring-cloud-deployer-69437306715667832/httptest-1539933007348/httptest.log              ║
╚════════════════════╧═══════════╧════════════════════════════════════════════════════════════════════════════════════════════════════════════╝
</code></pre></li>
<li><p>发一条测试数据</p>
<pre><code>dataflow:&gt;http post --target http://127.0.0.1:54544 --data &quot;hello world&quot;
&gt; POST (text/plain) http://127.0.0.1:54544 hello world
&gt; 202 ACCEPTED
</code></pre></li>
<li><p>在 <code>/tmp/spring-cloud-deployer-69437306715667832/httptest-1539933007348/httptest.log/stdout_0.log</code> 中可以看到打印的 hello world 信息。</p>
</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java Virtual Machine Tools]]></title>
      <url>/2018/09/12/java-virtual-machine-tools/</url>
      <content type="html"><![CDATA[<h3 id="jps"><a href="#jps" class="headerlink" title="jps"></a>jps</h3><p>jps (JVM Process Status Tool) 列出正在运行的 JVM 的进程，以及执行主类的名称和进程的本地虚拟机 id 。jps 通常是查看 jvm 信息的第一步。</p>
<pre><code>$ jps -help
Usage: jps [-help]
       jps [-q] [-mlvV] [&lt;hostid&gt;]

Definitions:
    &lt;hostid&gt;:      &lt;hostname&gt;[:&lt;port&gt;]

Options:
       jps 命令支持下列选项，使用这些选项会改变 jsp 的输出内容。
       -q  显示 JVM ID
       -m  显示 main 方法的参数
       -l  显示 main 方法的包名或 jar 文件路径
       -v  显示 JVM 参数
       -V  等同与 jps
</code></pre><p>jps 的使用示例：</p>
<pre><code>$ jps
4611 SubApplication
25782 Main
7415 Jps
4504 RemoteMavenServer
4072 Main
24617 EurekaServerApplication
26297 ZuulApplication
25835 Main
</code></pre><h3 id="jstat"><a href="#jstat" class="headerlink" title="jstat"></a>jstat</h3><p>jstat (JVM Statistics Monitor Tool) 是用于监视 JVM 的运行状态信息的命令行工具。</p>
<pre><code>$ jstat -help
Usage: jstat -help|-options
       jstat -&lt;option&gt; [-t] [-h&lt;lines&gt;] &lt;vmid&gt; [&lt;interval&gt; [&lt;count&gt;]]

Definitions:


Options:
   General Options
           General Options 只有两个选项
           -help 帮助
           -options    显示 statis 选项
   Output Options
           输入选项决定 stat 命令的输出内容和格式。stat 命令的输出是类似表格，列之间用空格分隔。选项可以组合使用。
        class: 类加载器行为监视
        compiler: Java HotSpot VM Just-in-Time 编译器行为监视
        gc: GC 行为监视
        gccapacity: GC 容量和占用空间监视
        gccause: 当前或上一次 GC 监视及原因
        gcnew: 新生代行为监视
        gcnewcapacity: 新生代容量和占用空间监视
        gcold: 老年代行为监视
        gcoldcapacity: 老年代容量和占用空间监视
        gcmetacapacity: metaspace 大小监视，metaspace 就是原来的持久代，从 jdk8 开始使用
        gcutil: 垃圾回收监视汇总
        printcompilation: 显示被 JIT 编译的方法
</code></pre><p>示例：每 250 毫秒查询一次 GC 的情况一共查看 20 次</p>
<pre><code>$ jstat -gc 28511 250 20
</code></pre><p>Stat Options 说明</p>
<ul>
<li>class 选项<ul>
<li>Loaded: 加载的类的数量</li>
<li>Bytes: 加载的类的大小（kBs）</li>
<li>Unloaded: 未加载的类的数量</li>
<li>Bytes: 未加载的类的大小 （Kbytes）</li>
<li>Time: 加载或卸载所消耗的时间</li>
</ul>
</li>
</ul>
<pre><code>$ jstat -class 28511
Loaded  Bytes  Unloaded  Bytes     Time   
 14547 26373.1        0     0.0      17.13
</code></pre><ul>
<li>compiler 选项<ul>
<li>Compiled: 执行 JIT 编译任务的数量</li>
<li>Failed: JIT 编译任务失败的数量</li>
<li>Invalid: JIT 编译任务不合法的数量</li>
<li>Time: 执行 JIT 编译任务的时间</li>
<li>FailedType: 上一个编译失败的类型</li>
<li>FailedMethod: 上一次编译失败的类和方法名字</li>
</ul>
</li>
</ul>
<pre><code>$ jstat -compiler 28511
Compiled Failed Invalid   Time   FailedType FailedMethod
    7910      2       0    60.44          1 java/net/URLClassLoader$1 run
</code></pre><ul>
<li>gc 选项<ul>
<li>S0C: Survivor 0 容量 (kB)</li>
<li>S1C: Survivor 1 容量 (kB)</li>
<li>S0U: Survivor 0 使用量 (kB)</li>
<li>S1U: Survivor 1 使用量 (kB)</li>
<li>EC: Eden 区容量 (kB)</li>
<li>EU: Eden 区使用量 (kB)</li>
<li>OC: 老年代容量 (kB)</li>
<li>OU: 老年代使用量 (kB)</li>
<li>MC: Metaspace 容量 (kB)</li>
<li>MU: Metacspace 使用量 (kB)</li>
<li>CCSC: 类压缩空间容量 (kB) 也是 Java8 新出的概念，配合 matespace 使用</li>
<li>CCSU: 类压缩空间使用量 (kB)</li>
<li>YGC: Young GC 次数</li>
<li>YGCT: Young GC 消耗时间</li>
<li>FGC: Full GC 次数</li>
<li>FGCT: Full GC 消耗时间</li>
<li>GCT: GC 总耗时</li>
</ul>
</li>
</ul>
<pre><code>$ jstat -gc 28511 
 S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT   
6144.0 17408.0  0.0   17393.6 997888.0 919208.4  226304.0   43056.4   75136.0 73724.1 9856.0 9576.9     21    0.279   3      0.451    0.731
</code></pre><ul>
<li>gccapacity 选项<ul>
<li>NGCMN: 新生代最小容量 (kB)</li>
<li>NGCMX: 新生代最大容量 (kB)</li>
<li>NGC: 新生代容量 (kB)</li>
<li>S0C: Survivor 0 容量 (kB)</li>
<li>S1C: Survivor 1 容量 (kB)</li>
<li>EC: Eden 区容量 (kB)</li>
<li>OGCMN: 老年代最小容量 (kB)</li>
<li>OGCMX: 老年代最大容量 (kB)</li>
<li>OGC: 老年代容量 (kB)</li>
<li>OC: 老年代容量 (kB)</li>
<li>MCMN: 元空间最小容量 (kB)</li>
<li>MCMX: 元空间最大容量 (kB)</li>
<li>MC: 元空间容量 (kB)</li>
<li>CCSMN: 类压缩空间最小容量 (kB)</li>
<li>CCSMX: 类压缩空间最大容量 (kB)</li>
<li>CCSC: 类压缩空间容量 (kB)</li>
<li>YGC: Young GC 次数</li>
<li>FGC: Full GC 次数</li>
</ul>
</li>
</ul>
<pre><code>$ jstat -gccapacity 28511 
 NGCMN    NGCMX     NGC     S0C   S1C       EC      OGCMN      OGCMX       OGC         OC       MCMN     MCMX      MC     CCSMN    CCSMX     CCSC    YGC    FGC 
 84480.0 1344000.0 1076736.0 6144.0 17408.0 997888.0   169472.0  2688512.0   226304.0   226304.0      0.0 1114112.0  75136.0      0.0 1048576.0   9856.0     21     3
</code></pre><ul>
<li>gccause 选项<br>和 gcutil 选项相同，但是多了下面两个选项<ul>
<li>LGCC: 上一次 GC 原因</li>
<li>GCC: 当前 GC 原因</li>
</ul>
</li>
</ul>
<pre><code>$ jstat -gccause 28511 
  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT    LGCC                 GCC                 
  0.00  99.92  92.12  19.03  98.12  97.17     21    0.279     3    0.451    0.731 Allocation Failure   No GC
</code></pre><ul>
<li>gcnew 选项<ul>
<li>S0C: Survivor 0 容量 (kB)</li>
<li>S1C: Survivor 1 容量 (kB)</li>
<li>S0U: Survivor 0 使用量 (kB)</li>
<li>S1U: Survivor 1 使用量 (kB)</li>
<li>TT: 新生代需要经历多少次 GC 晋升到老年代</li>
<li>MTT: 新生代需要经历多少次 GC 晋升到老年代中的最大阈值</li>
<li>DSS: 期望的 Survivor 大小 (kB)</li>
<li>EC: Eden 区容量 (kB)</li>
<li>EU: Eden 区使用量 (kB)</li>
<li>YGC: Young GC 次数</li>
<li>YGCT: Young GC 耗时</li>
</ul>
</li>
</ul>
<pre><code>$ jstat -gcnew 28511 
 S0C    S1C    S0U    S1U   TT MTT  DSS      EC       EU     YGC     YGCT  
6144.0 17408.0    0.0 17393.6  4  15 20992.0 997888.0 919208.4     21    0.279
</code></pre><ul>
<li>gcnewcapacity 选项<ul>
<li>NGCMN: 新生代最小容量 (kB)</li>
<li>NGCMX: 新生代最大容量 (kB)</li>
<li>NGC: 新生代容量 (kB)</li>
<li>S0CMX: Survivor 0 最大容量 (kB)</li>
<li>S0C: Survivor 0 容量 (kB)</li>
<li>S1CMX: Survivor 1 最大容量 (kB)</li>
<li>S1C: Survivor 1 容量 (kB)</li>
<li>ECMX: Eden 区最大容量 (kB)</li>
<li>EC: Eden 区容量 (kB)</li>
<li>YGC: Young GC 次数</li>
<li>FGC: Full GC 次数</li>
</ul>
</li>
</ul>
<pre><code>$ jstat -gcnewcapacity 28511 
  NGCMN      NGCMX       NGC      S0CMX     S0C     S1CMX     S1C       ECMX        EC      YGC   FGC 
   84480.0  1344000.0  1076736.0 448000.0   6144.0 448000.0  17408.0  1342976.0   997888.0    21     3
</code></pre><ul>
<li>gcold 选项<ul>
<li>MC: 元空间容量 (kB)</li>
<li>MU: 元空间使用量 (kB)</li>
<li>CCSC: 类压缩空间容量 (kB)</li>
<li>CCSU: 类压缩空间使用量 (kB)</li>
<li>OC: 老年代容量 (kB)</li>
<li>OU: Old space 使用量 (kB)</li>
<li>YGC: Young GC 次数</li>
<li>FGC: Full GC 次数</li>
<li>FGCT: Full GC 耗时</li>
<li>GCT: GC 总耗时</li>
</ul>
</li>
</ul>
<pre><code>$ jstat -gcold 28511 
   MC       MU      CCSC     CCSU       OC          OU       YGC    FGC    FGCT     GCT   
 75136.0  73724.1   9856.0   9576.9    226304.0     43056.4     21     3    0.451    0.731
</code></pre><ul>
<li>gcoldcapacity 选项<ul>
<li>OGCMN: 老年代最小容量 (kB)</li>
<li>OGCMX: 老年代最大容量 (kB)</li>
<li>OGC: 老年代容量 (kB)</li>
<li>OC: Old space 容量 (kB)</li>
<li>YGC: Young GC 次数</li>
<li>FGC: Full GC 次数</li>
<li>FGCT: Full GC 耗时</li>
<li>GCT: GC 总耗时</li>
</ul>
</li>
</ul>
<pre><code>$ jstat -gcoldcapacity 28511 
   OGCMN       OGCMX        OGC         OC       YGC   FGC    FGCT     GCT   
   169472.0   2688512.0    226304.0    226304.0    21     3    0.451    0.731
</code></pre><ul>
<li>gcmetacapacity 选项<ul>
<li>MCMN: 元空间最小容量 (kB)</li>
<li>MCMX: 元空间最大容量 (kB)</li>
<li>MC: 元空间容量 (kB)</li>
<li>CCSMN: 类压缩空间最小容量 (kB)</li>
<li>CCSMX: 类压缩空间最大容量 (kB)</li>
<li>YGC: Young GC 次数</li>
<li>FGC: Full GC 次数</li>
<li>FGCT: Full GC 耗时</li>
<li>GCT: GC 总耗时</li>
</ul>
</li>
</ul>
<pre><code>$ jstat -gcmetacapacity 28511 
   MCMN       MCMX        MC       CCSMN      CCSMX       CCSC     YGC   FGC    FGCT     GCT   
       0.0  1114112.0    75136.0        0.0  1048576.0     9856.0    21     3    0.451    0.731
</code></pre><ul>
<li>gcutil 选项<ul>
<li>S0: Survivor 0 使用量对空间容量占比</li>
<li>S1: Survivor 1 使用量对空间容量占比</li>
<li>E: Eden 区使用量对空间容量占比</li>
<li>O: 老年代使用量对空间容量占比</li>
<li>M: 元空间使用量对空间容量占比</li>
<li>CCS: 类压缩空间使用量对空间容量占比</li>
<li>YGC: Young GC 次数.</li>
<li>YGCT: Young generation garbage collection time.</li>
<li>FGC: Full GC 次数.</li>
<li>FGCT: Full GC 耗时.</li>
<li>GCT: GC 总耗时.</li>
</ul>
</li>
</ul>
<pre><code>$ jstat -gcutil 28511 
  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT   
  0.00  99.92  94.69  19.03  98.12  97.17     21    0.279     3    0.451    0.731
</code></pre><ul>
<li>printcompilation 选项<ul>
<li>Compiled: 最近编译的方法中 JIT 编译任务数量</li>
<li>Size: 最近编译方法字节码的字节数</li>
<li>Type: 最近编译的方法的编译类型</li>
<li>Method: 标识最近编译的方法的类名和方法名，类名使用 <code>/</code> 代替 <code>.</code> ，类名和方法名的格式和 HotSpot -XX:+PrintCompilation 选项一致</li>
</ul>
</li>
</ul>
<pre><code>$ jstat -printcompilation 28511 
Compiled  Size  Type Method
    7913     21    1 java/net/InetAddress$InetAddressHolder init
</code></pre><h3 id="jstack"><a href="#jstack" class="headerlink" title="jstack"></a>jstack</h3><p>jstack (Stack Trace for Java) 用于生成 JVM 当前时刻的线程快照（threaddump 或 javacore）。线程快照是当前 JVM 每个线程正在执行的方法的堆栈集合，生成线程快照的目的是定位线程出现长时间停顿的原因，比如死锁。用法如下：</p>
<pre><code>$ jstack -help
Usage:
    jstack [-l] &lt;pid&gt;
        (to connect to running process)
    jstack -F [-m] [-l] &lt;pid&gt;
        (to connect to a hung process)
    jstack [-m] [-l] &lt;executable&gt; &lt;core&gt;
        (to connect to a core file)
    jstack [-m] [-l] [server_id@]&lt;remote server IP or hostname&gt;
        (to connect to a remote debug server)

Options:
    -F  强制，线程无响应时使用
    -m  输出 java 和 native 堆栈信息
    -l  显示锁信息
    -h or -help to print this help message
</code></pre><h3 id="jinfo"><a href="#jinfo" class="headerlink" title="jinfo"></a>jinfo</h3><p>jinfo (Configuration Info for Java) 的作用是查看调整 JVM 参数。用法如下：</p>
<pre><code>$ jinfo -help
Usage:
    jinfo [option] &lt;pid&gt;

where &lt;option&gt; is one of:
    -flag &lt;name&gt;         打印指定名称的参数
    -flag [+|-]&lt;name&gt;    打开或关闭参数
    -flag &lt;name&gt;=&lt;value&gt; 设置参数
    -flags               打印所有参数
    -sysprops            打印 Java system properties
    &lt;no option&gt;          打印 flags 和 sysprops
</code></pre><p>如果我们想查看某进程的 GC 日志信息，可以使用命令</p>
<pre><code>$ jinfo -flag GCLogFileSize 14801
-XX:GCLogFileSize=8192
</code></pre><h3 id="jmap"><a href="#jmap" class="headerlink" title="jmap"></a>jmap</h3><p>jmap (Memory Map for Java) 用于生成堆的存储快照（dump 文件），查询 finalize 执行队列， Java 堆和永久代信息。用法如下：</p>
<pre><code>$ jmap -help
Usage:
    jmap [option] &lt;pid&gt;

where &lt;option&gt; is one of:
    &lt;none&gt;               to print same info as Solaris pmap
    -heap                显示堆的详细信息
    -histo[:live]        显示堆的统计信息
    -clstats             信息 classloader 的统计信息
    -finalizerinfo       显示等待执行 finalize 方法的对象
    -dump:&lt;dump-options&gt; 生成堆的存储快照
                         dump-options:
                           live         dump only live objects; if not specified,
                                        all objects in the heap are dumped.
                           format=b     binary format
                           file=&lt;file&gt;  dump heap to &lt;file&gt;
                         Example: jmap -dump:live,format=b,file=heap.bin &lt;pid&gt;
    -F                   强制生成 dump
    -h | -help           to print this help message
    -J&lt;flag&gt;             to pass &lt;flag&gt; directly to the runtime system
</code></pre><p>如果我们想生成进程的 dump 文件，可以使用</p>
<pre><code>$ jmap -dump:file=14801.dump 14801 
Dumping heap to /home/root/14801.dump ...
Heap dump file created
</code></pre><h3 id="jhat"><a href="#jhat" class="headerlink" title="jhat"></a>jhat</h3><p>jhat （JVM Heap Analysis Tool） 是用来分析 dump 文件的，通常和 jmap 搭配使用。</p>
<pre><code>$ jhat -help
Usage:  jhat [-stack &lt;bool&gt;] [-refs &lt;bool&gt;] [-port &lt;port&gt;] [-baseline &lt;file&gt;] [-debug &lt;int&gt;] [-version] [-h|-help] &lt;file&gt;

  -J&lt;flag&gt;          Pass &lt;flag&gt; directly to the runtime system. For
        example, -J-mx512m to use a maximum heap size of 512MB
  -stack false:     Turn off tracking object allocation call stack.
  -refs false:      Turn off tracking of references to objects
  -port &lt;port&gt;:     Set the port for the HTTP server.  Defaults to 7000
  -exclude &lt;file&gt;:  Specify a file that lists data members that should
        be excluded from the reachableFrom query.
  -baseline &lt;file&gt;: Specify a baseline object dump.  Objects in
        both heap dumps with the same ID and same class will
        be marked as not being &quot;new&quot;.
  -debug &lt;int&gt;:     Set debug level.
          0:  No debug output
          1:  Debug hprof file parsing
          2:  Debug hprof file parsing, no server
  -version          Report version number
  -h|-help          Print this help and exit
  &lt;file&gt;            The file to read

For a dump file that contains multiple heap dumps,
you may specify which dump in the file
by appending &quot;#&lt;number&gt;&quot; to the file name, i.e. &quot;foo.hprof#3&quot;.

All boolean options default to &quot;true&quot;
</code></pre><p>jmap 提供了一个 http 服务，可以通过浏览器查看 dump 文件信息</p>
<pre><code>$ jhat 14801.dump 
Reading from 14801.dump...
Dump file created Mon Feb 18 17:10:37 CST 2019
Snapshot read, resolving...
Resolving 2366175 objects...
Chasing references, expect 473 dots.............
Eliminating duplicate references................
Snapshot resolved.
Started HTTP server on port 7000
Server is ready.
</code></pre><p>访问 <a href="http://localhost:7000" target="_blank" rel="external">http://localhost:7000</a> 可以查看 dump 信息，不过并不常用。</p>
<h3 id="HSDIS"><a href="#HSDIS" class="headerlink" title="HSDIS"></a>HSDIS</h3><h3 id="JConsole"><a href="#JConsole" class="headerlink" title="JConsole"></a>JConsole</h3><p>JConsole (Java Monitoring and Management Console) 是一种基于 JMX 的可视化工具，主要针对 JMX MBean 进行管理。使用 jconsole 可以启动。</p>
<h3 id="VirtualVM"><a href="#VirtualVM" class="headerlink" title="VirtualVM"></a>VirtualVM</h3>]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Eureka Data Structure]]></title>
      <url>/2018/08/29/eureka-data-structure/</url>
      <content type="html"><![CDATA[<p>在 Eureka Server 中，使用了双层 ConcurrentHashMap 来存储 Eureka Client 的注册信息。</p>
<pre><code class="java">private final ConcurrentHashMap&lt;String, Map&lt;String, Lease&lt;InstanceInfo&gt;&gt;&gt; registry
            = new ConcurrentHashMap&lt;String, Map&lt;String, Lease&lt;InstanceInfo&gt;&gt;&gt;();
</code></pre>
<p>第一层 Map 的 Key 是 Eureka Client 的 <code>spring.application.name</code> ，Value 是 ConcurrentHashMap 。第二层 Map 的 Key 是 Client 的 instanceId ，Value 是一个 Lease 对象，对象存放 InstanceInfo 和 Client 的注册时间，剔除时间，续约时间，持续时长等信息。InstanceInfo 包含的信息如图：</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/112829711.png" style="width:240px;"></p>
<p>详情可参考 <code>com.netflix.eureka.registry.AbstractInstanceRegistry</code> 中的 <code>register()</code> 方法。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/185301822.png" style="width:600px;"></p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Communication between Eureka Server and Client]]></title>
      <url>/2018/08/29/communication-between-eureka-server-and-client/</url>
      <content type="html"><![CDATA[<p>Eureka Server 和 Eureka Client 之间是通过一组 API 进行通信的，包括服务注册（registry），续约（renew），退出（cancel）和剔除（evict）。</p>
<h3 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h3><p>Eureka Client 启动之后首先会向 Eureka Server 进行注册，注册流程如下：</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/213336520.png" style="width:600px;"></p>
<ol>
<li><p>Client 通过 <code>POST /eureka/v2/apps/{appID}</code> 向 Server 发起注册请求；</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/194055677.png" alt="mark"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/193909570.png" alt="mark"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/195210819.png" alt="mark"></p>
</li>
<li><p>Server 收到请求后，用双层 HashMap 保存注册信息；</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/202843068.png" alt="mark"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/203115942.png" alt="mark"></p>
</li>
<li><p>更新自我保护机制阈值 <code>expectedNumberOfRenewsPerMin</code> 和 <code>numberOfRenewsPerMinThreshold</code> ;</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/203204566.png" alt="mark"></p>
<blockquote>
<ul>
<li><code>expectedNumberOfRenewsPerMin</code> ，期望<strong>最大</strong>每分钟<strong>续租</strong>次数。</li>
<li><code>numberOfRenewsPerMinThreshold</code> ，期望<strong>最小</strong>每分钟<strong>续租</strong>次数。</li>
</ul>
</blockquote>
</li>
<li><p>将服务名字放到 <code>recentRegisteredQueue</code> 中；</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/203238017.png" alt="mark"></p>
</li>
<li><p>更新实例的状态；</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/203428268.png" alt="mark"></p>
</li>
<li><p>将实例信息放到 <code>recentlyChangedQueue</code> 中；</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/203518017.png" alt="mark"></p>
</li>
<li><p>通过 <code>invalidate()</code> 清除 guava 缓存；</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180902/203555642.png" alt="mark"></p>
</li>
<li><p>向相邻节点复制信息。</p>
</li>
</ol>
<h3 id="续约"><a href="#续约" class="headerlink" title="续约"></a>续约</h3><p>Eureka Client 注册到 Eureka Server 后，需要定期（每30s）发送心跳来维持通信。如果超时未收到心跳，服务器会认为服务不可用，从而将 Eureka Client 的注册信息从服务器删除。Renew 的流程如下：<br>   <img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/181214611.png" style="width:600px;"></p>
<ol>
<li>Eureka Client 通过定时任务向服务器发起 renew 请求<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/103505114.png" alt="mark"><br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/103600120.png" alt="mark"></li>
<li>Eureka Server 收到请求后会更新该 Client 的更新时间<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181209/105522756.png" alt="mark"><br>更新最小分钟数 renewsLastMin 和 最后更新时间<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181209/110101803.png" alt="mark"></li>
<li>Eureka Server 向相邻节点同步信息<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/105217080.png" alt="mark"></li>
</ol>
<h3 id="剔除"><a href="#剔除" class="headerlink" title="剔除"></a>剔除</h3><p>在 Eureka Server 上未正常推出和超时未收到心跳的 Client 注册信息会被剔除。 Evict 的流程如下：<br>   <img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/203523620.png" style="width:600px;"></p>
<ol>
<li>初始化环境和上下文<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181209/111039577.png" alt="mark"></li>
<li>从相邻节点同步注册信息<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181209/173229607.png" alt="mark"></li>
<li>更新自我保护阈值<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/194857681.png" alt="mark"></li>
<li>创建 evictionTask<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181209/174851249.png" alt="mark"><br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/194744627.png" alt="mark"></li>
<li>判断是否过期<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/195021721.png" alt="mark"><br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/195402678.png" alt="mark"><br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/195834558.png" alt="mark"></li>
<li>计算剔除的数量并随机删除<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/200711079.png" alt="mark"></li>
<li>更新缓存</li>
</ol>
<h3 id="退出"><a href="#退出" class="headerlink" title="退出"></a>退出</h3><p>退出是 Eureka Client 主动向服务通知服务关闭的操作，流程如下：<br>   <img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/210042210.png" style="width:600px;"></p>
<ol>
<li>Eureka Client 向服务器发送 cancel 请求<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180916/204524786.png" alt="mark"></li>
<li>Eureka Server 收到请求后，将实例从服务列表中删除<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181209/182926978.png" alt="mark"><br>将实例信息放到 recentlyChangedQueue 中，清空 guava 缓存<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181209/183358439.png" alt="mark"></li>
<li>向相邻节点同步信息，更新阈值<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181209/183044458.png" alt="mark"></li>
</ol>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[cache in eureka server]]></title>
      <url>/2018/08/29/cache-in-eureka-server/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Synchronization between Eureka Server Nodes]]></title>
      <url>/2018/08/29/synchronization-between-eureka-server-nodes/</url>
      <content type="html"><![CDATA[<p>多个 Eureka Server 可以构成集群，集群搭建方式参考 <a href="../../../../2020/03/22/building-eureka-server-with-peer-awareness/">Building Eureka Server with Peer Awareness</a> 。</p>
<p>Eureka Server 使用 peer to peer 的方式来同步数据，即每个 Server Node 都作为 Client 向其他 Server 注册信息。Eureka Server 收到 Eureka Client 的请求（注册，续约，注销）之后，会将自己当作 Client 向其他 Eureka Server 发送请求同步数据。多个 Eureka Server 之间进行数据同步，就可能会存在同一个 Eureka Client 的信息存在多份，Eureka Server 会通过 lastDirtyTimestamp 来获取最新的数据。如果这个过程出现了网络异常，数据同步失败，那么会在下一次心跳的时候再进行复制。当发生网络分区时， Eureka Server 依旧可以提供服务注册，如果大面积心跳接收失败，会进入自我保护模式。当网络恢复后，会自动恢复。</p>
<p>再来看下源码，就以 heartbeat 为例：<br><img src="https://s1.ax1x.com/2020/03/22/85XrVI.png" alt="85XrVI.png" border="0"><br>会创建一个 ReplicationTask ，通过 TaskProcessor 异步执行任务进行数据同步。如果响应 404 ，说明对方没有该注册信息，则向对方注册，同样也是任务放到线程队列由 TaskProcessor 来执行。如果信息的 timestamp 不一致，则根据 timestamp 判断是否进行 override 。<br><img src="https://s1.ax1x.com/2020/03/22/8ISec8.png" alt="8ISec8.png" border="0"></p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Eureka Server Self Preservation Mode]]></title>
      <url>/2018/08/29/eureka-server-self-preservation-mode/</url>
      <content type="html"><![CDATA[<p>Eureka Client 可以向 Eureka Server 注册信息，并通过心跳来维持注册信息有效，当 Eureka Client 进行显示的注销或一段时间内 Eureka Server 没有收到心跳时，Eureka Server 会删除掉该 Eureka Client 的注册信息。当发生网络分区时，Eureka Server 长时间无法收到 Eureka Client 的心跳信息，如果 3 次心跳异常数量超出阈值，会进入自我保护模式。目的是为了保护注册信息不会被 Eureka Server 删除而导致大面积注册信息失效，并且在 Eureka Server 之间同步时不会影响其他的 Server Node 。默认情况下，Eureka Server 会开启自我保护机制，当失效的服务数量大于 15% 时，会进入自我保护模式，直到恢复到阈值之上或自我保护被关闭。</p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Eureka Region and Zone]]></title>
      <url>/2018/08/29/eureka-region-and-zone/</url>
      <content type="html"><![CDATA[<p>Region 和 Zone 是 AWS 的概念，Region 可以理解为地区，Zone 可以理解为机房。参考 Eureka 的架构图：<br><img src="https://s1.ax1x.com/2020/03/22/84w60K.png" alt="84w60K.png" border="0" style="width:600px;"></p>
<p>us-east-1 为 Region ，us-east-1 下有 3 个 Zone : us-east-1c ，us-east-1d ，us-east-1e 。每个 Zone 中有 Eureka Server 和 Eureka Client ，Eureka Client 优先向同一个 Zone 中的 Eureka Server 注册，除非当前 Zone 中的 Eureka Server 不可用，才会向远端的 Zone 中的 Eureka Server 注册。Eureka Client 虽然只向各自 Zone 中的 Eureka Server 注册，但是 Eureka Server 之间会同步注册信息，所以 Eureka Client 之间依旧可以相互调用。<br>Practice 参考 <a href="../../../../2020/03/22/building-eureka-server-with-region-and-zone/">Building Eureka Server with Region and Zone</a></p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Garbage Collection Basics]]></title>
      <url>/2018/08/27/garbage-collection-basics/</url>
      <content type="html"><![CDATA[<h4 id="垃圾对象判断"><a href="#垃圾对象判断" class="headerlink" title="垃圾对象判断"></a>垃圾对象判断</h4><p>垃圾回收第一步就是确定哪些对象需要被回收，方法有 2 种：</p>
<ol>
<li><strong>引用计数</strong><br>引用计数就是在全局维护一个 Map 保存对象的引用，当引用一个对象的时候，就给对应的 value 加 1 ，当这个引用失效的时候，就将对应的 value 减 1 。当 value 的值为 0 的时候，就说明此刻该对象是垃圾对象，可以被回收掉。引用计数的缺点：<br>1） 无法解决循环引用的问题。<br>2） 引用计数需要实时更新，开销大。</li>
<li><strong>可达性分析</strong><br>可达性分析就是从 GC root 开始遍历，能遍历到的对象就不会被回收。hotspot 的定义的 GC roots 有：<br>1） 虚拟机栈中引用的对象（栈帧中局部变量表中的对象）。<br>2） 方法区中静态属性和常量引用的对象。<br>3） 本地方法栈中的对象。</li>
</ol>
<h4 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h4><ol>
<li><strong>标记-清除算法</strong><br>标记清除算法是最基本的垃圾收集算法。算法分为标记和清除两个阶段。首先，标记出所有需要回收的对象，在标记完后统一回收所有被标记的对象。标记清楚算法缺点：<br>1）效率不高；<br>2）清除后会产生大量不连续的内存碎片，碎片太多，会导致在创建大对象时没有足够的连续内存，会再次触发垃圾回收。</li>
<li><strong>复制算法</strong><br>复制算法是为了解决标记清除算法的效率问题提出的。复制算法将内存分为大小相等的两份，每次使用其中一份。当其中一块用完了，就将对象复制到另一块上，然后再把原来的内存一次清除。这样每次都对一整块内存进行操作，不会出现内存碎片的问题，简单高效，但是缺点也很明显，就是每次只有一半的内存可以使用。复制算法在新生代的垃圾回收中被大量采用，新生代被分为 Eden 和 Survivor 。当进行垃圾回收时， Eden 和其中一个 Survivor 的对象会被复制到另一个 Survivor 中。如果 Survivor 空间不够，对象会进入 Old 区，这被称为分配担保（Handle Promotion）。</li>
<li><strong>标记-整理算法</strong><br>由于复制算法的特点，一般不会在 Old 区使用。根据 Old 区的特点，提出了另一种标记-整理算法。首先对对象进行标记，然后将对象向一端移动，然后清理掉边界以外的内存空间。</li>
<li><strong>分代收集算法</strong><br>分代收技算法是根据对象的存活时间，将内存分为几块，根据不同区域的特点选择不同的垃圾回收算法。如新生代中对象创建和死亡的频率很高，所以大多采用复制算法。老年代没有额外的内存进行分配担保，所以大多使用标记-删除和标记-复制算法。</li>
</ol>
<h4 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h4><p>垃圾收集器是对垃圾收集算法的实现，垃圾收集器可以搭配使用。</p>
<ul>
<li>年轻代垃圾收集器<br><strong> 1. Serial 收集器</strong><br>Serial 收集器是单线程的，它会在进行垃圾回收时，会暂停其他所有线程（stop-the-world）。Serial 收集器简单高效，虽然会造成停顿，但是在 Client 模式下，Serial 收集器是一个不错的选择。<br><strong>2. ParNew 收集器</strong><br>ParNew 是 Serial 的多线程版本，由于 CMS 只能搭配 ParNew 使用，所以 ParNew 是 Server 模式下的新生代收集器首选。<br><strong>3. Parallel Scavenge 收集器</strong><br>Parallel Scavenge 是新生代收集器，使用复制算法，并行的多线程收集器。Parallel Scavenge 的衡量标准是吞吐量。吞吐量是 CPU 用于运行用户代码与 CPU 总消耗时间的比值。</li>
</ul>
<ul>
<li><p>老年代垃圾收集器<br><strong>1. Serial Old 收集器</strong><br>Serial Old 是 Serial 的老年代版本。会暂停所有线程，使用标记整理算法。<br><strong>2. <a href="../../../../2020/02/23/cms-garbage-collector">CMS 收集器</a></strong><br>Concurrent Mark Sweep 目标是减少停顿。使用标记清除算法。<br><strong>3. Parallel Old 收集器</strong><br>Parallel Old 是 Parallel Scavenge 的老年代版本，搭配 Parallel Scanvenge 使用。</p>
</li>
<li><p><a href="../../../../2020/02/23/g1-garbage-collector">G1 收集器</a></p>
</li>
</ul>
<h4 id="串行，并行和并发"><a href="#串行，并行和并发" class="headerlink" title="串行，并行和并发"></a>串行，并行和并发</h4><p>串行：应用和 GC 是顺序执行的，在 GC 的时候应用需要停止，只有一个线程在 GC 。<br>并行：应用和 GC 是顺序执行的，在 GC 的时候应用需要停止，有多个线程在 GC 。<br>并发：应用和 GC 是同时执行的，可能同时执行，也可能交替执行。</p>
]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[JVM Architecture]]></title>
      <url>/2018/08/13/jvm-architecture/</url>
      <content type="html"><![CDATA[<p>Java Virtual Mechine （JVM）包含三部分，分别是：类加载器子系统、运行时数据区和执行引擎。</p>
<p><img src="https://s2.ax1x.com/2020/03/11/8A2ZHH.png" alt="8A2ZHH.png" border="0" style="width:500px"></p>
<h4 id="类加载子系统"><a href="#类加载子系统" class="headerlink" title="类加载子系统"></a><strong>类加载子系统</strong></h4><p>类加载是将 <code>.class</code> 文件加载到虚拟机内存并创建对象的整个过程。类加载子系统提供 Java 的类动态加载功能，它有三个主要阶段：加载、链接和初始化。  </p>
<p><strong>加载</strong></p>
<p>加载是 JVM 通过一个类的完全限定名来获取类的二进制字节流，将字节流代表的静态存储结构转化为方法区中的运行时数据结构，然后在内存中生成一个代表这个类的 Class 对象作为访问入口的过程。<br>在 Java 中有多种途径可以获取类的二进制字节流：</p>
<ol>
<li>从 zip 中获取，jar ，ear ，war 都属于这类。</li>
<li>从网络中获取，比如 applet 。</li>
<li>通过动态代理生成。</li>
<li>通过文件生成，比如 jsp 被编译成 class 。</li>
<li>等等。</li>
</ol>
<p>加载既可以通过系统提供的类加载器加载，也可以通过自定义的类加载器加载。系统提供的类加载器有 3 个：Bootstrap ClassLoader 、Extention ClassLoader 和 Application ClassLoader 。</p>
<ol>
<li>Bootstrap ClassLoader 负责加载 \lib 下的类。</li>
<li>Extention ClassLoader 负责加载 \lib\ext 下的类。</li>
<li>Application ClassLoader 负责加载应用程序级别的类，即系统类路径 <code>classpath</code> 下的类。</li>
</ol>
<p>类加载器在加载类时使用委托算法。委托算法的原理是：如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行，如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器，如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载。</p>
<blockquote>
<p>除了顶层的类加载器，每个类加载器都要有父类加载器，这些加载器之间并不是继承关系，而是组合关系。</p>
</blockquote>
<p>使用这种委托算法的优点有二：</p>
<ol>
<li>防止重复加载，父加载器加载过的类子类加载器就不用再加载一次</li>
<li>安全，Java API 定义的类不会被篡改，因为父类已经加载了 Java 核心类，如果我们要加载自己修改的核心类，父加载器将不会加载。</li>
</ol>
<p><strong>链接</strong></p>
<p>链接包含三个步骤：验证、准备和解析。</p>
<ol>
<li>验证<br>验证的目的在于确保 Class 文件的字节流中包含信息符合当前虚拟机要求，不会危害虚拟机自身安全。虽然一些非法的操作（比如将一个类型转成一个不存在的类型，或者将代码跳转到不存在行）在编译期间编译器拒绝编译，但是 JVM 并没有限制字节码一定要由 java 编译器编译生成，所以理论上甚至可以通过直接编写生成 class 文件，所以验证是非常重要的。<br>验证包括四种：<br>&nbsp;&nbsp;&nbsp;&nbsp;1) 文件格式验证，验证是否符合 class 文件格式规范。<br>&nbsp;&nbsp;&nbsp;&nbsp;2) 元数据验证，对元数据信息进行语义分析，比如是否有父类，是否可以继承等。<br>&nbsp;&nbsp;&nbsp;&nbsp;3) 字节码验证，通过数据流和控制流分析程序的合法性，比如在栈上放一个 int 类型的数据，使用时按 long 类型加载。<br>&nbsp;&nbsp;&nbsp;&nbsp;4) 符号引用验证，对类自身信息以外的信息进行校验，比如常量池。</li>
<li>准备<br>准备是为类变量（即 <code>static</code> 修饰的字段变量）分配内存并且设置类变量的初始值的阶段。例如 <code>static int i=5;</code> 这里只将 i 初始化为 0 ，至于 5 的值将在初始化时赋值。这里不包含用 <code>final</code> 修饰的 <code>static</code>，因为 <code>final</code> 在编译的时候就会分配了，注意这里不会为实例变量分配初始化，类变量会分配在方法区中，而实例变量是会随着对象一起分配到 Java 堆中。</li>
<li>解析<br>解析是将常量池中的符号引用替换为直接引用的过程。<strong>符号引用</strong>就是一组符号来描述目标，可以是任何字面量，而<strong>直接引用</strong>就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。<blockquote>
<p>符号引用转化成直接引用分为两种：在解析阶段转化叫静态解析，运行期转化叫动态连接。</p>
</blockquote>
</li>
</ol>
<p><strong>初始化</strong></p>
<p>初始化是类加载的最后阶段，将为所有静态变量分配原始值，并执行静态块。<br>在 JVM 规范中规定，有且只有 5 种情况必须进行初始化：</p>
<ol>
<li>遇到 new ，getstatic ，putstatic 和 invokestatic 4 个字节码指令时如果没有初始化，则必须进行初始化。也就是在使用 new 实例化对象时，读写类的静态变量时，以及调用静态方法时。</li>
<li>使用反射调用时。</li>
<li>在初始化一个类且它的父类还没有被初始化时。</li>
<li>虚拟机启动执行主类时。</li>
<li>使用 MethodHandle 解析 REF_getStatic ，REF_putStatic 和 REF_invokeStatic 的方法句柄时。</li>
</ol>
<h4 id="运行时数据区"><a href="#运行时数据区" class="headerlink" title="运行时数据区"></a><strong>运行时数据区</strong></h4><p><strong>程序寄存器（Program Counter）</strong><br>线程私有。<br>存储当前线程执行程序的字节码指令的行号。<br>JVM 未规定异常。<br><strong>虚拟机栈（Java Vitrual Machine Stacks）</strong><br>线程私有。<br>存储使用栈帧来保存局部变量表、操作数栈、动态链接、方法出口等。</p>
<p>JVM 规定了两种异常：StackOutOfMemoryError 和 OutOfMemoryError 。<br><strong>本地方法栈（Native Methon Stack）</strong><br>本地方法栈和虚拟机栈类似，区别是本地方法栈用于执行本地方法。<br><strong>堆（Java Heap）</strong><br>堆是共享的，是 Java 内存最大的区域。Java 内存回收主要发生在堆，按照分代收集算法进行内存回收。堆内存可以细分为新生代和老年代。新生代又分为 Eden 、From Survivor 和 To Survivor 。堆是逻辑连续的，物理可以不连续。<br>JVM 规定的异常为 OutOfMemoryError 。<br><strong>方法区（Method Area）</strong><br>线程共享的。<br>存储已被 JVM 加载的类信息、常量、静态变量、及时编译器编译后的代码。<br>JVM 规定的异常为 OutOfMemoryError 。</p>
<h4 id="执行引擎"><a href="#执行引擎" class="headerlink" title="执行引擎"></a><strong>执行引擎</strong></h4><p>执行引擎用来执行分配给运行时数据区的字节码。<br>执行引擎分为：解释器、JIT 编译器和垃圾回收器。<br><strong>解释器</strong><br>解释会读取字节码，解释并逐行执行。解释器解释的速度很快但是执行速度很慢，而且一个方法被调用多次，解释过程也会进行多次。<br><strong>JIT 编译器</strong><br>JIT 编译器使用解释器进行字节码转换，遇到重复的代码，JIT 编译器会将整个字节码编译成机器码。机器码将用于重复方法的调用，从而提高性能。<br><strong>垃圾回收器</strong><br>垃圾回收器用于收集 <code>new</code> 产生的对象。垃圾回收可以通过 <code>System.gc()</code> 来触发，但是不一定会立刻执行。不是用 <code>new</code> 生成的对象可以使用 <code>finalize()</code> 进行回收。</p>
]]></content>
      
        <categories>
            
            <category> JVM </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Tracing with Spring Cloud Sleuth and Zipkin]]></title>
      <url>/2018/07/02/tracing-with-spring-cloud-sleuth-and-zipkin/</url>
      <content type="html"><![CDATA[<p>在前边章节中，我们学习了如何使用 spring cloud 搭建微服务，随着服务越来越多，一旦服务出错，定位很难，所以我们就需要有一个能够快速直观的监控服务机制，本节要学习的 sleuth 就是这样一款分布式跟踪工具。 </p>
<p>假如我们已经有 3 个服务，它们之间的调用关系为 service1 调用 service2 ，service2 调用 service3 。要使用 sleuth 来监控他们的调用链只需要加上 sleuth 的依赖。</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-sleuth&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>之后我们就会在控制台看到有类似 <code>[service1,84caca7a1662da40,84caca7a1662da40,false]</code> 的日志，sleuth 对调用链的监控就是靠这个实现的。那么这些日志都是什么意思呢？这就涉及到 zipkin 的基本概念了。</p>
<ul>
<li>traceId<br>就是一个全局的跟踪 ID ，用来标识一条调用链。</li>
<li>spanId<br>一个 span 可以看成是一次调用，spanId 就是这次调用的 ID 。</li>
<li>parentId<br>上一次调用的 ID，用来将前后的请求串联起来。</li>
<li>cs（client send）<br>客户端发起请求，在 span 开始的时候设置。</li>
<li>sr（server receive）<br>服务端收到请求之后开始处理请求之前。sr 和 cs 的时间差就是网络延时。</li>
<li>ss（server send）<br>服务端处理完成并返回给客户端。ss 和 sr 的时间差就是服务器处理的时长。</li>
<li>cr（client receive）<br>客户端收到响应，在 span 结束的时候设置。cr 标识着一次请求完成。</li>
</ul>
<p>了解了这些基本概念，再结合日志我们就可以搞清楚 sleuth 的处理过程了。</p>
<pre><code>[serviceName,traceId,spanId,upload]
[service1,8412e2eebe56a8c0,8412e2eebe56a8c0,true]
[service2,8412e2eebe56a8c0,ced32b7682dfb002,true]
[service3,8412e2eebe56a8c0,fecfced41b92ee72,true]
</code></pre><p>当我们请求 service1 时，由于这是一个新的请求，所以首先会生成一个随机的 traceId 和 spanId <code>8412e2eebe56a8c0</code>，parentId 为空，当 service1 调用下游的 service2 时，会生成一个新的 span 同时生成一个新的 spanId <code>ced32b7682dfb002</code> ，但会使用相同的 traceId <code>8412e2eebe56a8c0</code> ，service1 的 spanId <code>8412e2eebe56a8c0</code> 会作为 service2 的 parantId 。service2 调用 service3 处理逻辑也是一样的。Trace 的信息就会通过这样的方式从上游服务 service1 一直传递到下游服务 service3 ，直到整个调用链结束。</p>
<p>有了这些跟踪信息，在通过可视化的组建 zipkin 就可以直观的监控调用链的信息了。下面我们就来看看如何使用 zipkin 收集 sleuth 的日志信息。</p>
<p>首先在服务中加入依赖。</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-sleuth-zipkin&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>添加 zipkin 配置。</p>
<pre><code>spring:
  zipkin:
    base-url: http://localhost:9411
</code></pre><p>然后启动一个 zipkin-server ，以 docker 为例。</p>
<pre><code>docker run -d -p 9411:9411 openzipkin/zipkin
</code></pre><p>访问 <code>http://localhost:9411/zipkin/</code> 可以看到 zipkin-server 的界面。然后我们请求 service1 ，日志出现 [service1,249309b6a4120e9f,249309b6a4120e9f,false] 类似日志，最后一位表示是否采样，就是是否被 zipkin 收集，false 表示未收集，访问第 10 次就会输出一条 true 的日志（和采样率 <code>spring.sleuth.sampler.probability</code> 有关，默认是 10%），这时我们在 zipkin 中就能够查询到调用链的信息了。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20190505/1557045399872.png" alt=""></p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Monitoring and Integrating Hystrix using Hystrix Dashboard and Turbine]]></title>
      <url>/2018/07/01/monitoring-and-integrating-hystrix-using-hystrix-dashboard-and-turbine/</url>
      <content type="html"><![CDATA[<p>在上一节中我们通过 <code>/actuator/health</code> 可以看到 hystrix 的状态，actuator 还提供了一个 <code>/actuator/hystrix.stream</code> 端点用来监控 HystrixCommand 。只要开启了 <code>hystrix.stream</code> 权限，就可以通过 <code>/actuator/hystrix.stream</code> 查看 HystrixCommand 的信息。</p>
<pre><code>management:
  endpoints:
    web:
      exposure:
        include: &#39;*&#39;
</code></pre><p>通过接口返回的是一个 json 格式的 stream ，并不直观，可以借助另一个可视化组件 Hystrix Dashboard 来展示。</p>
<p>首先需要添加依赖。</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>然后给启动类加上 <code>@EnableHystrixDashboard</code> ，启动之后访问 <code>http://localhost:8403/hystrix</code> 即可看到界面。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20190505/1557021014718.png" alt=""></p>
<p>填入相应信息提交，就可以看到监控的图表。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20190505/1557021430616.png" alt=""></p>
<p>到此，我们就可以通过可视化界面来监控 Hystrix 了。</p>
<h4 id="Turbine"><a href="#Turbine" class="headerlink" title="Turbine"></a>Turbine</h4><p>在微服务系统中，用 dashboard 监控单个应用用处并不大，会很不方便，所以我们需要将多个监控信息收集起来统一展示，这就需要用到 Turbine 。</p>
<p>turbine 的使用方式和 hystrix dashboard 类似，首先是添加依赖。</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-turbine&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>然后给启动类添加 <code>@EnableTurbine</code> 和 <code>@EnableHystrixDashboard</code> 注解。最后在配置文件中加入要监控的服务。</p>
<pre><code>turbine:
  # 要监控的微服务列表，多个用,分隔
  appConfig: order-client,feign-order-client
  clusterNameExpression: &quot;&#39;default&#39;&quot;
</code></pre><p>访问 hystrix dashboard 输入 <code>http://localhost:8500/turbine.stream</code> 就可以看到收集的信息了。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20190505/1557022968334.png" alt=""></p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Client Side Loadbalancing with Spring Cloud Ribbon]]></title>
      <url>/2018/06/30/client-side-loadbalancing-with-spring-cloud-ribbon/</url>
      <content type="html"><![CDATA[<p>Spring Cloud Ribbon 是 Netflix 开源的组件之一，主要功能是提供客户端的负载均衡。 Spring Cloud 和 Ribbon 的集成使得实现负载均衡变得非常容易。我们先实现一个简单的例子，由一个客户端在两个服务器之间实现负载均衡。</p>
<p>首先，创建一个 ribbon-server </p>
<pre><code>@GetMapping(&quot;/ribbon&quot;)
public String ribbon(HttpServletRequest request) {
    log.info(&quot;uri {} called&quot;, &quot;/ribbon&quot;);
    return &quot;host=&quot; + request.getRemoteHost() + &quot;, port=&quot; +     request.getServerPort();
}
</code></pre><p>mvn package 打包后，使用 java -jar xxx.jar –server.port=9999 和 java -jar xxx.jar –server.port=9988 启动两个服务。</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>创建客户端程序，添加依赖。</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>通过访问客户端可以发现请求轮流发送给服务端。</p>
<pre><code>@Autowired
LoadBalancerClient loadBalancerClient;
@Autowired
RestTemplate restTemplate;

@GetMapping(&quot;/hello&quot;)
public String hello() {
    log.info(&quot;uri {} called&quot;, &quot;/hello&quot;);
    ServiceInstance serviceInstance = loadBalancerClient.choose(&quot;ribbon-server&quot;);
    String url = &quot;http://&quot; + serviceInstance.getHost() + &quot;:&quot; + serviceInstance.getPort() + &quot;/ribbon&quot;;
    log.info(&quot;url : {}&quot;, url);
    return restTemplate.getForObject(url, String.class);
}
</code></pre><p>如果使用声明式注解，上边的代码也可以这样写：</p>
<pre><code>@Autowired
RestTemplate restTemplate;

@LoadBalanced
@Bean
public RestTemplate restTemplate() {
    return new RestTemplate();
}

@GetMapping(&quot;/ribbon-client&quot;)
public String hello() {
    return restTemplate.getForObject(&quot;http://ribbon-server/ribbon&quot;, String.class);
}
</code></pre><p>使用 <code>@RibbonClient</code> 注解可以指定 ribbon 的自定义配置来替换默认配置。</p>
<pre><code>@RibbonClient(name = &quot;ribbon-server&quot;, configuration = RibbonConfiguration.class)
public class RibbonClient1Controller {

}
</code></pre><p>默认 ribbon 使用的是轮询策略，我们可以将其改成自定义策略，比如每访问 10 次 A 服务就访问一次 B 服务：</p>
<pre><code>@Configuration
public class RibbonConfiguration {
    @Bean
    public IRule ribbonRule() {
        return new MyRibbonRule();
    }
}
</code></pre><p>自定义规则类可以继承 AbstractLoadBalancerRule 或是 实现 IRule 接口。</p>
<pre><code>@Slf4j
public class MyRibbonRule extends AbstractLoadBalancerRule {
    private AtomicInteger nextServerCyclicCounter;
    private AtomicInteger times;

    public MyRibbonRule() {
        nextServerCyclicCounter = new AtomicInteger(0);
        times = new AtomicInteger(0);
    }

    public Server choose(ILoadBalancer lb, Object key) {
        if (lb == null) {
            log.warn(&quot;no load balancer&quot;);
            return null;
        }
        Server server = null;
        int count = 0;
        while (server == null &amp;&amp; count++ &lt; 10) {
            List&lt;Server&gt; reachableServers = lb.getReachableServers();
            List&lt;Server&gt; allServers = lb.getAllServers();
            int upCount = reachableServers.size();
            int serverCount = allServers.size();
            if ((upCount == 0) || (serverCount == 0)) {
                log.warn(&quot;No up servers available from load balancer: &quot; + lb);
                return null;
            }
            int nextServerIndex = incrementTimes();
            server = allServers.get(nextServerIndex);

            if (server == null) {
                /* Transient. */
                Thread.yield();
                continue;
            }
            if (server.isAlive() &amp;&amp; (server.isReadyToServe())) {
                return (server);
            }
            // Next.
            server = null;
        }
        if (count &gt;= 10) {
            log.warn(&quot;No available alive servers after 10 tries from load balancer: &quot;
                    + lb);
        }
        return server;
    }

    private int incrementTimes() {
        for (; ; ) {
            int current = nextServerCyclicCounter.get();
            int next = times.addAndGet(1);
            if (next &lt; 10) {
                log.info(&quot;times = {}&quot;, times);
                return current;
            } else {
                times.set(0);
                log.info(&quot;times set 0 and current = {}&quot;, current);
                return current + 1;
            }
        }
    }

    @Override
    public void initWithNiwsConfig(IClientConfig iClientConfig) {

    }

    @Override
    public Server choose(Object key) {
        return choose(getLoadBalancer(), key);
    }
}
</code></pre><p>ribbon 除了 IRule 之外，还提供 IPing 接口用来通过 ping 服务器的 url 来判断服务是否可用。</p>
<h4 id="ribbon-的懒加载问题"><a href="#ribbon-的懒加载问题" class="headerlink" title="ribbon 的懒加载问题"></a>ribbon 的懒加载问题</h4><p>由于 ribbon 是懒加载的，所以在服务启动的时候并不会初始化 ribbon 的相关类，而是在第一次调用的时候才会初始化，这就导致第一次请求的时间会更长，这有可能就会因为超过了超时时间导致失败，所以为了解决这个问题，我们可以取消懒加载配置，让 ribbon 在启动的时候就初始化。</p>
<p>在 RibbonAutoConfiguration 类中有这样一段代码，意思就是会按照 <code>ribbon.eager-load.enabled</code> 属性来决定是否初始化。</p>
<pre><code>@Bean
@ConditionalOnProperty(&quot;ribbon.eager-load.enabled&quot;)
public RibbonApplicationContextInitializer ribbonApplicationContextInitializer() {
    return new RibbonApplicationContextInitializer(springClientFactory(),
                ribbonEagerLoadProperties.getClients());
}
</code></pre><p>所以我们可以通过修改这个值来让 ribbon 启动时初始化。</p>
<pre><code>ribbon:
  eager-load:
    enabled: true
</code></pre>]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Circuit Breaker using Spring Cloud Hystrix]]></title>
      <url>/2018/06/30/circuit-breaker-using-spring-cloud-hystrix/</url>
      <content type="html"><![CDATA[<p>断路器（Circuit Breaker）的是微服务系统中一个非常重要且关键的概念。为什么说它重要呢？是因为在微服务的系统中，服务之间是相互调用的，如果其中一个服务挂掉了，其他的服务请求还在不断的请求这个服务，如果没有特殊的处理，那么通常要等请求超时请求才能返回，每个请求就是一个线程，而在这期间线程不会被释放，那么很快调用端就会因为线程阻塞而消耗大量资源，一旦调用端资源耗尽，那么就会引起连锁反应。所以，为了保证服务之间尽可能少的相互影响，就提出了断路器的概念。</p>
<p>Hystrix 是 Netflix 开源的延迟和容错库，它提供了断路器的功能。本节我们来看看如何使用 Hystrix 来达到熔断的效果。</p>
<p>首先添加依赖。</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>第二步添加 fallback 方法，并给需要熔断的方法加上 @HystrixCommand 注解。</p>
<pre><code>@HystrixCommand(fallbackMethod = &quot;defaultOrder&quot;)
@GetMapping(&quot;/orders/{id}&quot;)
public Order findById(@PathVariable(&quot;id&quot;) String id) {
    return restTemplate.getForObject(&quot;http://order-service/orders/&quot; + id, Order.class);
}

public Order defaultOrder(String id, Throwable e) {
    log.error(&quot;fall back findById&quot;, e);
    return new Order(&quot;0&quot;, &quot;&quot;, &quot;0&quot;);
}
</code></pre><p>第三步在启动类上添加 @EnableCircuitBreaker 注解。</p>
<p>在添加断路器之前，我们通过 order-client 调用 order-service 服务的 getById 方法大概需要 10+ 毫秒，如果我们停掉 order-service 服务，响应会 1000+ 毫秒才能返回，可见等待请求超时再返回会使线程阻塞很长时间，在有大量请求访问的时候会导致服务端资源耗尽。当我们启用断路器之后，如果 order-service 服务不可用，会直接返回 fallback 方法的返回值。</p>
<p>断路器的状态可以通过 <code>/actuator/health</code> 查看。</p>
<pre><code>management:
  endpoint:
    health:
      show-details: always
</code></pre><p>在配置文件中加入 actuator 配置后可以查看 hystrix 的信息。</p>
<pre><code>{
    &quot;status&quot;: &quot;UP&quot;,
    &quot;details&quot;: {
        &quot;diskSpace&quot;: {...},
        &quot;refreshScope&quot;: {...},
        &quot;discoveryComposite&quot;: {...},
        &quot;hystrix&quot;: {
            &quot;status&quot;: &quot;CIRCUIT_OPEN&quot;
        }
    }
}
</code></pre><p>hystrix 的断路器并不是始终打开的，当 <code>circuitBreaker.requestVolumeThreshold</code> （调用次数，默认是 20）在 <code>metrics.rollingStats.timeInMilliseconds</code> （默认 10 秒）定义的时间内故障率超过 <code>circuitBreaker.errorThresholdPercentage</code> （默认 50）时，则断路器会打开。</p>
<p>多请求几次 order-client 后可以看到断路器的状态变化。</p>
<pre><code>{
    &quot;status&quot;: &quot;UP&quot;,
    &quot;details&quot;: {
        &quot;diskSpace&quot;: {...},
        &quot;refreshScope&quot;: {...},
        &quot;discoveryComposite&quot;: {...},
        &quot;hystrix&quot;: {
            &quot;status&quot;: &quot;CIRCUIT_OPEN&quot;,
            &quot;details&quot;: {
                &quot;openCircuitBreakers&quot;: [&quot;OrderClient::findById&quot;]
            }
        }
    }
}
</code></pre><p>如果我们修改 circuitBreaker 的参数</p>
<pre><code>@HystrixCommand(fallbackMethod = &quot;defaultOrder&quot;, commandProperties = {
            @HystrixProperty(name = HystrixPropertiesManager.CIRCUIT_BREAKER_ERROR_THRESHOLD_PERCENTAGE, value = &quot;100&quot;),
            @HystrixProperty(name = HystrixPropertiesManager.CIRCUIT_BREAKER_REQUEST_VOLUME_THRESHOLD, value = &quot;1&quot;)
})
</code></pre><p>重启之后调用一次 order-client 就可以看到 CIRCUIT_OPEN 的状态了。</p>
<h4 id="Feign-使用-Hystrix"><a href="#Feign-使用-Hystrix" class="headerlink" title="Feign 使用 Hystrix"></a>Feign 使用 Hystrix</h4><p>作为 Netflix 的组件 Feign 也整合了 Hystrix 。本节我们来看看如何使用 Feign 的 Hystrix 。</p>
<p>首先加入依赖，创建一个 feign-client ，可参考 <a href="../../../../2018/06/20/services-communication-using-feign/">Services Communication using Feign</a> ，然后创建一个 fallback 实现。</p>
<pre><code>@Component
public class OrderServiceFallback implements OrderService {
    @Override
    public Order findById(String id) {
        return new Order(&quot;0&quot;, &quot;&quot;, &quot;0&quot;);
    }
}
</code></pre><p>然后在 feign-client 中指定 fallback 。</p>
<pre><code>@FeignClient(name = &quot;order-service&quot;, fallback = OrderServiceFallback.class)
</code></pre><p>如果需要捕获异常可以这样写。</p>
<pre><code>@Component
@Slf4j
public class OrderServiceFallbackFactory implements FallbackFactory&lt;OrderClient&gt; {
    private static final Order order = new Order(&quot;0&quot;, &quot;&quot;, &quot;0&quot;);
    @Override
    public OrderClient create(Throwable throwable) {
        return new OrderClient() {
            @Override
            public Order findById(String id) {
                log.error(&quot;fallback findById&quot;, throwable);
                return order;
            }
        };
    }
}
</code></pre><p>在 feign-client 中指定 fallbackFactory 。</p>
<pre><code>@FeignClient(name = &quot;order-service&quot;, fallbackFactory = OrderServiceFallbackFactory.class)
</code></pre><p>最后在配置文件中启用 feign hystrix 配置。</p>
<pre><code>feign:
  hystrix:
    enabled: true
</code></pre><p>默认是 false 。</p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Dynamic Configuration Management with Spring Cloud Bus]]></title>
      <url>/2018/06/27/dynamic-configuration-management-with-spring-cloud-bus/</url>
      <content type="html"><![CDATA[<p>前一节我们使用 Spring Cloud Config 集中管理配置文件，并通过 Config Client 远程刷新。但是这样做有一个明显的问题，就是单独刷新每一个服务会随着服务的数量增加变得越来困难。Spring Cloud 提供了一种消息总线的模式，通过消息中间件把消息路由到各个服务来实现统一刷新服务配置，可以让问题变得简单。<br><img src="http://blog.didispace.com/assets/5-7.png" alt=""><br>使用 Spring Cloud Bus 需要在原来 Spring Cloud Config 的基础上稍作改动。</p>
<p>首先把需要用总线联系的服务中加入 Spring Cloud Bus 的配置。</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>然后加入消息中间件的配置</p>
<pre><code>spring:
  rabbitmq:
    host: localhost
    port: 5672
    username: guest
    password: guest
</code></pre><p>server 和 client 都需要加。完成后，通过 <code>POST /actuator/bus-refresh</code> 刷新 Config Server 就可以动态更新所有服务配置了。</p>
<h4 id="webhooks"><a href="#webhooks" class="headerlink" title="webhooks"></a>webhooks</h4><p>主动刷新 config-server 的方式虽然比单独刷新 client 的方式简便，但是利用 git webhooks 完成配置修改后自动刷新则更加方便。下面以 gitlab 为例：</p>
<p>首先在 gitlab 中配置 integrations，url 为 config-server 的刷新地址，即 http:localhost:8888/actuator/bus-refresh 。由于 gitlab 不能配置本地 localhost ，所以需要借助一个小工具 natapp ，具体用法参考 <a href="https://natapp.cn/" target="_blank" rel="external">https://natapp.cn/</a> 。简单配置之后就可以将 localhost 映射成外网地址，比如 <a href="http://r44n2x.natappfree.cc/actuator/bus-refresh" target="_blank" rel="external">http://r44n2x.natappfree.cc/actuator/bus-refresh</a> 。由于 spring cloud bus的 bug 导致直接在 gitlab 上配置 /actuator/bus-refresh 并不会触发刷新，所以我们需要转发一下请求。</p>
<pre><code>@PostMapping(value = &quot;/refresh-config&quot;)
public void refresh() {
    RestTemplate restTemplate = new RestTemplate();
    HttpHeaders headers = new HttpHeaders();
    headers.setContentType(MediaType.APPLICATION_JSON_UTF8);
    HttpEntity&lt;String&gt; entity = new HttpEntity&lt;String&gt;(&quot;&quot;, headers);
    restTemplate.exchange(&quot;http://localhost:8888/actuator/bus-refresh&quot;, HttpMethod.POST, entity, String.class);
}
</code></pre><p>在 config-server 上添加一个服务，然后将 gitlab 的 webhoots 的 url 换成 <a href="http://r44n2x.natappfree.cc/refresh-config" target="_blank" rel="external">http://r44n2x.natappfree.cc/refresh-config</a> ，保存之后再更新配置即可看到效果。</p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Configuration Management with Spring Cloud Config]]></title>
      <url>/2018/06/26/configuration-management-with-spring-cloud-config/</url>
      <content type="html"><![CDATA[<p>微服务架构中面临的一个问题就是每个服务有一个配置，随着服务的不断增加，配置文件散落各处，管理不便。Spring Cloud 提供一套中心化配置管理的方案，通过 Spring Cloud Config Server 来对服务提供配置服务。Spring Cloud Config 支持多种管理配置文件的方式，比如环境变量、本地文件、版本控制工具等，相比之下使用版本控制工具来管理更加方便。假如我们使用 github 来管理配置文件，形式如下：</p>
<pre><code>/config
    /default
        config-client.yml
    /dev
        config-client-dev.yml
    /prod
        config-client-prod.yml
    /test
        config-client-test.yml
</code></pre><p>default 下的配置文件以应用名称命名，存放公共的配置信息。dev，prod 和 test 分别对应开发，生产和测试的配置文件，各自存放环境差异的配置。Spring Boot 在加载配置文件的时候会先加载 defualt ，然后在加载指定的配置文件，如果有相同的配置，default 中的配置会被覆盖。使用 git 管理配置文件只是我们的第一步，接下来我们看看如何创建 Config Server 。</p>
<h3 id="Config-Server"><a href="#Config-Server" class="headerlink" title="Config Server"></a><strong>Config Server</strong></h3><p>通过声明式注解的方式可以很方便地创建一个 Config Server 。简单起见，我们先在本地创建一个config-repo 文件夹，然后新建三个配置文件分别为 order-service-dev.yml，order-service-test.yml，order-service-prod.yml，并对其内容加以区分。接下来就可以来配置 congif-server 了。</p>
<p>1.首先添加 maven 的配置</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>2.修改配置文件</p>
<pre><code>server:
  port: 8888
spring:
  application:
    name: config-server
  profiles:
    active: native
  cloud:
    config:
      server:
        native:
          search-locations: file:///D:\config-repo
</code></pre><p>3.最后给启动类加上 <code>@EnableConfigServer</code> 注解</p>
<pre><code>@EnableConfigServer
@SpringBootApplication
public class ConfigServerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConfigServerApplication.class, args);
    }
}
</code></pre><p>启动服务访问 <a href="http://localhost:8888/order-service/dev" target="_blank" rel="external">http://localhost:8888/order-service/dev</a> 即可看到开发环境的配置信息。</p>
<h3 id="Config-Client"><a href="#Config-Client" class="headerlink" title="Config Client"></a><strong>Config Client</strong></h3><p>接下来看看客户端如何使用 Config Server 来获取配置。</p>
<p>1.添加 maven 配置</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>2.添加配置文件</p>
<p>客户端的配置文件有一个特殊的地方需要注意，Config Server 的连接信息要写在 bootstrap.yml 中，不能写在 application.yml 中。原因是 bootstrap.yml 会先于程序启动，这样就可以在程序启动之前加载配置信息。</p>
<pre><code>spring:
  application:
    name: order-service
  cloud:
    config:
      uri:  http://localhost:8888
      name: ${spring.application.name}
      profile: dev
</code></pre><blockquote>
<p>bootstrap.yml 中的内容都是静态的，如果将 bootstrap.yml 打成镜像，就不能灵活修改了，所以 label 和 profile 最好不要写在配置中，而是通过启动参数来控制 <code>java -jar config-client-1.0-SNAPSHOT.jar --spring.profiles.active=prod --spring.cloud.config.label=develop --spring.cloud.config.profile=prod</code> 。</p>
</blockquote>
<p>配置好以后，启动服务可以看到类似的日志。</p>
<pre><code>c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at : http://localhost:8888
</code></pre><p>并且程序可以正常启动。</p>
<p>3.可以添加测试方法来验证。</p>
<pre><code>@Value(&quot;${msg}&quot;)
String msg;

@GetMapping(&quot;/msg&quot;)
String getMsg() {
    return msg;
}
</code></pre><p><a href="http://localhost:9001/msg" target="_blank" rel="external">http://localhost:9001/msg</a> 会得到 msg 的信息。</p>
<h3 id="配置更新"><a href="#配置更新" class="headerlink" title="配置更新"></a>配置更新</h3><p>我们已经通过 Config Server 管理配置文件，并配置 Config Client 获取配置，但此时如果更新了配置文件，order-service 服务是不会生效的。因为配置是在启动时候加载的，如果配置文件更新，程序是无法动态获取最新的配置的，只有重启之后再次加载配置。那么有没有办法让应用不停机就能获取最新的配置信息呢？答案当然是肯定的。Spring Cloud Config 提供了一个入口可以远程刷新配置，这个入口是隐藏的，需要借助 actuator 才能开启。</p>
<p>1.首先在 maven 中添加 actuator 配置</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>2.在 controller 上添加 <code>@RefreshScope</code> 注解</p>
<pre><code>@RefreshScope
public class OrderController {
    ...    
}
</code></pre><p>3.添加配置信息，打开 actuator 开关</p>
<pre><code>management:
  endpoints:
    web:
      exposure:
        include: &#39;*&#39;
</code></pre><p>配置完成后启动服务，更新配置文件并请求 msg 信息，msg 还是启动之前的信息。使用 <code>curl -XPOST &#39;http://localhost:9001/actuator/refresh&#39;</code> 来刷新配置，成功后会返回 [“msg”] 信息。此时再重新请求 msg 就会发现 msg 信息已经更新了。</p>
<h3 id="使用-Git-保存配置"><a href="#使用-Git-保存配置" class="headerlink" title="使用 Git 保存配置"></a>使用 Git 保存配置</h3><p>我们已经通过本地的 config-repo 实现了 Config Server ，但是通常很少有使用本地文件作为 config-repo，更多的是将使用 git 来做 config-repo 。要使用 git 需要对 config-server 的配置进行修改。</p>
<pre><code>spring:
  cloud:
    config:
      server:
        git:
          uri: https://github.com/bsyonline/config-repo # git repo 的地址
          search-paths: /** # 检索该目录下的配置文件
</code></pre><p>可以通过 <code>/{name}/{profile}/{label}</code>  的方式访问。</p>
<ul>
<li>name ${spring.application.name}</li>
<li>profile ${spring.profiles.active} ，就是环境后缀 dev ， prod 和 test</li>
<li>label 分支，默认为 master</li>
</ul>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Services Communication using Feign]]></title>
      <url>/2018/06/20/services-communication-using-feign/</url>
      <content type="html"><![CDATA[<p>在服务注册到 Eureka 后，可以通过 Eureka 获取服务地址，使用 http 可以进行通信，这和我们使用 httpclient 、jeseryclient 或 restTemplate 的方式一样。但是还有一种更为简单的方式，就是 Feign 。Feign 是 Spring Cloud 的组件之一，是一个声明式的 REST 客户端。</p>
<h4 id="使用声明式的-Feign-注解"><a href="#使用声明式的-Feign-注解" class="headerlink" title="使用声明式的 Feign 注解"></a><strong>使用声明式的 Feign 注解</strong></h4><p>Feign 内部集成了 Ribbon ，使用起来要简单很多。假定我们已有服务 order-service 。</p>
<pre><code>@RestController
@Slf4j
public class OrderController {
    @GetMapping(&quot;/orders/{id}&quot;)
    public Order get(@PathVariable String id) {
        return new Order(&quot;1&quot;, LocalDateTime.now().toString(), &quot;1&quot;);
    }
}
</code></pre><p>这就是一个普通的服务。那么如何使用 feign 来进行通信呢？</p>
<p>1.在的 api-gateway 中添加 maven 配置</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>2.创建一个 feign 客户端</p>
<pre><code>@FeignClient(name=&quot;order-service&quot;)
@Service
public interface OrderService {
    @GetMapping(value = &quot;/orders/{id}&quot;)
    Order findById(@PathVariable(&quot;id&quot;) String id);
}
</code></pre><p>FeignClient 的 name 要指定，请求的路径和服务端一致，请求参数也应和服务端一致。</p>
<p>3.在启动类添加注解 <code>@EnableFeignClients</code></p>
<pre><code>@EnableFeignClients
@SpringBootApplication
public class FeignApplication {
    public static void main(String[] args) {
        SpringApplication.run(FeignApplication.class, args);
    }
}
</code></pre><p>4.调用 feign 客户端</p>
<pre><code>@Test
public void findById() {
    Order result = orderService.findById(&quot;1&quot;);
    Assert.assertEquals(&quot;1&quot;, result.getId());
}
</code></pre><p>可以看到，比我们使用 httpclient 等方式要简洁很多。</p>
<h4 id="Feign-的其他用法"><a href="#Feign-的其他用法" class="headerlink" title="Feign 的其他用法"></a><strong>Feign 的其他用法</strong></h4><p>如果想定制 Feign 的功能，可以使用 FeignClientsConfiguration 。FeignClientsConfiguration 可以复写 <code>feign.Decoder</code>、<code>feign.Encoder</code> 和 <code>feign.Contract</code> ，并在 <code>@FeignClient</code> 中添加属性。</p>
<pre><code>@FeignClient(name = &quot;stores&quot;, configuration = FooConfiguration.class)
public interface StoreClient {
    //..
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
            <tag> Feign </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Routing and Filtering with Zuul]]></title>
      <url>/2018/06/17/routing-and-filtering-with-zuul/</url>
      <content type="html"><![CDATA[<p>在微服务架构中系统为客户端应用程序提供一个独特的入口 —— API 网关是一种非常常见的微服务模式。API 网关实现代理、路由、流量控制，同时为用户提供了统一的界面，而屏蔽了微服务内部的细节。<br>使用 API 网关的优点：</p>
<ul>
<li>集中处理逻辑，比如鉴权、速率限定、监控等；</li>
<li>提高了安全性，对外只暴露一个入口；</li>
<li>提高了扩展性，重构微服务不会影响客户行为。</li>
</ul>
<p>同时，使用 API 网关也会带来以下缺点：</p>
<ul>
<li>面临单点问题；</li>
<li>增加了额外的路由。</li>
</ul>
<h3 id="Spring-Cloud-Zuul"><a href="#Spring-Cloud-Zuul" class="headerlink" title="Spring Cloud Zuul"></a><strong>Spring Cloud Zuul</strong></h3><p>Spring Cloud Zuul 是 Netflix 开源的基于 Java 的 API 网关，通过声明式注解可以方便的实现路由、过滤等功能。</p>
<h4 id="实现路由"><a href="#实现路由" class="headerlink" title="实现路由"></a>实现路由</h4><p>首先我们对 service1 服务进行一些改造，为它添加一个访问入口。</p>
<pre><code>@RestController(value = &quot;/api&quot;)
public class Service1Controller {

    @GetMapping(value = &quot;/hello&quot;)
    public String hello(String name) {
        return &quot;hello, &quot; + name;
    }
}
</code></pre><p>访问 <a href="http://localhost:9900/api/hello?name=tom" target="_blank" rel="external">http://localhost:9900/api/hello?name=tom</a> 可以看到返回结果。通常不会直接将服务入口暴露出来，而是在服务前加一层网关来进行代理，比如 nginx，zuul 也可以实现类似功能。</p>
<p>1.创建一个工程，加入 maven 配置</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>2.在启动类添加注解<code>@EnableZuulProxy</code></p>
<pre><code>@EnableZuulProxy
@EnableDiscoveryClient
@SpringBootApplication
public class ApiGatewayApplication {
    public static void main(String[] args) {
        SpringApplication.run(ApiGatewayApplication.class, args);
    }
}
</code></pre><p>3.添加配置文件</p>
<pre><code>spring:
  application:
    name: api-gateway
server:
  port: 9000
eureka:
  client:
    serviceUrl:
      defaultZone: http://localhost:8761/eureka/
  instance:
    instanceId: ${spring.application.name}:${vcap.application.instance_id:${spring.application.instance_id:${random.value}}}
zuul:
  routes:
    hello: # 访问的 uri
      url: http://localhost:9900/api/hello
  prefix: /api
</code></pre><p>完成以上配置，访问 <a href="http://localhost:9000/api/hello?name=bob" target="_blank" rel="external">http://localhost:9000/api/hello?name=bob</a> 会跳转到 service1 服务。</p>
<p>zuul 的路由规则可以指定 url 也可以通过 path 来匹配，比如:</p>
<pre><code>zuul:
  routes:
    service1:
      path: /hello
      serviceId: service1
</code></pre><p>这个规则会匹配 service1 服务的 “/hello” 接口。</p>
<p>还可以支持通配符，比如： </p>
<pre><code>zuul:
  routes:
    service4:
      path: /hello/*/world
      serviceId: service1
</code></pre><p>如果 service1 服务有2个接口分别是 “/hello/{id}/world” 和 “/{id}/world” ，这个规则会将请求路由到 “/{id}/world” 这个接口。”*“ 号表示匹配一级，如果有多级可以用 “**” 。</p>
<h4 id="实现负载均衡"><a href="#实现负载均衡" class="headerlink" title="实现负载均衡"></a>实现负载均衡</h4><p>在上一个例子中， zuul 已经实现了负载均衡的功能，只不过我们只有一个实例，为了显示直观，我们重新创建一个 service2 并加入一些返回信息。</p>
<pre><code>@RestController
public class Service2Controller {

    @Autowired
    DiscoveryClient discoveryClient;

    @GetMapping(value = &quot;/hello&quot;)
    public String hello(HttpServletRequest request) {
        return &quot;host=&quot; + request.getRemoteHost() + &quot;, port=&quot; + request.getServerPort();
    }
}
</code></pre><p>更新 api-gateway 的配置文件：</p>
<pre><code>zuul:
  routes:
    service2:
      path: /service2/**
      serviceId: service2
  prefix: /api
</code></pre><p>启动服务使用不同端口启动两个 service2 实例，然后访问 <a href="http://localhost:9000/api/service2/hello" target="_blank" rel="external">http://localhost:9000/api/service2/hello</a> ，刷新请求会看到返回信息在来回切换，这实际上就是 zuul 实现了负载均衡，对 service2 的两个实例轮询访问。</p>
<h4 id="过滤器"><a href="#过滤器" class="headerlink" title="过滤器"></a>过滤器</h4><p>过滤器是 Spring Cloud Zuul 的核心组件之一，对应请求的生命周期，zuul 定义了 4 种过滤器类型：</p>
<ul>
<li>pre 在请求被路由之前调用；</li>
<li>route 将请求路由到微服务；</li>
<li>post 在路由到微服务以后执行；</li>
<li>error 发生错误时执行。</li>
</ul>
<p>除了以上 4 种，zuul 还支持自定义过滤器。</p>
<h5 id="Pre-Filter"><a href="#Pre-Filter" class="headerlink" title="Pre Filter"></a>Pre Filter</h5><p>我们先来看看 pre filter 。我们编写一个简单的 pre filter 来打印访问日志信息。</p>
<pre><code>@Component
@Slf4j
public class PreFilter extends ZuulFilter {

    @Override
    public String filterType() {
        return &quot;pre&quot;;
    }

    @Override
    public int filterOrder() {
        return 0;
    }

    @Override
    public boolean shouldFilter() {
        return true;
    }

    @Override
    public Object run() {
        RequestContext ctx = RequestContext.getCurrentContext();
        HttpServletRequest request = ctx.getRequest();
        log.info(String.format(&quot;send %s request to %s&quot;, request.getMethod(), request.getRequestURL().toString()));
        return null;
    }
}
</code></pre><p>在 api-gateway 项目中加入上面的代码，然后重启，每次发送请求都可以看到打印的日志信息。<br>zuul 内置了很多过滤器，如果要去掉一个过滤器，可以通过配置文件灵活配置。</p>
<pre><code>zuul:
  PreFilter:
    pre:
      disable: true
</code></pre><p>这样我们刚才加入的 PreFilter 就不起作用了，可以重启服务试试看。同理，对于其他的过滤器，我们也可以使用 <code>zuul.{filterName}.{filterType}.disable</code> 的方式来进行配置。</p>
<h5 id="Route-Filter"><a href="#Route-Filter" class="headerlink" title="Route Filter"></a>Route Filter</h5><p>route filter 的作用就是把请求路由到其他服务。我们在本文的开始通过配置，实现了路由功能，现在我们通过自己写一个过滤器来实现路由功能。</p>
<pre><code>@Component
@Slf4j
public class RouteFilter extends ZuulFilter {

    @Override
    public String filterType() {
        return &quot;route&quot;;
    }

    @Override
    public int filterOrder() {
        return 10;
    }

    @Override
    public boolean shouldFilter() {
        return true;
    }

    @Override
    public Object run() throws ZuulException {
        RequestContext ctx = RequestContext.getCurrentContext();
        HttpServletResponse response = ctx.getResponse();
        String url = &quot;http://cn.bing.com&quot;;
        try {
            log.info(String.format(&quot;redirect to %s&quot;, url));
            response.sendRedirect(url);
        } catch (IOException e) {
            e.printStackTrace();
        }
        return null;
    }
}
</code></pre><h5 id="Post-Filter"><a href="#Post-Filter" class="headerlink" title="Post Filter"></a>Post Filter</h5><p>Post Filter 用来处理服务对响应后要进行的操作，比如添加 http header 。</p>
<pre><code>@Component
@Slf4j
public class PostFilter extends ZuulFilter {

    @Override
    public String filterType() {
        return &quot;post&quot;;
    }

    @Override
    public int filterOrder() {
        return 0;
    }

    @Override
    public boolean shouldFilter() {
        return true;
    }

    @Override
    public Object run() throws ZuulException {
        log.info(&quot;post&quot;);
        RequestContext ctx = RequestContext.getCurrentContext();
        List&lt;Pair&lt;String, String&gt;&gt; headers = ctx.getZuulResponseHeaders();
        headers.add(1, new Pair&lt;String, String&gt;(&quot;X-RateLimit-Remaining&quot;, &quot;30&quot;));
        return null;
    }
}
</code></pre><h5 id="Error-Filter"><a href="#Error-Filter" class="headerlink" title="Error Filter"></a>Error Filter</h5><p>在过滤器中出现的任何错误都会进入 error filter 处理，所以在 error filter 中统一处理异常比在每一处代码都使用 try-catch 要简单很多。</p>
<pre><code>@Component
@Slf4j
public class ErrorFilter extends ZuulFilter {

    @Override
    public String filterType() {
        return &quot;error&quot;;
    }

    @Override
    public int filterOrder() {
        return 0;
    }

    @Override
    public boolean shouldFilter() {
        return true;
    }

    @Override
    public Object run() throws ZuulException {
        RequestContext ctx = RequestContext.getCurrentContext();
        Throwable throwable = ctx.getThrowable();
        log.info(String.format(&quot;take exception %s&quot;, throwable.getCause().getMessage()));
        return null;
    }
}
</code></pre><p>这样在出错时就可以得到一个 <code>/error</code> 的映射，比如可以对映射进行简单的处理：</p>
<pre><code>@RestController
public class ErrorHandlerController implements ErrorController {
    @Override
    public String getErrorPath() {
        return &quot;/error&quot;;
    }

    @RequestMapping(&quot;/error&quot;)
    public String error() {
        return &quot;{\&quot;code\&quot;: 500, \&quot;msg\&quot;:\&quot;internal server error\&quot;}&quot;;
    }
}
</code></pre><p>这样错误就不会直接暴露给用户了。</p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Service Registration and Discovery]]></title>
      <url>/2018/06/16/service-registration-and-discovery/</url>
      <content type="html"><![CDATA[<p>服务发现和注册是微服务架构的关键步骤，它是一种使微服务能够在不知道确切位置（通常是URL）的情况下使用其他微服务的机制。在简单的环境中服务可以通过静态配置记录每个服务的地址、端口和 URL 等信息，但是在微服务架构中，由于服务的动态增减和持续集成的因素，静态的配置信息将不再适用，所以就需要能够动态记录各个服务的连接信息，这就是服务注册和发现产生的原因。<br>服务注册和发现通常需要以下几步：</p>
<ol>
<li>服务提供者向注册中心提交自己的配置信息；</li>
<li>服务使用者向注册中心询问服务提供者的配置信息；</li>
<li>注册中心返回最新的服务提供者配置信息；</li>
<li>服务使用者与服务提供者通信。</li>
</ol>
<p>下图展示了两个服务通信的简单流程：<br><img src="https://vaadin.com/documents/226808/13548263/client-side-load-balancer-flow.png/df1c6235-311e-4715-a232-4ecfca470b95?t=1512740698000" alt=""></p>
<p>服务注册和发现的程序原理比较简单，我们可以假想通过维护一个 key-value 的集合来提供注册发现服务会涉及哪些问题：</p>
<ol>
<li>假如以 redis 作为注册中心，服务将配置信息发送到 redis ，通过 add 将信息保存起来；</li>
<li>服务在注销时从 redis 中把注册信息删除；</li>
<li>正常情况下，1 和 2 就可以提供服务，但是这并不完善。如果服务的配置信息变更了没有及时向注册中心提交信息或是服务停止了而没有删除注册中心的信息，那么在别的服务在请求注册中心的时候就会得到错误信息，导致服务通信失败。这是就需要“心跳服务”，每隔一段时间，发送一次心跳，如果注册中心在一段时间内没有收到心跳，则认为服务死亡，从而删除该服务的注册信息；</li>
<li>注册中心维护着所有服务的访问信息，服务之间要通信，首先要访问注册中心，那么注册中心就会成为瓶颈，所以如果采用主从模式在每个客户端维护一份副本，那么服务就不用每次都去访问注册中心了。这样虽然解决了注册中心的瓶颈问题，但是需要主从之间进行同步；</li>
<li>作为主节点，如果注册服务关闭，那么其他副本也就无法同步，所以主节点还要解决单点问题，比如使用分布式机器来提供服务。</li>
</ol>
<p>综上看来，实现一个服务注册和发现的程序还是比较复杂的。不过，有很多优秀的框架已经实现了这些功能，比如 Eureka。</p>
<h4 id="Eureka"><a href="#Eureka" class="headerlink" title="Eureka"></a><strong>Eureka</strong></h4><p>Eureka 是 netflix 开源的产品，通过和 Spring Cloud 集成，通过 Java 注解声明式的注册和调用服务变得非常简单，以下以 Greenwich.SR1 为例说明。</p>
<p>1.加入 maven 配置</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>2.在 springboot 启动类上添加注解 <code>@EnableEurekaServer</code></p>
<pre><code>@EnableEurekaServer
@SpringBootApplication
public class RegisterCenterApplication {
    public static void main(String[] args) {
        SpringApplication.run(RegisterCenterApplication.class, args);
    }
}
</code></pre><p>3.修改配置文件</p>
<pre><code>server:
  port: 8761
eureka:
  instance:
    hostname: localhost
  client:
    registerWithEureka: false #不对外提供服务调用
    fetchRegistry: false #不拉取注册信息
    serviceUrl:
      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/
</code></pre><p>简单三步即可实现一个注册发现服务。启动服务访问 <a href="http://localhost:8761/" target="_blank" rel="external">http://localhost:8761/</a> 即可看到界面。<br>此时还没有任何服务注册到 Eureka ，我们接下来就来看看如何将服务注册到 Eureka 。</p>
<p>我们再创建另一个应用 eureka-client 注册到 eureka server 上。<br>1.添加 maven 配置</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><p>2.在启动类上添加注解 <code>@EnableDiscoveryClient</code>，从 Edgware.RELEASE 版本之后这个注解可以省略。</p>
<pre><code>//@EnableDiscoveryClient
@SpringBootApplication
public class Service1Application {
    public static void main(String[] args) {
        SpringApplication.run(Service1Application.class, args);
    }
}
</code></pre><p>3.添加配置文件。</p>
<pre><code>spring:
  application:
    name: service1
server:
  port: 9900
eureka:
  client:
    service-url:
      defaultZone: http://localhost:8761/eureka/
  instance:
    prefer-ip-address: true
</code></pre><p>完成以上三步，启动服务，即可在 Eureka 中看到注册的服务 eureka-client 。</p>
]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
            <tag> Eureka </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spring Cloud with gRPC]]></title>
      <url>/2018/06/09/spring-cloud-with-grpc/</url>
      <content type="html"><![CDATA[<p>微服务架构中服务之间通信有很多种方式，大多数是使用 REST 。由于 rpc 在性能上的优势，使用 rpc 进行内部服务之间通信越来越普遍。rpc 框架有很多，gRPC 在性能、跨平台等方面的优秀表现，被很多公司作为选型方案。作为主流的微服务开发工具 Spring Cloud 对 gRPC 也提供了集成。</p>
<p>使用 gRPC 的 Spring Cloud 启动器 <a href="https://github.com/yidongnan/grpc-spring-boot-starter" target="_blank" rel="external">https://github.com/yidongnan/grpc-spring-boot-starter</a> 可以在 Spring Cloud 中很简单的集成 gRPC 。</p>
<h4 id="gRPC-proto"><a href="#gRPC-proto" class="headerlink" title="gRPC proto"></a><strong>gRPC proto</strong></h4><h5 id="1-编写-proto"><a href="#1-编写-proto" class="headerlink" title="1. 编写 proto"></a>1. 编写 proto</h5><pre><code>syntax = &quot;proto3&quot;;

option java_multiple_files = true;
option java_package = &quot;com.rolex.microservices.grpc&quot;;
option java_outer_classname = &quot;ProductProto&quot;;
option objc_class_prefix = &quot;HLW&quot;;

service ProductService {
  rpc FindProductByClientId (ProductRequest) returns (ProductResponse) {}
}

message ProductRequest {
  string user_id = 1;
}

message ProductResponse {
  uint64 product_id = 1;
  string user_id = 2;
  string client_id = 3;
}
</code></pre><h5 id="2-添加-maven-配置"><a href="#2-添加-maven-配置" class="headerlink" title="2. 添加 maven 配置"></a>2. 添加 maven 配置</h5><pre><code>&lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-netty&lt;/artifactId&gt;
            &lt;version&gt;${grpc.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt;
            &lt;version&gt;${grpc.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt;
            &lt;version&gt;${grpc.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-alts&lt;/artifactId&gt;
            &lt;version&gt;${grpc.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-testing&lt;/artifactId&gt;
            &lt;version&gt;${grpc.version}&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.netty&lt;/groupId&gt;
            &lt;artifactId&gt;netty-tcnative-boringssl-static&lt;/artifactId&gt;
            &lt;version&gt;${netty.tcnative.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.google.api.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;proto-google-common-protos&lt;/artifactId&gt;
            &lt;version&gt;1.0.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;junit&lt;/groupId&gt;
            &lt;artifactId&gt;junit&lt;/artifactId&gt;
            &lt;version&gt;4.12&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mockito&lt;/groupId&gt;
            &lt;artifactId&gt;mockito-core&lt;/artifactId&gt;
            &lt;version&gt;2.18.3&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;build&gt;
        &lt;extensions&gt;
            &lt;extension&gt;
                &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt;
                &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;1.5.0.Final&lt;/version&gt;
            &lt;/extension&gt;
        &lt;/extensions&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;0.5.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;protocArtifact&gt;com.google.protobuf:protoc:3.5.1-1:exe:${os.detected.classifier}&lt;/protocArtifact&gt;
                    &lt;pluginId&gt;grpc-java&lt;/pluginId&gt;
                    &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:${grpc.version}:exe:${os.detected.classifier}
                    &lt;/pluginArtifact&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;compile&lt;/goal&gt;
                            &lt;goal&gt;compile-custom&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;source&gt;1.8&lt;/source&gt;
                    &lt;target&gt;1.8&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
</code></pre><h4 id="gRPC-Server"><a href="#gRPC-Server" class="headerlink" title="gRPC Server"></a><strong>gRPC Server</strong></h4><h5 id="1-服务端代码"><a href="#1-服务端代码" class="headerlink" title="1. 服务端代码"></a>1. 服务端代码</h5><pre><code>@GrpcService(ProductServiceGrpc.class)
public class ProductGrpcServerService extends ProductServiceGrpc.ProductServiceImplBase {

    @Override
    public void findProductByClientId(ProductRequest request, StreamObserver&lt;ProductResponse&gt; responseObserver) {
        ProductResponse productResponse = null;
        if (&quot;1&quot;.equals(request.getUserId())) {
            productResponse = ProductResponse.newBuilder()
                .setClientId(&quot;1&quot;)
                .setUserId(&quot;1&quot;)
                .setClientId(&quot;1&quot;)
                .setProductId(1L)
                .build();
        }
        responseObserver.onNext(productResponse);
        responseObserver.onCompleted();
    }

}
</code></pre><h5 id="2-配置文件添加-gRPC-Server-配置"><a href="#2-配置文件添加-gRPC-Server-配置" class="headerlink" title="2. 配置文件添加 gRPC Server 配置"></a>2. 配置文件添加 gRPC Server 配置</h5><pre><code>grpc:
  server:
    port: 9402
    host: ${spring.application.name}
</code></pre><h4 id="gRPC-Client"><a href="#gRPC-Client" class="headerlink" title="gRPC Client"></a><strong>gRPC Client</strong></h4><h5 id="1-客户端代码"><a href="#1-客户端代码" class="headerlink" title="1. 客户端代码"></a>1. 客户端代码</h5><pre><code>@Service
public class ProductService {

    @GrpcClient(&quot;product-center&quot;)
    Channel serverChannel;
    public ProductResponse findProductByUserId(String userId) {
        ProductServiceGrpc.ProductServiceBlockingStub stub = ProductServiceGrpc.newBlockingStub(serverChannel);
        ProductResponse response = stub.findProductByClientId(ProductRequest.newBuilder().setUserId(userId).build());
        return response;
    }

}
</code></pre><h5 id="2-添加-gRPC-Client-配置"><a href="#2-添加-gRPC-Client-配置" class="headerlink" title="2. 添加 gRPC Client 配置"></a>2. 添加 gRPC Client 配置</h5><pre><code>grpc:
  client:
    product-center:
      port: 9402
</code></pre>]]></content>
      
        <categories>
            
            <category> Spring Cloud </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Cloud </tag>
            
            <tag> Microservices </tag>
            
            <tag> gRPC </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Getting Started with gRPC]]></title>
      <url>/2018/06/09/getting-started-with-grpc/</url>
      <content type="html"><![CDATA[<p>grpc 是 google 开发的一个支持多种语言的远程调用类库。使用 grpc ，客户端程序可以像调用本地方法一样直接调用不同机器上的服务方法。<br><img src="https://grpc.io/img/landing-2.svg" alt="https://grpc.io/img/landing-2.svg"><br>使用 grpc 能够使用不同语言来编写服务端和客户端，并可以很容易进行集成。<br>grpc 是一个高效的 rpc 库，默认使用 protocol buffers 。通过 protocol buffers 的定义语言可以定义服务的参数及返回值，然后通过 protoc 编译器生成服务器端和客户端代码。 </p>
<h4 id="java-grpc"><a href="#java-grpc" class="headerlink" title="java-grpc"></a><strong>java-grpc</strong></h4><p>以 java 语言为例，首先定义 proto 。</p>
<pre><code>syntax = &quot;proto3&quot;;

option java_multiple_files = true;
option java_package = &quot;com.rolex.grpc.helloworld&quot;; // 生成 java 代码的包名
option java_outer_classname = &quot;HelloWorldProto&quot;; // 生成 java 代码的类名
option objc_class_prefix = &quot;HLW&quot;;

package helloworld;

// The greeting service definition.
service Greeter {
  // Sends a greeting
  rpc SayHello (HelloRequest) returns (HelloReply) {}
}

// The request message containing the user&#39;s name.
message HelloRequest {
  string name = 1;
}

// The response message containing the greetings
message HelloReply {
  string message = 1;
}
</code></pre><p>proto 定义好以后，就可以生成代码了。 生成 Java 版的代码有两种方式，一是安装 protoc 编译器，进行编译；二是使用插件，这种方法比较简单，方便开发。以 maven 插件为例，pom.xml 文件如下：</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.rolex&lt;/groupId&gt;
    &lt;artifactId&gt;grgc-samples&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;grpc.version&gt;1.12.0&lt;/grpc.version&gt;
        &lt;junit.version&gt;4.12&lt;/junit.version&gt;
        &lt;os-maven-plugin.version&gt;1.5.0.Final&lt;/os-maven-plugin.version&gt;
        &lt;protobuf-maven-plugin.version&gt;0.5.0&lt;/protobuf-maven-plugin.version&gt;
        &lt;netty.tcnative.version&gt;2.0.7.Final&lt;/netty.tcnative.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-netty&lt;/artifactId&gt;
            &lt;version&gt;${grpc.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt;
            &lt;version&gt;${grpc.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt;
            &lt;version&gt;${grpc.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-alts&lt;/artifactId&gt;
            &lt;version&gt;${grpc.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;grpc-testing&lt;/artifactId&gt;
            &lt;version&gt;${grpc.version}&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.netty&lt;/groupId&gt;
            &lt;artifactId&gt;netty-tcnative-boringssl-static&lt;/artifactId&gt;
            &lt;version&gt;${netty.tcnative.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.google.api.grpc&lt;/groupId&gt;
            &lt;artifactId&gt;proto-google-common-protos&lt;/artifactId&gt;
            &lt;version&gt;1.0.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;junit&lt;/groupId&gt;
            &lt;artifactId&gt;junit&lt;/artifactId&gt;
            &lt;version&gt;4.12&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mockito&lt;/groupId&gt;
            &lt;artifactId&gt;mockito-core&lt;/artifactId&gt;
            &lt;version&gt;2.18.3&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;build&gt;
        &lt;extensions&gt;
            &lt;extension&gt;
                &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt;
                &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;1.5.0.Final&lt;/version&gt;
            &lt;/extension&gt;
        &lt;/extensions&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt;
                &lt;version&gt;0.5.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;protocArtifact&gt;com.google.protobuf:protoc:3.5.1-1:exe:${os.detected.classifier}&lt;/protocArtifact&gt;
                    &lt;pluginId&gt;grpc-java&lt;/pluginId&gt;
                    &lt;pluginArtifact&gt;io.grpc:protoc-gen-grpc-java:${grpc.version}:exe:${os.detected.classifier}&lt;/pluginArtifact&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;compile&lt;/goal&gt;
                            &lt;goal&gt;compile-custom&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;source&gt;1.8&lt;/source&gt;
                    &lt;target&gt;1.8&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre><p>使用 <code>os-maven-plugin</code> 插件，不用关心系统要使用的编译器版本和路径。</p>
<p>写好 pom 后使用命令 <code>mvn clean compile</code> 即可生成相关代码。</p>
<p>编写测试程序，服务端代码：</p>
<pre><code>import io.grpc.Server;
import io.grpc.ServerBuilder;
import io.grpc.stub.StreamObserver;
import java.io.IOException;
import java.util.logging.Logger;

/**
 * Server that manages startup/shutdown of a {@code Greeter} server.
 */
public class HelloWorldServer {
  private static final Logger logger = Logger.getLogger(HelloWorldServer.class.getName());

  private Server server;

  private void start() throws IOException {
    /* The port on which the server should run */
    int port = 50051;
    server = ServerBuilder.forPort(port)
        .addService(new GreeterImpl())
        .build()
        .start();
    logger.info(&quot;Server started, listening on &quot; + port);
    Runtime.getRuntime().addShutdownHook(new Thread() {
      @Override
      public void run() {
        // Use stderr here since the logger may have been reset by its JVM shutdown hook.
        System.err.println(&quot;*** shutting down gRPC server since JVM is shutting down&quot;);
        HelloWorldServer.this.stop();
        System.err.println(&quot;*** server shut down&quot;);
      }
    });
  }

  private void stop() {
    if (server != null) {
      server.shutdown();
    }
  }

  /**
   * Await termination on the main thread since the grpc library uses daemon threads.
   */
  private void blockUntilShutdown() throws InterruptedException {
    if (server != null) {
      server.awaitTermination();
    }
  }

  /**
   * Main launches the server from the command line.
   */
  public static void main(String[] args) throws IOException, InterruptedException {
    final HelloWorldServer server = new HelloWorldServer();
    server.start();
    server.blockUntilShutdown();
  }

  public static class GreeterImpl extends GreeterGrpc.GreeterImplBase {

    @Override
    public void sayHello(HelloRequest req, StreamObserver&lt;HelloReply&gt; responseObserver) {
      HelloReply reply = HelloReply.newBuilder().setMessage(&quot;Hello &quot; + req.getName()).build();
      responseObserver.onNext(reply);
      responseObserver.onCompleted();
    }
  }
}
</code></pre><p>客户端代码：</p>
<pre><code>import io.grpc.ManagedChannel;
import io.grpc.ManagedChannelBuilder;
import io.grpc.StatusRuntimeException;
import java.util.concurrent.TimeUnit;
import java.util.logging.Level;
import java.util.logging.Logger;

/**
 * A simple client that requests a greeting from the {@link HelloWorldServer}.
 */
public class HelloWorldClient {
  private static final Logger logger = Logger.getLogger(HelloWorldClient.class.getName());

  private final ManagedChannel channel;
  private final GreeterGrpc.GreeterBlockingStub blockingStub;

  /** Construct client connecting to HelloWorld server at {@code host:port}. */
  public HelloWorldClient(String host, int port) {
    this(ManagedChannelBuilder.forAddress(host, port)
        // Channels are secure by default (via SSL/TLS). For the example we disable TLS to avoid
        // needing certificates.
        .usePlaintext(true)
        .build());
  }

  /** Construct client for accessing RouteGuide server using the existing channel. */
  public HelloWorldClient(ManagedChannel channel) {
    this.channel = channel;
    blockingStub = GreeterGrpc.newBlockingStub(channel);
  }

  public void shutdown() throws InterruptedException {
    channel.shutdown().awaitTermination(5, TimeUnit.SECONDS);
  }

  /** Say hello to server. */
  public void greet(String name) {
    logger.info(&quot;Will try to greet &quot; + name + &quot; ...&quot;);
    HelloRequest request = HelloRequest.newBuilder().setName(name).build();
    HelloReply response;
    try {
      response = blockingStub.sayHello(request);
    } catch (StatusRuntimeException e) {
      logger.log(Level.WARNING, &quot;RPC failed: {0}&quot;, e.getStatus());
      return;
    }
    logger.info(&quot;Greeting: &quot; + response.getMessage());
  }

  /**
   * Greet server. If provided, the first element of {@code args} is the name to use in the
   * greeting.
   */
  public static void main(String[] args) throws Exception {
    HelloWorldClient client = new HelloWorldClient(&quot;localhost&quot;, 50051);
    try {
      /* Access a service running on the local machine on port 50051 */
      String user = &quot;world&quot;;
      if (args.length &gt; 0) {
        user = args[0]; /* Use the arg as the name to greet if provided */
      }
      client.greet(user);
    } finally {
      client.shutdown();
    }
  }
}
</code></pre><p>先启动服务端程序，再执行客户端代码可看到结果。<br>以上是一个简单 rpc 的例子，即客户端向服务端发送一个请求，然后服务端返回一个响应。除此之外，还可以创建服务器端或客户端的 streaming RPC 进行交互，可参考 <a href="https://github.com/grpc/grpc-java/tree/master/examples" target="_blank" rel="external">https://github.com/grpc/grpc-java/tree/master/examples</a> 。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> RPC </tag>
            
            <tag> gRPC </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[About Consistency]]></title>
      <url>/2018/05/31/about-consistency/</url>
      <content type="html"><![CDATA[<p>一致性模型是分布式系统中非常重要的概念，一致性模型有很多分类：</p>
<ul>
<li>以数据为中心的一致性模型（Data-centric Consistency Models）<ul>
<li>强一致性/严格一致性/原子一致性（Strict Consistency）</li>
<li>顺序一致性（Sequential Consistency）</li>
<li>因果一致性（Causal Consistency）</li>
</ul>
</li>
<li>以客户为中心的一致性模型（Client-centric Consistency Models）<ul>
<li>最终一致性（Eventual Consistency）</li>
<li>单调读一致性（Monotonic Read Consistency）</li>
<li>单调写一致性（Monotonic Write Consistency）</li>
<li>Read-your-writes Consistency</li>
<li>写跟随读一致性（Writes-follows-reads Consistency）</li>
</ul>
</li>
</ul>
<h4 id="强一致性-严格一致性-原子一致性（Strict-Consistency）"><a href="#强一致性-严格一致性-原子一致性（Strict-Consistency）" class="headerlink" title="强一致性/严格一致性/原子一致性（Strict Consistency）"></a><strong>强一致性/严格一致性/原子一致性（Strict Consistency）</strong></h4><h4 id="顺序一致性（Sequential-Consistency）"><a href="#顺序一致性（Sequential-Consistency）" class="headerlink" title="顺序一致性（Sequential Consistency）"></a><strong>顺序一致性（Sequential Consistency）</strong></h4><h4 id="因果一致性（Causal-Consistency）"><a href="#因果一致性（Causal-Consistency）" class="headerlink" title="因果一致性（Causal Consistency）"></a><strong>因果一致性（Causal Consistency）</strong></h4><h4 id="最终一致性（Eventual-Consistency）"><a href="#最终一致性（Eventual-Consistency）" class="headerlink" title="最终一致性（Eventual Consistency）"></a><strong>最终一致性（Eventual Consistency）</strong></h4><h4 id="单调读一致性（Monotonic-Read-Consistency）"><a href="#单调读一致性（Monotonic-Read-Consistency）" class="headerlink" title="单调读一致性（Monotonic Read Consistency）"></a><strong>单调读一致性（Monotonic Read Consistency）</strong></h4><h4 id="单调写一致性（Monotonic-Write-Consistency）"><a href="#单调写一致性（Monotonic-Write-Consistency）" class="headerlink" title="单调写一致性（Monotonic Write Consistency）"></a><strong>单调写一致性（Monotonic Write Consistency）</strong></h4><h4 id="Read-your-writes-Consistency"><a href="#Read-your-writes-Consistency" class="headerlink" title="Read-your-writes Consistency"></a><strong>Read-your-writes Consistency</strong></h4><h4 id="写跟随读一致性（Writes-follows-reads-Consistency）"><a href="#写跟随读一致性（Writes-follows-reads-Consistency）" class="headerlink" title="写跟随读一致性（Writes-follows-reads Consistency）"></a><strong>写跟随读一致性（Writes-follows-reads Consistency）</strong></h4>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Distributed Computing </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Understanding the CAP Theorem]]></title>
      <url>/2018/05/28/understanding-the-cap-theorem/</url>
      <content type="html"><![CDATA[<p>CAP 定理是分布式计算中的一个概念，由 Eric Brewer 提出。 CAP 是 Consistency、Availability、Partition tolerance 的缩写。最初 CAP 是一个假设，即在分布式系统中，CAP 3 项不可能同时满足，只能同时满足其中两项。后来由 Seth Gilbert 和 Nancy Lynch 对该假设进行了证明。<br>那么 CAP 定理如何理解呢？我们先重申一下 CAP 的释义。</p>
<ul>
<li>Consistency<br>  一致性，即所有节点副本内容都是相同的。要强调一下，这里所说的一致性，是线性一致性或者叫顺序一致性。</li>
<li>Availability<br>  可用性，即每一个请求都会收到一个响应，但是结果可能不是最新的。</li>
<li>Partition tolerance<br>  分区容错，即系统产生分区后依然能够运行。分区简单讲就是节点之间不能通信，包括网络故障，宕机等。</li>
</ul>
<p>你一定和我一样有这样的疑惑，为什么 CAP 不能同时满足呢？<br>前边提到， Seth Gilbert 和 Nancy Lynch 对该假设进行了证明，证明过程参考<a href="https://www.glassbeam.com/sites/all/themes/glassbeam/images/blog/10.1.1.67.6951.pdf" target="_blank" rel="external">https://www.glassbeam.com/sites/all/themes/glassbeam/images/blog/10.1.1.67.6951.pdf</a> 。<br>这里有一片文章对论文加上了一些图片，看起来更直观 <a href="https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/" target="_blank" rel="external">https://mwhittaker.github.io/blog/an_illustrated_proof_of_the_cap_theorem/</a> 。<br>基于 CAP 我们可以“简单”地将系统分为三类：</p>
<ul>
<li>CP</li>
<li>AP</li>
<li>CA</li>
</ul>
<p>但是，大多数人认为在现实中分区是不可避免的，原因也显而易见，保证一个节点永远可用几乎是不可能，所以只能在 CP 和 AP 中选择。如果按照这样的思路，既然故障不可避免，那么当故障发生时，我们该如何选择？</p>
<ul>
<li>如果系统选择在存在分区时“一致性”的权重更高，则通过拒绝响应某些请求，以保证其原子读取和写入。比如完全关闭或拒绝写入又或者只响应对“主”节点位于分区内的数据片段进行读写。只要满足业务的需要，这些都是合理的，而且这也会大大降低系统的复杂度。</li>
<li>如果系统选择在存在分区时“可用性”的权重更高，则将响应所有请求，可能会返回过时的读取并接受冲突的写入。这些不一致通过其他技术手段来解决解决，这也是合理的。</li>
</ul>
<p>这让我们又一次陷入疑惑，到底是 CP 还是 AP ？ 先别急，我们在做出选择之前，先想一想，是不是所有的分布式系统都可以严格的分为 CP 和 AP 呢？如果答案是肯定的，那么我们可以从系统分类中找到每种分类的系统共性，从而找到规律来给下一个系统贴上 CP 或 AP 的标签。 如果答案是否定的，那么就意味着强行将系统分类成 AP 或 CP 是不合适的。<br>我们先找几个系统来试着进行分类。</p>
<ul>
<li>master/slave 系统<br>  主从结构的是很多分布式系统采用的方式。通过 master 将其他节点联系起来，如果客户端与 master 分区，则无法写入。即便可以从 slave 节点读取，但是不能写入决定了单一 master 的系统不是 CP 的。</li>
<li>关系数据库<br>  数据库为了提供高并发，就会放弃线性化，如果不能保证线性化，那么系统自然就不是 CP 的。</li>
<li>NoSQL数据库<br>  大多数 NoSQL 数据的卖点都是高可用，但是如果数据的副本少于约定数量，在恢复副本到正常数量之前，是不满足 AP 的。</li>
<li>共识系统<br>  共识系统的主要特点就是保证一致性，如 zookeeper 。这样看 zookeeper 是一个 CP 的系统，但是 zookeeper 默认是不提供线性化读的，即在读取 zookeeper 的一个节点时，即使其他节点的数据更新，但是依旧只能读取本地节点的旧数据。为了提供更好的性能，zookeeper 并不是任何时候都执行同步的，所以在同步之前，它不是 CP 的。</li>
</ul>
<p>好了，上面我们列举了一些系统，他们既不符合 <code>CAP-一致</code>也不符合 <code>CAP-可用</code>，它们只是满足 P 。再回头来看刚才提出的问题，好像到底是 CP 还是 AP ，并没有一个明确的标准来严格区分。如果这样，我们无法将系统明确的区分为 CP 或 AP ，那我们研究 CAP 的意义是什么呢？ CAP 为我们提供了一个实际问题的一个简化模型，通过这个模型，让我们对实际问题进行思考和讨论，了解我们在分区时将面对什么。 CAP 的启发意义远大于其定理本身。</p>
]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[about practical byzantine fault tolerance]]></title>
      <url>/2018/05/28/about-practical-byzantine-fault-tolerance/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[About Delegated Proof of Stake]]></title>
      <url>/2018/05/28/about-delegated-proof-of-stake/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[About Proof of Stake]]></title>
      <url>/2018/05/28/about-proof-of-stake/</url>
      <content type="html"><![CDATA[<p>Proof of stake (PoS) 是一种区块链网络数字加密货币的一种算法，目的是为了解决分布式共识问题。和比特币使用的计算复杂问题并进行验证来创建新的区块的方式不同，基于 PoS 的加密货币通过财富、龄等多种随机组合来选择下一个区块的创建者。</p>
<h4 id="Pos-的几种方式"><a href="#Pos-的几种方式" class="headerlink" title="Pos 的几种方式"></a><strong>Pos 的几种方式</strong></h4><ul>
<li>随机选择<br>  和比特币类似，随机预测一个符合权益的组合的最小哈希，由其他节点来对权益进行验证。</li>
<li>基于币龄选择<br>  币龄等于货币的数量和持有货币的天数乘积。货币至少 30 天未被使用，才能用来创建区块。币龄越大，创建区块的概率越高。货币被用来创建区块后，币龄清零，至少 30 天后才能参与下一次创建区块。为了防止超大币龄控制区块链，所以货币在持有 90 天币龄达到最大值。这种方式的好处是不用消耗巨大的算力就可以创建新的区块。</li>
</ul>
<h4 id="Pos-和-PoW-的区别"><a href="#Pos-和-PoW-的区别" class="headerlink" title="Pos 和 PoW 的区别"></a><strong>Pos 和 PoW 的区别</strong></h4><p>PoS 和 PoW 相比，不是严格意义上的去中心化。<br>PoS 比 PoW 需要消耗的计算量小。换句话说，PoS 创建新块的成本比 PoW 要小，所以就可以以很小的成本作用于多条链，会产生“双花”问题。<br>在 PoW 方式中，矿工本身可不用拥有货币，而 PoS 方式中，虽然也需要挖矿，但是节点是要持有货币的。</p>
]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Understanding Remote Procedure Call]]></title>
      <url>/2018/05/18/understanding-rpc/</url>
      <content type="html"><![CDATA[<p>关于 RPC ，最近在知乎上看了一段文字，描述的比较透彻 <a href="https://www.zhihu.com/question/25536695/answer/221638079" target="_blank" rel="external">https://www.zhihu.com/question/25536695/answer/221638079</a> 。</p>
<p>本地过程调用 RPC 就是要像调用本地的函数一样去调远程函数。在研究 RPC 前，我们先看看本地调用是怎么调的。假设我们要调用函数 Multiply 来计算 lvalue * rvalue 的结果:</p>
<pre><code>1. int Multiply(int l, int r) {
2.   int y = l * r;
3.   return y;
4.}
5. 
6. int lvalue = 10;
7. int rvalue = 20;
8. int l_times_r = Multiply(lvalue, rvalue);
</code></pre><p>那么在第 8 行时，我们实际上执行了以下操作：将 lvalue 和 rvalue 的值压栈进入 Multiply 函数，取出栈中的值10 和 20，将其赋予 l 和 r 执行第 2 行代码，计算 l * r ，并将结果存在 y 将 y 的值压栈，然后从 Multiply 返回第 8 行，从栈中取出返回值 200 ，并赋值给 l_times_r 以上 5 步就是执行本地调用的过程。</p>
<p>在远程调用时，我们需要执行的函数体是在远程的机器上的，也就是说，Multiply 是在另一个进程中执行的。这就带来了几个新问题：</p>
<ul>
<li>Call ID映射<br>我们怎么告诉远程机器我们要调用 Multiply，而不是 Add 或者 FooBar 呢？在本地调用中，函数体是直接通过函数指针来指定的，我们调用 Multiply，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。所以，在RPC中，所有的函数都必须有自己的一个 ID 。这个 ID 在所有进程中都是唯一确定的。Call ID 映射可以直接使用函数字符串，也可以使用整数 ID 。客户端在做远程过程调用时，必须附上这个 ID 。然后我们还需要在客户端和服务端分别维护一个 <code>{函数 &lt;--&gt; Call ID}</code> 的对应表。映射表一般就是一个哈希表。两者的表不一定需要完全相同，但相同的函数对应的 Call ID 必须相同。当客户端需要进行远程调用时，它就查一下这个表，找出相应的 Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。</li>
<li>序列化和反序列化<br>客户端怎么把参数值传给远程的函数呢？在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言（比如服务端用 C++ ，客户端用 Java 或者 Python ）。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。序列化反序列化可以自己写，也可以使用 Protobuf 或者 FlatBuffers 之类的。</li>
<li>网络传输<br>远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把 Call ID 和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分 RPC 框架都使用 TCP 协议，但其实 UDP 也可以，而 gRPC 干脆就用了 HTTP2 。当然也可以自己写 socket 或者用 asio，ZeroMQ，Netty 之类。</li>
</ul>
<p>所以，要实现一个 RPC 框架，其实只需要把以上三点实现了就基本完成了。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[learning solidity]]></title>
      <url>/2018/05/05/learning-solidity/</url>
      <content type="html"><![CDATA[<p>Solidity 是实现智能合约官方的推荐语言之一。Solidity 的语法和 Javascript 类似。</p>
<h4 id="版本指令"><a href="#版本指令" class="headerlink" title="版本指令"></a><strong>版本指令</strong></h4><p>每个智能合约的代码都是以版本指令声明开始的。这个是一个空的智能合约。</p>
<pre><code>pragma solidity ^0.4.23;
contract HelloWorld {
}
</code></pre><h4 id="状态变量和数据类型"><a href="#状态变量和数据类型" class="headerlink" title="状态变量和数据类型"></a><strong>状态变量和数据类型</strong></h4><p>状态变量会被永久地保存在合约中，保存在区块链上。</p>
<pre><code>pragma solidity ^0.4.23;
contract HelloWorld {
        uint a = 100;
}
</code></pre><p>上边的例子声明了一个 uint 类型的变量并赋值为 100 。在 Solidity 中 uint 实际上是 uint256 的省略写法。<br>Solidity 还有其他数据类型：布尔类型 bool，整型 uint，uint8，uint32，uint64 … uint256，字符串类型 string，数组类型 []，映射 mapping 等。</p>
<h5 id="地址"><a href="#地址" class="headerlink" title="地址"></a>地址</h5><p>以太坊区块链由 account (账户)组成。一个帐户的余额是以太（在以太坊区块链上使用的币种），帐户之间可以支付和接受以太币。帐户地址是属于特定用户（或智能合约）的。每个帐户都有一个“地址”，是账户唯一的标识。<br>msg.sender 是当前调用者（或智能合约）的 address，是一个全局变量，并且它总是存在的。</p>
<pre><code>mapping (address =&gt; uint) favoriteNumber;

function setMyNumber(uint _myNumber) public {
  // 更新我们的 `favoriteNumber` 映射来将 `_myNumber`存储在 `msg.sender`名下
  favoriteNumber[msg.sender] = _myNumber;
  // 存储数据至映射的方法和将数据存储在数组相似
}

function whatIsMyNumber() public view returns (uint) {
  // 拿到存储在调用者地址名下的值
  // 若调用者还没调用 setMyNumber， 则值为 `0`
  return favoriteNumber[msg.sender];
}
</code></pre><h5 id="映射"><a href="#映射" class="headerlink" title="映射"></a>映射</h5><p>映射的定义方式如下：</p>
<pre><code>//对于金融应用程序，将用户的余额保存在一个 uint类型的变量中：
mapping (address =&gt; uint) public accountBalance;
//或者可以用来通过userId 存储/查找的用户名
mapping (uint =&gt; string) userIdToName;
</code></pre><p>映射本质上是存储和查找数据所用的键-值对。在第一个例子中，键是一个 address，值是一个 uint，在第二个例子中，键是一个uint，值是一个 string。</p>
<h4 id="运算"><a href="#运算" class="headerlink" title="运算"></a><strong>运算</strong></h4><p>Solidity 支持基本的数学运算：加，减，乘，除，取模，乘方。</p>
<pre><code>pragma solidity ^0.4.23;
contract HelloWorld {
        uint a = 3;
        uint b = 2;
        uint c = a + b;
        uint d = a - b;
        uint e = a * b;
        uint f = a / b;
        uint g = a % b;
        uint h = a ** b;    // a 的 b 次方
        uint i = a ^ b;    // a 的 b 次方
}
</code></pre><h4 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a><strong>结构体</strong></h4><p>结构体是一种更复杂的数据类型，可以包含多个属性。</p>
<pre><code>struct  Person {
        string name;
        uint age;
}
</code></pre><h4 id="数组"><a href="#数组" class="headerlink" title="数组"></a><strong>数组</strong></h4><p>Solidity 支持两种数组：静态数组和动态数组。</p>
<pre><code>pragma solidity ^0.4.23;
contract HelloWorld {
        // 固定长度为2的静态数组:
        uint[2] fixedArray;
        // 固定长度为5的string类型的静态数组:
        string[5] stringArray;
        // 动态数组，长度不固定，可以动态添加元素:
        uint[] dynamicArray;
        // 结构体数组
        Person[] structArray;
        // 公共数组
        uint[] public intArray;
        uint[] numbers;
        numbers.push(5);
}
</code></pre><p>Solidity 会为 public 数组自动创建 getter 方法，其他的合约可以从 public 数组中读取数据（不可写），所以可以用 public 数组存储公共数据。</p>
<h4 id="函数"><a href="#函数" class="headerlink" title="函数"></a><strong>函数</strong></h4><p>Solidity 中可以通过一下形式创建函数：</p>
<pre><code>function fun(string _arg1, uint _arg2){

}
</code></pre><p>虽然函数的属性默认为公共，但是这会易于受到攻击，所以将函数声明为私有，在需要的时候再改为共有是一个好习惯。用 private 就可以声明一个私有函数。</p>
<pre><code>function _fun(uint _number) private {
        numbers.push(_number);
}
</code></pre><p>以（_）开头是私有函数的命名约定。</p>
<h5 id="internal-和-external"><a href="#internal-和-external" class="headerlink" title="internal 和 external"></a>internal 和 external</h5><p>除 public 和 private 属性之外，Solidity 还使用了另外两个描述函数可见性的修饰词：internal（内部） 和 external（外部）。internal 和 private 类似，不过， 如果某个合约继承自其父合约，这个合约即可以访问父合约中定义的“内部”函数。external 与 public 类似，只不过这些函数只能在合约之外调用，它们不能被合约内的其他函数调用。<br>声明函数 internal 或 external 类型的语法，与声明 private 和 public类 型相同：</p>
<pre><code>contract Sandwich {
        uint private sandwichesEaten = 0;

        function eat() internal {
                sandwichesEaten++;
        }
}

contract BLT is Sandwich {
        uint private baconSandwichesEaten = 0;

        function eatWithBacon() public returns (string) {
                baconSandwichesEaten++;
                // 因为eat() 是internal 的，所以我们能在这里调用
                eat();
        }
}
</code></pre><p>上边的函数没有返回值，可以通过 returns 定义返回值。</p>
<pre><code>function fun() public returns (string) {
        return &quot;abc&quot;;
}
</code></pre><p>上边的函数没有改变任何值，所以可以把它定义为 view 。</p>
<pre><code>function fun() public view returns (string) {
        return &quot;abc&quot;;
}
</code></pre><p>Solidity 里还有一种特殊的函数，pure 函数，即函数不访问应用数据，返回值只依赖于输入参数。</p>
<pre><code>function _multiply(uint a, uint b) private pure returns (uint) {
        return a * b;
}
</code></pre><h4 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a><strong>类型转换</strong></h4><p>两种不同数据类型的数据进行运算时会出现类型转换的问题，有时会出现错误。</p>
<pre><code>uint8 a = 5;
uint b = 6;
// 将会抛出错误，因为 a * b 返回 uint, 而不是 uint8
uint8 c = a * b;
</code></pre><p>要么将 c 的类型变成 uint，要么将 b 强转成 uint8 。</p>
<pre><code>uint8 c = a * uint8(b);
</code></pre><h4 id="事件"><a href="#事件" class="headerlink" title="事件"></a><strong>事件</strong></h4><p>事件是合约和区块链通讯的一种机制。前端应用“监听”某些事件，并做出反应。</p>
<pre><code>event IntegersAdded(uint x, uint y, uint result);
function add(uint _x, uint _y) public {
        uint result = _x + _y;
        //触发事件，通知app
        IntegersAdded(_x, _y, result);
        return result;
}
</code></pre><p>同时在前端 javascript 中监听事件。</p>
<pre><code>var MyContract = web3.eth.contract(abi).at(contractAddress)
// 监听 `IntegersAdded` 事件, 并且更新UI
var event = MyContract.add(function(error, result) {
  if (error) return
  updateUI()
})
</code></pre><h4 id="Require"><a href="#Require" class="headerlink" title="Require"></a><strong>Require</strong></h4><p>在调用函数的过程中，经常需要加上一些前置规则的验证，这就要用到 require 。require 使得函数在执行过程中，当不满足某些条件时抛出错误，并停止执行。</p>
<pre><code>function sayHiToVitalik(string _name) public returns (string) {
        // 比较 _name 是否等于 &quot;Vitalik&quot;. 如果不成立，抛出异常并终止程序
        // (敲黑板: Solidity 并不支持原生的字符串比较, 我们只能通过比较
        // 两字符串的 keccak256 哈希值来进行判断)
        require(keccak256(_name) == keccak256(&quot;Vitalik&quot;));
        // 如果返回 true, 运行如下语句
        return &quot;Hi!&quot;;
}
</code></pre><h4 id="继承"><a href="#继承" class="headerlink" title="继承"></a><strong>继承</strong></h4><p> 当代合约码过于冗长的时候，最好将代码和逻辑分拆到多个不同的合约中，以便于管理，这就要用到继承。</p>
<pre><code> contract Doge {
       function catchphrase() public returns (string) {
               return &quot;So Wow CryptoDoge&quot;;
        }
}
contract BabyDoge is Doge {
        function anotherCatchphrase() public returns (string) {
                return &quot;Such Moon BabyDoge&quot;;
        }
}
</code></pre><p>BabyDoge  继承了 Doge ，所以可以访问 Doge 中的所有公有函数。</p>
<h4 id="接口"><a href="#接口" class="headerlink" title="接口"></a><strong>接口</strong></h4><p>Solidity 也支持接口，</p>
<h4 id="import"><a href="#import" class="headerlink" title="import"></a><strong>import</strong></h4><p>通常情况下，当 Solidity 项目中的代码太长的时候我们就把它分成多个文件以便于管理。在 Solidity 中，当你有多个文件并且想把一个文件导入另一个文件时，可以使用 import 语句。</p>
<pre><code>import &quot;./someothercontract.sol&quot;;

contract newContract is SomeOtherContract {

}
</code></pre><p>./ 就是同一目录的意思。</p>
<h4 id="Storage与Memory"><a href="#Storage与Memory" class="headerlink" title="Storage与Memory"></a><strong>Storage与Memory</strong></h4><p>在 Solidity 中，有两个地方可以存储变量 ： storage 或 memory 。Storage 变量是指永久存储在区块链中的变量。 Memory 变量则是临时的，当外部函数对某合约调用完成时，内存型变量即被移除。 状态变量（在函数之外声明的变量）默认为“storage”形式，并永久写入区块链；而在函数内部声明的变量是“memory”型的，它们函数调用结束后消失。<br>大多数时候都用不到这些关键字，默认情况下 Solidity 会自动处理它们。然而也有一些情况下，你需要手动声明存储类型，主要用于处理函数内的 结构体和数组时：</p>
<pre><code>contract SandwichFactory {
        struct Sandwich {
              string name;
              string status;
        }

        Sandwich[] sandwiches;

        function eatSandwich(uint _index) public {
                 // Sandwich mySandwich = sandwiches[_index];

                 // ^ 看上去很直接，不过 Solidity 将会给出警告
                 // 告诉你应该明确在这里定义 `storage` 或者 `memory`。

                 // 所以你应该明确定义 `storage`:
                 Sandwich storage mySandwich = sandwiches[_index];
             // ...这样 `mySandwich` 是指向 `sandwiches[_index]`的指针
          // 在存储里，另外...
          mySandwich.status = &quot;Eaten!&quot;;
          // ...这将永久把 `sandwiches[_index]` 变为区块链上的存储

          // 如果你只想要一个副本，可以使用`memory`:
          Sandwich memory anotherSandwich = sandwiches[_index + 1];
          // ...这样 `anotherSandwich` 就仅仅是一个内存里的副本了
          // 另外
         anotherSandwich.status = &quot;Eaten!&quot;;
         // ...将仅仅修改临时变量，对 `sandwiches[_index + 1]` 没有任何影响
         // 不过你可以这样做:
          sandwiches[_index + 1] = anotherSandwich;
         // ...如果你想把副本的改动保存回区块链存储
        }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
            <tag> Ethereum </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elastic Learning Path]]></title>
      <url>/2018/05/03/elastic-learning-path/</url>
      <content type="html"><![CDATA[<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20180520/174555154.png" alt=""></p>
<h3 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h3><p><a href=""><strong>Elasticsearch Installation I - Single Node</strong></a><br><a href=""><strong>Elasticsearch Installation II - Cluster</strong></a><br><a href="../../../../2017/12/28/elasticsearch-6-rest-api-practice-1"><strong>Elasticsearch 6 REST API Practice I - Index</strong></a><br><a href="../../../../2017/12/29/elasticsearch-6-rest-api-practice-2"><strong>Elasticsearch 6 REST API Practice II - Document</strong></a><br><a href="../../../../2017/12/30/elasticsearch-6-rest-api-practice-3"><strong>Elasticsearch 6 REST API Practice III - Cat</strong></a><br><a href="../../../../2017/12/31/elasticsearch-6-rest-api-practice-4"><strong>Elasticsearch 6 REST API Practice IV - Search</strong></a><br><a href="../../../../2018/01/01/elasticsearch-6-rest-api-practice-5"><strong>Elasticsearch 6 REST API Practice V - Query DSL</strong></a><br><a href="../../../../2018/01/02/elasticsearch-6-rest-api-practice-6"><strong>Elasticsearch 6 REST API Practice VI - Aggragation</strong></a><br><a href="../../../../2018/01/03/elasticsearch-6-rest-api-practice-7"><strong>Elasticsearch 6 REST API Practice VII - Settings</strong></a></p>
<h3 id="Kibana"><a href="#Kibana" class="headerlink" title="Kibana"></a>Kibana</h3><p><a href=""></a></p>
<h3 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h3><p><a href=""></a></p>
<h3 id="Beats"><a href="#Beats" class="headerlink" title="Beats"></a>Beats</h3><p><a href=""></a></p>
<h3 id="X-Pact"><a href="#X-Pact" class="headerlink" title="X-Pact"></a>X-Pact</h3><p><a href=""></a><br><a href=""></a><br><a href=""></a></p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Installing and Configuring Apache Kylin]]></title>
      <url>/2018/04/10/installing-and-configuring-apache-kylin/</url>
      <content type="html"><![CDATA[<h4 id="kylin-简介"><a href="#kylin-简介" class="headerlink" title="kylin 简介"></a><strong>kylin 简介</strong></h4><p>Apache Kylin 是一个开源的分布式分析引擎，提供 Hadoop 之上的 SQL 查询接口及多维分析（OLAP）能力以支持超大规模数据，最初由 eBay Inc. 开发并贡献至开源社区。</p>
<h4 id="kylin-安装"><a href="#kylin-安装" class="headerlink" title="kylin 安装"></a><strong>kylin 安装</strong></h4><p>kylin 是基于 hadoop 生态的，所以依赖于 hadoop 、hbase、hive 等组件。这里我们使用的是 hadoop-2.6.2、hbase-1.2.6 、hive-1.2.2 和 kylin-2.3.1 。</p>
<h5 id="安装-hadoop"><a href="#安装-hadoop" class="headerlink" title="安装 hadoop"></a><strong>安装 hadoop</strong></h5><ol>
<li>下载<pre><code>wget https://archive.apache.org/dist/hadoop/core/hadoop-2.6.2/hadoop-2.6.2.tar.gz
tar -zxf hadoop-2.6.2.tar.gz
cd hadoop-2.6.2
</code></pre></li>
<li>修改环境变量<pre><code>sudo echo &quot;HADOOP_HOME=/hadoop-2.6.2&quot; &gt;&gt; /etc/profile.d/hadoop.sh
sudo echo &#39;PATH=$HADOOP_HOME/bin:$PATH&#39; &gt;&gt; /etc/profile.d/hadoop.sh
sudo echo &quot;export HADOOP_HOME PATH&quot; &gt;&gt; /etc/profile.d/hadoop.sh
. /etc/profile
</code></pre></li>
<li>修改配置<br>hadoop-2.6.2/etc/hadoop/core-site.xml<pre><code>&lt;configuration&gt;
 &lt;property&gt;
     &lt;name&gt;fs.defaultFS&lt;/name&gt;
     &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
 &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>hadoop-2.6.2/etc/hadoop/hdfs-site.xml<pre><code>&lt;configuration&gt;
 &lt;property&gt;
     &lt;name&gt;dfs.replication&lt;/name&gt;
     &lt;value&gt;1&lt;/value&gt;
 &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>hadoop-2.6.2/etc/hadoop/mapred-site.xml<pre><code>&lt;configuration&gt;
 &lt;property&gt;
     &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
     &lt;value&gt;yarn&lt;/value&gt;
 &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>hadoop-2.6.2/etc/hadoop/yarn-site.xml<pre><code>&lt;configuration&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
     &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
 &lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
<li>格式化 namenode<pre><code>cd hadoop-2.6.2/bin
./hdfs namenode -format
</code></pre></li>
<li>启动<pre><code>cd hadoop-2.6.2/sbin
./start-yarn.sh
./start-dfs.sh
./mr-jobhistory-daemon.sh start historyserver
</code></pre></li>
</ol>
<h5 id="安装-hbase"><a href="#安装-hbase" class="headerlink" title="安装 hbase"></a><strong>安装 hbase</strong></h5><ol>
<li>下载<pre><code>wget https://archive.apache.org/dist/hbase/1.2.6/hbase-1.2.6-bin.tar.gz
tar -zxf hbase-1.2.6-bin.tar.gz
</code></pre></li>
<li>修改环境变量<pre><code>sudo echo &quot;HBASE_HOME=/hbase-1.2.6&quot; &gt;&gt; /etc/profile.d/hbase.sh
sudo echo &#39;PATH=$HBASE_HOME/bin:$PATH&#39; &gt;&gt; /etc/profile.d/hbase.sh
sudo echo &quot;export HBASE_HOME PATH&quot; &gt;&gt; /etc/profile.d/hbase.sh
. /etc/profile
</code></pre></li>
<li>修改配置<br>hbase-1.2.6/conf/hbase-env.sh<pre><code>export JAVA_HOME=/u01/java/latest
</code></pre>hbase-1.2.6/conf/hbase-site.xml<pre><code>&lt;configuration&gt;
&lt;property&gt;
 &lt;name&gt;hbase.rootdir&lt;/name&gt;
 &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
 &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
 &lt;value&gt;localhost&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
<li>启动<pre><code>cd hbase-1.2.6/bin
./start-hbase.sh
./local-regionservers.sh start 1
./local-master-backup.sh start 1
</code></pre></li>
</ol>
<h5 id="安装-hive"><a href="#安装-hive" class="headerlink" title="安装 hive"></a><strong>安装 hive</strong></h5><ol>
<li>下载<pre><code>wget https://archive.apache.org/dist/hive/hive-1.2.2/apache-hive-1.2.2-bin.tar.gz
tar -zxf apache-hive-1.2.2-bin.tar.gz
</code></pre></li>
<li>修改环境变量<pre><code>sudo echo &quot;HIVE_HOME=/apache-hive-1.2.2-bin&quot;&gt;/etc/profile.d/hive.sh
sudo echo &#39;PATH=$PATH:$HIVE_HOME/bin&#39;&gt;&gt;/etc/profile.d/hive.sh
sudo echo &quot;export HIVE_HOME PATH&quot;&gt;&gt;/etc/profile.d/hive.sh
. /etc/profile
</code></pre></li>
<li>修改配置<pre><code>cd apache-hive-1.2.2-bin/conf
cp hive-default.xml.template hive-default.xml
cp hive-env.sh.template hive-env.sh
cp hive-log4j.properties.template hive-log4j.propertiesn
cp hive-exec-log4j.properties.template hive-exec-log4j.properties
</code></pre></li>
<li>配置 MySQL<br>hive 默认使用 derby 存储元数据，但是 derby 存在多用户访问异常的问题，所以使用 mysql 存储元数据。<br>安装 mysql <pre><code>sudo apt-get install mysql-server
</code></pre>修改权限<pre><code>mysql -uroot -p123456
mysql&gt; CREATE USER &#39;hive&#39; IDENTIFIED BY &#39;hive&#39;;
mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;hive&#39;@&#39;%&#39; WITH GRANT OPTION;
mysql&gt; flush privileges;
</code></pre>创建 hive 元数据库<pre><code>mysql -uhive -phive
mysql&gt; create database hive;
</code></pre>修改 apache-hive-1.2.2-bin/conf/hive-site.xml 。<pre><code>&lt;configuration&gt;
 &lt;!-- mysql 配置 --&gt;
&lt;property&gt;
 &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;
 &lt;value&gt;jdbc:mysql://localhost:3306/hive?characterEncoding=UTF-8&lt;/value&gt;
 &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;
 &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;
 &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;
 &lt;value&gt;hive&lt;/value&gt;
 &lt;description&gt;Username to use against metastore database&lt;/description&gt;
&lt;/property&gt;
&lt;property&gt;
 &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;
 &lt;value&gt;hive&lt;/value&gt;
 &lt;description&gt;password to use against metastore database&lt;/description&gt;
&lt;/property&gt;
&lt;configuration&gt;
</code></pre>拷贝 mysql 驱动到 apache-hive-1.2.2-bin/lib 。</li>
<li>启动<pre><code>cd apache-hive-1.2.2-bin/bin
./hive
</code></pre></li>
</ol>
<h5 id="安装-kylin"><a href="#安装-kylin" class="headerlink" title="安装 kylin"></a><strong>安装 kylin</strong></h5><ol>
<li>下载<pre><code>wget https://archive.apache.org/dist/kylin/apache-kylin-2.3.1/apache-kylin-2.3.1-hbase1x-bin.tar.gz
tar -zxf apache-kylin-2.3.1-hbase1x-bin.tar.gz
</code></pre></li>
<li>修改环境变量<pre><code>sudo echo &quot;KYLIN_HOME=/kylin-sample/apache-kylin-2.3.1-bin&quot; &gt;&gt; /etc/profile.d/kylin.sh
sudo echo &quot;export KYLIN_HOME&quot;
. /etc/profile
</code></pre></li>
<li>检查环境<pre><code>cd apache-kylin-2.3.1-hbase1x-bin/bin
./check-env.sh
./find-hadoop-conf-dir.sh
./find-hbase-dependency.sh
./find-hive-dependency.sh
</code></pre>如果以上都安装成功，此处检查应该没有问题。</li>
<li>启动<pre><code>cd apache-kylin-2.3.1-hbase1x-bin/bin
./kylin start
</code></pre>启动后通过 <a href="localhost:7070/kylin" target="_blank" rel="external">localhost:7070/kylin</a> 访问，用户名密码： ADMIN/KYLIN。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Big Data </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Apache Kylin </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[concept of merkle tree in ethereum]]></title>
      <url>/2018/03/16/concept-of-merkle-tree-in-ethereum/</url>
      <content type="html"><![CDATA[<p>Merkle Tree 是一种在密码学和计算机科学中常见的数据结构，它是一种 <code>Hash Tree</code> ，即所有的节点都是 Hash 值，叶子节点是数据块的 hash 值，非叶子节点是其子节点的 hash 值。</p>
<h4 id="Hash-Tree-和-Hash-List-的区别"><a href="#Hash-Tree-和-Hash-List-的区别" class="headerlink" title="Hash Tree 和 Hash List 的区别"></a><strong>Hash Tree 和 Hash List 的区别</strong></h4><p><code>Hash Tree</code> 可以高效地对大型的数据结构的内容进行安全验证。<code>Hash List</code> 可以看做是一种特殊的 <code>Hash Tree</code> ，高度为 2 的多叉 <code>Hash Tree</code> 。<code>Hash List</code> 的结构简单，但是在校验某节点是否是 list 中的一部分时需要的计算所有节点的 Hash 值。而 <code>Hash Tree</code> 在校验某一节点是否是二进制哈希树的一部分时所需要的节点数量是 <code>log(所有节点树)</code> 。</p>
<h4 id="Merkle-Tree-的应用"><a href="#Merkle-Tree-的应用" class="headerlink" title="Merkle Tree 的应用"></a><strong>Merkle Tree 的应用</strong></h4><p>下面我们用一个简化的图来说明 Merkle Tree 的结构。下图中 <code>T</code> 代表数据，如交易数据，<code>H</code> 代表哈希。<br><img src="https://i.investopedia.com/content/term/merkle_tree/merkle_tree_aa.jpg" alt="https://i.investopedia.com/content/term/merkle_tree/merkle_tree_aa.jpg"><br>通过两个场景来看如和应用。</p>
<ol>
<li>如果我们想验证交易 <code>TD</code> 是否是树的节点。</li>
</ol>
<ul>
<li>首先，我们可以用 <code>HC</code> 和 <code>HD</code> 计算出 <code>HCD</code> 。</li>
<li>第二步，用 <code>HAB</code> 和 <code>HCD</code> 计算出 <code>HABCD</code> 。</li>
<li>第三步，用 <code>HABCD</code> 和 <code>HEFGH</code> 计算出 <code>HABCDEFGH</code> ，如果相同，则是正确的数据。</li>
</ul>
<ol>
<li>如果我们获取了整个树，但是发现有数据损坏或可能被篡改，那么我们如何找到异常的数据节点呢。</li>
</ol>
<ul>
<li>首先，比对 root 的值 <code>HABCDEFGH</code>，如果不一样则比较子节点。</li>
<li>第二步，比较 <code>HABCDEFGH</code> 的子节点 <code>HABCD</code> 和 <code>HEFGH</code> 。</li>
<li>第三步，发现 <code>HABCD</code> 的值不同，则比较 <code>HABCD</code> 的子节点 <code>HAB</code> 和 <code>HCD</code> 。</li>
<li>第四步，发现 <code>HCD</code> 不同，则比较 <code>HCD</code> 的子节点 <code>HC</code> 和 <code>HD</code> ，最终定位到 <code>HD</code> 。</li>
</ul>
<p><img src="https://i.investopedia.com/content/term/merkle_tree/merkle_tree_ab.jpg" alt="https://i.investopedia.com/content/term/merkle_tree/merkle_tree_ab.jpg"></p>
<h4 id="Merkle-Tree-在区块链中的应用"><a href="#Merkle-Tree-在区块链中的应用" class="headerlink" title="Merkle Tree 在区块链中的应用"></a><strong>Merkle Tree 在区块链中的应用</strong></h4>]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
            <tag> Ethereum </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Interpretation of Blockchain Terms]]></title>
      <url>/2018/03/16/interpretation-of-blockchain-terms/</url>
      <content type="html"><![CDATA[<p>ethereum</p>
<p>contracts</p>
<p>gas</p>
<p>图灵完备</p>
]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Intergrating Ethereum and IPFS]]></title>
      <url>/2018/03/15/intergrating-ethereum-and-ipfs/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
            <tag> Ethereum </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Building and Configuring IPFS]]></title>
      <url>/2018/03/15/building-and-configuring-ipfs/</url>
      <content type="html"><![CDATA[<h4 id="IPFS-简介"><a href="#IPFS-简介" class="headerlink" title="IPFS 简介"></a><strong>IPFS 简介</strong></h4><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a><strong>安装</strong></h4><pre><code>wget https://dist.ipfs.io/go-ipfs/v0.4.14/go-ipfs_v0.4.14_linux-amd64.tar.gz
tar -zxf go-ipfs_v0.4.14_linux-amd64.tar.gz
cd go-ipfs
./install.sh
</code></pre><p>导入 ipfs 命令成功后可以使用命令查看 ipfs 信息。</p>
<pre><code>$ ipfs version
ipfs version 0.4.14
</code></pre><p> 安装好 ipfs 后第一次需要先初始化。</p>
<pre><code>$ ipfs init
initializing IPFS node at /home/rolex/.ipfs
generating 2048-bit RSA keypair...done
peer identity: QmcePzyBWVKhhi1vhh9CXmAiCEKLQdnRo5vsq3pdaDyQnc
to get started, enter:

    ipfs cat /ipfs/QmS4ustL54uo8FzR9455qaxZwuMiUhyvMcX9Ba8nUH4uVv/readme

$
</code></pre><p>查看 readme 即可看到如下类似信息：</p>
<pre><code>$ ipfs cat /ipfs/QmS4ustL54uo8FzR9455qaxZwuMiUhyvMcX9Ba8nUH4uVv/readme
Hello and Welcome to IPFS!

██╗██████╗ ███████╗███████╗
██║██╔══██╗██╔════╝██╔════╝
██║██████╔╝█████╗  ███████╗
██║██╔═══╝ ██╔══╝  ╚════██║
██║██║     ██║     ███████║
╚═╝╚═╝     ╚═╝     ╚══════╝

If you&#39;re seeing this, you have successfully installed
IPFS and are now interfacing with the ipfs merkledag!

 -------------------------------------------------------
| Warning:                                              |
|   This is alpha software. Use at your own discretion! |
|   Much is missing or lacking polish. There are bugs.  |
|   Not yet secure. Read the security notes for more.   |
 -------------------------------------------------------

Check out some of the other files in this directory:

  ./about
  ./help
  ./quick-start     &lt;-- usage examples
  ./readme          &lt;-- this file
  ./security-notes
$
</code></pre><h4 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a><strong>基本使用</strong></h4><p>查看 id 信息</p>
<pre><code>$ ipfs id
{
    &quot;ID&quot;: &quot;QmcePzyBWVKhhi1vhh9CXmAiCEKLQdnRo5vsq3pdaDyQnc&quot;,
    &quot;PublicKey&quot;: &quot;CAASpgIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC1fFtQLEn4l3nr1ey5RLkmIc3Gx6HTamconhoGPD9Fjw8+KVmH3e52SxH9t3Xxan2ZuG7Eh59IkY13gceakV6vvYvM2WZfipHJ5FKM2KCZ2vukytBV3prU3uk/UszX/ZDJP/IUhJg4HLHjRvaPYlbTEwbi9RwfC10ViGHWmGSitkNaKYwqHkMpZjP5mqfi19ycCN9k0cCGwFophXmR3x9DvlPqP0zctm/GY9hqCVSo5H8c1OCLhO5uNhs1EcpMnY3629pJsLMi03Y4lZaky2YQZLfmb2T18BvQPKSq+byuS2oL6wWam4y8LJIDHevl7y4AOFeVq2w44b3ypW/nkJ+JAgMBAAE=&quot;,
    &quot;Addresses&quot;: null,
    &quot;AgentVersion&quot;: &quot;go-ipfs/0.4.14/&quot;,
    &quot;ProtocolVersion&quot;: &quot;ipfs/0.1.0&quot;
}
$
</code></pre><p>添加文件到 ipfs</p>
<pre><code>$ echo &#39;hello&#39; &gt; website/hello
$ echo &#39;world&#39; &gt; website/world
$ echo &#39;hello world&#39; &gt; website/helloworld
$ ipfs add -r website/
added QmZULkCELmmk5XNfCgTnCyFgAVxBRBXyDHGGMVoLFLiXEN website/hello
added QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o website/helloworld
added QmaRGe7bVmVaLmxbrMiVNXqW4pRNNp3xq7hFtyRKA3mtJL website/world
added Qmb6vsJUAxdxRDg8LrD9fueJSmnwrsUXZWf3rJP7EL19fb website
$
</code></pre><p>哈希值是根据文件内容计算的，只要文件内容不变，多次添加地址也不变。</p>
<p>查看文件</p>
<pre><code>$ ipfs cat QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o
hello world
$
</code></pre><p>获取文件</p>
<pre><code>$ ipfs get Qmb6vsJUAxdxRDg8LrD9fueJSmnwrsUXZWf3rJP7EL19fb -o foo1
Saving file(s) to foo1
 71 B / 71 B [====================================================================================================================================================================================================================] 100.00% 0s
$
</code></pre><p>获取对象</p>
<pre><code>$ ipfs object get QmZULkCELmmk5XNfCgTnCyFgAVxBRBXyDHGGMVoLFLiXEN
{&quot;Links&quot;:[],&quot;Data&quot;:&quot;\u0008\u0002\u0012\u0006hello\n\u0018\u0006&quot;}
$ ipfs object get QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o
{&quot;Links&quot;:[],&quot;Data&quot;:&quot;\u0008\u0002\u0012\u000chello world\n\u0018\u000c&quot;}
$ ipfs object get QmaRGe7bVmVaLmxbrMiVNXqW4pRNNp3xq7hFtyRKA3mtJL
{&quot;Links&quot;:[],&quot;Data&quot;:&quot;\u0008\u0002\u0012\u0006world\n\u0018\u0006&quot;}
$ ipfs object get Qmb6vsJUAxdxRDg8LrD9fueJSmnwrsUXZWf3rJP7EL19fb
{&quot;Links&quot;:[{&quot;Name&quot;:&quot;hello&quot;,&quot;Hash&quot;:&quot;QmZULkCELmmk5XNfCgTnCyFgAVxBRBXyDHGGMVoLFLiXEN&quot;,&quot;Size&quot;:14},{&quot;Name&quot;:&quot;helloworld&quot;,&quot;Hash&quot;:&quot;QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o&quot;,&quot;Size&quot;:20},{&quot;Name&quot;:&quot;world&quot;,&quot;Hash&quot;:&quot;QmaRGe7bVmVaLmxbrMiVNXqW4pRNNp3xq7hFtyRKA3mtJL&quot;,&quot;Size&quot;:14}],&quot;Data&quot;:&quot;\u0008\u0001&quot;}
$
</code></pre><p>对象是用 JSON 表示的，<code>Lisks</code> 表示目录，<code>Data</code> 表示数据。</p>
<p>启动 ipfs</p>
<pre><code>$ ipfs daemon
Initializing daemon...
Successfully raised file descriptor limit to 2048.
Swarm listening on /ip4/10.12.6.66/tcp/4001
Swarm listening on /ip4/127.0.0.1/tcp/4001
Swarm listening on /ip4/172.17.0.1/tcp/4001
Swarm listening on /ip4/172.18.0.1/tcp/4001
Swarm listening on /ip6/::1/tcp/4001
Swarm listening on /p2p-circuit/ipfs/QmcePzyBWVKhhi1vhh9CXmAiCEKLQdnRo5vsq3pdaDyQnc
Swarm announcing /ip4/10.12.6.66/tcp/4001
Swarm announcing /ip4/127.0.0.1/tcp/4001
Swarm announcing /ip4/172.17.0.1/tcp/4001
Swarm announcing /ip4/172.18.0.1/tcp/4001
Swarm announcing /ip6/::1/tcp/4001
API server listening on /ip4/127.0.0.1/tcp/5001
Gateway (readonly) server listening on /ip4/127.0.0.1/tcp/8080
Daemon is ready
</code></pre><p>启动后可以访问管理界面：<a href="localhost:5001/webui" target="_blank" rel="external">localhost:5001/webui</a> 。<br>使用浏览器也可以查看刚刚添加的文件 <a href="http://localhost:8080/ipfs/Qmb6vsJUAxdxRDg8LrD9fueJSmnwrsUXZWf3rJP7EL19fb" target="_blank" rel="external">http://localhost:8080/ipfs/Qmb6vsJUAxdxRDg8LrD9fueJSmnwrsUXZWf3rJP7EL19fb</a>  。</p>
<p>重定向</p>
<pre><code>$ ipfs refs -r QmYRMUVULBfj7WrdPESnwnyZmtayN6Sdrwh1nKcQ9QgQeZ
QmT78zSuBmuS4z925WZfrqQ1qHaJ56DQaTfyMUF7F8ff5o
$
</code></pre><p>地址绑定</p>
<p>IPFS 是通过文件内容的哈希进行寻找的，所以每次修改文件，文件路径都会改变，为了使用固定的地址来访问，可以将文件地址和节点绑定。</p>
<pre><code>$ ipfs name publish Qmb6vsJUAxdxRDg8LrD9fueJSmnwrsUXZWf3rJP7EL19fb
Published to QmcePzyBWVKhhi1vhh9CXmAiCEKLQdnRo5vsq3pdaDyQnc: /ipfs/Qmb6vsJUAxdxRDg8LrD9fueJSmnwrsUXZWf3rJP7EL19fb
</code></pre><p>绑定之后就可以使用 <a href="localhost:8080/ipns/QmcePzyBWVKhhi1vhh9CXmAiCEKLQdnRo5vsq3pdaDyQnc" target="_blank" rel="external">localhost:8080/ipns/QmcePzyBWVKhhi1vhh9CXmAiCEKLQdnRo5vsq3pdaDyQnc</a> 来访问。地址是节点固定的，每次修改文件再 publish 一次即可。不过 ipns 的速度实在是很慢啊。</p>
]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[how to build riskbell on blockchain]]></title>
      <url>/2018/03/11/how-to-build-riskbell-on-blockchain/</url>
      <content type="html"><![CDATA[<p>风铃目前面临的问题：</p>
<ul>
<li>数据处理资源不足</li>
<li>存储中心化，要保证服务高可用</li>
</ul>
<p>用 riskbell 基于 blockchain 需要具有哪些功能</p>
<ul>
<li>分布式数据存储</li>
<li>数据就近查询</li>
<li>保证数据隐私（公司数据和客户数据）</li>
<li>交易记录可查</li>
</ul>
<p>需要搞清楚如何实现的点：</p>
<ul>
<li>如何将企业数据放到 blockchain 中<br>  STATUS into blockchain and data into IPFS</li>
<li>用户如何查询到企业数据（不能随意查，即要有相应的控制措施）</li>
<li>如何订正数据</li>
</ul>
]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Adding a New Node to Ethereum Private Blockchain]]></title>
      <url>/2018/03/11/adding-a-new-node-to-ethereum-private-blockchain/</url>
      <content type="html"><![CDATA[<p>前一篇我们介绍了如何搭建 ethereum 私有链，我们当时我们只创建了一个节点，本篇我们将介绍如何将一个新的节点添加到私有链中。</p>
<h4 id="查看节点连接信息"><a href="#查看节点连接信息" class="headerlink" title="查看节点连接信息"></a><strong>查看节点连接信息</strong></h4><p>首先，先启动节点，然后可以查看节点的 enode 信息：</p>
<pre><code>&gt; admin.nodeInfo.enode
&quot;enode://6e6052f981fc9748e36df7e3c115a3bc90f49eac91b48bb166bb1f3d59e2d3bb88f6c700295ad30bb7a822c84f881dbfce018f1d677f6f11c1226492a5f38296@[::]:30303?discport=0&quot;
&gt; net.listening
true
&gt; net.peerCount
0
&gt;
</code></pre><p>下一步，我们将在本地在创建一个新的节点。如果要在本地创建多个节点，需要满足以下条件：</p>
<ul>
<li>每个节点要有独立的数据存储路径，即 –datadir 不能相同。</li>
<li>每个节点要有独立的端口号，即 –port 和 –rpcport 不能相同。</li>
<li>ipc 唯一或设置 ipc 不可用。</li>
</ul>
<p>按照 <a href="../../../../2018/03/07/building-and-running-a-private-ethereum-blockchain/">Building and Running a Private Ethereum Blockchain</a> 的步骤创建节点，并修改对应的路径和端口号。完成后启动 ethereum-console 查看节点连接信息。</p>
<pre><code>&gt; net.listening
true
&gt; net.peerCount
0
&gt; admin.peers
[]
&gt; admin.nodeInfo.enode
&quot;enode://7b84943bcdb8335a60771a7694169d5995831f7429637e6359fe16705c5770634140f177a7fbae3fcd3097843a355c7f0b45c70833a00958d06de291fba11531@[::]:30304?discport=0&quot;
&gt;
</code></pre><blockquote>
<p>注意这个节点的端口号是 30304 。</p>
</blockquote>
<h4 id="添加节点"><a href="#添加节点" class="headerlink" title="添加节点"></a><strong>添加节点</strong></h4><p>保证 2 个节点同时启动，在 ethereum-console 输入命令：</p>
<pre><code>&gt; admin.addPeer(&quot;enode://7b84943bcdb8335a60771a7694169d5995831f7429637e6359fe16705c5770634140f177a7fbae3fcd3097843a355c7f0b45c70833a00958d06de291fba11531@[::]:30304?discport=0&quot;)
true
&gt; net.peerCount

1
&gt; admin.peers

[{
    caps: [&quot;eth/63&quot;],
    id: &quot;7b84943bcdb8335a60771a7694169d5995831f7429637e6359fe16705c5770634140f177a7fbae3fcd3097843a355c7f0b45c70833a00958d06de291fba11531&quot;,
    name: &quot;Geth/v1.8.2-stable-b8b9f7f4/linux-amd64/go1.9.4&quot;,
    network: {
      inbound: false,
      localAddress: &quot;[::1]:56356&quot;,
      remoteAddress: &quot;[::1]:30304&quot;,
      static: true,
      trusted: false
    },
    protocols: {
      eth: {
        difficulty: 7988311696,
        head: &quot;0xb971d46360be9329738fe90e54f0baf9e9a58136717694a9a735e9d8eb99558d&quot;,
        version: 63
      }
    }
}]
&gt;
</code></pre><p>可以看到节点已经添加成功。</p>
<h4 id="交易"><a href="#交易" class="headerlink" title="交易"></a><strong>交易</strong></h4><p>最后，我们可以通过转账来测试一下两个节点是否联通。打开两个 ethereum-console node0-console 和 node1-console 。先在 node1-console 中创建账户。</p>
<pre><code>&gt; personal.newAccount(&quot;123&quot;)
&quot;0x207c6bc14b2621bdf660eb651f9d47d90b322289&quot;
&gt; eth.accounts
[&quot;0x207c6bc14b2621bdf660eb651f9d47d90b322289&quot;]
&gt;
</code></pre><p>再通过 node0-console 给 <code>0x207c6bc14b2621bdf660eb651f9d47d90b322289</code> 转账 2000 ether 。</p>
<pre><code>&gt; eth.sendTransaction({from:&#39;0x3d85328ac7e7306717bdd9d2e6aca00c3ff12941&#39;, to:&#39;0x207c6bc14b2621bdf660eb651f9d47d90b322289&#39;, value:web3.toWei(1000,&#39;ether&#39;)})
&quot;0x357931adaff330c747b40088016b1f41e69203c3d9591eded70645364197332e&quot;
&gt;
</code></pre><p>等待挖矿确认交易后，即可查看到新节点的账户中多了 2000 ether 。</p>
<pre><code>&gt; web3.fromWei(eth.getBalance(&#39;0x207c6bc14b2621bdf660eb651f9d47d90b322289&#39;), &#39;ether&#39;)
2000
&gt;
</code></pre>]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
            <tag> Ethereum </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Developing Smart Contract using Truffle Framework]]></title>
      <url>/2018/03/08/developing-smart-contract-using-truffle-framework/</url>
      <content type="html"><![CDATA[<h4 id="truffle-介绍"><a href="#truffle-介绍" class="headerlink" title="truffle 介绍"></a><strong>truffle 介绍</strong></h4><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a><strong>安装</strong></h4><pre><code>npm install -g truffle
npm install -g ethereumjs-testrpc
</code></pre><h4 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a><strong>创建项目</strong></h4><pre><code>cd ~
cd blockchain-samples
mkdir truffle-demo
cd truffle-demo
truffle init
</code></pre><p>在 contracts 下创建合约 <code>HelloWorld.js</code> </p>
<pre><code>pragma solidity ^0.4.17;

contract HelloWorld {
    function say() constant public returns (string) {
        return &quot;hello world&quot;;
    }
}
</code></pre><p>在 migrations 下创建 <code>2_initial_helloworld.js</code> </p>
<pre><code>var helloWorld = artifacts.require(&quot;./HelloWorld.sol&quot;);

module.exports = function(deployer) {
  deployer.deploy(helloWorld);
};
</code></pre><p>在 <code>truffle.js</code> 中添加网路配置</p>
<pre><code>module.exports = {
  // See &lt;http://truffleframework.com/docs/advanced/configuration&gt;
  // to customize your Truffle configuration!
  networks: {
    dev: {
      host: &quot;localhost&quot;, //本地地址，因为是在本机上建立的节点
      port: 8545,        //Ethereum的rpc监听的端口号，默认是8545
      network_id: 999    // 自定义网络号
    }
  }
};
</code></pre><h4 id="编译"><a href="#编译" class="headerlink" title="编译"></a><strong>编译</strong></h4><pre><code>truffle compile
truffle migrate --network dev --reset
</code></pre><h4 id="调用合约"><a href="#调用合约" class="headerlink" title="调用合约"></a><strong>调用合约</strong></h4><pre><code>truffle comsole --network dev
</code></pre><pre><code>truffle(dev)&gt; HelloWorld.deployed().then(instance =&gt; helloworld = instance)
TruffleContract {
  constructor: 
   { [Function: TruffleContract]
     _static_methods: 
      { setProvider: [Function: setProvider],
        new: [Function: new],
        at: [Function: at],
        deployed: [Function: deployed],
        defaults: [Function: defaults],
        hasNetwork: [Function: hasNetwork],
        isDeployed: [Function: isDeployed],
        detectNetwork: [Function: detectNetwork],
        setNetwork: [Function: setNetwork],
        resetAddress: [Function: resetAddress],
        link: [Function: link],
        clone: [Function: clone],
        addProp: [Function: addProp],
        toJSON: [Function: toJSON] },
     _properties: 
      { contract_name: [Object],
        contractName: [Object],
        abi: [Object],
        network: [Function: network],
        networks: [Function: networks],
        address: [Object],
        transactionHash: [Object],
        links: [Function: links],
        events: [Function: events],
        binary: [Function: binary],
        deployedBinary: [Function: deployedBinary],
        unlinked_binary: [Object],
        bytecode: [Object],
        deployedBytecode: [Object],
        sourceMap: [Object],
        deployedSourceMap: [Object],
        source: [Object],
        sourcePath: [Object],
        legacyAST: [Object],
        ast: [Object],
        compiler: [Object],
        schema_version: [Function: schema_version],
        schemaVersion: [Function: schemaVersion],
        updated_at: [Function: updated_at],
        updatedAt: [Function: updatedAt] },
     _property_values: {},
     _json: 
      { contractName: &#39;HelloWorld&#39;,
        abi: [Object],
        bytecode: &#39;0x6060604052341561000f57600080fd5b6101578061001e6000396000f300606060405260043610610041576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff168063954ab4b214610046575b600080fd5b341561005157600080fd5b6100596100d4565b6040518080602001828103825283818151815260200191508051906020019080838360005b8381101561009957808201518184015260208101905061007e565b50505050905090810190601f1680156100c65780820380516001836020036101000a031916815260200191505b509250505060405180910390f35b6100dc610117565b6040805190810160405280600b81526020017f68656c6c6f20776f726c64000000000000000000000000000000000000000000815250905090565b6020604051908101604052806000815250905600a165627a7a72305820fcc0cd665f3f7d4bc38115abb0cab0cd48aa0640db2bdc8e3efcdeea6c35c5fd0029&#39;,
        deployedBytecode: &#39;0x606060405260043610610041576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff168063954ab4b214610046575b600080fd5b341561005157600080fd5b6100596100d4565b6040518080602001828103825283818151815260200191508051906020019080838360005b8381101561009957808201518184015260208101905061007e565b50505050905090810190601f1680156100c65780820380516001836020036101000a031916815260200191505b509250505060405180910390f35b6100dc610117565b6040805190810160405280600b81526020017f68656c6c6f20776f726c64000000000000000000000000000000000000000000815250905090565b6020604051908101604052806000815250905600a165627a7a72305820fcc0cd665f3f7d4bc38115abb0cab0cd48aa0640db2bdc8e3efcdeea6c35c5fd0029&#39;,
        sourceMap: &#39;26:113:0:-;;;;;;;;;;;;;;;;;&#39;,
        deployedSourceMap: &#39;26:113:0:-;;;;;;;;;;;;;;;;;;;;;;;;52:85;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;23:1:-1;8:100;33:3;30:1;27:2;8:100;;;99:1;94:3;90;84:5;80:1;75:3;71;64:6;52:2;49:1;45:3;40:15;;8:100;;;12:14;3:109;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;52:85:0;92:6;;:::i;:::-;110:20;;;;;;;;;;;;;;;;;;;;52:85;:::o;26:113::-;;;;;;;;;;;;;;;:::o&#39;,
        source: &#39;pragma solidity ^0.4.17;\n\ncontract HelloWorld {\n    function say() constant public returns (string) {\n        return &quot;hello world&quot;;\n    }\n}\n&#39;,
        sourcePath: &#39;/home/rolex/blockchain-samples/dapps/truffle-demo/contracts/HelloWorld.sol&#39;,
        ast: [Object],
        legacyAST: [Object],
        compiler: [Object],
        networks: [Object],
        schemaVersion: &#39;2.0.0&#39;,
        updatedAt: &#39;2018-03-08T11:23:39.505Z&#39; },
     setProvider: [Function: bound setProvider],
     new: [Function: bound new],
     at: [Function: bound at],
     deployed: [Function: bound deployed],
     defaults: [Function: bound defaults],
     hasNetwork: [Function: bound hasNetwork],
     isDeployed: [Function: bound isDeployed],
     detectNetwork: [Function: bound detectNetwork],
     setNetwork: [Function: bound setNetwork],
     resetAddress: [Function: bound resetAddress],
     link: [Function: bound link],
     clone: [Function: bound clone],
     addProp: [Function: bound addProp],
     toJSON: [Function: bound toJSON],
     web3: 
      Web3 {
        _requestManager: [Object],
        currentProvider: [Object],
        eth: [Object],
        db: [Object],
        shh: [Object],
        net: [Object],
        personal: [Object],
        bzz: [Object],
        settings: [Object],
        version: [Object],
        providers: [Object],
        _extend: [Object] },
     class_defaults: 
      { from: &#39;0x78cd8b9edb6457cbb8455805e0b8e7edad54cebc&#39;,
        gas: 6721975,
        gasPrice: 100000000000 },
     currentProvider: 
      HttpProvider {
        host: &#39;http://localhost:8545&#39;,
        timeout: 0,
        user: undefined,
        password: undefined,
        headers: undefined,
        send: [Function],
        sendAsync: [Function],
        _alreadyWrapped: true },
     network_id: &#39;999&#39; },
  abi: 
   [ { constant: true,
       inputs: [],
       name: &#39;say&#39;,
       outputs: [Object],
       payable: false,
       stateMutability: &#39;view&#39;,
       type: &#39;function&#39; } ],
  contract: 
   Contract {
     _eth: 
      Eth {
        _requestManager: [Object],
        getBalance: [Object],
        getStorageAt: [Object],
        getCode: [Object],
        getBlock: [Object],
        getUncle: [Object],
        getCompilers: [Object],
        getBlockTransactionCount: [Object],
        getBlockUncleCount: [Object],
        getTransaction: [Object],
        getTransactionFromBlock: [Object],
        getTransactionReceipt: [Object],
        getTransactionCount: [Object],
        call: [Object],
        estimateGas: [Object],
        sendRawTransaction: [Object],
        signTransaction: [Object],
        sendTransaction: [Object],
        sign: [Object],
        compile: [Object],
        submitWork: [Object],
        getWork: [Object],
        coinbase: [Getter],
        getCoinbase: [Object],
        mining: [Getter],
        getMining: [Object],
        hashrate: [Getter],
        getHashrate: [Object],
        syncing: [Getter],
        getSyncing: [Object],
        gasPrice: [Getter],
        getGasPrice: [Object],
        accounts: [Getter],
        getAccounts: [Object],
        blockNumber: [Getter],
        getBlockNumber: [Object],
        protocolVersion: [Getter],
        getProtocolVersion: [Object],
        iban: [Object],
        sendIBANTransaction: [Function: bound transfer] },
     transactionHash: null,
     address: &#39;0xd50fb501d6ef3d04cb415e3c0bb5b053d0a7e95f&#39;,
     abi: [ [Object] ],
     say: 
      { [Function: bound ]
        request: [Function: bound ],
        call: [Function: bound ],
        sendTransaction: [Function: bound ],
        estimateGas: [Function: bound ],
        getData: [Function: bound ],
        &#39;&#39;: [Circular] },
     allEvents: [Function: bound ] },
  say: 
   { [Function]
     call: [Function],
     sendTransaction: [Function],
     request: [Function: bound ],
     estimateGas: [Function] },
  sendTransaction: [Function],
  send: [Function],
  allEvents: [Function: bound ],
  address: &#39;0xd50fb501d6ef3d04cb415e3c0bb5b053d0a7e95f&#39;,
  transactionHash: null }
truffle(dev)&gt; helloworld.say()
&#39;hello world&#39;
truffle(dev)&gt;
</code></pre>]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
            <tag> Ethereum </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Compiling Colidity Contract using Command Line]]></title>
      <url>/2018/03/08/compiling-solidity-contract-using-command-line/</url>
      <content type="html"><![CDATA[<p>上一篇我们编写了一个简单的智能合约，并使用 remix-browser 工具进行编译。事实上每一个合约代码都需要先经过编译才能运行。Solidity 的编译器有很多种，官方推荐使用 Remix 。remix-browser 就是 Remix 提供的在线工具。使用在线工具的好处是不用安装任何东西，即可快速编写和运行，对于调试简单的合约尤为方便，但是如果合约复杂并且庞大，使用命令行编译更加有效。本篇我们会介绍如何使用命令行编译运行 solidity 。</p>
<h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a><strong>安装</strong></h4><p>如果使用 ubuntu 安装过程会十分简单。详细可参考：<a href="https://solidity.readthedocs.io/en/develop/installing-solidity.html" target="_blank" rel="external">Installing the Solidity Compiler</a></p>
<pre><code>sudo add-apt-repository ppa:ethereum/ethereum
sudo apt-get update
sudo apt-get install solc
</code></pre><h4 id="编译合约"><a href="#编译合约" class="headerlink" title="编译合约"></a><strong>编译合约</strong></h4><p>还是编译 helloworld.sol 。</p>
<pre><code>cd ~
cd blockchain-samples
mkdir contracts
touch helloworld.sol
</code></pre><p>文件内容如下：</p>
<pre><code>pragma solidity ^0.4.0;
contract helloworld {
    string greeting;

    function helloworld(string _greeting) public {
        greeting = _greeting;
    }

    function say() constant public returns (string) {
        return greeting;
    }
}
</code></pre><p>执行编译</p>
<pre><code>cd ~/`blockchain-samples/contracts
solc -o target --bin --abi helloworld.sol
</code></pre><p>编译完成会生成 .abi 和 .bin 文件。接下来只需要将两个文件中的内容填到模板中。</p>
<pre><code>var _greeting = &quot;Hello World&quot; ;
var helloContract = web3.eth.contract(/**.abi文件的内容**/);
var hello = helloContract.new(
   _greeting,
   {
     from: web3.eth.accounts[0], 
     data: &#39;/**0x+.bin文件的内容**/&#39;, 
     gas: &#39;燃料值&#39;
   }, function (e, contract){
    console.log(e, contract);
    if (typeof contract.address !== &#39;undefined&#39;) {
         console.log(&#39;Contract mined! address: &#39; + contract.address + &#39; transactionHash: &#39; + contract.transactionHash);
    }
 })
</code></pre><p>将替换好的内容拷贝到 eth-console 中，就可以完成部署。</p>
]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
            <tag> Ethereum </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Building a Smart Contract on Ethereum]]></title>
      <url>/2018/03/08/building-a-smart-contract-on-ethereum/</url>
      <content type="html"><![CDATA[<p>上一篇我们介绍了如何搭建和运行 ethereum 私链，接下来我们会介绍如何基于我们搭建的 ethereum 环境开发智能合约。</p>
<h4 id="智能合约介绍"><a href="#智能合约介绍" class="headerlink" title="智能合约介绍"></a><strong>智能合约介绍</strong></h4><h4 id="编写合约"><a href="#编写合约" class="headerlink" title="编写合约"></a><strong>编写合约</strong></h4><p>官方推荐的编写智能合约的语言是 Solidity ，类似 JavaScript 。官方推荐使用 Remix 来编写简单的合约以及学习 Solidity 。Remix 也提供了在线调试的功能 <a href="https://remix.ethereum.org/#optimize=false&amp;version=soljson-v0.4.21+commit.dfe3193c.js" target="_blank" rel="external">remix-browser</a> 。在示例的基础修改，可以开发自己的合约代码。</p>
<pre><code>pragma solidity ^0.4.0;
contract hello {
    string greeting;

    function hello(string _greeting) public {
        greeting = _greeting;
    }

    function say() constant public returns (string) {
        return greeting;
    }
}
</code></pre><h4 id="部署合约"><a href="#部署合约" class="headerlink" title="部署合约"></a><strong>部署合约</strong></h4><p>写完代码可以直接在浏览器中编译，通过后，将 detail 中的 web3Deploy 部分拷贝并修改名字。</p>
<pre><code>var _greeting = &quot;Hello World&quot; ;
var helloContract = web3.eth.contract([{&quot;constant&quot;:true,&quot;inputs&quot;:[],&quot;name&quot;:&quot;say&quot;,&quot;outputs&quot;:[{&quot;name&quot;:&quot;&quot;,&quot;type&quot;:&quot;string&quot;}],&quot;payable&quot;:false,&quot;stateMutability&quot;:&quot;view&quot;,&quot;type&quot;:&quot;function&quot;},{&quot;inputs&quot;:[{&quot;name&quot;:&quot;_greeting&quot;,&quot;type&quot;:&quot;string&quot;}],&quot;payable&quot;:false,&quot;stateMutability&quot;:&quot;nonpayable&quot;,&quot;type&quot;:&quot;constructor&quot;}]);
var hello = helloContract.new(
   _greeting,
   {
     from: web3.eth.accounts[0], 
     data: &#39;0x6060604052341561000f57600080fd5b6040516102b83803806102b8833981016040528080518201919050508060009080519060200190610041929190610048565b50506100ed565b828054600181600116156101000203166002900490600052602060002090601f016020900481019282601f1061008957805160ff19168380011785556100b7565b828001600101855582156100b7579182015b828111156100b657825182559160200191906001019061009b565b5b5090506100c491906100c8565b5090565b6100ea91905b808211156100e65760008160009055506001016100ce565b5090565b90565b6101bc806100fc6000396000f300606060405260043610610041576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff168063954ab4b214610046575b600080fd5b341561005157600080fd5b6100596100d4565b6040518080602001828103825283818151815260200191508051906020019080838360005b8381101561009957808201518184015260208101905061007e565b50505050905090810190601f1680156100c65780820380516001836020036101000a031916815260200191505b509250505060405180910390f35b6100dc61017c565b60008054600181600116156101000203166002900480601f0160208091040260200160405190810160405280929190818152602001828054600181600116156101000203166002900480156101725780601f1061014757610100808354040283529160200191610172565b820191906000526020600020905b81548152906001019060200180831161015557829003601f168201915b5050505050905090565b6020604051908101604052806000815250905600a165627a7a723058209c2dcec2c9ed98141a1a6082b04b2bf20f66a53c0daff8ad0596a766f17aa8380029&#39;, 
     gas: &#39;4700000&#39;
   }, function (e, contract){
    console.log(e, contract);
    if (typeof contract.address !== &#39;undefined&#39;) {
         console.log(&#39;Contract mined! address: &#39; + contract.address + &#39; transactionHash: &#39; + contract.transactionHash);
    }
 })
</code></pre><p>将以上内容拷贝到 geth-console 中，启动挖矿，可以看到合约部署成功。</p>
<pre><code>Contract mined! address: 0x451cf68a0950f2affebd7ebaabd212db602a6e62 transactionHash: 0x62025991d86e0eb761c93b304f70b30868d368f5b290bd48f58b601d40094861
</code></pre><p>在 console 中可以执行。</p>
<pre><code>&gt; hello
{
  abi: [{
      constant: true,
      inputs: [],
      name: &quot;say&quot;,
      outputs: [{...}],
      payable: false,
      stateMutability: &quot;view&quot;,
      type: &quot;function&quot;
  }, {
      inputs: [{...}],
      payable: false,
      stateMutability: &quot;nonpayable&quot;,
      type: &quot;constructor&quot;
  }],
  address: &quot;0x451cf68a0950f2affebd7ebaabd212db602a6e62&quot;,
  transactionHash: &quot;0x62025991d86e0eb761c93b304f70b30868d368f5b290bd48f58b601d40094861&quot;,
  allEvents: function(),
  say: function()
}
&gt; hello.say
function()
&gt; hello.say()
&quot;Hello World&quot;
&gt;
</code></pre>]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
            <tag> Ethereum </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Building and Running a Private Ethereum Blockchain]]></title>
      <url>/2018/03/07/building-and-running-a-private-ethereum-blockchain/</url>
      <content type="html"><![CDATA[<p>本文介绍如何在 Ubuntu 上安装 private ethereum blockchain ，通过安装私链来初步了解区块链，为我们以后编程做好准备。</p>
<h4 id="安装-ethereum"><a href="#安装-ethereum" class="headerlink" title="安装 ethereum"></a><strong>安装 ethereum</strong></h4><p>首先，需要搭建 ethereum 环境，推荐使用 ubuntu 来完成第一个试验。本文介绍内容均给予 Ubuntu 16.04 LTS 。安装说明参考：<a href="https://github.com/ethereum/go-ethereum/wiki/Installation-Instructions-for-Ubuntu" target="_blank" rel="external">Installation Instructions for Ubuntu</a></p>
<pre><code>sudo apt-get install software-properties-common
sudo add-apt-repository -y ppa:ethereum/ethereum
sudo apt-get update
sudo apt-get install ethereum
</code></pre><p>安装完成后使用 <code>geth version</code> 来查看 ethereum 的版本，不同的版本配置信息略有差异。</p>
<h4 id="准备工作空间"><a href="#准备工作空间" class="headerlink" title="准备工作空间"></a><strong>准备工作空间</strong></h4><pre><code>cd ~
mkdir blockchain-samples
cd blockchain-samples
mkdir node0
cd node0
mkdir config
mkdir data
mkdir scripts
mkdir log
</code></pre><h4 id="定义创世区块"><a href="#定义创世区块" class="headerlink" title="定义创世区块"></a><strong>定义创世区块</strong></h4><pre><code>cd ~/blockchain-samples/node0/config
touch genesis-block.json
</code></pre><p>在 genesis-block.json 中写入以下内容：</p>
<pre><code>{
   &quot;config&quot;: {
        &quot;chainId&quot;: 424242,
        &quot;homesteadBlock&quot;: 0,
        &quot;eip155Block&quot;: 0,
        &quot;eip158Block&quot;: 0
    },
    &quot;nonce&quot;: &quot;0x0000000000000042&quot;,
    &quot;mixhash&quot;: &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;,
    &quot;difficulty&quot;: &quot;0x400&quot;,
    &quot;coinbase&quot;: &quot;0x3333333333333333333333333333333333333333&quot;,
    &quot;timestamp&quot;: &quot;0x00&quot;,
    &quot;parentHash&quot;: &quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;,
    &quot;gasLimit&quot;: &quot;0xffffffff&quot;,
    &quot;alloc&quot;: {}
}
</code></pre><p>这是私链的初始化配置。</p>
<blockquote>
<p>不同版本的配置略有差异，如果配置信息不正确，在初始化的时候会出现错误。常见错误有：</p>
<ul>
<li>Fatal: invalid genesis file: missing 0x prefix for hex data：这个错误信息意思很明白，就是你的 json 文件中，对于16进制数据，需要加上 0x 前缀</li>
<li>Fatal: invalid genesis file: hex string has odd length: 从 v1.6 开始，设置的十六进制数值，不能是奇数位， 比如不能是 0x0，而应该是 0x00。</li>
<li>Fatal: failed to write genesis block: genesis has no chain configuration ：这个错误信息，就是说，你的 json 文件中，缺少 config 部分。看到这个信息，我们不需要把 geth 退回到 v1.5 版本，而是需要加上 config 部分。</li>
<li>Error: invalid sender undefined: 这个错误不会导致初始化失败，但是会在以后的转账（eth.sendTransaction），或者部署智能合约的时候产生。解决方法就是 chainId 不能设置为 0 。 如果你完全按照 github 上给的官方配置文件，就会产生这个错误。</li>
</ul>
</blockquote>
<h4 id="初始化创世区块"><a href="#初始化创世区块" class="headerlink" title="初始化创世区块"></a><strong>初始化创世区块</strong></h4><p>我们可以使用一段 shell 脚本来执行初始化工作。</p>
<pre><code>cd ~/blockchain-samples/node0/scripts
touch init_private_chain.sh
chmod +x init_private_chain.sh
</code></pre><p>脚本内容如下：</p>
<pre><code>#!/bin/sh

DATADIR=/home/$USER/blockchain-samples/node0/data
GENESIS=/home/$USER/blockchain-samples/node0/config/genesis-block.json
NETWORKID=42
IDENTITY=&quot;PrivateChainNode0&quot;
PORT=30303
RPCPORT=8000

# Initialize the private blockchain
geth --networkid $NETWORKID --datadir=$DATADIR --identity $IDENTITY --port $PORT --rpcport $RPCPORT init $GENESIS
</code></pre><p>执行脚本可以看到初始化成功。</p>
<h4 id="启动节点"><a href="#启动节点" class="headerlink" title="启动节点"></a><strong>启动节点</strong></h4><p>初始化成功后，我们使用另外一段脚本来启动节点。</p>
<pre><code>cd ~/blockchain-samples/node0/scripts
touch start_node_daemon.sh
chmod +x start_node_daemon.sh
</code></pre><p>脚本内容如下：</p>
<pre><code>#!/bin/sh
PORT=30303
RPCPORT=8000
NETWORKID=42
IDENTITY=&quot;PrivateChainNode0&quot;
DATADIR=/home/$USER/blockchain-samples/node0/data
NAT=none
RPCADDR=&quot;0.0.0.0&quot;

nohup geth --rpc --ws --port $PORT --rpcport $RPCPORT --networkid $NETWORKID --datadir $DATADIR --nat $NAT --identity $IDENTITY --rpcaddr $RPCADDR --wsaddr $RPCADDR --rpccorsdomain * &amp;
</code></pre><p>执行脚本可以启动区块链节点。如果想作为永久节点，可以使用 nohup 来后台运行。</p>
<h4 id="创建账户"><a href="#创建账户" class="headerlink" title="创建账户"></a><strong>创建账户</strong></h4><p>先创建个启动命令行的脚本方便以后使用：</p>
<pre><code>cd ~/blockchain-samples/node0/scripts
touch start_console.sh
chmod +x start_console.sh
</code></pre><p>脚本内容如下：</p>
<pre><code>#!/bin/sh

PORT=30303
RPCPORT=8545
NETWORKID=42
IDENTITY=&quot;PrivateChainNode0&quot;
DATADIR=/home/$USER/blockchain-samples/node0/data
LOGDIR=/home/$USER/blockchain-samples/node0/log
NAT=none
RPCADDR=&quot;0.0.0.0&quot;

geth --rpc --rpccorsdomain &quot;*&quot; --rpcapi &quot;db,eth,net,web3&quot; --ws --port $PORT --rpcport $RPCPORT --networkid $NETWORKID --datadir $DATADIR --nat $NAT --identity $IDENTITY --rpcaddr $RPCADDR --wsaddr $RPCADDR console 2&gt;&gt; $LOGDIR/console.log
</code></pre><p>进入 geth 命令行，执行命令查看账户信息：</p>
<pre><code>&gt; eth.accounts
[]
&gt; personal.newAccount(&quot;rolex&quot;)
&quot;0x78cd8b9edb6457cbb8455805e0b8e7edad54cebc&quot;
&gt; eth.accounts
[&quot;0x78cd8b9edb6457cbb8455805e0b8e7edad54cebc&quot;]
&gt; eth.accounts
[&quot;0x78cd8b9edb6457cbb8455805e0b8e7edad54cebc&quot;]
&gt; personal.newAccount(&quot;123456&quot;)
&quot;0x9d78bc5b7d1311aa9a4c265a7d7889cc3cd3052a&quot;
&gt; eth.accounts
[&quot;0x78cd8b9edb6457cbb8455805e0b8e7edad54cebc&quot;, &quot;0x9d78bc5b7d1311aa9a4c265a7d7889cc3cd3052a&quot;]
&gt;
</code></pre><h4 id="挖矿"><a href="#挖矿" class="headerlink" title="挖矿"></a><strong>挖矿</strong></h4><pre><code>&gt; miner.start()
null
&gt;
</code></pre><p>查看日志可以看到如下日志：</p>
<pre><code>INFO [03-07|16:44:17] Generating DAG in progress               epoch=0 percentage=93 elapsed=2m29.758s
INFO [03-07|16:44:18] Generating DAG in progress               epoch=0 percentage=94 elapsed=2m31.311s
INFO [03-07|16:44:20] Generating DAG in progress               epoch=0 percentage=95 elapsed=2m32.813s
INFO [03-07|16:44:22] Generating DAG in progress               epoch=0 percentage=96 elapsed=2m34.367s
INFO [03-07|16:44:23] Generating DAG in progress               epoch=0 percentage=97 elapsed=2m35.942s
INFO [03-07|16:44:25] Generating DAG in progress               epoch=0 percentage=98 elapsed=2m37.509s
INFO [03-07|16:44:26] Generating DAG in progress               epoch=0 percentage=99 elapsed=2m39.305s
INFO [03-07|16:44:26] Generated ethash verification cache      epoch=0 elapsed=2m39.308s
INFO [03-07|16:44:27] Successfully sealed new block            number=1 hash=b09b14…85ce33
INFO [03-07|16:44:27] 🔨 mined potential block                  number=1 hash=b09b14…85ce33
INFO [03-07|16:44:27] Commit new mining work                   number=2 txs=0 uncles=0 elapsed=174.747µs
</code></pre><p>在挖矿完成前查看账户的余额为 0 ，挖矿完成后，只要账户余额不为 0 ，说明挖矿成功。</p>
<pre><code>&gt; acc0=eth.accounts[0]
&quot;0x78cd8b9edb6457cbb8455805e0b8e7edad54cebc&quot;
&gt; eth.getBalance(acc0)
0
&gt; eth.getBalance(acc0)
55000000000000000000
&gt; eth.getBalance(acc0)
1.715e+21
&gt;
</code></pre><h4 id="交易"><a href="#交易" class="headerlink" title="交易"></a><strong>交易</strong></h4><p>我们创建了两个账户，然后来在挖矿获得的代币被存入默认账户（第一个账户）中，我们可以模拟一次交易，将第一个账户的 1 个代币转账到第二个账户中。</p>
<pre><code>&gt; amount=web3.toWei(1)
&quot;1000000000000000000&quot;
&gt; eth.sendTransaction({from:acc0, to:acc1, value:amount})
Error: authentication needed: password or unlock
    at web3.js:3143:20
    at web3.js:6347:15
    at web3.js:5081:36
    at &lt;anonymous&gt;:1:1

&gt;
</code></pre><p>转账发生错误，提示账户锁定，所以先解锁账户。</p>
<pre><code>&gt; personal.unlockAccount(acc0)
Unlock account 0x78cd8b9edb6457cbb8455805e0b8e7edad54cebc
Passphrase: 
true
&gt; eth.sendTransaction({from:acc0, to:acc1, value:amount})
&quot;0x4af2f15da47d054f167b5f96dfc39c3aa49345111badddca186f24a00204a81f&quot;
&gt; eth.getBalance(acc1)
1000000000000000000
&gt;
</code></pre><p>如果我们没有启动挖矿，那么当交易完成时，我们查看两个账户的余额时会发现没有余额没有变化。这是因为区块链的交易信息需要由矿工挖矿来确认，从而加入到区块链的大账本中。因此，我们只要再次启动 <code>miner.start()</code> 后在查看账户余额，就可以看到余额的变化了。</p>
]]></content>
      
        <categories>
            
            <category> Blockchain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Blockchain </tag>
            
            <tag> Ethereum </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Unit Test with Mockito in Spring Boot]]></title>
      <url>/2018/01/15/unit-test-with-mockito-in-spring-boot/</url>
      <content type="html"><![CDATA[<p>在单元测试中，经常会遇到测试某一个方法，但是代码关联了很多模块，如 HttpServlet、数据库连接等，还可能关联其他的环境和服务，造成单元测试难度大，测试过程复杂。这个时候用 Mock 就能极大简化测试过程。Mock 会帮我们将单元测试依赖解耦，借助 Mock 模拟这些依赖，并验证所调用的依赖的行为。</p>
<p>Mock 的测试框架很多，Spring boot 中集成了 Mockito 。下面就来看看如何在 spring boot 中使用 mock 来做单元测试。</p>
<p>假如我们开发了一个查询接口，需要进行单元测试。</p>
<pre><code>@Mapper
@Component
public interface UserDao {
    User findById(@Param(&quot;id&quot;) int id);
}
</code></pre><pre><code>@Service
public class UserService {
    @Autowired
    UserDao userDao;
    public User findById(int id){
        return userDao.findById(id);
    }
}
</code></pre><pre><code>@RestController
public class UserController {
    @Autowired
    UserService userService;
    @RequestMapping(&quot;/users/{id}&quot;)
    public User list(@PathVariable(&quot;id&quot;) int  id) {
        return userService.findById(id);
    }
}
</code></pre><p>如果不使用 Mock ，我们需要连接数据库和启动服务器。如果每次修改代码测试都要保证数据库和服务器环境正常，会使单元测试变得复杂且效率低下。所以我们可以使用 Mock 来模拟依赖对象进行测试。</p>
<pre><code>import com.rolex.bean.User;
import com.rolex.controller.UserController;
import com.rolex.service.UserService;
import org.junit.Assert;
import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.boot.test.mock.mockito.MockBean;
import org.springframework.test.context.junit4.SpringRunner;
import org.springframework.test.web.servlet.MockMvc;
import org.springframework.test.web.servlet.request.MockMvcRequestBuilders;
import org.springframework.test.web.servlet.setup.MockMvcBuilders;

import static org.mockito.Mockito.when;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.jsonPath;
import static org.springframework.test.web.servlet.result.MockMvcResultMatchers.status;


@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringBootTestApplicationTests {

    MockMvc mockMvc;
    @Autowired
    UserController userController;
    @MockBean
    UserService userService;

    @Before
    public void setUp() {
        mockMvc = MockMvcBuilders.standaloneSetup(userController).build();
    }

    @Test
    public void findById() throws Exception {
        User user = new User(&quot;Phillip&quot;, 20);
        when(userService.findById(1)).thenReturn(user);
        Assert.assertEquals(&quot;Phillip&quot;, userService.findById(1).getName());
    }

    @Test
    public void findById1() throws Exception {
        User user = new User(&quot;Phillip&quot;, 20);
        when(userService.findById(1)).thenReturn(user);
        mockMvc.perform(MockMvcRequestBuilders.get(&quot;/users/1&quot;))
                .andExpect(status().isOk())
                .andExpect(jsonPath(&quot;$.name&quot;).value(&quot;Phillip&quot;));
    }
}
</code></pre><p>完整代码参考：<a href="https://github.com/bsyonline/spring-boot-test" target="_blank" rel="external">https://github.com/bsyonline/spring-boot-test</a></p>
]]></content>
      
        <categories>
            
            <category> Spring Boot </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Boot </tag>
            
            <tag> Mock </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[sign_and_send_pubkey: signing failed: agent refused operation 错误的解决办法]]></title>
      <url>/2018/01/04/sign-and-send-pubkey-signing-failed-agent-refused-operation/</url>
      <content type="html"><![CDATA[<p>Git 安装配置公钥后，报错：</p>
<pre><code>sign_and_send_pubkey: signing failed: agent refused operation
</code></pre><p>执行以下代码即可：</p>
<pre><code>eval &quot;$(ssh-agent -s)&quot;
ssh-add
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Git </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch 6 REST API Practice VI - Aggragation]]></title>
      <url>/2018/01/02/elasticsearch-6-rest-api-practice-6/</url>
      <content type="html"><![CDATA[<h2 id="VI-Aggragation"><a href="#VI-Aggragation" class="headerlink" title="VI. Aggragation"></a>VI. Aggragation</h2><h4 id="Cat-Count"><a href="#Cat-Count" class="headerlink" title="Cat Count"></a>Cat Count</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/count/change?v&quot;
</code></pre><h4 id="Cat-health"><a href="#Cat-health" class="headerlink" title="Cat health"></a>Cat health</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/health?v&quot;
</code></pre><p>查看状态是 yellow 的索引</p>
<pre><code>curl -X GET &quot;localhost:9200/_cat/indices?v&amp;health=yellow&quot;
</code></pre><p>按 count 排序</p>
<pre><code>curl -X GET &quot;localhost:9200/_cat/indices?v&amp;s=docs.count:desc&quot;
</code></pre><h4 id="Cat-Template"><a href="#Cat-Template" class="headerlink" title="Cat Template"></a>Cat Template</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/templates?v&amp;s=name&quot;
</code></pre><h4 id="Cat-Snapshot"><a href="#Cat-Snapshot" class="headerlink" title="Cat Snapshot"></a>Cat Snapshot</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/snapshots/repo1?v&amp;s=id&quot;
</code></pre><h4 id="Cat-Recovery"><a href="#Cat-Recovery" class="headerlink" title="Cat Recovery"></a>Cat Recovery</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/recovery?v&quot;
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch 6 REST API Practice V - Query DSL]]></title>
      <url>/2018/01/01/elasticsearch-6-rest-api-practice-5/</url>
      <content type="html"><![CDATA[<h2 id="V-Query-DSL"><a href="#V-Query-DSL" class="headerlink" title="V. Query DSL"></a>V. Query DSL</h2><h4 id="Cat-Count"><a href="#Cat-Count" class="headerlink" title="Cat Count"></a>Cat Count</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/count/change?v&quot;
</code></pre><h4 id="Cat-health"><a href="#Cat-health" class="headerlink" title="Cat health"></a>Cat health</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/health?v&quot;
</code></pre><p>查看状态是 yellow 的索引</p>
<pre><code>curl -X GET &quot;localhost:9200/_cat/indices?v&amp;health=yellow&quot;
</code></pre><p>按 count 排序</p>
<pre><code>curl -X GET &quot;localhost:9200/_cat/indices?v&amp;s=docs.count:desc&quot;
</code></pre><h4 id="Cat-Template"><a href="#Cat-Template" class="headerlink" title="Cat Template"></a>Cat Template</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/templates?v&amp;s=name&quot;
</code></pre><h4 id="Cat-Snapshot"><a href="#Cat-Snapshot" class="headerlink" title="Cat Snapshot"></a>Cat Snapshot</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/snapshots/repo1?v&amp;s=id&quot;
</code></pre><h4 id="Cat-Recovery"><a href="#Cat-Recovery" class="headerlink" title="Cat Recovery"></a>Cat Recovery</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/recovery?v&quot;
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch 6 REST API Practice IV - Search]]></title>
      <url>/2017/12/31/elasticsearch-6-rest-api-practice-4/</url>
      <content type="html"><![CDATA[<h2 id="IV-Search"><a href="#IV-Search" class="headerlink" title="IV. Search"></a>IV. Search</h2><h4 id="Routing"><a href="#Routing" class="headerlink" title="Routing"></a>Routing</h4><p>在执行搜索时，查询会被广播到所有的索引/索引碎片。由于数据是哈希存储的，所以一般也不存在性能问题。如果我们已经知道数据存储的位置，那么使用 routing 直接告诉系统去指定的位置查询数据，无疑会减少查询时的开销。要按数据的存储位置查询，自然是要在存储的时候就指定好数据的位置。指定位置可能会出现数据热点，所以需要根据业务需要来确定是否需要 routing 。就算没有指定 routing 也是生效的，只不过是按照 document 的 id 去做 routing 。</p>
<pre><code>curl -X POST &quot;localhost:9200/change/change?routing=560E8C402E5914FAE0531ECDA8C0CF0D&quot; -H &#39;Content-Type: appli cation/json&#39; -d&#39; 
{     
    &quot;pripid&quot; : &quot;560E8C402E5914FAE0531ECDA8C0CF0D&quot; 
}&#39;
</code></pre><p>将 pripid 为 <code>560E8C402E5914FAE0531ECDA8C0CF0D</code> 的文档指定 routing ，才能用 routing 查询。</p>
<pre><code>curl -X GET &quot;localhost:9200/change/_search?routing=560E8C402E5914FAE0531ECDA8C0CF0D&amp;q=pripid:560E8C402E5914FAE0531ECDA8C0CF0D&quot;
</code></pre><p>上边使用的是 uri 的查询方式，“q” 是一个参数，还有其他参数可以查询 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.2/search-uri-request.html" target="_blank" rel="external">https://www.elastic.co/guide/en/elasticsearch/reference/6.2/search-uri-request.html</a> 。</p>
<h4 id="Query-Body-Search"><a href="#Query-Body-Search" class="headerlink" title="Query Body Search"></a>Query Body Search</h4><p>除了 uri 的查询方式，通常更常用的 Query Body 的方式。</p>
<pre><code>curl -X GET &quot;localhost:9200/_search&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &quot;from&quot; : 0, &quot;size&quot; : 10,
    &quot;sort&quot; : [
        { &quot;date&quot; : {&quot;order&quot; : &quot;asc&quot;}},
        &quot;_score&quot;
    ],
    &quot;_source&quot;: [&quot;date&quot;, &quot;*_value&quot;],
    &quot;query&quot; : {
        &quot;term&quot; : { &quot;column&quot; : &quot;E_ENT_BASEINFO.NAME&quot; }
    }
}
&#39;
</code></pre><h4 id="Scroll"><a href="#Scroll" class="headerlink" title="Scroll"></a>Scroll</h4><p>通常 query 会返回少量的结果，如果要返回大量数据就需要用到 scroll 。</p>
<pre><code>curl -X POST &quot;localhost:9200/change/_search?scroll=1m&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &quot;size&quot;: 1,
    &quot;query&quot;: {
        &quot;match&quot; : {
            &quot;column&quot; : &quot;E_ENT_BASEINFO.NAME&quot;
        }
    }
}
&#39;
</code></pre><p>scroll 会返回一个 scroll_id ，以供获取后续数据时作为输入使用。</p>
<pre><code>curl -X POST &quot;localhost:9200/_search/scroll&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &quot;scroll&quot; : &quot;1m&quot;, 
    &quot;scroll_id&quot; : &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAHdFk5ZR0hvdFRsU1dhZkx5alE5UkhWWUEAAAAAAAAB3hZOWUdIb3RUbFNXYWZMeWpROVJIVllBAAAAAAAAAd8WTllHSG90VGxTV2FmTHlqUTlSSFZZQQAAAAAAAAHgFk5ZR0hvdFRsU1dhZkx5alE5UkhWWUEAAAAAAAAB4RZOWUdIb3RUbFNXYWZMeWpROVJIVllB&quot; 
}
&#39;
</code></pre><p>使用 scroll_id 来获取下一批数据，直到 scroll_id 为空，表示数据全部获取完成。<br>scroll 方式获取数据对 _doc 升序优化，如果对结果没有顺序要求，使用 scroll 可以获得很好的性能。 scroll_id 在到达失效时间后会被自动删除，但是如果确定 scroll_id 已被使用，并且以后不再使用，可以主动删除，已节省资源。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch 6 REST API Practice III - Cat]]></title>
      <url>/2017/12/30/elasticsearch-6-rest-api-practice-3/</url>
      <content type="html"><![CDATA[<h2 id="III-Cat"><a href="#III-Cat" class="headerlink" title="III. Cat"></a>III. Cat</h2><h4 id="Cat-Count"><a href="#Cat-Count" class="headerlink" title="Cat Count"></a>Cat Count</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/count/change?v&quot;
</code></pre><h4 id="Cat-health"><a href="#Cat-health" class="headerlink" title="Cat health"></a>Cat health</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/health?v&quot;
</code></pre><p>查看状态是 yellow 的索引</p>
<pre><code>curl -X GET &quot;localhost:9200/_cat/indices?v&amp;health=yellow&quot;
</code></pre><p>按 count 排序</p>
<pre><code>curl -X GET &quot;localhost:9200/_cat/indices?v&amp;s=docs.count:desc&quot;
</code></pre><h4 id="Cat-Template"><a href="#Cat-Template" class="headerlink" title="Cat Template"></a>Cat Template</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/templates?v&amp;s=name&quot;
</code></pre><h4 id="Cat-Snapshot"><a href="#Cat-Snapshot" class="headerlink" title="Cat Snapshot"></a>Cat Snapshot</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/snapshots/repo1?v&amp;s=id&quot;
</code></pre><h4 id="Cat-Recovery"><a href="#Cat-Recovery" class="headerlink" title="Cat Recovery"></a>Cat Recovery</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/recovery?v&quot;
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch 6 REST API Practice II - Document]]></title>
      <url>/2017/12/29/elasticsearch-6-rest-api-practice-2/</url>
      <content type="html"><![CDATA[<h2 id="II-Document"><a href="#II-Document" class="headerlink" title="II. Document"></a>II. Document</h2><h4 id="Write"><a href="#Write" class="headerlink" title="Write"></a>Write</h4><pre><code>curl -X PUT -H &#39;Content-Type: application/json&#39; &#39;http://localhost:9200/change/change/c6673e3c3c29af5c&#39; -d &#39;
{
    &quot;id&quot;: &quot;c6673e3c3c29af5c&quot;,
    &quot;node&quot;: 140000,
    &quot;pripid&quot;: &quot;560E8C402E5914FAE0531ECDA8C0CF0D&quot;,
    &quot;date&quot;: 20180418,
    &quot;column&quot;: &quot;E_ENT_BASEINFO.OPTO&quot;,
    &quot;new_value&quot;: &quot;2027-08-01&quot;,
    &quot;old_value&quot;: &quot;&quot;,
    &quot;type&quot;: &quot;UPDATE&quot;
}&#39;
</code></pre><h4 id="Get"><a href="#Get" class="headerlink" title="Get"></a>Get</h4><pre><code>curl -X GET &#39;http://localhost:9200/change/change/c6673e3c3c29af5c&#39;
</code></pre><p>不显示索引内容</p>
<pre><code>curl -X GET &#39;http://localhost:9200/change/change/c6673e3c3c29af5c?_source=false&#39;
</code></pre><p>只显示索引内容</p>
<pre><code>curl -X GET &#39;http://localhost:9200/change/change/c6673e3c3c29af5c/_source&#39;
</code></pre><h4 id="Multi-Get"><a href="#Multi-Get" class="headerlink" title="Multi Get"></a>Multi Get</h4><pre><code>curl -X GET &quot;localhost:9200/_mget&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &quot;docs&quot; : [
        {
            &quot;_index&quot; : &quot;change&quot;,
            &quot;_type&quot; : &quot;change&quot;,
            &quot;_id&quot; : &quot;c6673e3c3c29af5c&quot;
        },
        {
            &quot;_index&quot; : &quot;change&quot;,
            &quot;_type&quot; : &quot;change&quot;,
            &quot;_id&quot; : &quot;3750ab2377453d13&quot;
        }
    ]
}
&#39;
</code></pre><pre><code>curl -X GET &quot;localhost:9200/change/_mget&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &quot;docs&quot; : [
        {
            &quot;_type&quot; : &quot;change&quot;,
            &quot;_id&quot; : &quot;c6673e3c3c29af5c&quot;
        },
        {
            &quot;_type&quot; : &quot;change&quot;,
            &quot;_id&quot; : &quot;3750ab2377453d13&quot;
        }
    ]
}
&#39;
</code></pre><pre><code>curl -X GET &quot;localhost:9200/change/change/_mget&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &quot;docs&quot; : [
        {
            &quot;_id&quot; : &quot;c6673e3c3c29af5c&quot;
        },
        {
            &quot;_id&quot; : &quot;3750ab2377453d13&quot;
        }
    ]
}
&#39;
</code></pre><pre><code>curl -X GET &quot;localhost:9200/change/change/_mget&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &quot;ids&quot;: [&quot;c6673e3c3c29af5c&quot;,&quot;3750ab2377453d13&quot;]
}&#39;
</code></pre><pre><code>curl -X GET &quot;localhost:9200/change/change/_mget&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &quot;docs&quot;:[
      {
        &quot;_id&quot;:&quot;c6673e3c3c29af5c&quot;,
        &quot;_source&quot;:[&quot;old_value&quot;,&quot;date&quot;]
      },
      {
        &quot;_id&quot;:&quot;3750ab2377453d13&quot;,
        &quot;_source&quot;:[&quot;new_value&quot;]
      }
  ]
}&#39;
</code></pre><h4 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h4><pre><code>curl -X DELETE &#39;http://localhost:9200/change/change/5c0d81efc98b8954&#39;
</code></pre><h4 id="按条件删除"><a href="#按条件删除" class="headerlink" title="按条件删除"></a>按条件删除</h4><pre><code>curl -X POST &#39;http://localhost:9200/change/change/_delete_by_query&#39; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &quot;query&quot;: { 
    &quot;match&quot;: {
      &quot;pripid&quot;: &quot;560E8C402E5914FAE0531ECDA8C0CF0D&quot;
    }
  }
}&#39;
</code></pre><h4 id="更新索引"><a href="#更新索引" class="headerlink" title="更新索引"></a>更新索引</h4><pre><code>curl -X POST &#39;http://localhost:9200/change/change/c6673e3c3c29af5c/_update&#39; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &quot;doc&quot;: {
      &quot;node&quot;: 110000
  }
}&#39;
</code></pre><h4 id="批量操作"><a href="#批量操作" class="headerlink" title="批量操作"></a>批量操作</h4><pre><code>curl -X POST &#39;http://localhost:9200/_bulk&#39; -H &#39;Content-Type: application/json&#39; -d&#39;
{ &quot;index&quot; : { &quot;_index&quot; : &quot;change&quot;, &quot;_type&quot; : &quot;change&quot;, &quot;_id&quot; : &quot;c6673e3c3c29af5c&quot; } }
{&quot;id&quot;:&quot;c6673e3c3c29af5c&quot;,&quot;node&quot;:140000,&quot;pripid&quot;:&quot;560E8C402E5914FAE0531ECDA8C0CF0D&quot;,&quot;date&quot;:20180418,&quot;column&quot;:&quot;E_ENT_BASEINFO.OPTO&quot;,&quot;new_value&quot;:&quot;2027-08-01&quot;,&quot;old_value&quot;:&quot;&quot;,&quot;type&quot;:&quot;UPDATE&quot;}
{ &quot;index&quot; : { &quot;_index&quot; : &quot;change&quot;, &quot;_type&quot; : &quot;change&quot;, &quot;_id&quot; : &quot;5c0d81efc98b8954&quot; } }
{&quot;id&quot;:&quot;5c0d81efc98b8954&quot;,&quot;node&quot;:500000,&quot;pripid&quot;:&quot;500107010100010395&quot;,&quot;date&quot;:20180418,&quot;column&quot;:&quot;E_ENT_BASEINFO.OPTO&quot;,&quot;new_value&quot;:&quot;2099-12-31&quot;,&quot;old_value&quot;:&quot;&quot;,&quot;type&quot;:&quot;UPDATE&quot;}
{ &quot;index&quot; : { &quot;_index&quot; : &quot;change&quot;, &quot;_type&quot; : &quot;change&quot;, &quot;_id&quot; : &quot;3750ab2377453d13&quot; } }
{&quot;id&quot;:&quot;3750ab2377453d13&quot;,&quot;node&quot;:500000,&quot;pripid&quot;:&quot;5001071201403190469324&quot;,&quot;date&quot;:20180418,&quot;column&quot;:&quot;E_ENT_BASEINFO.OPTO&quot;,&quot;new_value&quot;:&quot;2099-12-31&quot;,&quot;old_value&quot;:&quot;&quot;,&quot;type&quot;:&quot;UPDATE&quot;}
&#39;
</code></pre><p>每行数据都要指定 index， type 和 id 。</p>
<h4 id="重建索引"><a href="#重建索引" class="headerlink" title="重建索引"></a>重建索引</h4><pre><code>curl -X POST &#39;http://localhost:9200/_reindex&#39; -H &#39;Content-Type: application/json&#39; -d&#39;
{
  &quot;source&quot;: {
    &quot;index&quot;: &quot;change&quot;
  },
  &quot;dest&quot;: {
    &quot;index&quot;: &quot;new_change&quot;
  }
}&#39;
</code></pre><p>对部分索引重建</p>
<pre><code>curl &#39;http://localhost:9200/_reindex&#39; -H &#39;Content-Type: application/json&#39;  -d &#39;
{
  &quot;source&quot;:{
    &quot;index&quot;:&quot;change&quot;,
    &quot;type&quot;: &quot;change&quot;,
    &quot;query&quot;:{
      &quot;term&quot;:{
        &quot;node&quot;: 650000
      }
    }
  },
  &quot;dest&quot;:{
    &quot;index&quot;:&quot;change_650000&quot;
  }
}&#39;
</code></pre><p>合并为新索引</p>
<pre><code>curl &#39;http://localhost:9200/_reindex&#39; -H &#39;Content-Type: application/json&#39; -d &#39;
{
  &quot;source&quot;:{
    &quot;index&quot;:[&quot;change_650000&quot;, &quot;change_410000&quot;],
    &quot;type&quot;: [&quot;change&quot;, &quot;change&quot;]
  },
  &quot;dest&quot;:{
    &quot;index&quot;:&quot;change_410000_650000&quot;
  }
}&#39;
</code></pre><p>index 可以使用通配符。</p>
<h4 id="远程重建索引"><a href="#远程重建索引" class="headerlink" title="远程重建索引"></a>远程重建索引</h4><pre><code>curl -X POST &#39;http://localhost:9200/_reindex&#39; -d &#39;
{
  &quot;source&quot;: {
    &quot;remote&quot;: {
      &quot;host&quot;: &quot;http://otherhost:9200&quot;,
      &quot;username&quot;: &quot;user&quot;,
      &quot;password&quot;: &quot;pass&quot;
    },
    &quot;index&quot;: &quot;source&quot;,
    &quot;query&quot;: {
      &quot;match&quot;: {
        &quot;test&quot;: &quot;data&quot;
      }
    }
  },
  &quot;dest&quot;: {
    &quot;index&quot;: &quot;dest&quot;
  }
}&#39;
</code></pre><h2 id="III-检索"><a href="#III-检索" class="headerlink" title="III. 检索"></a>III. 检索</h2><p><strong>初始化数据</strong></p>
<pre><code>curl -XPUT &#39;http://localhost:9200/twitter/tweet/1&#39; -d &#39;
{
    &quot;user&quot; : &quot;kimchy&quot;,
    &quot;postDate&quot; : &quot;2009-11-15T14:12:12&quot;,
    &quot;message&quot; : &quot;trying out Elasticsearch&quot;
}&#39;

curl -XPUT &#39;http://localhost:9200/twitter/tweet/2&#39; -d &#39;
{
    &quot;user&quot; : &quot;allen&quot;,
    &quot;postDate&quot; : &quot;2010-01-25T11:02:10&quot;,
    &quot;message&quot; : &quot;using Elasticsearch&quot;
}&#39;
</code></pre><h4 id="分页"><a href="#分页" class="headerlink" title="分页"></a>分页</h4><p>分页使用的参数 from 和 size ，from 表示从第一个文档开始，默认从 0 开始，size 表示一页几条记录，默认是 10 条。</p>
<pre><code>curl &#39;192.168.207.14:29200/change/_search&#39; -d &#39;
{
    &quot;from&quot;:0,
    &quot;size&quot;:10,
    &quot;query&quot;:{
        &quot;term&quot; : {&quot;date&quot; : &quot;20170518&quot;}
    }
}&#39;
</code></pre><blockquote>
<p>和数据库分页不同，elasticsearch 的分页数量 from + size 不能超出 index.max_result_window 参数的限制（默认为 10000）。该值可在 elasticsearch 的配置文件中修改。</p>
</blockquote>
<h4 id="查询得分"><a href="#查询得分" class="headerlink" title="查询得分"></a>查询得分</h4><p>每个查询到的文档都有一个得分，查询结果可以通过得分来过滤，不过这个不常用，因为无法知道每个文档在每次查询中的具体得分。</p>
<pre><code>curl &#39;localhost:9200/twitter/_search&#39; -d &#39;
{
    &quot;min_score&quot;:0.5,
    &quot;query&quot;:{
        &quot;term&quot; : {&quot;user&quot; : &quot;kimchy&quot;}
    }
}&#39;
</code></pre><h4 id="指定返回的字段"><a href="#指定返回的字段" class="headerlink" title="指定返回的字段"></a>指定返回的字段</h4><pre><code>curl &#39;localhost:9200/twitter/_search&#39; -d &#39;
{
    &quot;fields&quot;:[&quot;user&quot;,&quot;message&quot;],
    &quot;query&quot;:{
        &quot;term&quot; : {&quot;user&quot; : &quot;kimchy&quot;}
    }
}&#39;

curl &#39;localhost:9200/twitter/_search&#39; -d &#39;
{
    &quot;query&quot;:{
        &quot;term&quot; : {&quot;user&quot; : &quot;kimchy&quot;}
    }
}&#39;
</code></pre><blockquote>
<p>如果不指定 fields ，elasticsearch 默认返回 _source 字段。</p>
</blockquote>
<h4 id="指定查询的类型"><a href="#指定查询的类型" class="headerlink" title="指定查询的类型"></a>指定查询的类型</h4><p>elasticsearch 提供了一下几种查询类型：</p>
<ul>
<li>query_and_fetch<br>1.3 以后移除</li>
<li>query_then_fetch<br>先获文档排序信息，在获取相关分片，返回结果最大为 size 取值。</li>
<li>dfs_query_and_fetch<br>1.3 以后移除</li>
<li>dfs_query_then_fetch<br>比 query_then_fetch 多了一步计算分布式词频。</li>
<li>count<br>2.0 废弃</li>
<li>scan<br>2.0 废弃<br>可在查询是指定类型<pre><code>curl &#39;localhost:9200/twitter/_search?pretty=true&amp;search_type=query_then_fetch&#39; -d &#39;{
  &quot;query&quot;:{
      &quot;term&quot; : {&quot;user&quot; : &quot;kimchy&quot;}
  }
}&#39;
</code></pre><blockquote>
<p>默认是 query_then_fetch</p>
</blockquote>
</li>
</ul>
<h4 id="指定检索执行的位置（preference）"><a href="#指定检索执行的位置（preference）" class="headerlink" title="指定检索执行的位置（preference）"></a>指定检索执行的位置（preference）</h4><p>elasticsearch 默认在分片之间随机执行，可以修改为一下方式：</p>
<ul>
<li>_primary<br>在主分片上执行。</li>
<li>_primary_first<br>优先在主分片上执行，如果主分片不可用，则在其他分片上执行。</li>
<li>_local<br>在请求发送到的节点上的分片上执行。</li>
<li>_replica<br>在副本上执行。</li>
<li>_replica_first<br>优先在副本上执行。</li>
<li>_only_node:xyz<br>在 node_id 为 xyz 的节点上执行。</li>
<li>_prefer_node:xyz<br>优先在 node_id 为 xyz 的节点上执行。</li>
<li>_shards:2,3<br>在 2 和 3 分片上执行。</li>
<li>_only_nodes<br>在子节点上执行。</li>
<li>custome<br>一个字符串值，带有相同的值的请求会在相同的节点上执行。</li>
</ul>
<pre><code>curl &#39;localhost:9200/twitter/_search?preference=_local&#39; -d &#39;{
    &quot;query&quot;:{
        &quot;term&quot; : {&quot;user&quot; : &quot;kimchy&quot;}
    }
}&#39;
</code></pre><h4 id="DSL-查询"><a href="#DSL-查询" class="headerlink" title="DSL 查询"></a>DSL 查询</h4><p>DSL （Domain Specific Language）包含两种类型的子句：</p>
<ul>
<li>Leaf query clauses<br>用特定的值查找特定的字段</li>
<li>复合子句<br>Leaf query clauses 和 复合子句的包装<h5 id="全文检索"><a href="#全文检索" class="headerlink" title="全文检索"></a>全文检索</h5><h6 id="match-all"><a href="#match-all" class="headerlink" title="match_all"></a>match_all</h6><pre><code>curl &#39;localhost:9200/twitter/_search&#39; -d &#39;{
  &quot;query&quot;:{
      &quot;match_all&quot;: { &quot;boost&quot; : 1.2 }
  }
}&#39;
</code></pre><h6 id="match"><a href="#match" class="headerlink" title="match"></a>match</h6><pre><code>curl &#39;localhost:9200/twitter/_search&#39; -d &#39;{
  &quot;query&quot;:{
      &quot;match&quot; : {
          &quot;message&quot; : &quot;Elasticsearch&quot;
      }
  }
}&#39;
</code></pre>有三种类型：</li>
<li><strong>boolean match</strong><br>默认的 match 查询类型。<pre><code>curl &#39;localhost:9200/twitter/_search&#39; -d &#39;{
  &quot;query&quot;:{
      &quot;match&quot; : {
          &quot;message&quot; : {
              &quot;query&quot; : &quot;trying Elasticsearch&quot;,
              &quot;operator&quot; : &quot;and&quot;
          }
      }
  }
}&#39;
</code></pre>operator 的取值为 or 或 and ，默认为 or 。</li>
<li><strong>match_phrase</strong><br>使用 slop 来定义查询的词之间间隔多少个词算查询匹配。<pre><code>curl &#39;localhost:9200/twitter/_search&#39; -d &#39;{
  &quot;query&quot;:{
      &quot;match_phrase&quot; : {
          &quot;message&quot; : {
              &quot;query&quot; : &quot;trying Elasticsearch&quot;,
              &quot;slop&quot; : 2
          }
      }
  }
}&#39;
</code></pre></li>
<li><strong>match_phrase_prefix</strong><br>可以将最后一个词作为前缀匹配。比 match_phrase 多了一个 max_expansions 参数，表名最后一个词可以扩展多少个前缀。<pre><code>curl &#39;localhost:9200/twitter/_search&#39; -d &#39;{
  &quot;query&quot;:{
      &quot;match_phrase_prefix&quot; : {
          &quot;message&quot; : {
              &quot;query&quot; : &quot;using E&quot;,
              &quot;max_expansions&quot;: 20
          }
      }
  }
}&#39;
</code></pre></li>
</ul>
<h5 id="term-级别查询"><a href="#term-级别查询" class="headerlink" title="term 级别查询"></a>term 级别查询</h5><h6 id="term-查询"><a href="#term-查询" class="headerlink" title="term 查询"></a>term 查询</h6><p>精确匹配给定的值。</p>
<pre><code>curl &#39;localhost:9200/twitter/_search&#39; -d &#39;{
    &quot;query&quot;:{
        &quot;term&quot; : {&quot;user&quot; : &quot;kim&quot;}
    }
}&#39;
</code></pre><blockquote>
<p>term 不会解析查询的字段，即不会对字段分词</p>
</blockquote>
<h6 id="terms-查询"><a href="#terms-查询" class="headerlink" title="terms 查询"></a>terms 查询</h6><pre><code>curl &#39;localhost:9200/twitter/_search&#39; -d &#39;{
    &quot;query&quot;:{
        &quot;terms&quot; : {
            &quot;user&quot; : [&quot;kimchy&quot;, &quot;allen&quot;]
        }
    }
}&#39;
</code></pre><h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><p>elasticsearch 使用的默认排序为得分逆序排序。</p>
<pre><code>&quot;sort&quot;:[
    {&quot;_score&quot;: &quot;desc&quot;}
]
</code></pre><p>我们可对一个或多个字段指定排序规则。</p>
<pre><code>
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch 6 REST API Practice I - Index]]></title>
      <url>/2017/12/28/elasticsearch-6-rest-api-practice-1/</url>
      <content type="html"><![CDATA[<p>[TOC]</p>
<p>学习 Elasticsearch 6.2 REST API 时，使用过的实验例子。</p>
<h2 id="I-Index"><a href="#I-Index" class="headerlink" title="I. Index"></a>I. Index</h2><h4 id="Create-Index"><a href="#Create-Index" class="headerlink" title="Create Index"></a>Create Index</h4><pre><code>curl -X PUT -H &#39;Content-Type: application/json&#39; &#39;http://localhost:9200/change&#39; -d &#39;
{
  &quot;mappings&quot;: {
    &quot;change&quot;: {
      &quot;properties&quot;: {
        &quot;date&quot;: {
          &quot;format&quot;: &quot;yyyyMMdd&quot;,
          &quot;type&quot;: &quot;date&quot;
        },
        &quot;new_value&quot;: {
          &quot;type&quot;: &quot;keyword&quot;
        },
        &quot;node&quot;: {
          &quot;type&quot;: &quot;integer&quot;
        },
        &quot;pripid&quot;: {
          &quot;type&quot;: &quot;keyword&quot;
        },
        &quot;column&quot;: {
          &quot;type&quot;: &quot;keyword&quot;
        },
        &quot;id&quot;: {
          &quot;type&quot;: &quot;keyword&quot;
        },
        &quot;old_value&quot;: {
          &quot;type&quot;: &quot;keyword&quot;
        },
        &quot;type&quot;: {
          &quot;type&quot;: &quot;keyword&quot;
        },
        &quot;apprDate&quot;: {
          &quot;format&quot;: &quot;yyyy-MM-dd&quot;,
          &quot;type&quot;: &quot;date&quot;
        }
      }
    }
  }
}&#39;
</code></pre><p>从 6.0 开始 REST API 需要指定 header 信息。</p>
<h4 id="Get-Index"><a href="#Get-Index" class="headerlink" title="Get Index"></a>Get Index</h4><pre><code>curl -X GET &#39;http://localhost:9200/change&#39;
</code></pre><h4 id="Delete-Index"><a href="#Delete-Index" class="headerlink" title="Delete Index"></a>Delete Index</h4><pre><code>curl -X DELETE &#39;http://localhost:9200/change&#39;
</code></pre><h4 id="Indices-Exists"><a href="#Indices-Exists" class="headerlink" title="Indices Exists"></a>Indices Exists</h4><pre><code>curl -I &#39;http://localhost:9200/change&#39;
</code></pre><p>存在返回 200 ，不存在返回 404 。</p>
<h4 id="Types-Exists"><a href="#Types-Exists" class="headerlink" title="Types Exists"></a>Types Exists</h4><pre><code>curl -I &#39;http://localhost:9200/change/_mapping/change&#39;
</code></pre><p>存在返回 200 ，不存在返回 404 。</p>
<h4 id="Get-Mapping"><a href="#Get-Mapping" class="headerlink" title="Get Mapping"></a>Get Mapping</h4><pre><code>curl -X GET &#39;http://localhost:9200/change/_mapping/_doc&#39;
</code></pre><h4 id="Get-Field-Mapping"><a href="#Get-Field-Mapping" class="headerlink" title="Get Field Mapping"></a>Get Field Mapping</h4><pre><code>curl -X GET &#39;http://localhost:9200/change/_mapping/field/node&#39;
</code></pre><h4 id="Delete-Mapping"><a href="#Delete-Mapping" class="headerlink" title="Delete Mapping"></a>Delete Mapping</h4><p>不提供删除 Mapping 的操作，可以删除 Index ，再重建 Mapping 。</p>
<h4 id="Update-Mapping"><a href="#Update-Mapping" class="headerlink" title="Update Mapping"></a>Update Mapping</h4><p>我们发现有一个字段 apprDate 写错了，需要新加一个 appr_date 字段。</p>
<pre><code>curl -XPUT -H &#39;Content-Type: application/json&#39; &#39;http://localhost:9200/change/_mapping/change&#39; -d &#39;
{
  &quot;properties&quot;: {
    &quot;appr_date&quot;: {
      &quot;format&quot;: &quot;yyyy-MM-dd&quot;,
      &quot;type&quot;: &quot;date&quot;
    }
  }
}&#39;
</code></pre><h4 id="Add-Index-Alias"><a href="#Add-Index-Alias" class="headerlink" title="Add Index Alias"></a>Add Index Alias</h4><pre><code>curl -X POST &quot;http://localhost:9200/_aliases&quot; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &quot;actions&quot; : [
        { &quot;add&quot; : { &quot;index&quot; : &quot;change&quot;, &quot;alias&quot; : &quot;CHANGE&quot; } }
    ]
}&#39;
</code></pre><h4 id="Remove-Index-Alias"><a href="#Remove-Index-Alias" class="headerlink" title="Remove Index Alias"></a>Remove Index Alias</h4><pre><code>curl -X POST &#39;http://localhost:9200/_aliases&#39; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &quot;actions&quot; : [
        { &quot;remove&quot; : { &quot;index&quot; : &quot;change&quot;, &quot;alias&quot; : &quot;CHANGE&quot; } }
    ]
}&#39;
</code></pre><h4 id="Rename-Index-Alias"><a href="#Rename-Index-Alias" class="headerlink" title="Rename Index Alias"></a>Rename Index Alias</h4><pre><code>curl -X POST &#39;http://localhost:9200/_aliases&#39; -H &#39;Content-Type: application/json&#39; -d&#39;
{
    &quot;actions&quot; : [
        { &quot;remove&quot; : { &quot;index&quot; : &quot;change&quot;, &quot;alias&quot; : &quot;CHANGE&quot; } },
        { &quot;add&quot; : { &quot;index&quot; : &quot;change&quot;, &quot;alias&quot; : &quot;CHANGE1&quot; } }
    ]
}&#39;
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[spark-properties]]></title>
      <url>/2017/12/26/spark-properties/</url>
      <content type="html"><![CDATA[<h3 id="Application-Properties"><a href="#Application-Properties" class="headerlink" title="Application Properties"></a>Application Properties</h3><table class="table table-bordered table-striped table-condensed"><tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr><tr><td><code>spark.app.name</code></td><td>(none)</td><td> 应用程序名称，会在 UI 和日志中显示。</td></tr><tr><td><code>spark.driver.cores</code></td><td>1</td><td>驱动程序使用的核心数量，只在集群模式下有效。</td></tr><tr><td><code>spark.driver.maxResultSize</code></td><td>1g</td><td>限制每个 Spark action 所有分区序列化结果的大小。最小设置为 1 M，0 为不限制。如果超出限制，作业会终止。该值设置过大，会导致内存溢出。</td></tr><tr><td><code>spark.driver.memory</code></td><td>1g</td><td>SparkContext 初始化时驱动程序使用的内存总和 (e.g.<code>1g</code>, <code>2g</code>)。注意： 在 client 模式下，该设置不能通过配置 <code>SparkConf</code> 生效，因为启动程序的 JVM 已经启动了。可以通过<code>–driver-memory</code>命令行选项或在默认配置文件中设置。</td></tr><tr><td><code>spark.executor.memory</code></td><td>1g</td><td>每个 executor 使用的内存总和。 (e.g. <code>2g</code>, <code>8g</code>)</td></tr><tr><td><code>spark.extraListeners</code></td><td>(none)</td><td>可以设置多个实现<code>SparkListener</code>接口的类，用逗号分隔。SparkContext 初始化时，这些类的实例会被创建并注册到 Spark 的监听总线。创建时会调用只接收 SparkConf 为参数的构造函数或无参数的构造函数，如果没有合适的构造函数，SparkContext 会创建失败并抛出异常。</td></tr><tr><td><code>spark.local.dir</code></td><td>/tmp</td><td>Spark 的  “scratch” 空间路径, 用于存放 map 的输出文件和数据集。这个路径应该是一个系统本地路径，也可以是多个磁盘上的路径。    注意：从 Spark 1.0 开始，该参数会被  SPARK_LOCAL_DIRS (Standalone, Mesos)  或 LOCAL_DIRS (YARN) 覆盖。</td></tr><tr><td><code>spark.logConf</code></td><td>false</td><td>SparkContext 启动时，记录有效的 SparkConf 的 INFO 信息。</td></tr><tr><td><code>spark.master</code></td><td>(none)</td><td>集群管理节点地址。<a href="https://spark.apache.org/docs/2.1.1/submitting-applications.html#master-urls" target="_blank" rel="external">allowed master URL’s</a></td></tr><tr><td><code>spark.submit.deployMode</code></td><td>(none)</td><td>Spark 驱动程序的部署模式。”client” 驱动程序在本地启动，”cluster” 启动程序在集群中的某个节点上启动。</td></tr></table>

<h3 id="Runtime-Environment"><a href="#Runtime-Environment" class="headerlink" title="Runtime Environment"></a>Runtime Environment</h3><table class="table table-bordered table-striped table-condensed"><tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr><tr><td><code>spark.driver.extraClassPath</code></td><td>(none)</td><td>启动程序 classpath 的预加载扩展 classpath 路径。<br>注意：在 client 模式下，不能通过<code>SparkConf</code>设置，应使用<code>–driver-class-path</code>命令行选项或默认配置文件设置。</td></tr><tr><td><code>spark.driver.extraJavaOptions</code></td><td>(none)</td><td>额外的 JVM 选项，比如 GC 或日志。<br>注意：最大堆大内存（-Xmx） 不能通过该项设置。集群模式下，最大堆内存使用<code>spark.driver.memory</code>设置，client 模式下使用<code>–driver-memory</code>命令行选项设置。<br>注意：在 client 模式下，该项不能在<code>SparkConf</code>设置，应通过<code>–driver-java-options</code>命令行选项或默认配置文件设置。</td></tr><tr><td><code>spark.driver.extraLibraryPath</code></td><td>(none)</td><td>启动驱动程序 JVM 时设置一个特殊的库路径。<br>注意：在 client 模式下，该项不能在<code>SparkConf</code>设置，应通过<code>–driver-library-path</code>命令行选项或默认配置文件设置。</td></tr><tr><td><code>spark.driver.userClassPathFirst</code></td><td>false</td><td>（实验）是否设置用户的 jar 优先于 Spark 的 jar 。该特性用于解决 Spark 依赖和用户依赖之间的冲突。这个特性还在实验中，只在集群模式下生效。</td></tr><tr><td><code>spark.executor.extraClassPath</code></td><td>(none)</td><td>预设额外的类路径条目，这个属性主要是为了先后兼容老的 Spark 版本，用户通常不需要设置。</td></tr><tr><td><code>spark.executor.extraJavaOptions</code></td><td>(none)</td><td>向 executor 传递一个额外的 JVM 选项，比如 GC 或日志。<br>注意：该项不能设置 Spark Properties 或最大堆大小（-Xmx）。Spark properties 应使用 SparkConf 对象或 spark-defaults.conf 来设置。最大堆内存应通过 <code> spark.executor.memory</code>设置。</td></tr><tr><td><code>spark.executor.extraLibraryPath</code></td><td>(none)</td><td>executor JVM 启动时设置一个特殊库路径。</td></tr><tr><td><code>spark.executor.logs.rolling.maxRetainedFiles</code></td><td>(none)</td><td>设置系统保存的最新日志滚动数量，老的日志文件将被删除。默认禁用。</td></tr><tr><td><code>spark.executor.logs.rolling.enableCompression</code></td><td>false</td><td>启用日志压缩。如果启动，滚动的日志将被压缩。默认禁用。</td></tr><tr><td><code>spark.executor.logs.rolling.maxSize</code></td><td>(none)</td><td>设置日志文件滚动的字节数组最大长度。默认禁用。参考 <code>spark.executor.logs.rolling.maxRetainedFiles</code> 清除旧日志文件。</td></tr><tr><td><code>spark.executor.logs.rolling.strategy</code></td><td>(none)</td><td>设置日志滚动策略。默认禁用，可以基于“时间”滚动或按照“大小”滚动。基于“时间”，使用<code>spark.executor.logs.rolling.time.interval</code>设置滚动频率。按照“大小”，使用<code>spark.executor.logs.rolling.maxSize</code>设置最大滚动文件大小。</td></tr><tr><td><code>spark.executor.logs.rolling.time.interval</code></td><td>daily</td><td>设置日志滚动的时间间隔。默认不滚动。可以设置的值包括<code>daily</code>, <code>hourly</code>, <code>minutely</code> 或任意秒数。参考<code>spark.executor.logs.rolling.maxRetainedFiles</code>自动清除旧的日志。</td></tr><tr><td><code>spark.executor.userClassPathFirst</code></td><td>false</td><td>（实验）和<code>spark.driver.userClassPathFirst</code>功能相同，但是是作用在 executor 实例。</td></tr><tr><td><code>spark.executorEnv.[EnvironmentVariableName]</code></td><td>(none)</td><td>通过指定<code>EnvironmentVariableName</code>添加 executor 的环境变量，可以设置多个值。</td></tr><tr><td><code>spark.python.profile</code></td><td>false</td><td>在 python 的 worker 节点上启动 profile 。profile 的结果通过<code>sc.show_profiles()</code>显示或在启动程序退出前显示。通过<code>sc.dump_profiles(path)</code>设置磁盘的路径。如果 profile 结果被手动隐藏，那么在驱动程序退出时不显示。默认<code>pyspark.profiler.BasicProfiler</code> 启用，但是可以给 SparkContext 构造函数传一个 profiler 类参数覆盖该值。</td></tr><tr><td><code>spark.files</code></td><td></td><td>每个 executor 的工作目录列表，用逗号分隔。</td></tr><tr><td><code>spark.jars</code></td><td></td><td>设置驱动程序和 executor 类路径包含的本地 jar，用逗号分隔。 </td></tr><tr><td><code>spark.jars.packages</code></td><td></td><td>驱动程序和 executor 类路径包含的 jar 包的 maven 坐标。按照本地 maven 仓库，maven 中心库和<code>spark.jars.ivy</code>指定的附加远程仓库顺序查找。格式为：groupId:artifactId:version</td></tr><tr><td><code>spark.jars.excludes</code></td><td></td><td>排除<code>spark.jars.packages</code>提供的 jar 以避免冲突。</td></tr><tr><td><code>spark.jars.ivy</code></td><td></td><td>查找附加远程仓库<code>spark.jars.packages</code>指定的坐标，用逗号分隔。</td></tr></table>

<h3 id="Shuffle-Behavior"><a href="#Shuffle-Behavior" class="headerlink" title="Shuffle Behavior"></a>Shuffle Behavior</h3><table class="table table-bordered table-striped table-condensed"><tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr><tr><td><code>spark.reducer.maxSizeInFlight</code></td><td>48m</td><td>同时从每个 reduce 任务获取的 map 最大值。每个输出都需要创建缓冲区来接收，所以每个 reduce 任务都有固定的内存开销，因此应设置一个较小的值。</td></tr><tr><td><code>spark.reducer.maxReqsInFlight</code></td><td>Int.MaxValue</td><td>该选项限制任意给定的点接收远程请求的数量。但集群主机的数量增加，可能会有大量的请求连接到一个或多个节点，导致 worker 节点负载过大而出错。限制请求的数量可以避免出现此种问题。</td></tr><tr><td><code>spark.shuffle.compress</code></td><td>true</td><td>是否压缩 map 的输出文件。一般来说使用压缩是的好办法。压缩将使用<code>spark.io.compression.codec</code>属性。</td></tr><tr><td><code>spark.shuffle.file.buffer</code></td><td>32k</td><td>每个 shuffle 文件流的缓冲区大小。缓冲区会降低创建中间 shuffle 文件时的磁盘寻址和系统调用次数。</td></tr><tr><td><code>spark.shuffle.io.maxRetries</code></td><td>3</td><td>（Netty only）抓取到 IO 相关异常错误自动重试。重试使 shuffle 在遇到长时间 GC 暂停或短时间的网络异常更稳定。</td></tr><tr><td><code>spark.shuffle.io.numConnectionsPerPeer</code></td><td>1</td><td>（Netty only）在大规模集群中为了减少连接创建，主机之间的连接被重用。对于集群中有大量的硬盘少量的主机导致并发不足时，用户可以调大该值。</td></tr><tr><td><code>spark.shuffle.io.preferDirectBufs</code></td><td>true</td><td>（Netty only）在 shuffle 和缓存交换过程中，使用堆缓冲区来减少 GC 。对于堆缓冲区内存有限的环境，用户可能希望关闭这个功能，使所有分配都从 Netty 移到堆中。</td></tr><tr><td><code>spark.shuffle.io.retryWait</code></td><td>5s</td><td>（Netty only）每次抓取重试等待时间。默认最大延迟 15 秒<code>maxRetries * retryWait</code>。</td></tr><tr><td><code>spark.shuffle.service.enabled</code></td><td>false</td><td>应用额外的 shuffle 服务。该服务保存 executor 生成的 shuffle 文件，以保证 executor 被安全删除。如果<code>spark.dynamicAllocation.enabled</code>为 true，则该值必须设置为 true 。</td></tr><tr><td><code>spark.shuffle.service.port</code></td><td>7337</td><td>运行额外 shuffle 服务的端口号。</td></tr><tr><td><code>spark.shuffle.service.index.cache.entries</code></td><td>1024</td><td>shuffle 服务的缓存索引中保存的最大条目数量。</td></tr><tr><td><code>spark.shuffle.sort.bypassMergeThreshold</code></td><td>200</td><td>（高级）在基于排序的 shuffle 管理器中，如果没有 map 端的聚合，应避免合并排序数据并减少分区数量。</td></tr><tr><td><code>spark.shuffle.spill.compress</code></td><td>true</td><td>是否压缩 shuffle 过程中的溢出数据。压缩使用<code>spark.io.compression.codec</code>属性。</td></tr><tr><td><code>spark.io.encryption.enabled</code></td><td>false</td><td>使用 IO 加密。除 Mesos 外，其他模式都支持。使用该特性使建议使用 RPC 加密。</td></tr><tr><td><code>spark.io.encryption.keySizeBits</code></td><td>128</td><td>IO 加密的密钥大小。128，192，256 可选。</td></tr><tr><td><code>spark.io.encryption.keygen.algorithm</code></td><td>HmacSHA1</td><td>生成 IO 加密密钥的算法。支持的算法见Java密码体系结构标准算法名称文档的 KeyGenerator 部分。</td></tr></table>

<h3 id="Spark-UI"><a href="#Spark-UI" class="headerlink" title="Spark UI"></a>Spark UI</h3><table class="table table-bordered table-striped table-condensed"><tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr><tr><td><code>spark.eventLog.compress</code></td><td>false</td><td>如果<code>spark.eventLog.enabled</code>为 true ，是否使用压缩。</td></tr><tr><td><code>spark.eventLog.dir</code></td><td>file:///tmp/spark-events</td><td>如果<code>spark.eventLog.enabled</code>为 true ，设置路径为 Spark 事件日志的根目录。在这个目录下，Spark 为每个应用程序创建一个子路径，记录特殊的事件。用户可以将其设置为一个统一的路径，如 HDFS 上的路径，以便历史可读。</td></tr><tr><td><code>spark.eventLog.enabled</code></td><td>false</td><td>是否记录 Spark 事件日志，程序结束后重现 Web UI 很有用。</td></tr><tr><td><code>spark.ui.enabled</code></td><td>true</td><td>是否运行 web UI 程序。</td></tr><tr><td><code>spark.ui.killEnabled</code></td><td>true</td><td>允许通过 UI 杀掉任务。</td></tr><tr><td><code>spark.ui.port</code></td><td>4040</td><td>应用程序面板端口号。</td></tr><tr><td><code>spark.ui.retainedJobs</code></td><td>1000</td><td>GC 之前 Spark UI 和状态 api 能记录多少作业。</td></tr><tr><td><code>spark.ui.retainedStages</code></td><td>1000</td><td>GC 之前 Spark UI 和状态 api 能记录多少阶段。</td></tr><tr><td><code>spark.ui.retainedTasks</code></td><td>100000</td><td>GC 之前 Spark UI 和状态 api 能记录多少任务。</td></tr><tr><td><code>spark.ui.reverseProxy</code></td><td>false</td><td> Spark 主节点作为 worker 节点和 UI 的反向代理。Spark 主节点不需要访问主机就可以反向代理 worker 节点和 UI 。需要注意的是，worker 节点和 UI 不需要访问路径，只能通过主节点或代理访问。该设置影像所有的 wroker 节点和 UI ，必须在所有的 worker 节点，驱动程序和主节点上设置。</td></tr><tr><td><code>spark.ui.reverseProxyUrl</code></td><td></td><td>代理的 URL 。应包括 （http/https）和端口。</td></tr><tr><td><code>spark.worker.ui.retainedExecutors</code></td><td>1000</td><td>GC 之前 Spark UI 和状态 api 能记录多少完成的 executor 。</td></tr><tr><td><code>spark.worker.ui.retainedDrivers</code></td><td>1000</td><td>GC 之前 Spark UI 和状态 api 能记录多少完成的驱动程序。</td></tr><tr><td><code>spark.sql.ui.retainedExecutions</code></td><td>1000</td><td>GC 之前 Spark UI 和状态 api 能记录多少完成的 execution 。</td></tr><tr><td><code>spark.streaming.ui.retainedBatches</code></td><td>1000</td><td>GC 之前 Spark UI 和状态 api 能记录多少完成的 batch 。</td></tr><tr><td><code>spark.ui.retainedDeadExecutors</code></td><td>100</td><td>GC 之前 Spark UI 和状态 api 能记录多少死亡的 executor 。</td></tr></table>

<h3 id="Compression-and-Serialization"><a href="#Compression-and-Serialization" class="headerlink" title="Compression and Serialization"></a>Compression and Serialization</h3><table class="table table-bordered table-striped table-condensed"><tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr><tr><td><code>spark.broadcast.compress</code></td><td>true</td><td>是否在发送广播变量之前压缩</td></tr><tr><td><code>spark.io.compression.codec</code></td><td>lz4</td><td>用来压缩 RDD 分区、广播变量、shuffle 输出等内部数据的解码器。Spark 默认提供三种解码器：<code>lz4</code>, <code>lzf</code>, <code>snappy</code>。也可以使用完全类名来指定解码器，比如<code>org.apache.spark.io.LZ4CompressionCodec</code>,<code>org.apache.spark.io.LZFCompressionCodec</code>, <code>org.apache.spark.io.SnappyCompressionCodec</code>。</td></tr><tr><td><code>spark.io.compression.lz4.blockSize</code></td><td>32k</td><td>LZ4 压缩的块大小。块大小越小，shuffle 使用的内存越小。</td></tr><tr><td><code>spark.io.compression.snappy.blockSize</code></td><td>32k</td><td>Snappy 压缩的块大小。块大小越小，shuffle 使用的内存越小。</td></tr><tr><td><code>spark.kryo.classesToRegister</code></td><td>(none)</td><td>通过逗号分隔列表指定在 Kryo 中注册的类的名字。</td></tr><tr><td><code>spark.kryo.referenceTracking</code></td><td>true</td><td>在使用 Kryo 序列化数据时，是否跟踪相同对象的引用。如果对象图包含循环的话，这是必要的。如果没有，可以禁用来提高性能。</td></tr><tr><td><code>spark.kryo.registrationRequired</code></td><td>false</td><td>是否需要在 Kryo 注册。如果设置为 ‘true’，未注册的类在序列化时，Kryo 会抛出异常。如果设置为 ‘false’ ，Kryo 会将未注册的类名写到每一个对象，这个会造成巨大的性能开销，所以应保证序列化的类在 Kryo 中注册。</td></tr><tr><td><code>spark.kryo.registrator</code></td><td>(none)</td><td>通过逗号分隔的列表指定在 Kryo 中注册的类名。这在通过自定义方式注册类时很有用，否则使用<code>spark.kryo.classesToRegister</code>更简单。</td></tr><tr><td><code>spark.kryo.unsafe</code></td><td>false</td><td>是否使用不安全的 Kryo 序列化器。使用不安全的 IO 能极大提高性能。</td></tr><tr><td><code>spark.kryoserializer.buffer.max</code></td><td>64m</td><td>Kryo 序列化缓冲区允许的最大值。这个大小应大于任何想序列化的对象的大小。如果出现 “buffer limit exceeded” 异常，则调大该值。</td></tr><tr><td><code>spark.kryoserializer.buffer</code></td><td>64k</td><td>Kryo 序列化缓冲区的初始大小。注意：每个 worker 节点的每一个 core 都有一个缓冲区。<code>spark.kryoserializer.buffer.max</code>可以修改缓冲区的大小。</td></tr><tr><td><code>spark.rdd.compress</code></td><td>false</td><td>是否压缩 RDD 分区。可以节约大量的空间和额外的 CPU 时间。</td></tr><tr><td><code>spark.serializer</code></td><td>org.apache.spark.serializer.JavaSerializer</td><td>用来序列化对象的序列化器。默认的 Java 序列化器可以用于任何 Java 序列化对象，但是性能不高。对性能有要求时推荐使用<code>org.apache.spark.serializer.KryoSerializer</code>。</td></tr><tr><td><code>spark.serializer.objectStreamReset</code></td><td>100</td><td>使用 <code>org.apache.spark.serializer.JavaSerializer</code>时, 序列化器缓存对象会防止多余数据写入会导致这些对象不会被 GC 。通过调用 ‘reset’ 可以刷新序列化器信息，允许旧对象被回收。 默认情况下，每序列化 100 个对象会刷新一次，设置 -1  可以关闭刷新。</td></tr></table>

<h3 id="Memory-Management"><a href="#Memory-Management" class="headerlink" title="Memory Management"></a>Memory Management</h3><table class="table table-bordered table-striped table-condensed"><tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr><tr><td><code>spark.memory.fraction</code></td><td>0.6</td><td>执行和存储的内存比例（堆内存-300M）。比例越小，缓存数据回收和泄露越频繁。建议使用默认值。</td></tr><tr><td><code>spark.memory.storageFraction</code></td><td>0.5</td><td>存储内存的比例。值越高，执行可用的内存越少，数据写到磁盘的频率越高。建议使用默认值。</td></tr><tr><td><code>spark.memory.offHeap.enabled</code></td><td>false</td><td>是否使用非堆内存。</td></tr><tr><td><code>spark.memory.offHeap.size</code></td><td>0</td><td>用于分配非堆内存的内存绝对值。该值对对内存的使用没有影响，如果想将执行的内存消耗限制在一定范围，应减小 JVM 的对内存大小。<code>spark.memory.offHeap.enabled=true</code>时，该值必须设置。</td></tr><tr><td><code>spark.memory.useLegacyMode</code></td><td>false</td><td>是否使用 spark 1.5 及以前的 legacy memory management 模式。​legacy 模式将对内存分为固定大小的分区，如果没有调优，可能会导致大量的泄露。</td></tr><tr><td><code>spark.shuffle.memoryFraction</code></td><td>0.2</td><td>废弃的。This is read only if <code>spark.memory.useLegacyMode</code> is enabled. Fraction of Java heap to use for aggregation and cogroups during shuffles. At any given time, the collective size of all in-memory maps used for shuffles is bounded by this limit, beyond which the contents will begin to spill to disk. If spills are often, consider increasing this value at the expense of <code>spark.storage.memoryFraction</code>.</td></tr><tr><td><code>spark.storage.memoryFraction</code></td><td>0.6</td><td>废弃的。This is read only if <code>spark.memory.useLegacyMode</code> is enabled. Fraction of Java heap to use for Spark’s memory cache. This should not be larger than the “old” generation of objects in the JVM,which by default is given 0.6 of the heap, but you can increase it if you configure your own old generation size.</td></tr><tr><td><code>spark.storage.unrollFraction</code></td><td>0.2</td><td>(deprecated) This is read only if <code>spark.memory.useLegacyMode</code> is enabled. Fraction of <code>spark.storage.memoryFraction</code>to use for unrolling blocks in memory. This is dynamically allocated by dropping existing blocks when there is not enough free storage space to unroll the new block in its entirety.</td></tr></table>

<h3 id="Execution-Behavior"><a href="#Execution-Behavior" class="headerlink" title="Execution Behavior"></a>Execution Behavior</h3><table class="table table-bordered table-striped table-condensed"><tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr><tr><td><code>spark.broadcast.blockSize</code></td><td>4m</td><td><code>TorrentBroadcastFactory</code>每个块的大小。太大会降低并行度，使程序执行变慢。太小会影响<code>BlockManager</code>的性能。</td></tr><tr><td><code>spark.executor.cores</code></td><td>YARN 模式下是 1 ,standalone 和 Mesos 模式下为所有可用核心数量。</td><td>每个 executor 可以使用的核心数量。如果 worker 节点有充足的核心， 在 standalone 和 Mesos 模式下允许应用在同一个 worker 节点运行多个 executor 。否则一个 worker 节点只能运行一个 executor 。</td></tr><tr><td><code>spark.default.parallelism</code></td><td>父 RDD 最大分区数量，比如 <code>reduceByKey</code> and <code>join</code> 这样的分布式 shuffle 操作。没有父 RDD 的并且操作，依赖于集群管理器：<ul><li>Local mode: 本地集器的核心数</li><li>Mesos fine grained mode: 8</li><li>Others: executor 所有核心数和 2 的较大值</li></ul></td><td>转换操作返回的 RDD 分区数量，比如 <code>join</code>，<code>reduceByKey</code> 和 <code>parallelize</code>。</td></tr><tr><td><code>spark.executor.heartbeatInterval</code></td><td>10s</td><td>executor 和驱动程序之间心跳时间间隔。心跳可以让驱动程序知道哪些 executor 活着，更新正在执行的任务信息。<code>spark.executor.heartbeatInterval</code>应小于<code>spark.network.timeout</code>。</td></tr><tr><td><code>spark.files.fetchTimeout</code></td><td>60s</td><td>使用<code>SparkContext.addFile()</code>从驱动程序获取文件的超时时间。</td></tr><tr><td><code>spark.files.useFetchCache</code></td><td>true</td><td>如果设置为 true ，获取文件将使用本地缓存。本地缓存和同一个程序的 executor 是共享的，这样可以在相同主机同时运行多个 executor 时，任务启动更快。如果设置为 false，executor 会获取各自的文件副本。为了使用 NFS 文件系统的 Spark 本地目录，可以禁用该项。</td></tr><tr><td><code>spark.files.overwrite</code></td><td>false</td><td>通过<code>SparkContext.addFile()</code>获取文件，如果文件存在并且内容不一致时是否覆盖。</td></tr><tr><td><code>spark.files.maxPartitionBytes</code></td><td>134217728 (128 MB)</td><td>读文件时单个分区打包的最大字节数。</td></tr><tr><td><code>spark.files.openCostInBytes</code></td><td>4194304 (4 MB)</td><td>预估打开文件的成本，同时读取文件的字节数量。一个分区放置多个文件时使用。超过 4MB ，小文件的分区会比大文件的快。</td></tr><tr><td><code>spark.hadoop.cloneConf</code></td><td>false</td><td>如果设置为 true ，会为每一个任务克隆新的 Hadoop <code>Configuration</code> 对象。</td></tr><tr><td><code>spark.hadoop.validateOutputSpecs</code></td><td>true</td><td>如果设置为 true ，校验在使用 saveAsHadoopFile 或其他动作时的输出规范，如校验目录是否存在。除非要兼容 Spark 以前的版本，否则不推荐禁用该项。对于使用 spark streming 的 StreamingContext 创建作业，在检查恢复时，数据需要被重写到已存在的目录，该项会被忽略。</td></tr><tr><td><code>spark.storage.memoryMapThreshold</code></td><td>2m</td><td>从磁盘读取块时映射到 Spark 内存的块的大小。这可以防止映射到很小的块。通常，在操作系统关闭块和降低页大小时内存映射开销很大。</td></tr></table>

<h3 id="Networking"><a href="#Networking" class="headerlink" title="Networking"></a>Networking</h3><table class="table table-bordered table-striped table-condensed"><tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr><tr><td><code>spark.rpc.message.maxSize</code></td><td>128</td><td>executor 和驱动程序之间发送消息的最大大小。如果运行的作业包含几千个 map 和 reduce 任务，可以调大该值。</td></tr><tr><td><code>spark.blockManager.port</code></td><td>(random)</td><td>executor 和驱动程序上所有块管理器被监听的接口。</td></tr><tr><td><code>spark.driver.blockManager.port</code></td><td>(value of spark.blockManager.port)</td><td>块管理器的指定驱动程序监听端口，不能使用和 executor 相同的配置。</td></tr><tr><td><code>spark.driver.bindAddress</code></td><td>(value of spark.driver.host)</td><td>主机名或 IP 地址用于绑定 socket 。该配置会覆盖环境变量<code>SPARK_LOCAL_IP</code>。允许设置不同的地址从本地到 executor 或 外部系统。为了能够正常工作，驱动程序使用的不同的接口需要从容器主机转发。</td></tr><tr><td><code>spark.driver.host</code></td><td>(local hostname)</td><td>驱动程序的主机名或 IP 地址。用于 executor 和 standalone 主节点之间的通信。</td></tr><tr><td><code>spark.driver.port</code></td><td>(random)</td><td>驱动程序的端口。用于 executor 和 standalone 主节点之间的通信。</td></tr><tr><td><code>spark.network.timeout</code></td><td>120s</td><td>网络默认超时时间。如果<code>spark.core.connection.ack.wait.timeout</code>,<code>spark.storage.blockManagerSlaveTimeoutMs</code>, <code>spark.shuffle.io.connectionTimeout</code>,<code>spark.rpc.askTimeout</code> or <code>spark.rpc.lookupTimeout</code>没有配置，可以用该项代替。</td></tr><tr><td><code>spark.port.maxRetries</code></td><td>16</td><td>放弃端口前最大重试次数。给一个端口指定一个非 0 值，每次重试会将原来的值 +1 。从开始端口到从端口号加最大重试次数范围的端口号都会尝试。</td></tr><tr><td><code>spark.rpc.numRetries</code></td><td>3</td><td>RPC 任务放弃前重试次数。</td></tr><tr><td><code>spark.rpc.retry.wait</code></td><td>3s</td><td>RPC 询问重试的间隔时间。</td></tr><tr><td><code>spark.rpc.askTimeout</code></td><td><code>spark.network.timeout</code></td><td>RPC 询问超时时间。</td></tr><tr><td><code>spark.rpc.lookupTimeout</code></td><td>120s</td><td>RPC 寻找远程断点的超时时间。</td></tr></table>

<h3 id="Scheduling"><a href="#Scheduling" class="headerlink" title="Scheduling"></a>Scheduling</h3><table class="table table-bordered table-striped table-condensed"><br><tr><th>Property Name</th><th>Default</th><th>Meaning</th><br></tr><tr><td><code>spark.cores.max</code></td><td>(not set)</td><br><td>在 standalone 模式和 Mesos 粗粒度模式下，程序请求的 CPU 最大核心总数（不是每个机器的核心数量）。不设置该值，standalone 模式默认为<code>spark.deploy.defaultCores</code>的值，Mesos 默认是所有可用核心数。<br></td></tr><tr><td><code>spark.locality.wait</code></td><td>3s</td><br><td>放弃启动数据在本地的任务并启动一个非本地节点任务的等待时间。这和跳过多个本地级别（process-local, node-local, rack-local 等）的是相同的。<br>通过设置<code>spark.locality.wait.node</code>可以自定义每个级别的等待时间。默认时间通常可以正常工作，如果你的任务很长且不在本地执行，可以增大该值。<br></td></tr><tr><td><code>spark.locality.wait.node</code></td><td>spark.locality.wait</td><br><td>自定义本地节点的位置。例如，设置 0 以跳过本地节点并立刻搜索机架位置。</td></tr><tr><td><code>spark.locality.wait.process</code></td><td>spark.locality.wait</td><br><td>自定义本地进程的位置。会影响特殊的 executor 进程中试图访问缓存数据的任务。<br></td></tr><tr><td><code>spark.locality.wait.rack</code></td><td>spark.locality.wait</td><br><td>自定义本地机架的位置。</td></tr><tr><td><code>spark.scheduler.maxRegisteredResourcesWaitingTime</code></td><br><td>30s</td><td>调度开始前等待资源注册的最大时间。</td></tr><tr><br><td><code>spark.scheduler.minRegisteredResourcesRatio</code></td><br><td>YARN 模式为 0.8，standalone 模式和 Mesos 粗粒度模式为 0.0</td><br><td>调度开始前等待资源注册最小比例（注册的资源/期望注册的所有资源）。指定 0.0 到 1.0 之间的浮点数。不管是否到达设定值，最大等待时间是通过<code>spark.scheduler.maxRegisteredResourcesWaitingTime</code>控制的。<br></td></tr><tr><td><code>spark.scheduler.mode</code></td><br><td>FIFO</td><td>任务提交到相同的 SparkContext 的模式。多用户使用时可以设置<code>FAIR</code>来公平共享模式来代替 FIFO 。<br></td></tr><tr><td><code>spark.scheduler.revive.interval</code></td><br><td>1s</td><td>调度器恢复 worker 节点资源用来运行任务的时间。<br></td></tr><tr><td><code>spark.blacklist.enabled</code></td><td>false</td><br><td>如果设置为 true ，防止 Spark 从任务失败次数过多被加入黑名单的 executor 上调度任务。黑名单算法通过<code>spark.blacklist</code>配置项决定。<br></td></tr><tr><td><code>spark.blacklist.task.maxTaskAttemptsPerExecutor</code></td><td>1</td><br><td>（实验性）对于一个任务，executor 被加入黑名单前 executor 上的重试次数。<br></td></tr><tr><td><code>spark.blacklist.task.maxTaskAttemptsPerNode</code></td><td>2</td><br><td>（实验性）对于一个任务，节点被加入黑名单前节点上的重试次数。<br></td></tr><tr><td><code>spark.blacklist.stage.maxFailedTasksPerExecutor</code></td><br><td>2</td><br><td>（实验性）被加入黑名单前有多少个不同的任务在同一个阶段同一个 executor 上失败。<br></td></tr><tr><td><code>spark.blacklist.stage.maxFailedExecutorsPerNode</code></td><br><td>2</td><br><td>（实验性）在整个节点被标记为失败前有多少个不同的 executor 被加入黑名单。<br></td></tr><br><tr><td><code>spark.speculation</code></td><br><td>false</td><br><td>如果设置为 true ，执行任务执行情况推测。意味着如果一个阶段的一个或多个任务运行过慢，被重新启动。<br></td><br></tr><br><tr><br><td><code>spark.speculation.interval</code></td><br><td>100ms</td><br><td>多久检查一次任务执行预估。<br></td><br></tr><br><tr><br><td><code>spark.speculation.multiplier</code></td><br><td>1.5</td><br><td>任务执行速度比预估的中位数慢多少倍。<br></td><br></tr><br><tr><br><td><code>spark.speculation.quantile</code></td><br><td>0.75</td><br><td>执行任务预估前必须完成的任务比例。<br></td><br></tr><br><tr><br><td><code>spark.task.cpus</code></td><br><td>1</td><br><td>每个任务分配的核心数。<br></td><br></tr><br><tr><br><td><code>spark.task.maxFailures</code></td><br><td>4</td><br><td>一个具体的任务允许失败的次数。不同任务的失败总数不会导致作业失败。应该设置大于等于 1 ，允许重试次数比该值少 1 。</td><br></tr><br><tr><br><td><code>spark.task.reaper.enabled</code></td><br><td>false</td><br><td><br>Enables monitoring of killed / interrupted tasks. When set to true, any task which is killed will be<br>monitored by the executor until that task actually finishes executing. See the other <code>spark.task.reaper.*</code><br>configurations for details on how to control the exact behavior of this monitoring. When set to false (the<br>default), task killing will use an older code path which lacks such monitoring.<br></td><br></tr><br><tr><br><td><code>spark.task.reaper.pollingInterval</code></td><br><td>10s</td><br><td><br>When <code>spark.task.reaper.enabled = true</code>, this setting controls the frequency at which executors<br>will poll the status of killed tasks. If a killed task is still running when polled then a warning will be<br>logged and, by default, a thread-dump of the task will be logged (this thread dump can be disabled via the<br><code>spark.task.reaper.threadDump</code> setting, which is documented below).<br></td><br></tr><br><tr><br><td><code>spark.task.reaper.threadDump</code></td><br><td>true</td><br><td><br>When <code>spark.task.reaper.enabled = true</code>, this setting controls whether task thread dumps are<br>logged during periodic polling of killed tasks. Set this to false to disable collection of thread dumps.<br></td><br></tr><br><tr><br><td><code>spark.task.reaper.killTimeout</code></td><br><td>-1</td><br><td><br>When <code>spark.task.reaper.enabled = true</code>, this setting specifies a timeout after which the<br>executor JVM will kill itself if a killed task has not stopped running. The default value, -1, disables this<br>mechanism and prevents the executor from self-destructing. The purpose of this setting is to act as a<br>safety-net to prevent runaway uncancellable tasks from rendering an executor unusable.<br></td><br></tr><br></table>

<h3 id="Dynamic-Allocation"><a href="#Dynamic-Allocation" class="headerlink" title="Dynamic Allocation"></a>Dynamic Allocation</h3><table class="table table-bordered table-striped table-condensed"><br><tr><br><th>Property Name</th><br><th>Default</th><br><th>Meaning</th><br></tr><br><tr><br><td><code>spark.dynamicAllocation.enabled</code></td><br><td>false</td><br><td><br>Whether to use dynamic resource allocation, which scales the number of executors registered with this<br>application up and down based on the workload. For more detail, see the description <a href="job-scheduling.html#dynamic-resource-allocation">here</a>. <br><br> This requires <code>spark.shuffle.service.enabled</code><br>to be set. The following configurations are also relevant: <code>spark.dynamicAllocation.minExecutors</code>,<br><code>spark.dynamicAllocation.maxExecutors</code>, and <code>spark.dynamicAllocation.initialExecutors</code><br></td><br></tr><br><tr><br><td><code>spark.dynamicAllocation.executorIdleTimeout</code></td><br><td>60s</td><br><td><br>If dynamic allocation is enabled and an executor has been idle for more than this duration, the executor<br>will be removed. For more detail, see this <a href="job-scheduling.html#resource-allocation-policy">description</a>.<br></td><br></tr><br><tr><br><td><code>spark.dynamicAllocation.cachedExecutorIdleTimeout</code></td><br><td>infinity</td><br><td><br>If dynamic allocation is enabled and an executor which has cached data blocks has been idle for more than<br>this duration, the executor will be removed. For more details, see this <a href="job-scheduling.html#resource-allocation-policy">description</a>.<br></td><br></tr><br><tr><br><td><code>spark.dynamicAllocation.initialExecutors</code></td><br><td><code>spark.dynamicAllocation.minExecutors</code></td><br><td><br>Initial number of executors to run if dynamic allocation is enabled. <br><br> If <code>--num-executors</code> (or<br><code>spark.executor.instances</code>) is set and larger than this value, it will be used as the initial number of<br>executors.<br></td><br></tr><br><tr><br><td><code>spark.dynamicAllocation.maxExecutors</code></td><br><td>infinity</td><br><td><br>Upper bound for the number of executors if dynamic allocation is enabled.<br></td><br></tr><br><tr><br><td><code>spark.dynamicAllocation.minExecutors</code></td><br><td>0</td><br><td><br>Lower bound for the number of executors if dynamic allocation is enabled.<br></td><br></tr><br><tr><br><td><code>spark.dynamicAllocation.schedulerBacklogTimeout</code></td><br><td>1s</td><br><td><br>If dynamic allocation is enabled and there have been pending tasks backlogged for more than this duration,<br>new executors will be requested. For more detail, see this <a href="job-scheduling.html#resource-allocation-policy">description</a>.<br></td><br></tr><br><tr><br><td><code>spark.dynamicAllocation.sustainedSchedulerBacklogTimeout</code></td><br><td><code>schedulerBacklogTimeout</code></td><br><td><br>Same as <code>spark.dynamicAllocation.schedulerBacklogTimeout</code>, but used only for subsequent executor<br>requests. For more detail, see this <a href="job-scheduling.html#resource-allocation-policy">description</a>.<br></td><br></tr><br></table>

<h3 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h3><table class="table table-bordered table-striped table-condensed"><br><tr><br><th>Property Name</th><br><th>Default</th><br><th>Meaning</th><br></tr><br><tr><br><td><code>spark.acls.enable</code></td><br><td>false</td><br><td><br>Whether Spark acls should be enabled. If enabled, this checks to see if the user has access permissions to<br>view or modify the job. Note this requires the user to be known, so if the user comes across as null no<br>checks are done. Filters can be used with the UI to authenticate and set the user.<br></td><br></tr><br><tr><br><td><code>spark.admin.acls</code></td><br><td>Empty</td><br><td><br>Comma separated list of users/administrators that have view and modify access to all Spark jobs. This can be<br>used if you run on a shared cluster and have a set of administrators or devs who help debug when things do<br>not work. Putting a “<em>“ in the list means any user can have the privilege of admin.<br></em></td><br></tr><br><tr><br><td><code>spark.admin.acls.groups</code></td><br><td>Empty</td><br><td><br>Comma separated list of groups that have view and modify access to all Spark jobs. This can be used if you<br>have a set of administrators or developers who help maintain and debug the underlying infrastructure.<br>Putting a ““ in the list means any user in any group can have the privilege of admin. The user groups are<br>obtained from the instance of the groups mapping provider specified by<br><code>spark.user.groups.mapping</code>. Check the entry <code>spark.user.groups.mapping</code> for more<br>details.<br></td><br></tr><br><tr><br><td><code>spark.user.groups.mapping</code></td><br><td><code>org.apache.spark.security.ShellBasedGroupsMappingProvider</code></td><br><td><br>The list of groups for a user are determined by a group mapping service defined by the trait<br>org.apache.spark.security.GroupMappingServiceProvider which can configured by this property. A default unix<br>shell based implementation is provided<br><code>org.apache.spark.security.ShellBasedGroupsMappingProvider</code> which can be specified to resolve a<br>list of groups for a user. <em>Note:</em> This implementation supports only a Unix/Linux based environment.<br>Windows environment is currently <b>not</b> supported. However, a new platform/protocol can be supported by<br>implementing the trait <code>org.apache.spark.security.GroupMappingServiceProvider</code>.<br></td><br></tr><br><tr><br><td><code>spark.authenticate</code></td><br><td>false</td><br><td><br>Whether Spark authenticates its internal connections. See <code>spark.authenticate.secret</code> if not<br>running on YARN.<br></td><br></tr><br><tr><br><td><code>spark.authenticate.secret</code></td><br><td>None</td><br><td><br>Set the secret key used for Spark to authenticate between components. This needs to be set if not running on<br>YARN and authentication is enabled.<br></td><br></tr><br><tr><br><td><code>spark.authenticate.enableSaslEncryption</code></td><br><td>false</td><br><td><br>Enable encrypted communication when authentication is enabled. This is supported by the block transfer<br>service and the<br>RPC endpoints.<br></td><br></tr><br><tr><br><td><code>spark.network.sasl.serverAlwaysEncrypt</code></td><br><td>false</td><br><td><br>Disable unencrypted connections for services that support SASL authentication. This is currently supported<br>by the external shuffle service.<br></td><br></tr><br><tr><br><td><code>spark.core.connection.ack.wait.timeout</code></td><br><td><code>spark.network.timeout</code></td><br><td><br>How long for the connection to wait for ack to occur before timing out and giving up. To avoid unwilling<br>timeout caused by long pause like GC, you can set larger value.<br></td><br></tr><br><tr><br><td><code>spark.core.connection.auth.wait.timeout</code></td><br><td>30s</td><br><td><br>How long for the connection to wait for authentication to occur before timing out and giving up.<br></td><br></tr><br><tr><br><td><code>spark.modify.acls</code></td><br><td>Empty</td><br><td><br>Comma separated list of users that have modify access to the Spark job. By default only the user that<br>started the Spark job has access to modify it (kill it for example). Putting a “<em>“ in the list means any<br>user can have access to modify it.<br></em></td><br></tr><br><tr><br><td><code>spark.modify.acls.groups</code></td><br><td>Empty</td><br><td><br>Comma separated list of groups that have modify access to the Spark job. This can be used if you have a set<br>of administrators or developers from the same team to have access to control the job. Putting a ““ in the<br>list means any user in any group has the access to modify the Spark job. The user groups are obtained from<br>the instance of the groups mapping provider specified by <code>spark.user.groups.mapping</code>. Check the<br>entry <code>spark.user.groups.mapping</code> for more details.<br></td><br></tr><br><tr><br><td><code>spark.ui.filters</code></td><br><td>None</td><br><td><br>Comma separated list of filter class names to apply to the Spark web UI. The filter should be a standard <a href="http://docs.oracle.com/javaee/6/api/javax/servlet/Filter.html" target="_blank" rel="external"> javax servlet Filter</a>.<br>Parameters to each filter can also be specified by setting a java system property of: <br> <code>spark.&lt;class<br>name of filter&gt;.params=’param1=value1,param2=value2’</code><br> For example: <br> <code>-Dspark.ui.filters=com.test.filter1</code><br><br> <code>-Dspark.com.test.filter1.params=’param1=foo,param2=testing’</code></td><br></tr><br><tr><br><td><code>spark.ui.view.acls</code></td><br><td>Empty</td><br><td><br>Comma separated list of users that have view access to the Spark web ui. By default only the user that<br>started the Spark job has view access. Putting a “<em>“ in the list means any user can have view access to this<br>Spark job.<br></em></td><br></tr><br><tr><br><td><code>spark.ui.view.acls.groups</code></td><br><td>Empty</td><br><td><br>Comma separated list of groups that have view access to the Spark web ui to view the Spark Job details. This<br>can be used if you have a set of administrators or developers or users who can monitor the Spark job<br>submitted. Putting a ““ in the list means any user in any group can view the Spark job details on the Spark<br>web ui. The user groups are obtained from the instance of the groups mapping provider specified by <code>spark.user.groups.mapping</code>.<br>Check the entry <code>spark.user.groups.mapping</code> for more details.<br></td><br></tr><br></table>

<h3 id="Encryption"><a href="#Encryption" class="headerlink" title="Encryption"></a>Encryption</h3><table class="table table-bordered table-striped table-condensed"><br><tr><br><th>Property Name</th><br><th>Default</th><br><th>Meaning</th><br></tr><br><tr><br><td><code>spark.ssl.enabled</code></td><br><td>false</td><br><td><br>Whether to enable SSL connections on all supported protocols. <br>When <code>spark.ssl.enabled</code> is<br>configured, <code>spark.ssl.protocol</code> is required. <br>All the SSL settings like<br><code>spark.ssl.xxx</code> where <code>xxx</code> is a particular configuration property, denote the global<br>configuration for all the supported protocols. In order to override the global configuration for the<br>particular protocol, the properties must be overwritten in the protocol-specific namespace. <br>Use <code>spark.ssl.YYY.XXX</code><br>settings to overwrite the global configuration for particular protocol denoted by <code>YYY</code>. Example<br>values for <code>YYY</code> include <code>fs</code>, <code>ui</code>, <code>standalone</code>, and <code>historyServer</code>.<br>See <a href="security.html#ssl-configuration">SSL Configuration</a> for details on hierarchical SSL<br>configuration for services.<br></td><br></tr><br><tr><br><td><code>spark.ssl.enabledAlgorithms</code></td><br><td>Empty</td><br><td><br>A comma separated list of ciphers. The specified ciphers must be supported by JVM. The reference list of<br>protocols one can find on <a href="https://blogs.oracle.com/java-platform-group/entry/diagnosing_tls_ssl_and_https" target="_blank" rel="external">this</a> page.<br>Note: If not set, it will use the default cipher suites of JVM.<br></td><br></tr><br><tr><br><td><code>spark.ssl.keyPassword</code></td><br><td>None</td><br><td><br>A password to the private key in key-store.<br></td><br></tr><br><tr><br><td><code>spark.ssl.keyStore</code></td><br><td>None</td><br><td><br>A path to a key-store file. The path can be absolute or relative to the directory where the component is<br>started in.<br></td><br></tr><br><tr><br><td><code>spark.ssl.keyStorePassword</code></td><br><td>None</td><br><td><br>A password to the key-store.<br></td><br></tr><br><tr><br><td><code>spark.ssl.keyStoreType</code></td><br><td>JKS</td><br><td><br>The type of the key-store.<br></td><br></tr><br><tr><br><td><code>spark.ssl.protocol</code></td><br><td>None</td><br><td><br>A protocol name. The protocol must be supported by JVM. The reference list of protocols one can find on <a href="https://blogs.oracle.com/java-platform-group/entry/diagnosing_tls_ssl_and_https" target="_blank" rel="external">this</a> page.<br></td><br></tr><br><tr><br><td><code>spark.ssl.needClientAuth</code></td><br><td>false</td><br><td><br>Set true if SSL needs client authentication.<br></td><br></tr><br><tr><br><td><code>spark.ssl.trustStore</code></td><br><td>None</td><br><td><br>A path to a trust-store file. The path can be absolute or relative to the directory where the component is<br>started in.<br></td><br></tr><br><tr><br><td><code>spark.ssl.trustStorePassword</code></td><br><td>None</td><br><td><br>A password to the trust-store.<br></td><br></tr><br><tr><br><td><code>spark.ssl.trustStoreType</code></td><br><td>JKS</td><br><td><br>The type of the trust-store.<br></td><br></tr><br></table>]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[spark-hardware-provisioning]]></title>
      <url>/2017/12/26/spark-hardware-provisioning/</url>
      <content type="html"><![CDATA[<h3 id="存储系统"><a href="#存储系统" class="headerlink" title="存储系统"></a>存储系统</h3><p>Spark 任务会从外部存储系统中读取数据，所以将它放在尽可能近的地方是非常重要的。一般来说 Spark 程序和数据放在相同节点是效率最高的，如果无法保证相同节点，退一步讲，应将程序和数据放在同一网络环境下。</p>
<h4 id="本地磁盘"><a href="#本地磁盘" class="headerlink" title="本地磁盘"></a>本地磁盘</h4><p>虽然 Spark 是基于内存的运算，但是在数据无法放置到内存或保存 stage 间的中间数据还是需要使用磁盘。推荐每个节点 4-8 块磁盘，单独挂载不需要配置 RAID ，使用 noatime 选项减少不必要的写操作。 磁盘信息通过设置 spark.local.dir 参数配置。如果运行在 HDFS 上，可以使用和 HDFS 相同的配置。</p>
<h4 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h4><p>Spark 可以使用 8 到上百 GB 的内存，但是推荐分配 75% 的内存给 Spark，其他的留给操作系统和缓存使用。JVM 在 200 GB 以上的机器上表现并不理想，如果机器内存超过 200 GB ，可以在节点上运行多个 worker JVMs 。</p>
<h4 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h4><p>Spark 在运行期间是网络绑定的，使用万兆或更大的带宽程序会执行更快。对 group-bys，reduce-bys，joins 等分布式减少的程序尤其适用。</p>
<h4 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h4><p>Spark 可以在每个节点上扩展到十多个 CPU 内核，因为它是线程之间最小共享的。</p>
]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL 安装服务及 Windows CMD 中使用 MySQL 命令]]></title>
      <url>/2017/11/01/installing-mysql-service-and-use-mysql-command-in-windows-cmd/</url>
      <content type="html"><![CDATA[<p>Windows 上使用 zip 版的 MySQL 配置服务方法：</p>
<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>解压缩后，根路径创建配置文件 my.ini</p>
<pre><code># The following options will be passed to all MySQL clients  
[client]  
#password   = your_password  
port        = 3306  
[mysql]  
#设置mysql客户端的字符集  
default-character-set = utf8  
# The MySQL server  
[mysqld]  
port        = 3306  
#设置mysql的安装目录  
basedir = D:\Dev\MySQL\mysql-5.5.58
#设置mysql数据库的数据存放目录,必须是data或者\xxx-data  
datadir = D:\Dev\MySQL\mysql-5.5.58\data  
#设置服务器段的字符集  
character_set_server = utf8
</code></pre><h4 id="安装服务"><a href="#安装服务" class="headerlink" title="安装服务"></a>安装服务</h4><p>使用管理员权限打开 CMD ，输入命令：</p>
<pre><code>mysqld --install MySQL --defaults-file=D:\Dev\MySQL\mysql-5.5.58\my.ini
</code></pre><p>安装完成。</p>
<p>将 bin 目录加入环境变量即可在 CMD 中使用 MySQL 命令。</p>
]]></content>
      
        <categories>
            
            <category> Databases </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx 代理静态网页]]></title>
      <url>/2017/10/17/nginx-proxy-static-resources/</url>
      <content type="html"><![CDATA[<p>Nginx 默认是支持静态资源的，配置如下：</p>
<pre><code>server {
  listen      8202 ;

  charset utf-8;

  server_name 192.168.201.74;
  root /home/ops/developer.bidata.com.cn;
  index index.html;
  location ~* ^.+\.(jpg|jpeg|gif|png|ico|css|js|pdf|txt){
    root /home/ops/developer.bidata.com.cn;
  }
}
</code></pre><p>生效后，访问 192.168.201.74:8202/index.html 就会去访问 /home/ops/developer.bidata.com.cn 下的 index.html 。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch 备份与合并]]></title>
      <url>/2017/08/29/elasticsearch-backup-and-rebuild/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx 双机方案]]></title>
      <url>/2017/08/29/nginx-ha/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java 调用 shell 命令]]></title>
      <url>/2017/08/09/invoke-shell-in-java/</url>
      <content type="html"><![CDATA[<p>Java 调用 shell 命令主要用到 Process 和 Runtime 两个类。</p>
<pre><code class="java">Process process = Runtime.getRuntime().exec(cmd);
int c = process.waitFor();
if (c != 0) {
  System.out.println(&quot;执行shell异常终止&quot;);
}
</code></pre>
<p>waitFor() 用来判断 Process 进程是否终止，0代表正常终止。</p>
<p>如果想读取 shell 命令的输出，可以用 Java I/O 读取。</p>
<pre><code class="java">//读取标准输出流
BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(process.getInputStream()));
String line;
while ((line = bufferedReader.readLine()) != null) {
  System.out.println(line);
}
</code></pre>
<pre><code class="java">//读取标准错误流
BufferedReader brError = new BufferedReader(new InputStreamReader(process.getErrorStream()));
String errline = null;
while ((errline = brError.readLine()) != null) {
    System.out.println(errline);
}
</code></pre>
<p>基本用法很简单，但是还有一些小细节需要注意。在使用上边代码的时候，经常会出现执行一段时间之后程序就 hang 住不动，无法结束。原因是因为缓冲区被充满，造成 I/O 阻塞，导致程序无法结束，所以在使用应在调用wartFor() 之前先读取流，并且要先读取标准错误再读取标准输出。参考：<a href="http://brian.pontarelli.com/2005/11/11/java-runtime-exec-can-hang/" target="_blank" rel="external">Java Runtime exec can hang</a> 。</p>
<p>完整程序参考：</p>
<pre><code class="java">import java.io.*;
public class Executor {
    public void execute() {
        BufferedReader bReader = null;
        InputStreamReader sReader = null;
        try {
          Process p = Runtime.getRuntime().exec(cmd);
          //为&quot;错误输出流&quot;单独开一个线程读取之,否则会造成标准输出流的阻塞
          Thread t = new Thread(new InputStreamRunnable(p.getErrorStream(), &quot;ErrorStream&quot;));
          t.start();
          //&quot;标准输出流&quot;就在当前方法中读取
          BufferedInputStream bis = new BufferedInputStream(p.getInputStream());
          sReader = new InputStreamReader(bis, &quot;UTF-8&quot;);
          bReader = new BufferedReader(sReader);
          StringBuilder sb = new StringBuilder();
          String line;
          while ((line = bReader.readLine()) != null) {
            sb.append(line);
            sb.append(&quot;/n&quot;);
          }
          bReader.close();
          p.destroy();
          return sb.toString();
        } catch (Exception e) {
          e.printStackTrace();
        } 
    } 
}
</code></pre>
<pre><code class="java">import java.io.BufferedInputStream;
import java.io.BufferedReader;
import java.io.InputStream;
import java.io.InputStreamReader;

public class InputStreamRunnable implements Runnable {
    BufferedReader bReader = null;

    public InputStreamRunnable(InputStream is) {
        try {
            bReader = new BufferedReader(new InputStreamReader(new BufferedInputStream(is), &quot;UTF-8&quot;));
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    public void run() {
        String line;
        try {
            while ((line = bReader.readLine()) != null) {
                System.err.println(line);
            }
            bReader.close();
        } catch (Exception ex) {
        }
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 安装及修改 image 存储路径]]></title>
      <url>/2017/07/15/docker-install-and-change-images-path/</url>
      <content type="html"><![CDATA[<p>###安装 docker</p>
<pre><code>sudo yum install -y docker-engine-1.12.6-1.el7.centos.x86_64
sudo systemctl start docker
sudo docker run hello-world
sudo groupadd docker
sudo usermod -aG docker $USER
docker run hello-world
sudo systemctl enable docker
</code></pre><p>###修改 image 存储路径</p>
<pre><code>sudo systemctl stop docker
cd /var/lib
sudo cp -rf docker docker.bak
sudo cp -rf docker /u01/
sudo rm -rf docker 
sudo ln -s /u01/docker docker
sudo systemctl start docker
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java 一问一答]]></title>
      <url>/2017/07/05/java-one-question-one-answer/</url>
      <content type="html"><![CDATA[<h4 id="Q：-Spring-Data-的-repository-只定义了接口，没有实现，是如何完成数据访问操作的？"><a href="#Q：-Spring-Data-的-repository-只定义了接口，没有实现，是如何完成数据访问操作的？" class="headerlink" title="Q： Spring Data 的 repository 只定义了接口，没有实现，是如何完成数据访问操作的？"></a>Q： Spring Data 的 repository 只定义了接口，没有实现，是如何完成数据访问操作的？</h4><p>A： 这是通过 Java 编译器的衍生机制实现的。衍生机制基于 Java 6 的注解处理工具 APT ，它能够以编码的方式探查具有特殊注解的代码，然后调用函数生成查询元模型类。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark Streaming 简单实践]]></title>
      <url>/2017/05/31/spark-streaming-practice/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[机器学习基本概念]]></title>
      <url>/2017/05/30/machine-learning/</url>
      <content type="html"><![CDATA[<h3 id="什么是机器学习？"><a href="#什么是机器学习？" class="headerlink" title="什么是机器学习？"></a>什么是机器学习？</h3><p>在不直接针对问题进行编程的情况下，赋予计算机学习的能力。–来自 1959 年 Arthur Samuel 。<a id="more"></a></p>
<h3 id="机器学习的分类"><a href="#机器学习的分类" class="headerlink" title="机器学习的分类"></a>机器学习的分类</h3><h4 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h4><p>算法的输入训练数据集包含了某种程度上的“标准答案”，通过找到“标准输入”和标准答案“之间的关系，尝试在给出新的输入时得到更准确的答案。</p>
<p>监督学习有常见的2种分类：回归和分类。</p>
<p>回归问题处理的数据是连续的，分类处理的数据是离散的。</p>
<h4 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h4><p>算法的输入训练数据集不包含任何“标准答案”，尝试寻找数据中的联系。</p>
<p>聚类是最常见的无监督学习。</p>
<h3 id="工程应用中使用机器学习需要哪些步骤？"><a href="#工程应用中使用机器学习需要哪些步骤？" class="headerlink" title="工程应用中使用机器学习需要哪些步骤？"></a>工程应用中使用机器学习需要哪些步骤？</h3><h4 id="1-数据获取及存储"><a href="#1-数据获取及存储" class="headerlink" title="1. 数据获取及存储"></a>1. 数据获取及存储</h4><h4 id="2-数据清理及转换"><a href="#2-数据清理及转换" class="headerlink" title="2. 数据清理及转换"></a>2. 数据清理及转换</h4><ul>
<li>过滤数据</li>
<li>处理缺失，不完整，有缺陷数据</li>
<li>处理异常数据</li>
<li>合并</li>
<li>汇总</li>
</ul>
<h4 id="3-模型训练"><a href="#3-模型训练" class="headerlink" title="3. 模型训练"></a>3. 模型训练</h4><ul>
<li>特定问题最优建模方法选择</li>
<li>特定模型最佳参数选择</li>
</ul>
<h4 id="4-模型测试"><a href="#4-模型测试" class="headerlink" title="4. 模型测试"></a>4. 模型测试</h4><p>评估性能</p>
<table>
<thead>
<tr>
<th style="text-align:center">实际\预测</th>
<th style="text-align:center">1</th>
<th style="text-align:center">0</th>
<th style="text-align:center">合计</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">True Positive（TP）</td>
<td style="text-align:center">False Negative（FN）</td>
<td style="text-align:center">Actual Positive(TP+FN)</td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">False Positive（FP)</td>
<td style="text-align:center">True Negative(TN)</td>
<td style="text-align:center">Actual Negative(FP+TN)</td>
</tr>
<tr>
<td style="text-align:center">合计</td>
<td style="text-align:center">Predicted Positive(TP+FP)</td>
<td style="text-align:center">Predicted Negative(FN+TN)</td>
<td style="text-align:center">TP+FP+FN+TN</td>
</tr>
</tbody>
</table>
<pre><code>TP（True Positive）：指正确分类的正样本数，即预测为正样本，实际也是正样本。
FP（False Positive）：指被错误的标记为正样本的负样本数，即实际为负样本而被预测为正样本，所以是False。
TN（True Negative）：指正确分类的负样本数，即预测为负样本，实际也是负样本。
FN（False Negative）：指被错误的标记为负样本的正样本数，即实际为正样本而被预测为负样本，所以是False。
TP+FP+TN+FN：样本总数。
TP+FN：实际正样本数。
TP+FP：预测结果为正样本的总数，包括预测正确的和错误的。
FP+TN：实际负样本数。
TN+FN：预测结果为负样本的总数，包括预测正确的和错误的。
</code></pre><ul>
<li>正确率：训练样本中被正确分类的样本数量除以总样本数。</li>
</ul>
<p>$$<br>正确率（True Positive Rate）=\frac{TP+TN}{TP+FP+TN+FN}<br>$$</p>
<ul>
<li>错误率：训练样本中被错误分类的样本数量除以总样本数。</li>
</ul>
<p>$$<br>错误率（FalsePositiveRate）=\frac{FP+FN}{TP+FP+TN+FN}<br>$$</p>
<ul>
<li>准确率：评价结果的质量。</li>
</ul>
<p>$$<br>准确率（Precision）=\frac{TP}{TP+FP}<br>$$</p>
<ul>
<li>召回率：评价结果的完整性。</li>
</ul>
<p>$$<br>召回率（Recall）=\frac{FP}{TP+FN}<br>$$</p>
<ul>
<li><p>准确率-召回率曲线下方面积</p>
<p>准确率和召回率是负相关的，通常被一起组成聚合或者平均度量，PR曲线下方面积为平均准确率。PR曲线越往右上效果越好。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20170530/164219609.jpg" alt="mark"></p>
</li>
</ul>
<ul>
<li><p>ROC曲线</p>
<p>和PR曲线类似，表示不同决策阈值下TPR对FPR的折衷。ROC曲线越往左上效果越好。</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20170530/203047480.png" alt="mark"></p>
<ul>
<li><p>ROC曲线下的面积</p>
<p>ROC曲线下的面积表示平均值，也称作AUC。</p>
</li>
<li><p>F-Measure</p>
<p>综合评价指标是P和R的加权调和平均。<br>$$<br>f=\frac{(a^2+1)P\times{R}}{a^2(P+R)}<br>$$<br>当a=1时，即为最常见的F1-Measure。<br>$$<br>f1=2\times\frac{P\times{R}}{P+R}<br>$$</p>
</li>
</ul>
<h4 id="5-模型部署与整合"><a href="#5-模型部署与整合" class="headerlink" title="5. 模型部署与整合"></a>5. 模型部署与整合</h4><h4 id="6-模型监控与反馈"><a href="#6-模型监控与反馈" class="headerlink" title="6. 模型监控与反馈"></a>6. 模型监控与反馈</h4><h3 id="Spark-MLlib"><a href="#Spark-MLlib" class="headerlink" title="Spark MLlib"></a>Spark MLlib</h3><p>Spark MLlib 是一个机器学习库，包含两部分：</p>
<ul>
<li>spark.mllib: 数据类型，算法以及工具</li>
<li>spark.ml: 机器学习管道高级API</li>
</ul>
<h3 id="如何使用Spark-MLlib编程"><a href="#如何使用Spark-MLlib编程" class="headerlink" title="如何使用Spark MLlib编程"></a>如何使用Spark MLlib编程</h3><pre><code class="java">// 初始化上下文
SparkConf sparkConf = new SparkConf().setAppName(&quot;JavaNaiveBayesExample&quot;);
JavaSparkContext jsc = new JavaSparkContext(sparkConf);
// 获得数据
JavaRDD&lt;LabeledPoint&gt; inputData = MLUtils.loadLibSVMFile(jsc.sc(), path).toJavaRDD();
// 训练模型
NaiveBayesModel model = NaiveBayes.train(training.rdd());
// 保存模型
model.save(jsc.sc(), &quot;target/tmp/myNaiveBayesModel&quot;);
// 装载模型
NaiveBayesModel sameModel = NaiveBayesModel.load(jsc.sc(), &quot;target/tmp/myNaiveBayesModel&quot;);
// 预测
JavaPairRDD&lt;Double, Double&gt; predictionAndLabel =
      test.mapToPair(p -&gt; new Tuple2&lt;&gt;(model.predict(p.features()), p.label()));
// 评估性能
double accuracy =
predictionAndLabel.filter(pl -&gt; pl._1().equals(pl._2())).count() / (double) test.count();

jsc.stop();
jsc.close();
</code></pre>
<h3 id="欠拟合和过拟合"><a href="#欠拟合和过拟合" class="headerlink" title="欠拟合和过拟合"></a>欠拟合和过拟合</h3><p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20170530/230758020.png" alt="mark"></p>
<h3 id="如何确定训练数据足够？算法需要多少数据？"><a href="#如何确定训练数据足够？算法需要多少数据？" class="headerlink" title="如何确定训练数据足够？算法需要多少数据？"></a>如何确定训练数据足够？算法需要多少数据？</h3>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Machine Learning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[朴素贝叶斯算法]]></title>
      <url>/2017/05/18/machine-learning-native-bayes/</url>
      <content type="html"><![CDATA[<p>朴素贝叶斯 (Native Bayes) 是一个简单的多类分类算法，它假定每一对特征值都是彼此独立的。朴素贝叶斯算法具有很好的性能。数据训练能计算出每一个给定标签的特征可能的条件分布并可以利用它来观察特征的分布并用于预测。<a id="more"></a><br>Spark MLlib 支持多项朴素贝叶斯（multinomial naive Bayes）和伯努利朴素贝叶斯（Bernoulli naive Bayes），他们都是典型的文本分类算法。<br>每条观察数据都是由特征和指标构成的文本。特征表示一项在文本中出现的频率，特征的值必须是非负。指标 0 和 1 表示一项是否在文本中能找到。</p>
<p>MLlib 的实现的朴素贝叶斯算法接收三个参数： LabeledPoint 的 RDD ，lambda 是 The smoothing parameter ，默认值是 1.0 ， modelType 可以指定使用 multinomial 或是 Bernoulli ，输出是一个可以用于评估和预测的 NaiveBayesModel 。</p>
<pre><code class="scala">def train(input: RDD[LabeledPoint], lambda: Double, modelType: String): NaiveBayesModel
</code></pre>
<p>LabeledPoint 是一个存放特征和标签的类。</p>
<pre><code class="scala">LabeledPoint(label: Double, features: Vector)
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
            <tag> Machine Learning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker 搭建 Nginx 环境]]></title>
      <url>/2017/04/11/docker-build-nginx/</url>
      <content type="html"><![CDATA[<p>官方提供了 Nginx 的 docker 镜像，就不用自己打镜像了。首先下载 nginx 镜像 <a href="https://hub.docker.com/_/nginx/" target="_blank" rel="external">https://hub.docker.com/_/nginx/</a> 。</p>
<p>使用 nginx 的镜像比较简单，但是在挂载配置时出了一些问题，一个在物理机上正常使用的配置文件，有可能在 docker 中报错，所以要注意挂载的配置文件和路径是否正确。<a id="more"></a></p>
<p>使用下面的命令查看镜像中的配置文件。</p>
<pre><code class="shell">docker run --rm -it nginx:1.10.3 cat /etc/nginx/nginx.conf
</code></pre>
<p>可对照修改自己的配置文件。</p>
<pre><code class="shell">user  nginx;
worker_processes  1;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;
                      &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;
                      &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    include /etc/nginx/conf.d/*.conf;
}
</code></pre>
<p>完整的启动命令：</p>
<pre><code class="shell">docker run -p 80:80 -p 38002:38002 --name mynginx -v /home/rolex/work/conf.d/:/etc/nginx/conf.d/ -v /home/rolex/work/logs/:/etc/nginx/logs/ -it nginx:1.10.3
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Nginx </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spring AOP 开发]]></title>
      <url>/2017/04/10/spring-aop/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> AOP </tag>
            
            <tag> Spring </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[使用 IDEA 开发 AspectJ 程序]]></title>
      <url>/2017/04/10/aspectj-program-development/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
            <tag> AspectJ </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OpenResty 实践]]></title>
      <url>/2017/04/10/openresty-practice/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx 安装配置]]></title>
      <url>/2017/04/01/nginx-installation-and-configuration/</url>
      <content type="html"><![CDATA[<p>Nginx 是一款高性能的 HTTP 和反向代理服务器。</p>
<a id="more"></a>
<p>安装配置过程如下：</p>
<h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><pre><code class="shell">wget http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz
wget https://nginx.org/download/nginx-1.10.3.tar.gz
</code></pre>
<h3 id="安装编译工具和库"><a href="#安装编译工具和库" class="headerlink" title="安装编译工具和库"></a>安装编译工具和库</h3><p>CentOS </p>
<pre><code class="shell">yum group install Development Tools
yum install openssl openssl-devel zlib zlib-devel
</code></pre>
<p>ubuntu</p>
<pre><code class="shell">apt-get install openssl libssl-dev
</code></pre>
<p>安装 PCRE</p>
<pre><code class="shell">tar -zxf pcre-8.35.tar.gz
cd pcre-8.35
./configure
make &amp;&amp; make install
</code></pre>
<h3 id="安装-Nginx"><a href="#安装-Nginx" class="headerlink" title="安装 Nginx"></a>安装 Nginx</h3><pre><code class="shell">tar -zxf nginx-1.10.3.tar.gz
mv nginx-1.10.3 /opt/nginx/
cd /opt/nginx/nginx-1.10.3
./configure --prefix=/usr/local/webserver/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/root/pcre-8.35
make &amp;&amp; make install
</code></pre>
<p>显示版本信息则安装成功。</p>
<pre><code class="shell">/usr/local/webserver/nginx/sbin/nginx -v
</code></pre>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>nginx 的配置文件为 /usr/local/webserver/nginx/conf/nginx.conf</p>
<pre><code>user root;
worker_processes 8; #设置值和CPU核心数一致
error_log /usr/local/webserver/nginx/logs/nginx_error.log crit; #日志位置和日志级别
pid /usr/local/webserver/nginx/nginx.pid;
#Specifies the value for maximum file descriptors that can be opened by this process.
worker_rlimit_nofile 65535;
events
{
  use epoll;
  worker_connections 65535;
}
http
{
  include mime.types;
  default_type application/octet-stream;
  log_format main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;
               &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;
               &#39;&quot;$http_user_agent&quot; $http_x_forwarded_for&#39;;

  server_names_hash_bucket_size 128;
  client_header_buffer_size 32k;
  large_client_header_buffers 4 32k;
  client_max_body_size 8m;

  sendfile on;
  tcp_nopush on;
  keepalive_timeout 60;
  tcp_nodelay on;
  fastcgi_connect_timeout 300;
  fastcgi_send_timeout 300;
  fastcgi_read_timeout 300;
  fastcgi_buffer_size 64k;
  fastcgi_buffers 4 64k;
  fastcgi_busy_buffers_size 128k;
  fastcgi_temp_file_write_size 128k;
  gzip on; 
  gzip_min_length 1k;
  gzip_buffers 4 16k;
  gzip_http_version 1.0;
  gzip_comp_level 2;
  gzip_types text/plain application/x-javascript text/css application/xml;
  gzip_vary on;

  #limit_zone crawler $binary_remote_addr 10m;
  #下面是server虚拟主机的配置
  #server多的时候建议使用 include /opt/nginx/nginx-1.10.3/conf/conf.d/*.conf; 每个server 单独一个配置文件
 server
  {
    listen 80;#监听端口
    server_name localhost;#域名
    index index.html index.htm index.php;
    root /usr/local/webserver/nginx/html;#站点目录
      location ~ .*\.(php|php5)?$
    {
      #fastcgi_pass unix:/tmp/php-cgi.sock;
      fastcgi_pass 127.0.0.1:9000;
      fastcgi_index index.php;
      include fastcgi.conf;
    }
    location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|ico)$
    {
      expires 30d;
  # access_log off;
    }
    location ~ .*\.(js|css)?$
    {
      expires 15d;
   # access_log off;
    }
    access_log off;
  }

server {
    listen 8002 ;
    charset utf-8;
    access_log logs/host.access.log main;
    location /{
        proxy_pass http://cn.bing.com/;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Real-IP  $remote_addr;
    }
}
}
</code></pre><p>修改后，检查配置。</p>
<pre><code class="shell">/usr/local/webserver/nginx/sbin/nginx -t
</code></pre>
<p>启动 nginx</p>
<pre><code>/usr/local/webserver/nginx/sbin/nginx
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Nginx </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CentOS 7 设置国内源]]></title>
      <url>/2017/04/01/centos-7-yum-installation/</url>
      <content type="html"><![CDATA[<p>网易源设置帮助 <a href="http://mirrors.163.com/.help/centos.html" target="_blank" rel="external">http://mirrors.163.com/.help/centos.html</a>。</p>
<a id="more"></a>
<h3 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h3><pre><code class="shell">mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
</code></pre>
<h3 id="下载新源"><a href="#下载新源" class="headerlink" title="下载新源"></a>下载新源</h3><pre><code>cd /etc/yum.repos.d
wget http://mirrors.163.com/.help/CentOS7-Base-163.repo
</code></pre><h3 id="生成缓存"><a href="#生成缓存" class="headerlink" title="生成缓存"></a>生成缓存</h3><pre><code>yum clean all
yum makecache
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[AspectJ 和 Spring AOP 科普]]></title>
      <url>/2017/04/01/learning-about-aspectj-and-spring-aop/</url>
      <content type="html"><![CDATA[<p>AOP （面向方面编程） 是一种编程思想，是对 OOP 的有力补充。AspectJ 是对 Java 在 AOP 编程上的扩展。Spring AOP 是 Spring 提供的 AOP 编程框架。</p>
<p>在接触到 AOP 的时候用的就是 Spring AOP ， Spring 也提供了 AspectJ 的支持，可以在 Spring AOP 中使用 AspectJ 的语法，但 Spring AOP 和 AspectJ 还是有区别的。</p>
<p>AspectJ 功能强大到令人发指（虽然没用过），并且是在编译期就对代码进行织入，所以速度快。但是 AspectJ 需要使用特殊编译器编译，学习门槛较高。<br>Spring AOP 功能上有所限制（1. 相同类中的方法不能互相调用；2. 只能在 Spring 体系的类中使用；3. 粒度到方法级。），但是使用起来比 AspectJ 简单，采用动态织入，所以不需要专门的 AspectJ 编译器来编译，但速度慢于 AspectJ 。</p>
<p>在使用 AOP 的过程中，一般会涉及以下几个概念。</p>
<ul>
<li>Aspect: a modularization of a concern that cuts across multiple classes. Transaction management is a good example of a crosscutting concern in enterprise Java applications. In Spring AOP, aspects are implemented using regular classes (the schema-based approach) or regular classes annotated with the @Aspect annotation (the @AspectJ style).</li>
<li>Join point: a point during the execution of a program, such as the execution of a method or the handling of an exception. In Spring AOP, a join point always represents a method execution.</li>
<li>Advice: action taken by an aspect at a particular join point. Different types of advice include “around,” “before” and “after” advice. (Advice types are discussed below.) Many AOP frameworks, including Spring, model an advice as an interceptor, maintaining a chain of interceptors around the join point.</li>
<li>Pointcut: a predicate that matches join points. Advice is associated with a pointcut expression and runs at any join point matched by the pointcut (for example, the execution of a method with a certain name). The concept of join points as matched by pointcut expressions is central to AOP, and Spring uses the AspectJ pointcut expression language by default.</li>
<li>Introduction: declaring additional methods or fields on behalf of a type. Spring AOP allows you to introduce new interfaces (and a corresponding implementation) to any advised object. For example, you could use an introduction to make a bean implement an IsModified interface, to simplify caching. (An introduction is known as an inter-type declaration in the AspectJ community.)</li>
<li>Target object: object being advised by one or more aspects. Also referred to as the advised object. Since Spring AOP is implemented using runtime proxies, this object will always be a proxied object.</li>
<li>AOP proxy: an object created by the AOP framework in order to implement the aspect contracts (advise method executions and so on). In the Spring Framework, an AOP proxy will be a JDK dynamic proxy or a CGLIB proxy.</li>
<li>Weaving: linking aspects with other application types or objects to create an advised object. This can be done at compile time (using the AspectJ compiler, for example), load time, or at runtime. Spring AOP, like other pure Java AOP frameworks, performs weaving at runtime. </li>
</ul>
<p>以上概念抄自 <a href="https://docs.spring.io/spring/docs/current/spring-framework-reference/html/aop.html" target="_blank" rel="external">https://docs.spring.io/spring/docs/current/spring-framework-reference/html/aop.html</a> 。</p>
<p>AspectJ 有专门的 Java 编译器，可在官网下载 <a href="https://eclipse.org/aspectj/downloads.php#stable_release" target="_blank" rel="external">https://eclipse.org/aspectj/downloads.php#stable_release</a> 。AspectJ 也有集成开发环境，最常见的比如 AJDT 是 eclipse 的插件。IDEA 官方没有插件，具体设置参考 <a href="https://www.jetbrains.com/help/idea/2017.1/aspectj.html" target="_blank" rel="external">https://www.jetbrains.com/help/idea/2017.1/aspectj.html</a> </p>
<p>这里不涉及细节，只是科普，所以具体细节可参考：</p>
<ol>
<li><a href="http://blog.csdn.net/zl3450341/article/details/7673938" target="_blank" rel="external">跟我学 aspectj</a> </li>
<li><a href="../../../../2017/04/10/使用-IDEA-开发-AspectJ-程序/">使用 IDEA 开发 AspectJ 程序</a></li>
<li><a href="../../../../2017/04/10/Spring-AOP-开发/">Spring AOP 开发</a></li>
</ol>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> AspectJ </tag>
            
            <tag> AOP </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Sublime Text 3 安装配置]]></title>
      <url>/2017/03/28/sublime-text-3-installation/</url>
      <content type="html"><![CDATA[<p>Windows 上之前一直用 notepad++ ，后来在 linux 上用了一段时间 atom ，git 的插件用起来很顺手，但是由于长期不关机，导致 atom 经常卡死，所以换 Sublime 试试。</p>
<a id="more"></a>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>没用过 Sublime ，所以选择了 Sublime Text 3 。下载安装很简单。<a href="https://www.sublimetext.com/3" target="_blank" rel="external">https://www.sublimetext.com/3</a></p>
<pre><code class="shell">sudo dpkg -i sublime-text_build-3126_amd64.deb
</code></pre>
<h3 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h3><p>外观控必须先搞个主题，我挑了一个黑色主题 Afteglow ， <a href="https://github.com/YabataDesign/afterglow-theme" target="_blank" rel="external">https://github.com/YabataDesign/afterglow-theme</a> 。</p>
<p>文档详细，配置简单，关键还有 markdown 的配色。</p>
<p>最后附一个 user settings</p>
<pre><code class="json">{
    &quot;color_inactive_tabs&quot;: true,
    &quot;theme&quot;: &quot;Afterglow-green.sublime-theme&quot;,
    &quot;folder_no_icon&quot;: false,
    &quot;font_face&quot;: &quot;Yahei Consolas Hybrid&quot;,
    &quot;font_size&quot;: 10,
    &quot;ignored_packages&quot;:
    [
        &quot;Vintage&quot;
    ],
    &quot;line_padding_bottom&quot;: 5,
    &quot;line_padding_top&quot;: 5,
    &quot;sidebar_no_icon&quot;: false,
    &quot;sidebar_row_padding_large&quot;: true,
    &quot;sidebar_size_11&quot;: true,
    &quot;status_bar_brighter&quot;: true,
    &quot;tabs_padding_small&quot;: true,
    &quot;tabs_small&quot;: true,
}
</code></pre>
<p>关于细节调整，可以在 <code>Afterglow-green.sublime-theme</code> 中修改。</p>
<h3 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h3><p>网上推荐的很多，选了一些先用着。</p>
<p>package control <a href="https://packagecontrol.io/installation" target="_blank" rel="external">https://packagecontrol.io/installation</a> 这个肯定是要装的，欲善其事，先利器器，顺序不能乱。</p>
<p>安装完，后边的插件安装都是小意思啦。</p>
<p>Alignment<br>BracketHighlighter<br>Emmet<br>Git<br>Markdown Editing<br>Side bar<br>Themr<br>CSScomb<br>ConvertToUFT8</p>
]]></content>
      
        <categories>
            
            <category> Wiki </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Sublime </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Windows 安装 hexo 小计]]></title>
      <url>/2017/03/24/installing-hexo-on-windows/</url>
      <content type="html"><![CDATA[<p>一直在 linux 上用 hexo ，自己还有一个 windows 的机器，也想利用起来。对于我来说，需求非常简单，windows 作为 linux 的一个补充，能在本地运行，能通过 git 同步数据即可。</p>
<a id="more"></a>
<h3 id="1-安装"><a href="#1-安装" class="headerlink" title="1. 安装"></a>1. 安装</h3><p>首先需要按装 node.js 。和 linux 一样，下载 node.js windows 的安装包安装 node.js 环境。</p>
<p>然后安装 hexo 。</p>
<pre><code>npm config set registry &quot;https://registry.npm.taobao.org&quot;
npm install -g hexo-cli
</code></pre><p>等待几分钟即可完成安装。</p>
<h3 id="2-配置"><a href="#2-配置" class="headerlink" title="2. 配置"></a>2. 配置</h3><p>linux 上已经安装了 hexo ，相关的配置已经在 github 上，所以，不用重新配置，初始化完成后，同步git 即可。</p>
<pre><code>hexo init hexo
cd hexo
git init
git remote add &lt;url&gt;
git pull origin master
hexo clean
hexo g
hexo s
</code></pre><p>以上。</p>
]]></content>
      
        <categories>
            
            <category> Wiki </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（28）： sed]]></title>
      <url>/2017/03/07/one-day-one-command-28-sed/</url>
      <content type="html"><![CDATA[<p>sed 命令的全名是 stream editor ，用来把文档或字符串里面的文字经过一系列编辑命令转换为另一种格式输出，是简化版的 awk 。</p>
<p>sed 命令格式:</p>
<pre><code class="shell">Usage: sed [OPTION]... {script-only-if-no-other-script} [input-file]...

  -n, --quiet, --silent
                 suppress automatic printing of pattern space
  -e script, --expression=script
                 add the script to the commands to be executed
  -f script-file, --file=script-file
                 将替换的内容放到文件
  --follow-symlinks
                 follow symlinks when processing in place
  -i[SUFFIX], --in-place[=SUFFIX]
                 替换结果应用于源文件
  -b, --binary
                 open files in binary mode (CR+LFs are not processed specially)
  -l N, --line-length=N
                 specify the desired line-wrap length for the &#39;l&#39; command
  --posix
                 disable all GNU extensions.
  -r, --regexp-extended
                 use extended regular expressions in the script.
  -s, --separate
                 consider files as separate rather than as a single continuous
                 long stream.
  -u, --unbuffered
                 load minimal amounts of data from the input files and flush
                 the output buffers more often
  -z, --null-data
                 separate lines by NUL characters
      --help     display this help and exit
      --version  output version information and exit
</code></pre>
<p>可接受的命令：</p>
<pre><code class="shell">       i      之前插入
       a      追加
       c \

       text   Replace the selected lines with text, which has each embedded newline preceded by a backslash.

       d      删除.

       D      If pattern space contains no newline, start a normal new cycle as if the d command was issued.  Otherwise, delete text in the pattern space up to the first newline, and restart cycle with the resultant  pattern  space,
              without reading a new line of input.

       h H    Copy/append pattern space to hold space.

       g G    Copy/append hold space to pattern space.

       l      List out the current line in a ``visually unambiguous&#39;&#39; form.

       l width
              List out the current line in a ``visually unambiguous&#39;&#39; form, breaking it at width characters.  This is a GNU extension.

       n N    Read/append the next line of input into the pattern space.

       p      Print the current pattern space.

       P      Print up to the first embedded newline of the current pattern space.

       s/regexp/replacement/
              替换.

       t label
              If a s/// has done a successful substitution since the last input line was read and since the last t or T command, then branch to label; if label is omitted, branch to end of script.

       T label
              If no s/// has done a successful substitution since the last input line was read and since the last t or T command, then branch to label; if label is omitted, branch to end of script.  This is a GNU extension.

       w filename
              Write the current pattern space to filename.

       W filename
              Write the first line of the current pattern space to filename.  This is a GNU extension.

       x      Exchange the contents of the hold and pattern spaces.

       y/source/dest/
              转换.
</code></pre>
<p>举例：</p>
<p>将文件中的 java 替换成 scala：</p>
<pre><code class="shell">sed &#39;s/java/scala/&#39; a.txt
</code></pre>
<blockquote>
<p>默认情况下 sed 不会修改源文件，所有的操作都是在缓冲区的副本中进行的。每次读入一行到缓冲区，处理完成后将结果发送到标准输出，然后删除缓冲区中的行，再读入下一行。</p>
</blockquote>
<p>将替换结果应用于源文件：</p>
<pre><code class="shell">sed -i &#39;s/java/scala/&#39; a.txt
</code></pre>
<p>移除空白行：</p>
<pre><code class="shell">sed &#39;/^$/d&#39; a.txt
</code></pre>
<blockquote>
<p>^$行尾标记紧临表示空白行。</p>
</blockquote>
<p>&amp;代表已经匹配的字符串：</p>
<pre><code class="shell">echo this is a test | sed &#39;s/\w\+/[&amp;]/g&#39;
--
[this] [is] [a] [test]
</code></pre>
<blockquote>
<p>\w+ 正则表达式表示匹配每一个单词，&amp;对应于之前所匹配到的单词</p>
</blockquote>
<p>多个表达式：</p>
<pre><code class="shell">cat a.txt | sed &#39;s/linux/LINUX/&#39; | sed &#39;s/sed/SED/&#39;
or
cat test.txt | sed &#39;s/linux/LINUX/;s/sed/SED/&#39;
</code></pre>
<p>文本中包含分界符需要转义：</p>
<pre><code class="shell">echo &quot;te/st1 te/st2 te/st3 te/st4 &quot; | sed &quot;s/te\/st/TEST/g&quot;
</code></pre>
<p>在包含 java 的行前插入：</p>
<pre><code class="shell">sed -i &#39;/java/i\learning &#39; a.txt
--
learning
java
</code></pre>
<p>在包含 java 的行后追加：</p>
<pre><code class="shell">sed -i &#39;/java/a\scala&#39; a.txt
--
java
scala
</code></pre>
<p>删除包含 java 的行：</p>
<pre><code class="shell">sed -i &#39;/java/d&#39; a.txt
</code></pre>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（27）： telnet]]></title>
      <url>/2017/03/06/one-day-one-command-27-telnet/</url>
      <content type="html"><![CDATA[<p>free 命令可以显示 Linux 系统中空闲的、已用的物理内存及 swap 内存,及被内核使用的 buffer，是最经常使用的系统监控工具之一。</p>
<a id="more"></a>
<p>free 命令格式：</p>
<pre><code class="shell">Usage:
 free [options]
Options:
 -b, --bytes         以 bytes 为单位显示
 -k, --kilo          以 kilobytes 为单位显示
 -m, --mega          以 megabytes 为单位显示
 -g, --giga          以 gigabytes 为单位显示
     --tera          以 terabytes 为单位显示
 -h, --human         show human-readable output
     --si            use powers of 1000 not 1024
 -l, --lohi          show detailed low and high memory statistics
 -t, --total         显示 RAM + swap
 -s N, --seconds N   每 N 秒刷新显示
 -c N, --count N     刷新 N 次后退出
 -w, --wide          wide output
</code></pre>
<p>举例：</p>
<p>比较两个文件：</p>
<pre><code class="shell">free -hw
              total        used        free      shared     buffers       cache   available
Mem:           7.5G        5.6G        327M        199M        385M        1.2G        1.3G
Swap:          7.6G        3.2G        4.5G

--
total:总计物理内存的大小。
used:已使用多大。
free:可用有多少。
Shared:多个进程共享的内存总额。
Buffers/cached:磁盘缓存的大小。
</code></pre>
<blockquote>
<p>buffers 和 cached 的区别</p>
<p>为了提高磁盘存取效率, Linux做了一些精心的设计, 除了对dentry进行缓存(用于VFS,加速文件路径名到inode的转换), 还采取了两种主要Cache方式：Buffer Cache和Page Cache。前者针对磁盘块的读写，后者针对文件inode的读写。这些Cache有效缩短了 I/O系统调用(比如read,write,getdents)的时间。</p>
<p>磁盘的操作有逻辑级（文件系统）和物理级（磁盘块），这两种Cache就是分别缓存逻辑和物理级数据的。</p>
<p>Page cache实际上是针对文件系统的，是文件的缓存，在文件层面上的数据会缓存到page cache。文件的逻辑层需要映射到实际的物理磁盘，这种映射关系由文件系统来完成。当page cache的数据需要刷新时，page cache中的数据交给buffer cache，因为Buffer Cache就是缓存磁盘块的。但是这种处理在2.6版本的内核之后就变的很简单了，没有真正意义上的cache操作。</p>
<p>Buffer cache是针对磁盘块的缓存，也就是在没有文件系统的情况下，直接对磁盘进行操作的数据会缓存到buffer cache中，例如，文件系统的元数据都会缓存到buffer cache中。</p>
<p>简单说来，page cache用来缓存文件数据，buffer cache用来缓存磁盘数据。在有文件系统的情况下，对文件操作，那么数据会缓存到page cache，如果直接采用dd等工具对磁盘进行读写，那么数据会缓存到buffer cache。</p>
<p>所以我们看linux,只要不用swap的交换空间,就不用担心自己的内存太少.如果常常swap用很多,可能你就要考虑加物理内存了.这也是linux看内存是否够用的标准.</p>
<p>如果是应用服务器的话，一般只看第二行，+buffers/cache,即对应用程序来说free的内存太少了，也是该考虑优化程序或加内存了。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（26）： awk]]></title>
      <url>/2017/03/05/one-day-one-command-26-awk/</url>
      <content type="html"><![CDATA[<p>free 命令可以显示 Linux 系统中空闲的、已用的物理内存及 swap 内存,及被内核使用的 buffer，是最经常使用的系统监控工具之一。</p>
<a id="more"></a>
<p>free 命令格式：</p>
<pre><code class="shell">Usage:
 free [options]
Options:
 -b, --bytes         以 bytes 为单位显示
 -k, --kilo          以 kilobytes 为单位显示
 -m, --mega          以 megabytes 为单位显示
 -g, --giga          以 gigabytes 为单位显示
     --tera          以 terabytes 为单位显示
 -h, --human         show human-readable output
     --si            use powers of 1000 not 1024
 -l, --lohi          show detailed low and high memory statistics
 -t, --total         显示 RAM + swap
 -s N, --seconds N   每 N 秒刷新显示
 -c N, --count N     刷新 N 次后退出
 -w, --wide          wide output
</code></pre>
<p>举例：</p>
<p>比较两个文件：</p>
<pre><code class="shell">free -hw
              total        used        free      shared     buffers       cache   available
Mem:           7.5G        5.6G        327M        199M        385M        1.2G        1.3G
Swap:          7.6G        3.2G        4.5G

--
total:总计物理内存的大小。
used:已使用多大。
free:可用有多少。
Shared:多个进程共享的内存总额。
Buffers/cached:磁盘缓存的大小。
</code></pre>
<blockquote>
<p>buffers 和 cached 的区别</p>
<p>为了提高磁盘存取效率, Linux做了一些精心的设计, 除了对dentry进行缓存(用于VFS,加速文件路径名到inode的转换), 还采取了两种主要Cache方式：Buffer Cache和Page Cache。前者针对磁盘块的读写，后者针对文件inode的读写。这些Cache有效缩短了 I/O系统调用(比如read,write,getdents)的时间。</p>
<p>磁盘的操作有逻辑级（文件系统）和物理级（磁盘块），这两种Cache就是分别缓存逻辑和物理级数据的。</p>
<p>Page cache实际上是针对文件系统的，是文件的缓存，在文件层面上的数据会缓存到page cache。文件的逻辑层需要映射到实际的物理磁盘，这种映射关系由文件系统来完成。当page cache的数据需要刷新时，page cache中的数据交给buffer cache，因为Buffer Cache就是缓存磁盘块的。但是这种处理在2.6版本的内核之后就变的很简单了，没有真正意义上的cache操作。</p>
<p>Buffer cache是针对磁盘块的缓存，也就是在没有文件系统的情况下，直接对磁盘进行操作的数据会缓存到buffer cache中，例如，文件系统的元数据都会缓存到buffer cache中。</p>
<p>简单说来，page cache用来缓存文件数据，buffer cache用来缓存磁盘数据。在有文件系统的情况下，对文件操作，那么数据会缓存到page cache，如果直接采用dd等工具对磁盘进行读写，那么数据会缓存到buffer cache。</p>
<p>所以我们看linux,只要不用swap的交换空间,就不用担心自己的内存太少.如果常常swap用很多,可能你就要考虑加物理内存了.这也是linux看内存是否够用的标准.</p>
<p>如果是应用服务器的话，一般只看第二行，+buffers/cache,即对应用程序来说free的内存太少了，也是该考虑优化程序或加内存了。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（25）： free]]></title>
      <url>/2017/03/04/one-day-one-command-25-free/</url>
      <content type="html"><![CDATA[<p>free 命令可以显示 Linux 系统中空闲的、已用的物理内存及 swap 内存,及被内核使用的 buffer，是最经常使用的系统监控工具之一。</p>
<a id="more"></a>
<p>free 命令格式：</p>
<pre><code class="shell">Usage:
 free [options]
Options:
 -b, --bytes         以 bytes 为单位显示
 -k, --kilo          以 kilobytes 为单位显示
 -m, --mega          以 megabytes 为单位显示
 -g, --giga          以 gigabytes 为单位显示
     --tera          以 terabytes 为单位显示
 -h, --human         show human-readable output
     --si            use powers of 1000 not 1024
 -l, --lohi          show detailed low and high memory statistics
 -t, --total         显示 RAM + swap
 -s N, --seconds N   每 N 秒刷新显示
 -c N, --count N     刷新 N 次后退出
 -w, --wide          wide output
</code></pre>
<p>举例：</p>
<p>比较两个文件：</p>
<pre><code class="shell">free -hw
              total        used        free      shared     buffers       cache   available
Mem:           7.5G        5.6G        327M        199M        385M        1.2G        1.3G
Swap:          7.6G        3.2G        4.5G

--
total:总计物理内存的大小。
used:已使用多大。
free:可用有多少。
Shared:多个进程共享的内存总额。
Buffers/cached:磁盘缓存的大小。
</code></pre>
<blockquote>
<p>buffers 和 cached 的区别</p>
<p>为了提高磁盘存取效率, Linux做了一些精心的设计, 除了对dentry进行缓存(用于VFS,加速文件路径名到inode的转换), 还采取了两种主要Cache方式：Buffer Cache和Page Cache。前者针对磁盘块的读写，后者针对文件inode的读写。这些Cache有效缩短了 I/O系统调用(比如read,write,getdents)的时间。</p>
<p>磁盘的操作有逻辑级（文件系统）和物理级（磁盘块），这两种Cache就是分别缓存逻辑和物理级数据的。</p>
<p>Page cache实际上是针对文件系统的，是文件的缓存，在文件层面上的数据会缓存到page cache。文件的逻辑层需要映射到实际的物理磁盘，这种映射关系由文件系统来完成。当page cache的数据需要刷新时，page cache中的数据交给buffer cache，因为Buffer Cache就是缓存磁盘块的。但是这种处理在2.6版本的内核之后就变的很简单了，没有真正意义上的cache操作。</p>
<p>Buffer cache是针对磁盘块的缓存，也就是在没有文件系统的情况下，直接对磁盘进行操作的数据会缓存到buffer cache中，例如，文件系统的元数据都会缓存到buffer cache中。</p>
<p>简单说来，page cache用来缓存文件数据，buffer cache用来缓存磁盘数据。在有文件系统的情况下，对文件操作，那么数据会缓存到page cache，如果直接采用dd等工具对磁盘进行读写，那么数据会缓存到buffer cache。</p>
<p>所以我们看linux,只要不用swap的交换空间,就不用担心自己的内存太少.如果常常swap用很多,可能你就要考虑加物理内存了.这也是linux看内存是否够用的标准.</p>
<p>如果是应用服务器的话，一般只看第二行，+buffers/cache,即对应用程序来说free的内存太少了，也是该考虑优化程序或加内存了。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（24）： top]]></title>
      <url>/2017/03/03/one-day-one-command-24-top/</url>
      <content type="html"><![CDATA[<p>top 命令是 Linux 下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于 Windows 的任务管理器。</p>
<a id="more"></a>
<p>top 命令格式：</p>
<pre><code class="shell">Usage:  top -hv | -abcHimMsS -d delay -n iterations [-u user | -U user] -p pid [,pid ...]
Options:
  -b                    批处理
  -S                    积累模式
  -i &lt;时间&gt;               设置间隔时间
  -u &lt;用户名&gt;               指定用户名
  -p &lt;进程号&gt;               指定进程
  -n &lt;次数&gt;                 循环显示的次数
</code></pre>
<p>举例：</p>
<p>比较两个文件：</p>
<pre><code class="shell">top
</code></pre>
<blockquote>
<p>PID — 进程id</p>
<p>USER — 进程所有者</p>
<p>PR — 进程优先级</p>
<p>NI — nice值。负值表示高优先级，正值表示低优先级</p>
<p>VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES </p>
<p>RES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA</p>
<p>SHR — 共享内存大小，单位kb</p>
<p>S — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程</p>
<p>%CPU — 上次更新到现在的CPU时间占用百分比</p>
<p>%MEM — 进程使用的物理内存百分比</p>
<p>TIME+ — 进程使用的CPU时间总计，单位1/100秒</p>
<p>COMMAND — 进程名称（命令名/命令行）</p>
</blockquote>
<p>显示完整命令：</p>
<pre><code class="shell">top -c
</code></pre>
<p>以批处理模式显示程序信息：</p>
<pre><code class="shell">top -b
</code></pre>
<p>以累积模式显示程序信息：</p>
<pre><code>top -S
</code></pre><p>设置信息更新次数：</p>
<pre><code>top -n 2
</code></pre><p>设置信息更新时间：</p>
<pre><code>top -d 3
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（23）： diff]]></title>
      <url>/2017/03/02/one-day-one-command-23-diff/</url>
      <content type="html"><![CDATA[<p>diff 命令是 linux 上非常重要的工具，用于比较文件的内容，特别是比较两个版本不同的文件以找到改动的地方。</p>
<a id="more"></a>
<p>diff 命令格式：</p>
<pre><code class="shell">Usage: diff [OPTION]... FILES
按行比较文件。
Options:
  -q, --brief                   只显示差异
  -s, --report-identical-files  文件相同仍然显示
  -c, -C NUM, --context[=NUM]   显示 NUM (default 3) 行 of copied context
  -u, -U NUM, --unified[=NUM]   显示 NUM (default 3) 行 of unified context
  -e, --ed                      output an ed script
  -n, --rcs                     以 RCS 格式显示差异 diff
  -r, --recursive               递归比较子目录
  -i, --ignore-case             忽略大小写
  -y, --side-by-side            并列显示
  -W, --width=NUM               指定栏数 NUM (default 130)
</code></pre>
<p>举例：</p>
<p>比较两个文件：</p>
<pre><code class="shell">diff 1.log 3.log
</code></pre>
<blockquote>
<p>a - add</p>
<p>c - change</p>
<p>d - delete</p>
</blockquote>
<p>并排格式输出：</p>
<pre><code class="shell">fiff -y -W 20 1.txt 2.txt
</code></pre>
<blockquote>
<p>“|”表示前后2个文件内容有不同</p>
<p>“&lt;”表示后面文件比前面文件少了1行内容</p>
<p>“&gt;”表示后面文件比前面文件多了1行内容</p>
</blockquote>
<p>上下文输出格式：</p>
<pre><code class="shell">diff -c 1.log 4.log
</code></pre>
<blockquote>
<p>“＋” 比较的文件的后者比前着多一行</p>
<p>“－” 比较的文件的后者比前着少一行</p>
<p>“！” 比较的文件两者有差别的行</p>
</blockquote>
<p>统一格式输出：</p>
<pre><code>diff -u 4.log 3.log
</code></pre><blockquote>
<p>“—“表示变动前的文件，”+++”表示变动后的文件</p>
<p>变动的位置用两个@作为起首和结束</p>
</blockquote>
<p>比较文件夹不同：</p>
<pre><code>diff  test3 test6
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（22）： du]]></title>
      <url>/2017/03/01/one-day-one-command-22-du/</url>
      <content type="html"><![CDATA[<p>Linux du 命令也是查看使用空间的，但是与 df 命令不同的是 du 命令是对文件和目录磁盘使用的空间的查看。</p>
<a id="more"></a>
<p>du 命令格式：</p>
<pre><code class="shell">Usage: du [OPTION]... [FILE]...
   or: du [OPTION]... --files0-from=FUsage: df [OPTION]... [FILE]...
显示每个文件和目录的磁盘使用空间。
Options:
  -a, --all             write counts for all files, not just directories
  -b, --bytes           等价 &#39;--apparent-size --block-size=1&#39;
  -h, --human-readable  以 K，M，G 为单位显示 (e.g., 1K 234M 2G)
  -m                    等价 --block-size=1M
  -c, --total           显示总计
</code></pre>
<p>举例：</p>
<p>显示目录或者文件所占空间：</p>
<pre><code class="shell">du
</code></pre>
<p>显示指定文件所占空间：</p>
<pre><code class="shell">du 1.txt
</code></pre>
<p>查看指定目录的所占空间：</p>
<pre><code class="shell">du /etc
</code></pre>
<p>显示多个文件所占空间：</p>
<pre><code>du 1.txt 2.txt
</code></pre><p>显示多个文件总计：</p>
<pre><code>du -c 1.txt 2.txt
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（21）： df]]></title>
      <url>/2017/02/28/one-day-one-command-21-df/</url>
      <content type="html"><![CDATA[<p>linux 中 df 命令的功能是用来检查 linux 服务器的文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。</p>
<a id="more"></a>
<p>df 命令格式：</p>
<pre><code class="shell">Usage: df [OPTION]... [FILE]...
显示指定文件或所有文件的占用磁盘信息.
Options:
 -a, --all 全部文件系统列表
 -h, --human-readable                  以 1K=1024B 显示 (e.g., 1023M)
 -H, --si                              以 1K=1000B 显示 (e.g., 1.1G)
 -T, --print-type                      显示文件系统类型
 -t &lt;TYPE&gt;, --type=TYPE                显示指定类型的文件系统
 -x &lt;TYPE&gt;, --exclude-type=TYPE        不显示指定类型的文件系统
</code></pre>
<p>举例：</p>
<p>显示磁盘使用情况：</p>
<pre><code class="shell">df
</code></pre>
<p>显示指定类型磁盘：</p>
<pre><code class="shell">df -t ext4
</code></pre>
<p>以更易读的方式显示目前磁盘空间和使用情况：</p>
<pre><code class="shell">df -h
</code></pre>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（20）： find]]></title>
      <url>/2017/02/27/one-day-one-command-20-find/</url>
      <content type="html"><![CDATA[<p>find 命令提供了强大的搜索文件的功能。</p>
<a id="more"></a>
<p>find 命令格式：</p>
<pre><code class="shell">Usage: find [-H] [-L] [-P] [-Olevel] [-D help|tree|search|stat|rates|opt|exec|time] [path...] [expression]
    path        find 命令所查找的目录路径。例如用 . 来表示当前目录，用 / 来表示系统根目录。默认是当前目录。
    expression  默认是 -print ，打印到控制台
Options：
    STANDARDS CONFORMANCE
       For closest compliance to the POSIX standard, you should set the POSIXLY_CORRECT environment variable.  The following options  are  specified  in  the  POSIX
       standard (IEEE Std 1003.1, 2003 Edition):

       -H     This option is supported.

       -L     This option is supported.

       -name  按照文件名查找文件。

       -type  Supported.   POSIX specifies `b&#39;, `c&#39;, `d&#39;, `l&#39;, `p&#39;, `f&#39; and `s&#39;.  GNU find also supports `D&#39;, representing a Door, where the OS provides these.

       -ok    Supported.   Interpretation  of  the  response is according to the &quot;yes&quot; and &quot;no&quot; patterns selected by setting the `LC_MESSAGES&#39; environment variable.
              When the `POSIXLY_CORRECT&#39; environment variable is set, these patterns are taken system&#39;s definition of a positive (yes) or  negative  (no)  response.
              See  the  system&#39;s  documentation for nl_langinfo(3), in particular YESEXPR and NOEXPR.    When `POSIXLY_CORRECT&#39; is not set, the patterns are instead
              taken from find&#39;s own message catalogue.

       -newer Supported.  If the file specified is a symbolic link, it is always dereferenced.  This is a change from previous behaviour, which  used  to  take  the
              relevant time from the symbolic link; see the HISTORY section below.

       -perm  按照文件权限来查找文件。

       Other predicates
              The predicates -atime, -ctime, -depth, -group, -links, -mtime, -nogroup, -nouser, -print, -prune, -size, -user and -xdev `-atime&#39;, `-ctime&#39;, `-depth&#39;,
              `-group&#39;, `-links&#39;, `-mtime&#39;, `-nogroup&#39;, `-nouser&#39;, `-perm&#39;, `-print&#39;, `-prune&#39;, `-size&#39;, `-user&#39; and `-xdev&#39;, are all supported.
</code></pre>
<p>Options 太多了，就不一一列举了。</p>
<p>create ‘rb_gs_change_v3’,’f’</p>
<p>举例：</p>
<p>按名字查找：</p>
<pre><code class="shell">find /tmp -name core
</code></pre>
<p>按权限查找：</p>
<pre><code class="shell">find . -perm -664
</code></pre>
<p>按权限查找：</p>
<pre><code class="shell">find . -perm /222
</code></pre>
<p>结合 exec 使用：</p>
<pre><code class="shell">find /tmp -name core -type f -print | xargs /bin/rm -f
</code></pre>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（19）： mv]]></title>
      <url>/2017/02/26/one-day-one-command-19-mv/</url>
      <content type="html"><![CDATA[<p>mv 的作用是移动文件和目录，也可以用来重命名文件。</p>
<a id="more"></a>
<p>mv 命令格式：</p>
<pre><code>Usage: mv [OPTION]... [-T] SOURCE DEST

Options:
-t, --target-directory=DIRECTORY  移动多个文件到 DIRECTORY
--backup[=CONTROL]                如果文件存在，则备份。CONTROL 是备份策略，共有四种：
                                    1.CONTROL=none或off : 不备份。
                                    2.CONTROL=numbered或t：数字编号的备份
                                    3.CONTROL=existing或nil：如果存在以数字编号的备份，则继续编号备份m+1…n。
                                      执行mv操作前已存在以数字编号的文件log2.txt.~1~，那么再次执行将产生log2.txt~2~，以次类推。
                                      如果之前没有以数字编号的文件，则使用下面讲到的简单备份。
                                    4.CONTROL=simple或never：使用简单备份：在被覆盖前进行了简单备份，简单备份只能有一份，再次被覆盖时，简单备份也会被覆盖。
-b                                like --backup 但是不能指定策略，而是使用环境变量 VERSION_CONTROL 来作为备份策略。
-f                                不备份，强制覆盖
</code></pre><p>移动当前目录的所有文件到上一级目录</p>
<pre><code>mv * ..
</code></pre><p>移动多个文件到指定目录</p>
<pre><code>mv -t /tmp/test a.txt b.txt c.txt
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（18）： cp]]></title>
      <url>/2017/02/25/one-day-one-command-18-cp/</url>
      <content type="html"><![CDATA[<p>cp 是 linux 中复制文件和目录的常用命令。</p>
<a id="more"></a>
<p>cp 命令格式：</p>
<pre><code>cp [OPTION]... [-T] SOURCE DEST

Options:
  -a, --archive
                same as -dR --preserve=all
  -R, -r, --recursive
                递归拷贝目录
  -p     same as --preserve=mode,ownership,timestamps
  --preserve[=ATTR_LIST]
         保持文件指定的属性 (default: mode,ownership,timestamps), if possible additional attributes: context, links, xattr, all
</code></pre><p>复制一个文件</p>
<pre><code>cp -a a.txt b.txt
</code></pre><p>使用选项 -a 两个文件的创建时间是一致的。</p>
<p>复制文件到目录</p>
<pre><code>cp a.txt books/
</code></pre><p>复制目录</p>
<pre><code>cp -r books book
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（17）： whereis]]></title>
      <url>/2017/02/24/one-day-one-command-17-whereis/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（16）： which]]></title>
      <url>/2017/02/23/one-day-one-command-16-which/</url>
      <content type="html"><![CDATA[<p>which 命令的作用是在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。换句话说，可以用 which 查看一个命令是否存在。</p>
<a id="more"></a>
<p>which 命令格式：</p>
<pre><code>Usage: which [-a] filename
</code></pre><blockquote>
<p>which 是在 PATH 中查找，不同的环境变量，查找结果不一定相同。<br>如果一个命令使用 which 查不到，那么肯定在 PATH 中没有配置。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（15）： touch]]></title>
      <url>/2017/02/22/one-day-one-command-15-touch/</url>
      <content type="html"><![CDATA[<p>touch 可以刷新文件的访问和修改时间，但是在印象中用途就是创建一个空文件。</p>
<a id="more"></a>
<p>touch 命令格式：</p>
<pre><code>Usage: touch [OPTION]... FILE...

Options:
  -d, --date=STRING      使用指定日期代替创建日期
  -t STAMP               使用 [[CC]YY]MMDDhhmm[.ss] 代替当前时间
</code></pre><p>创建一个空文件</p>
<pre><code>touch a.txt
</code></pre><p>修改文件创建日期</p>
<pre><code>touch -d 20170222 a.txt
</code></pre><p>修改时间</p>
<pre><code>touch -t 1702220930 a.txt
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（14）： less]]></title>
      <url>/2017/02/21/one-day-one-command-14-less/</url>
      <content type="html"><![CDATA[<p>less 的作用和 more 相同，选项更多，比 more 更复杂功能更强。</p>
<a id="more"></a>
<p>less 命令格式：</p>
<pre><code>Usage：less [-[+]aABcCdeEfFgGiIJKLmMnNqQrRsSuUVwWX~]
            [-b space] [-h lines] [-j line] [-k keyfile]
            [-{oO} logfile] [-p pattern] [-P prompt] [-t tag]
            [-T tagsfile] [-x tab,...] [-y lines] [-[z] lines]
            [-# shift] [+[+]cmd] [--] [filename]...
</code></pre><p>和 more 一样，进入 less 后也有一大堆命令可用，不过 less 是基于 more 和 vi 的，所以你懂得。</p>
<p>常用操作：</p>
<pre><code>b         向后翻一页
d         向后翻半页
u         向前滚动半页
Ctrl+B    返回上一屏
Ctrl+F    向后翻一屏
回车       向下一行
y         向前一行
空格       向下一屏
q         退出 less
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（13）： more]]></title>
      <url>/2017/02/20/one-day-one-command-13-more/</url>
      <content type="html"><![CDATA[<p>more 是另一个和 cat 功能类似的命令，不同的是 more 可以分页显示文件内容。</p>
<a id="more"></a>
<p>more 命令格式：</p>
<pre><code>Usage: more [options] &lt;file&gt;...

Options:
 -&lt;number&gt;   每次显示 number 行
 +&lt;number&gt;   从 number 行开始显示
</code></pre><p>常用操作：</p>
<pre><code>Enter     向下n行，需要定义。默认为1行
空格键     向下滚动一屏
Ctrl+B    返回上一屏
=         输出当前行的行号
:f        输出文件名和当前行的行号
q         退出 more
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（12）： tail]]></title>
      <url>/2017/02/19/one-day-one-command-12-tail/</url>
      <content type="html"><![CDATA[<p>tail 是查看 log 的最常用的命令，没有之一。</p>
<a id="more"></a>
<p>tail 命令的格式：</p>
<pre><code>Usage: tail [OPTION]... [FILE]...

Options:
  -f, --follow[={name|descriptor}]
                           循环输出文件增加的内容；
  -n, --lines=[+]NUM       输出最后的 NUM 行;
  -s, --sleep-interval=N   和 -f 一起使用，在每次循环间隔 N 秒。
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（11）： head]]></title>
      <url>/2017/02/18/one-day-one-command-11-head/</url>
      <content type="html"><![CDATA[<p>head 和 cat 一样是链接文件和标准输出的命令，不同的是 head 只输出文件的头部（默认前 10 行）。</p>
<a id="more"></a>
<p>head 命令格式：</p>
<pre><code>Usage: head [OPTION]... [FILE]...

Options:
  -n, --lines=[-]NUM       print the first NUM lines instead of the first 10;
                               with the leading &#39;-&#39;, print all but the last
                               NUM lines of each file
  -c, --bytes=[-]NUM       print the first NUM bytes of each file;
                               with the leading &#39;-&#39;, print all but the last
                               NUM bytes of each file
</code></pre><p>实际上用过的也只有 -n 了。</p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Rancher 搭建 ELK 日志收集系统小记]]></title>
      <url>/2017/02/17/building-elk-in-rancher/</url>
      <content type="html"><![CDATA[<p>ELK 是 elastic 公司提供的一套开源的实时日志分析系统。经过一段时间的学习，在 Rancher 上搭建了一套，在此将整个搭建过程做一个总结。</p>
<a id="more"></a>
<h3 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h3><p>使用环境：</p>
<pre><code>Rancher         v1.3.1
docker          v1.13.1
elasticsearch   v2.3
logstash        v2.3
kibana          v4.5
redis           v3.0
</code></pre><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>目前的需求是能够将多个应用的响应类的日志统计收集起来集中查看，所以我使用了一个简化的方式来搭建 ELK 系统。</p>
<p>应用程序通过 log 将日志写到 redis ，logstash 从 redis 收集日志，写到 elasticsearch ，kibana 从 elasticsearch 中获取数据展现。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/elk.png" alt="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/elk.png"></p>
<h3 id="搭建步骤"><a href="#搭建步骤" class="headerlink" title="搭建步骤"></a>搭建步骤</h3><h4 id="准备镜像"><a href="#准备镜像" class="headerlink" title="准备镜像"></a>准备镜像</h4><p>下载镜像</p>
<pre><code class="shell">docker pull logstash:2.3
docker pull elasticsearch:2.3
docker pull kibana:4.5
docker pull redis:3.0
</code></pre>
<p>打标签</p>
<pre><code class="shell">docker tag logstash:2.3 reg.dockcloud.cn/riskbell/logstash:2.3
docker tag kibana:4.5 reg.dockcloud.cn/riskbell/kibana:4.5
docker tag redis:3.0 reg.dockcloud.cn/riskbell/redis:3.0
docker tag elasticsearch:2.3 reg.dockcloud.cn/riskbell/elasticsearch:2.3
</code></pre>
<p>上传本地仓库</p>
<pre><code class="shell">docker push reg.dockcloud.cn/riskbell/logstash:2.3
docker push reg.dockcloud.cn/riskbell/kibana:4.5
docker push reg.dockcloud.cn/riskbell/redis:3.0
docker push reg.dockcloud.cn/riskbell/elasticsearch:2.3
</code></pre>
<h4 id="rancher-配置"><a href="#rancher-配置" class="headerlink" title="rancher 配置"></a>rancher 配置</h4><h5 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h5><p>redis 需要向外暴露端口给应用程序。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/20170217164234.png" alt="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/2020170217164234.png"></p>
<h5 id="elasticsearch"><a href="#elasticsearch" class="headerlink" title="elasticsearch"></a>elasticsearch</h5><p>elasticsearch 也不需要使用别的服务，为了能从浏览器查看数据，也向外暴露端口。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/20170217164654.png" alt="https://raw.githubusercontent.com/bsyonline/pic/master/20170217164654.png"></p>
<h5 id="kibana"><a href="#kibana" class="headerlink" title="kibana"></a>kibana</h5><p>kibana 需要 link elasticsearch 的服务，也要向外暴露端口。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/20170217164908.png" alt="https://raw.githubusercontent.com/bsyonline/pic/master/20170217164908.png"></p>
<h5 id="logstash"><a href="#logstash" class="headerlink" title="logstash"></a>logstash</h5><p>logstash 的 input 是 redis ， output 是 elasticsearch ，需要在配置文件中指定。</p>
<pre><code>input {

    stdin {
    }

    redis {
        batch_count =&gt; 1
        data_type =&gt; &quot;list&quot;
        key =&gt; &quot;logstash&quot;
        host =&gt; &quot;redis&quot;               #host
        port =&gt; 6379              
        db =&gt; 0
        threads =&gt; 1
    }
}

output {
    stdout {
        codec =&gt; rubydebug
    }

    elasticsearch {
        hosts =&gt; [&quot;elasticsearch&quot;]    #host:port
        index =&gt; &quot;logstash-%{+YYYY.MM.dd}&quot;
        document_type =&gt; &quot;log&quot;
        workers =&gt; 1
        flush_size =&gt; 20000
        idle_flush_time =&gt; 10
        template_overwrite =&gt; true
    }
}
</code></pre><p>应为使用 rancher ，所以这份配置文件的 host 位置没有写 ip ，而是 rancher 中的服务名字。由于 link 服务走的是 overlay 网络，所以，端口号也是内部的，配置文件在启动命令中指定。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/20170217165818.png" alt="https://raw.githubusercontent.com/bsyonline/pic/master/20170217165818.png"></p>
<p>这样就完成了 ELK 系统的搭建。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/20170217165856.png" alt="https://raw.githubusercontent.com/bsyonline/pic/master/Screenshot%20from%202017-02-17%2016-58-56.png"></p>
<h3 id="compose"><a href="#compose" class="headerlink" title="compose"></a>compose</h3><p>docker-compose.yml</p>
<pre><code>version: &#39;2&#39;
services:
  logstash:
    image: dev.dockcloud.cn/riskbell/logstash:2.3
    stdin_open: true
    volumes:
    - /opt/riskbell-elk/conf:/conf
    tty: true
    links:
    - elasticsearch:elasticsearch
    - redis:redis
    command:
    - logstash
    - -f
    - /conf/riskbell.conf
    labels:
      io.rancher.container.pull_image: always
      io.rancher.scheduler.affinity:host_label: hostname=d21
  elasticsearch:
    image: dev.dockcloud.cn/riskbell/es:2.3
    stdin_open: true
    tty: true
    ports:
    - 19200:9200/tcp
    - 19300:9300/tcp
    labels:
      io.rancher.container.pull_image: always
      io.rancher.scheduler.affinity:host_label: hostname=d21
  kibana:
    image: dev.dockcloud.cn/riskbell/kibana:4.5
    stdin_open: true
    tty: true
    links:
    - elasticsearch:elasticsearch
    ports:
    - 15601:5601/tcp
    labels:
      io.rancher.container.pull_image: always
      io.rancher.scheduler.affinity:host_label: hostname=d21
  redis:
    image: dev.dockcloud.cn/riskbell/redis:latest
    stdin_open: true
    tty: true
    ports:
    - 16379:6379/tcp
    labels:
      io.rancher.container.pull_image: always
      io.rancher.scheduler.affinity:host_label: hostname=d21
</code></pre><p>rancher-compose.yml</p>
<pre><code>version: &#39;2&#39;
services:
  logstash:
    scale: 1
    start_on_create: true
  elasticsearch:
    scale: 1
    start_on_create: true
  kibana:
    scale: 1
    start_on_create: true
  redis:
    scale: 1
    start_on_create: true
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（10）： cat]]></title>
      <url>/2017/02/17/one-day-one-command-10-cat/</url>
      <content type="html"><![CDATA[<p>当我们想查看一个文件中的内容的时候， cat 是一种方法。cat 命令的作用就是连接文件到标准输出。</p>
<a id="more"></a>
<p>cat 命令格式：</p>
<pre><code>Usage: cat [OPTION]... [FILE]...
</code></pre><p>cat 最基本的用法就是讲文件的全部内容输出到标准输出。</p>
<pre><code>cat /etc/hosts
</code></pre><p>cat 还可以创建一个新文件。</p>
<pre><code>cat &gt; hello.txt
</code></pre><p>还有一种比较常用的用法，将多个文件合并成一个文件。</p>
<pre><code>cat file1 file2 &gt; file3
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Restful API 接口设计最佳实践]]></title>
      <url>/2017/02/16/restful-api-best-practice/</url>
      <content type="html"><![CDATA[<p>Restful 原则是由 Roy Fielding 提出的，现在已经成为了普遍遵守的规范。随着 Restful API 的使用也越来越多，如何设计一套优秀的 API 是每一个服务首先需要考虑的事情。</p>
<a id="more"></a>
<p>我也开发过一些 API ，对 Restful 的理解也是渐进的过程。有过一些经验，也走过一些弯路，借这个机会复复盘。</p>
<p>最开始，对于 Restful 并不了解，看了概念也理解的很肤浅，对于资料中的举例倒是很好理解，但是实际要自己来设计 api 借口的时候，总感觉没还是很模糊，一些举例中没有设计的场景，就抓瞎了。</p>
<p>所以，总结几条建议来帮助设计：</p>
<ol>
<li>一个 URL 表示一个资源，资源是名词，不要使用动词。</li>
<li>应该尽量保持 api 和 http 规范一致。</li>
<li>名词使用复数形式，不要担心出现不符合语法的使用，比如使用 /persons 要比 /people 要好。</li>
<li>推荐在资源的开始使用版本号，如 /v2/users 。</li>
<li>返回使用 json 而不是 xml 。json 是现在普遍使用的数据格式，且比 xml 更精简。</li>
<li>返回 code 和含义应和 http 状态码保持一致。</li>
</ol>
<p>下面是一些参考示例：</p>
<p><strong>1. 通过 id 获取</strong></p>
<pre><code>GET /api/v2/users/1
</code></pre><p><strong>2. 用户列表</strong></p>
<pre><code>GET /api/v2/users
</code></pre><p><strong>3. 多个条件查询</strong></p>
<pre><code>GET /api/v2/users?firstName=tom&amp;age=20
</code></pre><p><strong>4. 创建用户</strong></p>
<pre><code>POST /api/v2/users
Content-Type: application/json

{
  &quot;firstName&quot;: &quot;Maggy&quot;,
  &quot;lastName&quot;: &quot;Miller&quot;
}
</code></pre><p>返回</p>
<pre><code>201 Created
Location: /api/v2/users/5197cc
Content-Type: application/json

{
  &quot;id&quot;: &quot;5197cc&quot;,
  &quot;firstName&quot;: &quot;Maggy&quot;,
  &quot;lastName&quot;: &quot;Miller&quot;
}
</code></pre><p><strong>5. 分页</strong></p>
<pre><code>GET /api/v2/users?offset=10&amp;limit=25
</code></pre><p><strong>6. 获取总量</strong></p>
<pre><code>GET /api/v2/users?count=true
</code></pre><p>返回</p>
<pre><code>200 OK
Total-Count: 135
Content-Type: application/json

[{
  &quot;id&quot;: &quot;5197cc&quot;,
  &quot;firstName&quot;: &quot;Scott&quot;,
  &quot;lastName&quot;: &quot;Green&quot;
},{
  &quot;id&quot;: &quot;5197cb&quot;,
  &quot;firstName&quot;: &quot;Maggy&quot;,
  &quot;lastName&quot;: &quot;Miller&quot;
},...]
</code></pre><p><strong>7. 信封</strong></p>
<pre><code>GET /api/v2/users/?envelope=true
</code></pre><p>返回</p>
<pre><code>200 OK
Content-Type: application/json

{
  &quot;status&quot;: 404,
  &quot;response&quot;: {
    &quot;message&quot;: &quot;Not Found&quot;
  }
}
</code></pre><p><strong>8. 排序</strong></p>
<pre><code>GET /api/v2/users?sort=-name,+age
</code></pre><p><strong>9. 状态码</strong></p>
<pre><code>Success codes:

    200 OK - Request succeeded. Response included
    201 Created - Resource created. URL to new resource in Location header
    204 No Content - Request succeeded, but no response body

Error codes:

    400 Bad Request - Could not parse request
    401 Unauthorized - No authentication credentials provided or authentication failed
    403 Forbidden - Authenticated user does not have access
    404 Not Found - Resource not found
    415 Unsupported Media Type - POST/PUT/PATCH request occurred without a application/json content type
    422 Unprocessable Entry - A request to modify or create a resource failed due to a validation error
    429 Too Many Requests - Request rejected due to rate limiting
    500, 501, 502, 503, etc - An internal server error occured
</code></pre><p>以上是常用的一些状态码，更多见 <a href="http://www.restapitutorial.com/httpstatuscodes.html" target="_blank" rel="external">http://www.restapitutorial.com/httpstatuscodes.html</a> 。</p>
<p><strong>10. 属性过滤</strong></p>
<pre><code>GET /api/v2/users?fields=id,firstName
</code></pre><p><strong>11. 速率限制</strong><br>使用秒数更直观。</p>
<pre><code>Rate-Limit-Limit - Total credit for current period
Rate-Limit-Remaining - Remaining credit for current period
Rate-Limit-Used - Number of credits used for this request
Rate-Limit-Reset - Number of seconds until the the credit count resets
</code></pre><p><strong>12. 压缩</strong></p>
<blockquote>
<p>参考：</p>
<ol>
<li><a href="http://www.vinaysahni.com/best-practices-for-a-pragmatic-restful-api" target="_blank" rel="external">http://www.vinaysahni.com/best-practices-for-a-pragmatic-restful-api</a></li>
<li><a href="http://dev.enchant.com/api/v1" target="_blank" rel="external">http://dev.enchant.com/api/v1</a></li>
</ol>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> RESTful </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（9）： chmod]]></title>
      <url>/2017/02/16/one-day-one-command-9-chmod/</url>
      <content type="html"><![CDATA[<p>chmod 命令用于改变 linux 系统文件或目录的访问权限。</p>
<a id="more"></a>
<p>Linux 文件系统的权限分为读 r ，写 w ，执行 x 3 种。Linux 有 3 类用户，所有者，同组用户和其他用户。在 linux 系统中文件和目录都具有权限，每种用户对文件或目录的权限通过 1 个文件类型 和 3 组 rwx 组成的字符串表示。</p>
<pre><code>-rw-rw-r--  1 rolex rolex   5185 Feb 13 17:16 sbt2182110252329960095.log
</code></pre><p>如果想修改 -rw-rw-r– 成其他权限，可以用 chmod 命令。<br>chmod 命令格式：</p>
<pre><code class="shell">Usage: chmod [OPTION]... MODE[,MODE]... FILE...
  or:  chmod [OPTION]... OCTAL-MODE FILE...
  or:  chmod [OPTION]... --reference=RFILE FILE...

Options:
  -R, --recursive        change files and directories recursively
</code></pre>
<p>权限有两种设定方式：字符方式和数字方式。</p>
<ol>
<li>字符方式</li>
</ol>
<p>字符方式是使用字母和操作符来操作权限。</p>
<p>u ：目录或者文件的当前的用户<br>g ：目录或者文件的当前的群组<br>o ：除了目录或者文件的当前用户或群组之外的用户或者群组<br>a ：所有的用户及群组<br>r ：读权限，用数字4表示<br>w ：写权限，用数字2表示<br>x ：执行权限，用数字1表示<br>- ：删除权限，用数字0表示<br>s ：特殊权限</p>
<p>比如，为所有用户增加写权限</p>
<pre><code class="shell">chmod a+w sbt2182110252329960095.log
</code></pre>
<ol>
<li>数字方式</li>
</ol>
<p>数字方式是用二进制方式表示权限，0 表示无权限，1 表示有权限。如 -rwxrw-rw- 可表示成 755 ， -rw-r–r– 可表示成 644 。</p>
<p>例如，为所有用户开放所有权限</p>
<pre><code class="shell">chmod 777 sbt2182110252329960095.log
</code></pre>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（8）： chown]]></title>
      <url>/2017/02/15/one-day-one-command-8-chown/</url>
      <content type="html"><![CDATA[<p>chown 用于修改文件的所有者和组。</p>
<a id="more"></a>
<p>命令格式：</p>
<pre><code class="shell">Usage: chown [OPTION]... [OWNER][:[GROUP]] FILE...
  or:  chown [OPTION]... --reference=RFILE FILE...

Options:
  -R, --recursive        operate on files and directories recursively
</code></pre>
<p>修改文件的所有者和组</p>
<pre><code>chown ops:ops text.txt
</code></pre><p>修改目录下所有文件的所有者和组</p>
<pre><code>chown -R ops:ops /tmp/logs/
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（7）： ln]]></title>
      <url>/2017/02/14/one-day-one-command-7-ln/</url>
      <content type="html"><![CDATA[<p>ln 命令是在 linux 系统中建立一个文件连接。</p>
<a id="more"></a>
<p>ln 命令格式：</p>
<pre><code>Usage: ln [OPTION]... [-T] TARGET LINK_NAME

Options:
  -s, --symbolic              make symbolic links instead of hard links
</code></pre><p>ln 比较简单，但是还有一个基本概念要明确一下。在 linux 系统中链接分两种，软链接和硬链接。<br>软链接，也叫符号链接，以路径方式存在，类似 windows 系统的快捷方式。通常用软链接来创建一个目录的 link ，作用就是快捷方式。<br>硬链接，是文件副本，不能链接目录。<br>ln 默认创建的是硬链接， 创建软链接要使用选项 -s 。</p>
<p>为一个目录创建软链接</p>
<pre><code>ln -s /u01/jdk1.8.0_111 java
</code></pre><p>删除软链接</p>
<pre><code>rm -rf java
</code></pre><blockquote>
<p>后边不能带“/”</p>
</blockquote>
<p>最后在强调一点，ln 的所有文件或目录是同步，修改任何一个位置，其他都会改变。</p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（6）： ps]]></title>
      <url>/2017/02/13/one-day-one-command-6-ps/</url>
      <content type="html"><![CDATA[<p>ps 是 Process Status 的缩写，ps 命令用来列出 linux 系统中当前运行的进程。</p>
<a id="more"></a>
<p>Linux 系统中进程有 5 种状态：</p>
<ol>
<li>运行(正在运行或在运行队列中等待)</li>
<li>中断(休眠中, 受阻, 在等待某个条件的形成或接受到信号)</li>
<li>不可中断(收到信号不唤醒和不可运行, 进程必须等待直到有中断发生)</li>
<li>僵死(进程已终止, 但进程描述符存在, 直到父进程调用 wait4() 系统调用后释放)</li>
<li>停止(进程收到 SIGSTOP, SIGSTP, SIGTIN, SIGTOU 信号后停止运行运行)</li>
</ol>
<p>要了解某时刻系统进程的运行状态，ps 是最常用的命令之一。</p>
<p>ps 命令格式：</p>
<pre><code>Usage:
 ps [options]

Basic options:
  -A, -e               all processes
  -a                   all with tty, except session leaders
   a                   all with tty, including other users
  -d                   all except session leaders
  -N, --deselect       negate selection
   r                   only running processes
   T                   all processes on this terminal
   x                   processes without controlling ttys

Selection by list:
  -C &lt;command&gt;         command name
  -G, --Group &lt;GID&gt;    real group id or name
  -g, --group &lt;group&gt;  session or effective group name
  -p, p, --pid &lt;PID&gt;   process id
         --ppid &lt;PID&gt;  parent process id
  -q, q, --quick-pid &lt;PID&gt;
                       process id (quick mode)
  -s, --sid &lt;session&gt;  session id
  -t, t, --tty &lt;tty&gt;   terminal
  -u, U, --user &lt;UID&gt;  effective user id or name
  -U, --User &lt;UID&gt;     real user id or name

 The selection options take as their argument either:
   a comma-separated list e.g. &#39;-u root,nobody&#39; or
   a blank-separated list e.g. &#39;-p 123 4567&#39;

Output formats:
  -F                   extra full
  -f                   full-format, including command lines
   f, --forest         ascii art process tree
  -H                   show process hierarchy
  -j                   jobs format
   j                   BSD job control format
  -l                   long format
   l                   BSD long format
  -M, Z                add security data (for SELinux)
  -O &lt;format&gt;          preloaded with default columns
   O &lt;format&gt;          as -O, with BSD personality
  -o, o, --format &lt;format&gt;
                       user-defined format
   s                   signal format
   u                   user-oriented format
   v                   virtual memory format
   X                   register format
  -y                   do not show flags, show rss vs. addr (used with -l)
      --context        display security context (for SELinux)
      --headers        repeat header lines, one per page
      --no-headers     do not print header at all
      --cols, --columns, --width &lt;num&gt;
                       set screen width
      --rows, --lines &lt;num&gt;
                       set screen height

Show threads:
   H                   as if they were processes
  -L                   possibly with LWP and NLWP columns
  -m, m                after processes
  -T                   possibly with SPID column

Miscellaneous options:
  -c                   show scheduling class with -l option
   c                   show true command name
   e                   show the environment after command
   k,    --sort        specify sort order as: [+|-]key[,[+|-]key[,...]]
   L                   show format specifiers
   n                   display numeric uid and wchan
   S,    --cumulative  include some dead child process data
  -y                   do not show flags, show rss (only with -l)
  -V, V, --version     display version information and exit
  -w, w                unlimited output width

         --help &lt;simple|list|output|threads|misc|all&gt;
                       display help and exit
</code></pre><p>例如显示所有进程信息：</p>
<pre><code>ps -ef
</code></pre><p>会看到类似信息</p>
<pre><code>UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 Feb13 ?        00:00:01 /sbin/init splash
root         2     0  0 Feb13 ?        00:00:00 [kthreadd]
root         3     2  0 Feb13 ?        00:00:00 [ksoftirqd/0]
-----------
UID：    进程属于那个用户
PID：    进程 ID
PPID：   进程父 ID
C：      CPU 使用资源的百分比
STIME：  进程启动时间
TTY：    登录终端
TIME：   用掉的 CPU 时间
CMD：    指令
</code></pre><p>列出所有正在内存中的程序</p>
<pre><code>ps aux
</code></pre><p>会看到类似信息</p>
<pre><code>USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.0 120068  3472 ?        Ss   Feb13   0:01 /sbin/init splash
root         2  0.0  0.0      0     0 ?        S    Feb13   0:00 [kthreadd]
root         3  0.0  0.0      0     0 ?        S    Feb13   0:00 [ksoftirqd/0]
root         5  0.0  0.0      0     0 ?        S&lt;   Feb13   0:00 [kworker/0:0H]
-----------
USER：     该 process 属于那个使用者账号的
PID：      该 process 的号码
%CPU：     该 process 使用掉的 CPU 资源百分比
%MEM：     该 process 所占用的物理内存百分比
VSZ：      该 process 使用掉的虚拟内存量 (Kbytes)
RSS：      该 process 占用的固定的内存量 (Kbytes)
TTY：      该 process 是在那个终端机上面运作，若与终端机无关，则显示 ?，另外， tty1-tty6 是本机上面的登入者程序，若为 pts/0 等等的，则表示为由网络连接进主机的程序。
STAT：     该程序目前的状态，主要的状态有
R：        该程序目前正在运作，或者是可被运作
S：        该程序目前正在睡眠当中 (可说是 idle 状态)，但可被某些讯号 (signal) 唤醒。
T：        该程序目前正在侦测或者是停止了
Z：        该程序应该已经终止，但是其父程序却无法正常的终止他，造成 zombie (疆尸) 程序的状态
START：    该 process 被触发启动的时间
TIME：     该 process 实际使用 CPU 运作的时间
COMMAND：  该程序的实际指令
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（5）： history]]></title>
      <url>/2017/02/12/one-day-one-command-5-history/</url>
      <content type="html"><![CDATA[<p>history 命令能够列出在终端执行的命令的列表，并且能够快速执行某条历史命令。</p>
<p>history 命令格式：</p>
<pre><code>history
</code></pre><p>执行后会看到类似信息：</p>
<pre><code>1804  shutdown -h now
1805  dependencyTree
1806  sbt dependencyTree
1807  sbt dependency-tree
1808  sbt dependency-graph
</code></pre><p>最常用的功能是快速执行历史命令中的某行，如想执行 ‘sbt dependencyTree’ ，可以使用如下命令：</p>
<pre><code>!1806
</code></pre><p>history 功能还有很多，不过都没怎么用过，基本是查看历史命令记录，不过想看命令的执行时间，有个小技巧可以用的上。</p>
<pre><code>export HISTTIMEFORMAT=&#39;%F %T &#39;
history
</code></pre><p>设置格式化后，可以看到 history 中会显示日期和时间。</p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（3）： scp]]></title>
      <url>/2017/02/11/one-day-one-command-4-scp/</url>
      <content type="html"><![CDATA[<p>scp 是 secure copy 的简写，用于在Linux下进行远程拷贝文件的命令，而且 scp 传输是加密的。</p>
<a id="more"></a>
<p>scp 命令格式：</p>
<pre><code class="shell">Usage: scp [-12346BCpqrv] [-c cipher] [-F ssh_config] [-i identity_file]
           [-l limit] [-o ssh_option] [-P port] [-S program]
           [[user@]host1:]file1 ... [[user@]host2:]file2

Options:
  -1  强制scp命令使用协议ssh1  
  -2  强制scp命令使用协议ssh2  
  -4  强制scp命令只使用IPv4寻址  
  -6  强制scp命令只使用IPv6寻址  
  -B  使用批处理模式（传输过程中不询问传输口令或短语）  
  -C  允许压缩。（将-C标志传递给ssh，从而打开压缩功能）  
  -p  保留原文件的修改时间，访问时间和访问权限。  
  -q  不显示传输进度条。  
  -r  递归复制整个目录。  
  -v  详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。   
  -c  cipher  以cipher将数据传输进行加密，这个选项将直接传递给ssh。   
  -F  ssh_config  指定一个替代的ssh配置文件，此参数直接传递给ssh。  
  -i  identity_file  从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。    
  -l  limit  限定用户所能使用的带宽，以Kbit/s为单位。     
  -o  ssh_option  如果习惯于使用ssh_config(5)中的参数传递方式，   
  -P  port  注意是大写的P, port是指定数据传输用到的端口号   
  -S  program  指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。
</code></pre>
<p>实际使用很简单，只用过选项 r :<br>拷贝目录到远程</p>
<pre><code>scp -r /etc ops@hadoop1:/tmp/etc/
</code></pre><p>拷贝文件到远程</p>
<pre><code>scp /etc/hosts ops@hadoop1:/tmp/
</code></pre><p>拷贝文件到本地</p>
<pre><code>scp ops@hadoop1:/etc/hosts /tmp/
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（3）： tar]]></title>
      <url>/2017/02/10/one-day-one-command-3-tar/</url>
      <content type="html"><![CDATA[<p>今天来看看 linux 的打包命令 tar 。在 linux 中打包指将多个文件或目录合成一个文件，这个过程可以用 tar 来完成，生成的文件通常以 .tar 结尾。和打包相关还有一个压缩，linux 只能针对一个文件进行压缩，所以通常我们要将多个文件或目录打成一个包，再进行压缩。<br><a id="more"></a></p>
<h3 id="tar"><a href="#tar" class="headerlink" title="tar"></a>tar</h3><p>tar 命令格式：</p>
<pre><code class="shell">Usage: tar [OPTION...] [FILE]...

Options:
-z, --gzip, --gunzip, --ungzip    filter the archive through gzip
-j, --bzip2                       filter the archive through bzip2
-v, --verbose                     verbosely list files processed
    --warning=KEYWORD             warning control
-x, --extract, --get              extract files from an archive
-f, --file=ARCHIVE                use archive file or device ARCHIVE
    --force-local                 archive file is local even if it has a colon
-c, --create                      create a new archive
-t, --list                        list the contents of an archive
    --test-label                  test the archive volume label and exit
</code></pre>
<p>还是举几个例子吧。</p>
<p>创建 tar 包</p>
<pre><code>tar -cf test.tar /etc/hosts
</code></pre><p>提取 tar 包</p>
<pre><code>tar -xf test.tar
</code></pre><p>打包并压缩</p>
<pre><code>tar -zcf test.tar.gz /etc/hosts
</code></pre><p>解压缩 .tar.gz 文件</p>
<pre><code>tar -zxf kernel.tar.gz
</code></pre><blockquote>
<p>在参数 f 之后的文件档名是自己取的，我们习惯上都用 .tar 来作为辨识。 如果加 z 参数，则以 .tar.gz 或 .tgz 来代表 gzip 压缩过的 tar包； 如果加 j 参数，则以 .tar.bz2 来作为tar包名。</p>
</blockquote>
<p>查看包中的内容</p>
<pre><code>tar -tvf test.tar
</code></pre><p>如果是 .tar.gz 包，在加上 z 选项就可以了。</p>
<p>提取包中的某个文件</p>
<pre><code>tar -zxf test.tar.gz ./books/c.txt
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（2）： grep]]></title>
      <url>/2017/02/09/one-day-one-command-2-grep/</url>
      <content type="html"><![CDATA[<p>grep 是比较常用的一个命令，用来搜索文件或标准输出中的匹配模式的内容，默认打印出匹配的行。<br><a id="more"></a></p>
<p>grep 命令格式：</p>
<pre><code class="shell">Usage: grep [OPTION]... PATTERN [FILE]...

Options:
  --help                    Print a usage message briefly summarizing these command-line options and the bug-reporting address, then exit.
  -i, --ignore-case         Ignore  case  distinctions  in  both  the PATTERN and the input files.  (-i is specified by POSIX.)
  -c, --count               Suppress normal output; instead print a count of matching lines for each input file.
                            With the -v,  --invert-match option (see below), count non-matching lines.  (-c is specified by POSIX.)
  -l, --files-with-matches  Suppress normal output; instead print the name of each input file from which output would normally have
                            been printed.  The scanning will stop on the first match.  (-l  is  specified by POSIX.)
  -n, --line-number         print line number with output lines
      --line-buffered       flush output on every line
</code></pre>
<p>用过的选项也就上面几个。<br>举个例子吧，查找 test.txt 文件中 linux 出现的次数，忽略大小写。</p>
<pre><code class="shell">grep -ic linux test.txt
</code></pre>
<p>grep 也支持正则表达式。</p>
<pre><code>^         #锚定行的开始 如：&#39;^grep&#39;匹配所有以grep开头的行。

$         #锚定行的结束 如：&#39;grep$&#39;匹配所有以grep结尾的行。

.         #匹配一个非换行符的字符 如：&#39;gr.p&#39;匹配gr后接一个任意字符，然后是p。

*         #匹配零个或多个先前字符 如：&#39;*grep&#39;匹配所有一个或多个空格后紧跟grep的行。

.*        #一起用代表任意字符。

[]        #匹配一个指定范围内的字符，如&#39;[Gg]rep&#39;匹配Grep和grep。

[^]       #匹配一个不在指定范围内的字符，如：&#39;[^A-FH-Z]rep&#39;匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。

\(..\)    #标记匹配字符，如&#39;\(love\)&#39;，love被标记为1。

\&lt;        #锚定单词的开始，如:&#39;\&lt;grep&#39;匹配包含以grep开头的单词的行。

\&gt;        #锚定单词的结束，如&#39;grep\&gt;&#39;匹配包含以grep结尾的单词的行。

x\{m\}    #重复字符x，m次，如：&#39;0\{5\}&#39;匹配包含5个o的行。

x\{m,\}   #重复字符x,至少m次，如：&#39;o\{5,\}&#39;匹配至少有5个o的行。

x\{m,n\}  #重复字符x，至少m次，不多于n次，如：&#39;o\{5,10\}&#39;匹配5--10个o的行。

\w        #匹配文字和数字字符，也就是[A-Za-z0-9]，如：&#39;G\w*p&#39;匹配以G后跟零个或多个文字或数字字符，然后是p。

\W        #\w的反置形式，匹配一个或多个非单词字符，如点号句号等。

\b        #单词锁定符，如: &#39;\bgrep\b&#39;只匹配grep。
</code></pre><pre><code class="shell">grep -ic lin.x test.txt
</code></pre>
<p>效果和第一个一样。</p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[每天一个 Linux 命令（1）： useradd]]></title>
      <url>/2017/02/08/one-day-one-command-1-useradd/</url>
      <content type="html"><![CDATA[<p>在伯乐在线上看到一个《每天一个 Linux 命令》的系列文章，觉得有必要对自己用过的和没有用过得命令做一个归纳，只是简单的 How-To 类的说明，算是对有些很久不用的知识做个备忘。<br><a id="more"></a><br>Linux 的命令有很多，常用的有 100 个？，所以也没有什么顺序，想到哪写到哪。今天用到了一个创建用户命令 useradd 。</p>
<h3 id="useradd"><a href="#useradd" class="headerlink" title="useradd"></a>useradd</h3><p>useradd 命令的作用是创建新用户或更新默认用户。</p>
<p>useradd 命令格式：</p>
<pre><code>Usage: useradd [options] LOGIN

Options:
  -b, --base-dir BASE_DIR       base directory for the home directory of the new account
  -c, --comment COMMENT         GECOS field of the new account
  -d, --home-dir HOME_DIR       home directory of the new account
  -D, --defaults                print or change default useradd configuration
  -e, --expiredate EXPIRE_DATE  expiration date of the new account
  -f, --inactive INACTIVE       password inactivity period of the new account
  -g, --gid GROUP               name or ID of the primary group of the new account
  -G, --groups GROUPS           list of supplementary groups of the new account
  -h, --help                    display this help message and exit
  -k, --skel SKEL_DIR           use this alternative skeleton directory
  -K, --key KEY=VALUE           override /etc/login.defs defaults
  -l, --no-log-init             do not add the user to the lastlog and faillog databases
  -m, --create-home             create the user&#39;s home directory
  -M, --no-create-home          do not create the user&#39;s home directory
  -N, --no-user-group           do not create a group with the same name as the user
  -o, --non-unique              allow to create users with duplicate (non-unique) UID
  -p, --password PASSWORD       encrypted password of the new account
  -r, --system                  create a system account
  -R, --root CHROOT_DIR         directory to chroot into
  -s, --shell SHELL             login shell of the new account
  -u, --uid UID                 user ID of the new account
  -U, --user-group              create a group with the same name as the user
  -Z, --selinux-user SEUSER     use a specific SEUSER for the SELinux user mapping
      --extrausers              Use the extra users database
</code></pre><p>实际上用过的选项只有 -G 和 -g ， -g 是指定用户所属的主组， -G 是指定用户的附加组。<br>如创建一个用户 rolex ， 主组是 hadoop ，副组是 ops  </p>
<pre><code>useradd -g hadoop -G ops rolex
</code></pre><p>指定的组必须是存在的，所以这个命令通常和 groupadd 和 passwd 一起使用。</p>
<h3 id="groupadd"><a href="#groupadd" class="headerlink" title="groupadd"></a>groupadd</h3><p>groupadd 命令格式：</p>
<pre><code>Usage: groupadd [options] GROUP
-f, --force                   exit successfully if the group already exists, and cancel -g if the GID is already used
-g, --gid GID                 use GID for the new group
-h, --help                    display this help message and exit
-K, --key KEY=VALUE           override /etc/login.defs defaults
-o, --non-unique              allow to create groups with duplicate (non-unique) GID
-p, --password PASSWORD       use this encrypted password for the new group
-r, --system                  create a system account
-R, --root CHROOT_DIR         directory to chroot into
    --extrausers              Use the extra users database
</code></pre><h3 id="passwd"><a href="#passwd" class="headerlink" title="passwd"></a>passwd</h3><p>passwd 命令格式：</p>
<pre><code>Usage: passwd [options] [LOGIN]

Options:
  -a, --all                     report password status on all accounts
  -d, --delete                  delete the password for the named account
  -e, --expire                  force expire the password for the named account
  -h, --help                    display this help message and exit
  -k, --keep-tokens             change password only if expired
  -i, --inactive INACTIVE       set password inactive after expiration to INACTIVE
  -l, --lock                    lock the password of the named account
  -n, --mindays MIN_DAYS        set minimum number of days before password change to MIN_DAYS
  -q, --quiet                   quiet mode
  -r, --repository REPOSITORY   change password in REPOSITORY repository
  -R, --root CHROOT_DIR         directory to chroot into
  -S, --status                  report password status on the named account
  -u, --unlock                  unlock the password of the named account
  -w, --warndays WARN_DAYS      set expiration warning days to WARN_DAYS
  -x, --maxdays MAX_DAYS        set maximum number of days before password
</code></pre><h3 id="用户和组的相关知识"><a href="#用户和组的相关知识" class="headerlink" title="用户和组的相关知识"></a>用户和组的相关知识</h3><p>创建的用户可以在 /etc/passwd 中查看</p>
<pre><code>rolex@T450:~$ cat /etc/passwd
root:x:0:0:root:/root:/bin/bash
rolex:x:1000:1000:rolex,,,:/home/rolex:/bin/bash
</code></pre><p>格式为：</p>
<pre><code>用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录 Shell

1. 用户名：
2. 口令：/etc/passwd 是对所有人可见的，所以口令用 x 作为站位，真正的口令存放在 /etc/shadow 中。
   /etc/passwd 和 /etc/shadow 是一一对应的，通过 pwconv 程序生成。
3. 用户标识号：用户在系统中的唯一标识，root 用户 为 0 。
4. 组标识号：对应着 /etc/group 文件中的一条记录。格式为：``组名:口令:组标识号:组内用户列表``
5. 注释性描述：真的就是注释而已。
6. 主目录：用户的起始工作目录，就是登录后所处的位置。
7. 登录 Shell：Shell 是用户与 Linux 系统之间的接口，shell 程序有很多种类，Ubuntu 默认是 /bin/bash 。
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[南方姑娘]]></title>
      <url>/2017/02/03/nan-fang-gu-niang/</url>
      <content type="html"><![CDATA[<p>伴奏1563微微有些伤感，配上明亮的词，很容易感受到青春期无限爆棚的情感和对于现实微弱掌控力的强烈反差。<br><a id="more"></a><br><strong>原唱：</strong>赵雷<br><strong>专辑：</strong>赵小雷<br><strong>歌词：</strong><br>北方的村庄住着一个南方的姑娘<br>她总是喜欢穿着带花的裙子站在路旁<br>她的话不多但笑起来是那么平静优雅<br>她柔弱的眼神里装的是什么 是思念的忧伤<br>南方的小镇阴雨的冬天没有北方冷<br>她不需要臃肿的棉衣去遮盖她似水的面容<br>她在来去的街头留下影子芳香在回眸人的心头<br>眨眼的时间芳香已飘散影子已不见<br>南方姑娘 你是否习惯北方的秋凉<br>南方姑娘 你是否喜欢北方人的直爽<br>日子过的就像那些不眠的晚上<br>她嚼着口香糖对墙满谈着理想<br>南方姑娘 我们都在忍受着漫长<br>南方姑娘 是不是高楼遮住了你的希望<br>昨日的雨曾淋漓过她瘦弱的肩膀<br>夜空的北斗也没有让她找到迷途的方向<br>阳光里她在院子中央晾晒着衣裳<br>在四季的风中她散着头发安慰着时光<br>南方姑娘 你是否爱上了北方<br>南方姑娘 你说今天你就要回到你的家乡<br>思念让人心伤 她呼唤着你的泪光<br>南方的果子已熟 那是最简单的理想<br>啦……啦……<br>啦……啦……<br>啦……啦……<br>南……..方…………</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/nfgn_1.png" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/nfgn_1.png"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/nfgn_2.png" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/nfgn_2.png"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/nfgn_3.png" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/nfgn_3.png"></p>
]]></content>
      
        <categories>
            
            <category> Guitar </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Guitar </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[可惜不是你]]></title>
      <url>/2017/02/03/ke-xi-bu-shi-ni/</url>
      <content type="html"><![CDATA[<p>一次重逢，一个熟悉的语气，一段温馨的回忆，一条走了一半的路，一声“可惜不是你”的感叹。深爱过却留不下，真的除了说可惜之外，也无力再作什么。<br><a id="more"></a><br><strong>原唱：</strong>梁静茹<br><strong>专辑：</strong>丝路<br><strong>歌词：</strong><br>这一刻突然觉得好熟悉<br>像昨天今天同时在放映<br>我这句语气原来好像你<br>不就是我们爱过的证据<br>差一点骗了自己骗了你爱与被爱不一定成正比<br>我知道被疼是一种运气<br>但我无法完全交出自己<br>努力为你改变<br>却变不了预留的伏线<br>以为在你身边那也算永远<br>仿佛还是昨天<br>可是昨天已非常遥远<br>但闭上我双眼我还看得见<br>可惜不是你<br>陪我到最后<br>曾一起走却走失那路口<br>感谢那是你<br>牵过我的手<br>还能感受那温柔<br>那一段我们曾心贴着心<br>我想我更有权利关心你可能你已走进别人风景<br>多希望也有星光的投影<br>努力为你改变<br>却变不了预留的伏线<br>以为在你身边那也算永远<br>仿佛还是昨天<br>可是昨天已非常遥远<br>但闭上我双眼我还看得见<br>可惜不是你<br>陪我到最后<br>曾一起走却走失那路口<br>感谢那是你<br>牵过我的手<br>还能感受那温柔<br>可惜不是你<br>陪我到最后<br>曾一起走却走失那路口<br>感谢那是你<br>牵过我的手<br>还能感受那温柔<br>感谢那是你<br>牵过我的手<br>还能温暖我胸口</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/kxbsn_1.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/kxbsn_1.gif"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/kxbsn_2.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/kxbsn_2.gif"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/kxbsn_3.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/kxbsn_3.gif"></p>
]]></content>
      
        <categories>
            
            <category> Guitar </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Guitar </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[忽然之间]]></title>
      <url>/2017/02/03/hu-ran-zhi-jian/</url>
      <content type="html"><![CDATA[<p>感情细腻、耐听，很难想到是赈灾歌曲。<br><a id="more"></a><br><strong>原唱：</strong>莫文蔚<br><strong>专辑：</strong>就是莫文蔚<br><strong>歌词：</strong><br>忽然之间 天昏地暗<br>世界可以忽然什么都没有<br>我想起了你 再想到自己<br>我为什么总在非常脆弱的时候 怀念你<br>我明白太放不开你的爱 太熟悉你的关怀<br>分不开 想你算是安慰还是悲哀<br>而现在 就算时针都停摆 就算生命像尘埃<br>分不开 我们也许反而更相信爱<br>如果这天地 最终会消失<br>不想一路走来珍惜的回忆 没有你<br>我明白太放不开你的爱 太熟悉你的关怀<br>分不开 想你算是安慰还是悲哀<br>而现在 就算时针都停摆 就算生命像尘埃<br>分不开 我们也许反而更相信爱<br>我明白太放不开你的爱 太熟悉你的关怀<br>分不开 想你算是安慰还是悲哀<br>而现在 就算时针都停摆 就算生命像尘埃<br>分不开 我们也许反而更相信爱</p>
<p><strong>由李霖Gary改编的吉他弹唱版本和原曲的吉他弹奏有了比较大的改变，前奏还能隐约听出原曲的旋律，但是间奏已和原曲完全不同，不过这个版本的弹唱是我听过的最好的版本。</strong></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/hrzj_1.jpg" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/hrzj_1.jpg"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/hrzj_2.jpg" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/hrzj_2.jpg"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/hrzj_4.jpg" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/hrzj_3.jpg"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/hrzj_4.jpg" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/hrzj_4.jpg"></p>
]]></content>
      
        <categories>
            
            <category> Guitar </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Guitar </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[董小姐]]></title>
      <url>/2017/02/03/dong-xiao-jie/</url>
      <content type="html"><![CDATA[<p>怅孤独的情愫隐含在旋律中，能够击中很多人情感上的软肋。</p>
<a id="more"></a>
<p><strong>原唱：</strong>宋冬野<br><strong>专辑：</strong>摩登天空7<br><strong>歌词：</strong><br>董小姐 你从没忘记你的微笑<br>就算你和我一样 渴望着衰老<br>董小姐 你嘴角向下的时候很美<br>就像安和桥下 清澈的水<br>董小姐 我也是个复杂的动物<br>嘴上一句带过 心里却一直重复<br>董小姐 鼓楼的夜晚时间匆匆<br>陌生的人 请给我一支兰州<br>所以那些可能都不是真的 董小姐<br>你才不是一个没有故事的女同学<br>爱上一匹野马 可我的家里没有草原<br>这让我感到绝望 董小姐<br>董小姐 你熄灭了烟 说起从前<br>你说前半生就这样吧 还有明天<br>董小姐 你可知道我说够了再见<br>在五月的早晨 终于丢失了睡眠<br>所以那些可能都不是真的 董小姐<br>你才不是一个没有<br>故事的女同学<br>爱上一匹野马 可我的家里没有草原<br>这让我感到绝望 董小姐<br>所以那些可能都会是真的 董小姐<br>谁会不厌其烦的安慰那无知的少年<br>我想和你一样 不顾那些所以<br>跟我走吧 董小姐<br>躁起来吧 董小姐</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/d%E8%91%A3%E5%B0%8F%E5%A7%90_1.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/d%E8%91%A3%E5%B0%8F%E5%A7%90_1.gif"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/d%E8%91%A3%E5%B0%8F%E5%A7%90_2.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/d%E8%91%A3%E5%B0%8F%E5%A7%90_2.gif"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/d%E8%91%A3%E5%B0%8F%E5%A7%90_3.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/d%E8%91%A3%E5%B0%8F%E5%A7%90_3.gif"></p>
]]></content>
      
        <categories>
            
            <category> Guitar </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Guitar </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[当你老了]]></title>
      <url>/2017/02/03/dang-ni-lao-le/</url>
      <content type="html"><![CDATA[<p>平实，没有高潮，音符却在缓慢的移动中凝聚成对母亲的爱。</p>
<a id="more"></a>
<p><strong>原唱：</strong>赵照<br><strong>专辑：</strong>当你老了<br><strong>歌词：</strong><br>当你老了头发白了<br>睡意昏沉<br>当你老了 走不动了<br>炉火旁打盹 回忆青春<br>多少人曾爱你青春欢畅的时辰<br>爱慕你的美丽 假意或真心<br>只有一个人还爱你虔诚的灵魂<br>爱你苍老的脸上的皱纹<br>当你老了 眼眉低垂<br>灯火昏黄不定<br>风吹过来 你的消息<br>这就是我心里的歌<br>当你老了 头发白了<br>睡意昏沉<br>当你老了 走不动了<br>炉火旁打盹回忆青春<br>多少人曾爱你青春欢畅的时辰<br>爱慕你的美丽 假意或真心<br>只有一个人还爱你虔诚的灵魂<br>爱你苍老的脸上的皱纹<br>当我老了 眼眉低垂<br>灯火昏黄不定<br>风吹过来 你的消息<br>这就是我心里的歌<br>当我老了 我真希望<br>这首歌是唱给你的</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/guitar/dnll_1.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/dnll_1.gif"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/dnll_2.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/dnll_2.gif"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/dnll_3.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/dnll_3.gif"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/dnll_4.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/dnll_4.gif"></p>
]]></content>
      
        <categories>
            
            <category> Guitar </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Guitar </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[斑马斑马]]></title>
      <url>/2017/02/03/ban-ma-ban-ma/</url>
      <content type="html"><![CDATA[<p>一只受伤了的“斑马”浪迹天涯的故事。</p>
<a id="more"></a>
<p><strong>原唱：</strong>宋冬野<br><strong>专辑：</strong>安和桥北<br><strong>歌词：</strong><br>斑马，斑马 你不要睡着啦<br>再给我看看你受伤的尾巴<br>我不想去触碰你伤口的疤<br>我只想掀起你的头发<br>斑马，斑马 你回到了你的家<br>可我浪费着我寒冷的年华<br>你的城市没有一扇门为我打开啊<br>我终究还要回到路上<br>斑马，斑马，你来自南方的红色啊<br>是否也是个动人的故事啊<br>你隔壁的戏子如果不能留下<br>谁会和你睡到天亮<br>斑马，斑马 你还记得我吗<br>我是只会歌唱的傻瓜<br>斑马，斑马 你睡吧睡吧<br>我会背上吉他离开北方<br>斑马，斑马 你还记得我吗<br>我是强说着忧愁的孩子啊<br>斑马，斑马 你睡吧睡吧<br>我把你的青草带回故乡<br>斑马，斑马 你不要睡着啦<br>我只是个匆忙的旅人啊<br>斑马，斑马 你睡吧睡吧<br>我要卖掉我的房子<br>浪迹天涯</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/bmbm_1.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/bmbm_1.gif"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/bmbm_2.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/bmbm_2.gif"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/bmbm_3.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/bmbm_3.gif"></p>
]]></content>
      
        <categories>
            
            <category> Guitar </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Guitar </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[安河桥]]></title>
      <url>/2017/02/03/an-he-qiao/</url>
      <content type="html"><![CDATA[<p>安和桥下学会弹吉他，在安和桥下走过的童年和青春，在安和桥下遇见的爱情，在安和桥下历经成长。环境变迁将所有美好的记忆深藏心底，流于指间，弹于心弦。<br><a id="more"></a><br><strong>原唱：</strong>宋冬野<br><strong>专辑：</strong>安和桥北<br><strong>歌词：</strong><br>让我再看你一遍<br>从南到北<br>像是被五环路蒙住的双眼<br>请你再讲一遍<br>关于那天<br>抱着盒子的姑娘<br>和擦汗的男人<br>我知道 那些夏天<br>就像青春一样回不来<br>代替梦想的也只能是勉为其难<br>我知道 吹过的牛逼<br>也会随青春一笑了之<br>让我困在城市里<br>纪念你<br>让我再尝一口<br>秋天的酒<br>一直往南方开<br>不会太久<br>让我再听一遍<br>最美的那一句<br>你回家了<br>我在等你呢<br>（music）<br>我知道<br>那些夏天就像青春一样回不来<br>代替梦想的<br>也只能是勉为其难<br>我知道<br>吹过的牛逼也会随青春一笑了之<br>让我困在城市里 纪念你<br>我知道<br>那些夏天就像你一样回不来<br>我已不会再对谁<br>满怀期待<br>我知道<br>这个世界每天都有太多遗憾<br>所以 你好 再见</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/anheqiao_1.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/anheqiao_1.gif"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/anheqiao_2.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/anheqiao_2.gif"></p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/anheqiao_3.gif" alt="https://raw.githubusercontent.com/bsyonline/pic/master/guitar/anheqiao_3.gif"></p>
]]></content>
      
        <categories>
            
            <category> Guitar </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Guitar </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark 类型转换异常的处理]]></title>
      <url>/2017/02/03/spark-type-conversion-exception/</url>
      <content type="html"><![CDATA[<p>在调试 Spark 程序的时候报了一个类型转换异常，信息如下：</p>
<pre><code>java.lang.ClassCastException: scala.Tuple2 cannot be cast to java.lang.Comparable
</code></pre><a id="more"></a>
<p>查看代码，发现是在调用 top() 方法时出现的，如果是调用 collect() 方法不会出现异常。</p>
<p>分析原因为在 top 时要对 RDD 的内容进行排序，但是 RDD 中存放的是 tuple ，并没有实现 Comparator 接口。<br>所以可以自己实现一个 tuple 的比较器。</p>
<pre><code>public class Tuple2Comparator implements Serializable, Comparator {

    @Override
    public int compare(Object o1, Object o2) {
        Tuple2 o11 = (Tuple2) o1;
        Tuple2 o12 = (Tuple2) o2;
        if (o11._1.hashCode() &gt; o12._1.hashCode()) {
            return 1;
        } else {
            return -1;
        }
    }
}
</code></pre><p>在使用 top 的时候，指定自定义的比较器。</p>
<pre><code>rdd.top(5, new Tuple2Comparator());
</code></pre><p>因为我只用到了 Tuple2 ，所以只定义了 Tuple2 的比较器，等对 scala 熟悉一些，再改进成通用所有 tuple 的。</p>
]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark ExecutorLostFailure 错误简单分析]]></title>
      <url>/2017/02/03/spark-executor-lost-failure/</url>
      <content type="html"><![CDATA[<p>用 Spark 读 HBase 的 4400 万数据的表时，出现了 ExecutorLostFailure 错误，如果读一个 100 万的数据表则正常执行。<a href="https://www.zybuluo.com/xtccc/note/254078" target="_blank" rel="external">网上资料</a>说它常常出现在数据量很大，特别是shuffle的数据量很大，或者 executor 内存比较小的时候。<br>我的环境 spark 1.5 ，由 4 个节点组成的 spark standalone 集群，每个 100G 内存，24 个 cores ，在运行的时候显示可用内存不到 50G （看资料说 spark 会将可用的内存的 50% 用于执行，50% 用于存储）。整个 4400 万数据全部加载到内存的话，大概会占用 40-50G 的存储。所以猜想是由于 executor 的内存不够，在查看 spark 日志也发现 java.lang.OutOfMemoryError: Java heap space 信息，所以基本可以确定是内存过小的缘故。</p>
<p>在寻找解决办法时，发现<a href="https://my.oschina.net/tearsky/blog/629201" target="_blank" rel="external">网络资料</a>有如下说明：</p>
<blockquote>
<p>由于我们在执行 Spark 任务是，读取所需要的原数据，数据量太大，导致在 Worker 上面分配的任务执行数据时所需要的内存不够，直接导致内存溢出了，所以我们有必要增加 Worker 上面的内存来满足程序运行需要。<br>在 Spark Streaming 或者其他 Spark 任务中，会遇到在 Spark 中常见的问题，典型如 Executor Lost 相关的问题 ( shuffle fetch 失败，Task 失败重试等 )。这就意味着发生了内存不足或者数据倾斜的问题。<br>这个目前需要考虑如下几个点以获得解决方案：</p>
<p>A、相同资源下，增加 partition 数可以减少内存问题。 原因如下：通过增加 partition 数，每个 task 要处理的数据少了，同一时间内，所有正在运行的 task 要处理的数量少了很多，所有 Executor 占用的内存也变小了。这可以缓解数据倾斜以及内存不足的压力。</p>
<p>B、关注 shuffle read 阶段的并行数。例如 reduce, group 之类的函数，其实他们都有第二个参数，并行度 ( partition 数 )，只是大家一般都不设置。不过出了问题再设置一下，也不错。</p>
<p>C、给一个 Executor 核数设置的太多，也就意味着同一时刻，在该 Executor 的内存压力会更大，GC 也会更频繁。我一般会控制在 3 个左右。然后通过提高 Executor 数量来保持资源的总量不变。</p>
</blockquote>
<p>所以按照 A 方案对程序进行了修改：</p>
<ol>
<li>将 HBase 表按 rowkey 进行划分，大概分成了 30 份；</li>
<li>按 startRow 和 stopRow 分别读取转换成 RDD；</li>
<li>将 30 个 RDD 进行 union 操作合并成一个 RDD，在进行运算。</li>
</ol>
<p>另外，针对 spark-submit 的参数也进行了相应的调整:</p>
<pre><code>--executor-memory 90G
--driver-memory 95G
--executor-cores 3
</code></pre><p>每台机器有 24 个 CPU ，如果不指定 executor-cores , 将会使用所有的 cores ，这样会因 GC 造成比较大的内存压力，在尝试将 executor-cores 降低后，内存溢出明显减少。</p>
<p>这样修改以后，程序正常执行。</p>
]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SBT 打包]]></title>
      <url>/2017/01/17/sbt-build-package/</url>
      <content type="html"><![CDATA[<p>紧接上一篇（<a href="../../../../2017/01/10/Spark-入门/">Spark 入门</a>），本节讨论一下 SBT 打包。</p>
<a id="more"></a>
<p>上节中，sbt 环境安装好后，执行</p>
<pre><code>sbt package
</code></pre><p>即可完成打包，并且上传到 spark 集群中也能够正常运行。但是，仔细观察可以发现，上传的 jar 包只有 135 KB，显然打包只包含了编译后的文件，依赖 jar 包并没有打包，而依赖的 spark jar 在集群中都有，所以也可以正常执行。<br>如果程序中引用了一些其他的 jar 这样就需要指定 –jars 参数，不过集群环境中需要在每个 worker 节点都安装相同的 jar 依赖，操作还是比较繁琐，比较方便的方式是将所有的依赖 jar 都打包成一个 <strong>fat jar</strong> 。</p>
<h3 id="sbt-assembly-使用"><a href="#sbt-assembly-使用" class="headerlink" title="sbt-assembly 使用"></a>sbt-assembly 使用</h3><p>SBT 的 sbt-assembly 插件可以帮助我们打包。<br>插件文档参考：<a href="https://github.com/sbt/sbt-assembly" target="_blank" rel="external">https://github.com/sbt/sbt-assembly</a></p>
<p>按照文档，简单三步可完成打包。</p>
<ol>
<li>修改 project/plugins.sbt ，加入<pre><code>addSbtPlugin(&quot;com.eed3si9n&quot; % &quot;sbt-assembly&quot; % &quot;0.14.3&quot;)
</code></pre></li>
<li><p>在根目录下创建 assembly.sbt</p>
<pre><code>import AssemblyKeys._

assemblySettings

name := &quot;spark-data-engine-batch&quot;
version := &quot;1.0&quot;
</code></pre></li>
<li><p>执行 sbt assembly</p>
</li>
</ol>
<h3 id="解决冲突"><a href="#解决冲突" class="headerlink" title="解决冲突"></a>解决冲突</h3><p>多数情况下，打包过程会出现异常，比如文件重复。</p>
<pre><code>[error] (*:assembly) deduplicate: different file contents found in the following:
[error] /home/rolex/.ivy2/cache/commons-collections/commons-collections/jars/commons-collections-3.2.1.jar:org/apache/commons/collections/ArrayStack.class
[error] /home/rolex/.ivy2/cache/commons-beanutils/commons-beanutils/jars/commons-beanutils-1.7.0.jar:org/apache/commons/collections/ArrayStack.class
[error] /home/rolex/.ivy2/cache/commons-beanutils/commons-beanutils-core/jars/commons-beanutils-core-1.8.0.jar:org/apache/commons/collections/ArrayStack.class
</code></pre><p>处理这类问题通常有两种方式：</p>
<ol>
<li>将其中一个 jar 在 sbt 中的 scope 指定为 Provided</li>
<li>使用 sbt-assembly 的 mergeStrategy</li>
</ol>
<p>第一种方式操作最简单，但是有时无法避免同一个包被引用多次的情况，那就只能使用第二种方式来合并冲突。<br>根据报错信息，参考 sbt-assembly 文档的示例进行修改。</p>
<pre><code>mergeStrategy in assembly := {
  case PathList(&quot;javax&quot;, &quot;servlet&quot;, xs@_*) =&gt; MergeStrategy.first
  case PathList(&quot;javax&quot;, &quot;el&quot;, xs@_*) =&gt; MergeStrategy.first
  case PathList(&quot;org&quot;, &quot;apache&quot;, xs@_*) =&gt; MergeStrategy.first
  case PathList(&quot;org&quot;, &quot;objectweb&quot;, &quot;asm&quot;, xs@_*) =&gt; MergeStrategy.first
  case PathList(&quot;org&quot;, &quot;slf4j&quot;, xs@_*) =&gt; MergeStrategy.first
  case PathList(ps@_*) if ps.last endsWith &quot;.properties&quot; =&gt; MergeStrategy.first
  case x =&gt;
    val oldStrategy = (mergeStrategy in assembly).value
    oldStrategy(x)
}
</code></pre><p>至此，使用 sbt assembly 就可以正确生成 fat jar 了。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> SBT </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hexo 3 安装简单指北]]></title>
      <url>/2017/01/16/hexo-3-installation/</url>
      <content type="html"><![CDATA[<p>之前装过一次 hexo ，用了一段时间，后来重做系统之后，安装出现了一些问题，花了一些时间重新整理一下。</p>
<p>node.js 和 git 安装好后，开始安装 hexo 。</p>
<pre><code class="shell">sudo npm install hexo -g
</code></pre>
<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><pre><code class="shell">hexo init hexo
</code></pre>
<p>网上有教程说先创建目录，再执行</p>
<pre><code>hexo init
</code></pre><p>也是可以的。</p>
<p>这步执行完就可以执行 clean ，generate ， server 等命令了。</p>
<h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><p>如果要使用 github 提供的网站服务，就需要将 hexo 部署到 github.io 上，所以需要先安装部署插件。</p>
<pre><code class="shell">npm install hexo-deployer-git --save
</code></pre>
<p>配置 git</p>
<pre><code>deploy:
  type: git
  repository: git@github.com:bsyonline/bsyonline.github.io.git
  branch: master
</code></pre><pre><code class="shell">heox clean
hexo g
hexo deploy
</code></pre>
<p>至此，访问 bsyinline.github.io 就可以看到网页。</p>
<h3 id="primer-主题安装"><a href="#primer-主题安装" class="headerlink" title="primer 主题安装"></a>primer 主题安装</h3><ol>
<li><p>primer 是一款 github 风格的主题，项目地址 <a href="https://github.com/yumemor/hexo-theme-primer" target="_blank" rel="external">https://github.com/yumemor/hexo-theme-primer</a> 。<br>我使用的是 primer 2.0 ，按照说明文档配置即可 <a href="https://github.com/yumemor/hexo-theme-primer/tree/2.0" target="_blank" rel="external">https://github.com/yumemor/hexo-theme-primer/tree/2.0</a> 。</p>
</li>
<li><p>添加 guitar 菜单</p>
</li>
</ol>
<p>guitar 基本参考 open 布局，在 themes/primer/layout/ 下创建 guitar.ejs</p>
<pre><code>&lt;body&gt;
    &lt;%- partial(&#39;_partial/header&#39;) %&gt;
    &lt;%- partial(&#39;_partial/guitar&#39;, {post: page}) %&gt;
</code></pre><p>在 themes/primer/layout/_partial/ 下创建 guitar.ejs</p>
<pre><code>&lt;section class=&quot;collection-head geopattern&quot;&gt;
    &lt;div style=&quot;height:30px;&quot;&gt;&lt;h1&gt;&amp;nbsp;&lt;/h1&gt;&lt;/div&gt;
&lt;/section&gt;
&lt;section class=&quot;container&quot;&gt;
    &lt;div class=&quot;search&quot; &gt;
      &lt;%- partial(&#39;_widget/guitar-search&#39;) %&gt;
    &lt;/div&gt;
    &lt;div class=&quot;guitar-card-list&quot;&gt;
      &lt;% site.categories.each(function(category){ %&gt;
        &lt;% if(category.name == &#39;guitar&#39;){ %&gt;
          &lt;% category.posts.each(function(post){ %&gt;
            &lt;li class=&quot;collection-card&quot;&gt;
              &lt;a href=&quot;{%=clone_url%}&quot; class=&quot;card text-center&quot; target=&quot;_blank&quot;&gt;
                  &lt;div class=&quot;thumbnail&quot; style=&quot;margin-bottom:0px&quot;&gt;
                      &lt;div class=&quot;guitar-card-image geopattern&quot; data-pattern-id=&quot;&lt;%=category.name%&gt;&quot;&gt;
                          &lt;div class=&quot;guitar-card-image-cell&quot;&gt;
                              &lt;h3 class=&quot;guitar-card-title&quot;&gt;
                                &lt;%- partial(&#39;post/title&#39;,{class_name:&#39;posts-list-name&#39;,post:post,index:true}) %&gt;
                              &lt;/h3&gt;
                          &lt;/div&gt;
                      &lt;/div&gt;
                  &lt;/div&gt;
              &lt;/a&gt;
            &lt;/li&gt;
          &lt;% }) %&gt;
        &lt;%}%&gt;
      &lt;% }) %&gt;
    &lt;/div&gt;
&lt;/section&gt;
</code></pre><p>在 themes/primer/source/_vendor/guitar/ 下创建 guitar.css</p>
<pre><code>.guitar-card-list {
    padding-left: 0;
    position: relative;
    padding-top: 2em;
}
.guitar-card-image {
    display: table;
    height: 120px;
    width: 100%;
    border-radius: 4px;
}

.guitar-card-image .guitar-card-image-cell {
    display: table-cell;
    vertical-align: middle;
    padding-left: 1em;
}

.guitar-card-image h3 {
    margin: 0;
    font-size: 1.5em;
    color: white;
}

.guitar-card-image a {
    color: #fff;
}

.guitar-card-description {
    height: 2em;
    overflow: hidden;
}

.card .thumbnail:hover .guitar-card-title a{
    color:#000;
    text-decoration:none;
}

.guitar-card-text .meta-info {
    margin-right: 10px;
}
</code></pre><p>在 themes/primer/source/css/style.styl 中引入 guitar.css</p>
<pre><code>@import &quot;_vendor/guitar/guitar.css&quot;
</code></pre><p>在 themes/primer/layout/_widget/ 下创建 guitar-search.ejs</p>
<pre><code>&lt;div id=&quot;site_search&quot; style=&quot;margin-left:10px;height:40px;&quot;&gt;
    &lt;div style=&quot;float:left;height:40px;margin-right:10px;margin-bottom:10px;font-size:18pt;&quot;&gt;
The Emerald Dream&lt;/div&gt;
    &lt;div style=&quot;float:right;height:40px;margin-bottom:10px;&quot;&gt;
    &lt;!-- Google --&gt;
    &lt;% if( theme.search.use == &quot;google&quot; ){ %&gt;
        &lt;form action=&quot;http://www.google.com/search?&quot; data-site=&quot;&lt;%=theme.url%&gt;&quot;&gt;
            &lt;input type=&quot;text&quot; id=&quot;search_box&quot; name=&quot;q&quot; placeholder=&quot;Search&quot; style=&quot;width: 600px;&quot;&gt;
            &lt;button type=&quot;button&quot; class=&quot;btn btn-default&quot; id=&quot;site_search_do&quot;&gt;&lt;span class=&quot;octicon octicon-search&quot;&gt;&lt;/span&gt;&lt;/button&gt;
        &lt;/form&gt;
    &lt;% } %&gt;

    &lt;!-- 本地搜索 --&gt;
    &lt;% if( theme.search.use == &quot;local&quot; ){ %&gt;
        &lt;!-- Local --&gt;
        &lt;form id=&quot;search-form&quot; &gt;
            &lt;input type=&quot;text&quot; id=&quot;search&quot; placeholder=&quot;Search&quot; style=&quot;width: 600px;background-color: #fff;
    background-position: right center;
    background-repeat: no-repeat;
    border: 1px solid #ccc;
    border-radius: 0px;
    box-shadow: 0 0px 0px rgba(0, 0, 0, 0.075) inset;
    color: #333;
    font-size: 13px;
        height:25px;
    min-height: 34px;
    outline: medium none;
    padding: 7px 8px;
    vertical-align: middle;&quot;&gt;
        &lt;/form&gt;

        &lt;div id=&quot;local-search-result&quot; style=&quot;width: 600px;&quot;&gt;&lt;/div&gt;

    &lt;% } %&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;style&gt;
#local-search-result{
    border-left: 1px solid #ccc;
    border-right: 1px solid #ccc;
    border-radius: 0px;
    box-shadow: 0 0px 0px rgba(0, 0, 0, 0.075) inset;
    font-size: 14px;
}
.search-result-list{
    width: 600px;

}
#local-search-result ul li{
    width: 598px;
    border-bottom: 1px solid #ccc;
    margin-top: -1px;
}
&lt;/style&gt;
</code></pre>]]></content>
      
        <categories>
            
            <category> Wiki </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch 6 REST API Practice VII - Settings]]></title>
      <url>/2017/01/03/elasticsearch-6-rest-api-practice-7/</url>
      <content type="html"><![CDATA[<h2 id="VII-Settings"><a href="#VII-Settings" class="headerlink" title="VII. Settings"></a>VII. Settings</h2><h4 id="Cat-Count"><a href="#Cat-Count" class="headerlink" title="Cat Count"></a>Cat Count</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/count/change?v&quot;
</code></pre><h4 id="Cat-health"><a href="#Cat-health" class="headerlink" title="Cat health"></a>Cat health</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/health?v&quot;
</code></pre><p>查看状态是 yellow 的索引</p>
<pre><code>curl -X GET &quot;localhost:9200/_cat/indices?v&amp;health=yellow&quot;
</code></pre><p>按 count 排序</p>
<pre><code>curl -X GET &quot;localhost:9200/_cat/indices?v&amp;s=docs.count:desc&quot;
</code></pre><h4 id="Cat-Template"><a href="#Cat-Template" class="headerlink" title="Cat Template"></a>Cat Template</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/templates?v&amp;s=name&quot;
</code></pre><h4 id="Cat-Snapshot"><a href="#Cat-Snapshot" class="headerlink" title="Cat Snapshot"></a>Cat Snapshot</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/snapshots/repo1?v&amp;s=id&quot;
</code></pre><h4 id="Cat-Recovery"><a href="#Cat-Recovery" class="headerlink" title="Cat Recovery"></a>Cat Recovery</h4><pre><code>curl -X GET &quot;localhost:9200/_cat/recovery?v&quot;
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[一个简单的 Spring Boot + JMS Sample]]></title>
      <url>/2016/10/26/spring-boot-jms/</url>
      <content type="html"><![CDATA[<p>学习 spring boot 集成 JMS 时写的一个小程序。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/jms_2.png" alt=""></p>
<a id="more"></a>
<p><strong>1. 加入 maven 依赖</strong><br>pom.xml</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;exclusions&gt;
        &lt;exclusion&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;
        &lt;/exclusion&gt;
    &lt;/exclusions&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework&lt;/groupId&gt;
    &lt;artifactId&gt;spring-jms&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt;
    &lt;artifactId&gt;activemq-core&lt;/artifactId&gt;
    &lt;version&gt;5.7.0&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-activemq&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
    &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;
    &lt;artifactId&gt;gson&lt;/artifactId&gt;
    &lt;version&gt;2.3.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p><strong>2. 在 Server 端的主类中加入 @EnableJms 注解，并注册两个队列</strong></p>
<pre><code class="java">import org.apache.activemq.command.ActiveMQQueue;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;
import org.springframework.jms.annotation.EnableJms;

import javax.jms.Queue;

@SpringBootApplication
@EnableJms
public class Main {

    public static void main(String[] args) {
        SpringApplication.run(Main.class, args);
    }

    @Bean(name = &quot;requestQueue&quot;)
    public Queue requestQueue() {
        return new ActiveMQQueue(&quot;Request.Queue&quot;);
    }

    @Bean(name = &quot;responseQueue&quot;)
    public Queue responseQueue() {
        return new ActiveMQQueue(&quot;Response.Queue&quot;);
    }
}
</code></pre>
<p><strong>3. 创建查询请求消息的消费者和查询响应消息的生产者</strong><br>生产者</p>
<pre><code class="java">import javax.annotation.Resource;
import javax.jms.Queue;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.jms.core.JmsMessagingTemplate;
import org.springframework.stereotype.Component;

@Component
public class Producer {

    @Autowired
    private JmsMessagingTemplate jmsMessagingTemplate;

    @Resource(name = &quot;responseQueue&quot;)
    private Queue responseQueue;

    public void send(String msg) {
        this.jmsMessagingTemplate.convertAndSend(this.responseQueue, msg);
    }

    public void send(Response msg) {
         this.jmsMessagingTemplate.convertAndSend(this.responseQueue, msg);
    }

}
</code></pre>
<p>消费者</p>
<pre><code class="java">import com.google.gson.Gson;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.jms.annotation.JmsListener;
import org.springframework.stereotype.Component;

@Component
public class Consumer {

    @Autowired
    Producer producer;

    @JmsListener(destination = &quot;Request.Queue&quot;)
    public void receiveQueue(String text) {
        System.out.println(text);
        Gson gson = new Gson();
         Request request = gson.fromJson(text, Request.class);
        System.out.println(&quot;do query&quot;);
        producer.send(new Gson().toJson(new Response(request.getId(),&quot;ok&quot;)));
    }

    @JmsListener(destination = &quot;Request.Queue&quot;)
    public void receiveQueue(Request obj) {
        System.out.println(obj.toString());
        System.out.println(&quot;do query&quot;);
        producer.send(new Gson().toJson(new Response(obj.getId(),&quot;ok&quot;)));
    }

}
</code></pre>
<p>实体类</p>
<pre><code class="java">import java.io.Serializable;

public class Request implements Serializable {

    private static final long serialVersionUID = -797586847427389162L;
    private final String id;

    public Request(String id) {
        this.id = id;
    }

    public String getId() {
        return id;
    }
}

import java.io.Serializable;

public class Response implements Serializable {

  private static final long serialVersionUID = -797586847427389162L;
    private final String id;
    private final String result;

    public Response(String id, String result) {
        this.id = id;
        this.result = result;
    }

    public String getId() {
        return id;
    }


    public String getResult() {
        return result;
    }
}
</code></pre>
<p>客户端和服务端类似，把生产者和消费者对应的队列交换即可。</p>
<pre><code class="java">import org.apache.activemq.command.ActiveMQQueue;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;
import org.springframework.jms.annotation.EnableJms;

import javax.jms.Queue;

@SpringBootApplication
@EnableJms
public class Main {

    @Bean(name = &quot;requestQueue&quot;)
    public Queue requestQueue() {
        return new ActiveMQQueue(&quot;Request.Queue&quot;);
    }

    @Bean(name = &quot;responseQueue&quot;)
    public Queue responseQueue() {
        return new ActiveMQQueue(&quot;Response.Queue&quot;);
    }

    public static void main(String[] args) {
        SpringApplication.run(Main.class, args);
    }
}
</code></pre>
<p>生产者</p>
<pre><code class="java">import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.jms.core.JmsTemplate;
import org.springframework.stereotype.Component;

import javax.annotation.Resource;
import javax.jms.Queue;

@Component
public class Producer {

    @Autowired
    private JmsTemplate jmsTemplate;

    @Resource(name = &quot;requestQueue&quot;)
    private Queue requestQueue;

    public void send(String msg) {
        this.jmsTemplate.convertAndSend(this.requestQueue, msg);
    }

    public void send(Request request) {
         this.jmsTemplate.convertAndSend(this.requestQueue, request);
    }

}
</code></pre>
<p>消费者</p>
<pre><code class="java">import org.springframework.jms.annotation.JmsListener;
import org.springframework.stereotype.Component;

@Component
public class Consumer {

    @JmsListener(destination = &quot;Response.Queue&quot;)
    public void receiveQueue(String text) {
        System.out.println(&quot;receive json response&quot;);
        System.out.println(text);
    }

    @JmsListener(destination = &quot;Response.Queue&quot;)
    public void receiveQueue(Request obj) {
        System.out.println(&quot;receive response&quot;);
        System.out.println(obj.toString());
    }

}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Spring Boot </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Boot </tag>
            
            <tag> JMS </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Ubuntu 16.04 修复 grub]]></title>
      <url>/2016/10/24/ubuntu-16-04-restore-grub/</url>
      <content type="html"><![CDATA[<p>今天手欠，更新了一下系统更新，结果无限引导界面，进不了系统了。之前都是直接重做系统，不过这次懒得捯饬备份，试了试修复 grub 。上网科普了一下步骤，看着都比较简单，不过第一次搞还是比较懵逼，记录一下操作步骤，备忘。<br><a id="more"></a><br><strong>1. 查看 /boot 分区位置</strong><br>首先准备一张 U 盘启动盘，用 U 盘启动，选择 Live CD ，进入系统后，打开终端,查看 /boot 分区在什么位置。</p>
<pre><code>sudo fdisk -l
</code></pre><p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/fdisk.png" alt=""><br>我的系统装在 /dev/sda5 , /dev/sda6, /dev/sda7 上，/boot 是单独在 /dev/sda5 的分区上。<br><strong>2. 挂载目录</strong></p>
<pre><code>sudo -i
mkdir /media/tmp
mount /dev/sda6 /media/tmp
mount /dev/sda5 /media/tmp/boot
</code></pre><p><strong>3. 安装 grub</strong></p>
<pre><code>grub-install --root-directory=/media/tmp /dev/sda
</code></pre><p>看到信息 <code>Installation finished， no error occured</code> 则安装成功，不出意外，重启就可以正常引导了。</p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Ubuntu </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Firewalld 试用]]></title>
      <url>/2016/10/21/firewalld-introduce/</url>
      <content type="html"><![CDATA[<p>CentOs 7 filewall 简单命令。</p>
<h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><pre><code>systemctl start firewalld
</code></pre><h3 id="停止"><a href="#停止" class="headerlink" title="停止"></a>停止</h3><pre><code>systemctl stop firewalld
</code></pre><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><pre><code>systemctl disable firewalld
</code></pre><h3 id="查看所有打开端口"><a href="#查看所有打开端口" class="headerlink" title="查看所有打开端口"></a>查看所有打开端口</h3><pre><code>firewall-cmd --zone=dmz --list-ports
</code></pre><h3 id="加入端口"><a href="#加入端口" class="headerlink" title="加入端口"></a>加入端口</h3><pre><code>firewall-cmd --zone=dmz --add-port=8080/tcp
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CentOS 7 环境升级]]></title>
      <url>/2016/10/21/centos-7-environmental-upgrade/</url>
      <content type="html"><![CDATA[<p>docker 1.12 版本要求 CentOS 7 ，生产环境系统升级到 CentOS 7 后安装 docker 环境步骤简单记录备忘。</p>
<a id="more"></a>
<h3 id="升级-linux-内核"><a href="#升级-linux-内核" class="headerlink" title="升级 linux 内核"></a>升级 linux 内核</h3><p>当前系统内核</p>
<pre><code># uname -r
3.10.0-327.el7.x86_64
</code></pre><p><strong>1. 下载新内核文件</strong></p>
<p>在 <a href="https://cdn.kernel.org/" target="_blank" rel="external">https://cdn.kernel.org/</a> 上看到当前最新稳定版本是 4.8.3 。</p>
<pre><code>wget https://cdn.kernel.org/pub/linux/kernel/v4.x/linux-4.8.3.tar.xz
</code></pre><p><strong>2.解压</strong></p>
<p>拷贝到压缩包到 /usr/src 下</p>
<pre><code>cp linux-4.8.3.tar.xz /usr/src
cd /usr/src
tar -xJf linux-4.8.3.tar.xz
</code></pre><p><strong>3. 清除残留编译文件</strong></p>
<pre><code>cd linux-4.8.3
make mrproper &amp;&amp; make clean
</code></pre><p>发现没有 gcc ，所以先安装 gcc 。</p>
<pre><code>yum install -y gcc
</code></pre><p>安装完成后重新执行 make 。<br><strong>4. 生成编译配置表</strong></p>
<pre><code>make oldconfig
</code></pre><p>默认配置，一路回车即可。<br><strong>5. 编译</strong></p>
<pre><code>make
</code></pre><p>编译过程中报错 <code>openssl/opensslv.h：没有那个文件或目录</code></p>
<pre><code>yum install -y openssl-devel
</code></pre><p>安装完成后重新编译。<br><strong>6. 编译安装模块</strong></p>
<pre><code>make modules &amp;&amp; make modules_install
make install
</code></pre><p><strong>7. 修改启动项&amp;重启</strong></p>
<p>到此安装结束，重启可以看到内核没变，有可能是启动顺序没改。</p>
<pre><code>awk -F\&#39; &#39;$1==&quot;menuentry &quot; {print $2}&#39; /etc/grub2.cfg
CentOS Linux (4.8.3) 7 (Core)
CentOS Linux (3.10.0-327.el7.x86_64) 7 (Core)
CentOS Linux (0-rescue-22be0cd4be87429fa67b5df5203a9126) 7 (Core)
</code></pre><p>修改启动项</p>
<pre><code>grub2-set-default 0
</code></pre><p>再重启就 OK 了。</p>
<pre><code>uname -r
4.8.3
</code></pre><blockquote>
<p>如果对内核版本没有要求，只是更新到最新稳定版本，直接用 yum 简单 3 步即可完成。<br>导入 Public Key</p>
<pre><code>rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm
</code></pre><p>升级内核</p>
<pre><code>yum --enablerepo=elrepo-kernel install kernel-lt -y
</code></pre><p>修改启动项</p>
<pre><code>grub2-set-default 0
</code></pre></blockquote>
<h3 id="安装-docker"><a href="#安装-docker" class="headerlink" title="安装 docker"></a>安装 docker</h3><p>按照 docker 官网文档安装即可。<br><strong>1. 添加源</strong></p>
<pre><code>sudo tee /etc/yum.repos.d/docker.repo &lt;&lt;-&#39;EOF&#39;
[dockerrepo]
name=Docker Repository
baseurl=https://yum.dockerproject.org/repo/main/centos/7/
enabled=1
gpgcheck=1
gpgkey=https://yum.dockerproject.org/gpg
EOF
</code></pre><p><strong>2. 安装</strong></p>
<pre><code>yum install -y docker-engine
</code></pre><p><strong>3. 启动服务</strong></p>
<pre><code>systemctl enable docker.service
</code></pre><p><strong>4. 启动镜像</strong></p>
<pre><code>systemctl start docker
</code></pre><p><strong>5. 验证</strong></p>
<pre><code>docker run --rm hello-world
</code></pre><p><strong>6. 创建 docker 组</strong></p>
<pre><code>sudo groupadd docker
</code></pre><p><strong>7. 添加用户到 docker 组</strong></p>
<pre><code>groupadd ops
useradd -G ops -g ops ops
sudo usermod -aG docker your_username`
</code></pre><h3 id="设置-docker-的启动参数"><a href="#设置-docker-的启动参数" class="headerlink" title="设置 docker 的启动参数"></a>设置 docker 的启动参数</h3><p>docker 默认使用的存储启动是 device-mapper ,需要改成 overlay 。<br><strong>1. 安装 overlay</strong></p>
<pre><code>sudo tee /etc/modules-load.d/overlay.conf &lt;&lt;-&#39;EOF&#39;
overlay
EOF
</code></pre><p>重启后确认是否安装成功。</p>
<pre><code>lsmod | grep overlay
overlay                49152  0
</code></pre><p><strong>2. 修改 docker 启动参数</strong></p>
<p>启用 docker.service 后，在 <code>/etc/systemd/system/multi-user.target.wants</code> 目录会生成 docker.service 文件连接，修改文件中的 <code>ExecStart=/usr/bin/dockerd</code> 。</p>
<pre><code>cd /etc/systemd/system/multi-user.target.wants
</code></pre><p>添加启动参数</p>
<pre><code>ExecStart=/usr/bin/dockerd --storage-driver=overlay2  --graph=&quot;/home/docker&quot;
</code></pre><p>重启系统。</p>
<h3 id="关闭-firewalld"><a href="#关闭-firewalld" class="headerlink" title="关闭 firewalld"></a>关闭 firewalld</h3><p>firewalld 是 CentOS 7 引入的新服务，参考 <a href="../../../../2016/10/21/Firewalld-试用/">Firewalld 试用</a></p>
<pre><code>systemctl stop firewalld.service
systemctl disable firewalld.service
</code></pre><h3 id="关闭-selinux"><a href="#关闭-selinux" class="headerlink" title="关闭 selinux"></a>关闭 selinux</h3><pre><code>vi /etc/selinux/config
SELINUX=disabled
</code></pre><h3 id="文件共享"><a href="#文件共享" class="headerlink" title="文件共享"></a>文件共享</h3><p>有 p75 和 p76 两台机器，需要将两台机器的 /u01/data/conf 目录共享。</p>
<p><strong>1. 安装</strong></p>
<pre><code>yum install -y glusterfs glusterfs-server glusterfs-fuse
glusterfs --version
</code></pre><p><strong>2. 启动服务</strong></p>
<pre><code>service glusterd start
service glusterfsd start
</code></pre><p><strong>3. 添加节点</strong></p>
<p>在任意节点执行即可。</p>
<pre><code>gluster peer probe p76

gluster pool list
UUID                    Hostname     State
6a6962c3-42ab-49bf-9844-9e98cf419613    p76          Connected
a0c173b4-341a-4f47-9eea-5e2ca9713665    localhost    Connected
</code></pre><p><strong>4. 创建数据目录</strong></p>
<pre><code>mkdir -p /opt/data/conf
gluster volume create gv3 replica 2 transport tcp p75:/u01/data/conf p76:/u01/data/conf force
gluster volume info
</code></pre><p><strong>5. 启动</strong></p>
<pre><code>gluster volume start gv3
</code></pre><p><strong>6. 安装 glusterfs 客户端</strong></p>
<p>将 p76 设置为客户端。</p>
<pre><code>yum -y install glusterfs glusterfs-fuse
</code></pre><p><strong>7. 挂载目录</strong></p>
<pre><code>mkdir -p /opt/data/conf
mount -t glusterfs -o rw p75:gv3 /opt/data/conf
</code></pre><p>至此，配置完成。在 p76 的 /opt/data/conf 目录放置的配置文件，在 p75 和 p76 的 /u01/data/conf 目录都能读取到。</p>
<blockquote>
<p>共享目录解决的是配置文件共享的问题，统一日志收集用ELK。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java Request 的测试方法]]></title>
      <url>/2016/10/17/java-request-testing-in-jmeter/</url>
      <content type="html"><![CDATA[<p>Jmeter 是一款简单的性能测试工具，以前都是用来测试 API 接口，没试过测试 Java 程序，这是一个例子。</p>
<a id="more"></a>
<p>Jmeter 使用，可参考 <a href="../../../../2016/09/07/Jmeter-使用入门/">Jmeter 使用入门</a>。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/jmeter.png" alt=""></p>
<h3 id="java-request-测试"><a href="#java-request-测试" class="headerlink" title="java request 测试"></a>java request 测试</h3><p>使用 jmeter 测试 java 程序，需要结合 jemter_java 编写测试代码。</p>
<ol>
<li>创建 maven 工程<br>pmx.xml<br>```xml<br>&lt;?xml version=”1.0” encoding=”UTF-8”?&gt;<br>&lt;project xmlns=”<a href="http://maven.apache.org/POM/4.0.0" target="_blank" rel="external">http://maven.apache.org/POM/4.0.0</a>“<pre><code>  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
  xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
</code></pre> <modelversion>4.0.0</modelversion><br> <groupid>com.rolex.jmeter</groupid><br> <artifactid>java-request-sample</artifactid><br> <version>1.0-SNAPSHOT</version><br> <build><pre><code> &lt;plugins&gt;
     &lt;plugin&gt;
         &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
         &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
         &lt;version&gt;2.3.2&lt;/version&gt;
         &lt;configuration&gt;
             &lt;source&gt;1.6&lt;/source&gt;
             &lt;target&gt;1.6&lt;/target&gt;
             &lt;encoding&gt;UTF-8&lt;/encoding&gt;
         &lt;/configuration&gt;
     &lt;/plugin&gt;
     &lt;plugin&gt;
         &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
         &lt;configuration&gt;
             &lt;descriptorRefs&gt;
                 &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;
             &lt;/descriptorRefs&gt;
         &lt;/configuration&gt;
         &lt;executions&gt;
             &lt;execution&gt;
                 &lt;id&gt;make-assembly&lt;/id&gt;
                 &lt;phase&gt;package&lt;/phase&gt;
                 &lt;goals&gt;
                     &lt;goal&gt;attached&lt;/goal&gt;
                 &lt;/goals&gt;
             &lt;/execution&gt;
         &lt;/executions&gt;
     &lt;/plugin&gt;
 &lt;/plugins&gt;
 &lt;resources&gt;
     &lt;resource&gt;
         &lt;targetPath&gt;libs/&lt;/targetPath&gt;
         &lt;directory&gt;libs/&lt;/directory&gt;
         &lt;includes&gt;
             &lt;include&gt;**/certNoToMd5.jar&lt;/include&gt;
             &lt;include&gt;**/Lite-20111106.jar&lt;/include&gt;
             &lt;include&gt;**/quantum-auth-1.0-SNAPSHOT.jar&lt;/include&gt;
         &lt;/includes&gt;
     &lt;/resource&gt;
 &lt;/resources&gt;
</code></pre> </build> <dependencies><br>     <dependency><br>         <groupid>com.rolex.jmeter.test</groupid><br>         <artifactid>jmeter-test</artifactid><br>         <version>1.0.0</version><br>         <scope>system</scope><br>         <systempath>${project.basedir}/libs/certNoToMd5.jar</systempath><br>     </dependency><br>     <!-- https://mvnrepository.com/artifact/org.apache.jmeter/ApacheJMeter_core --><br>     <dependency><br>         <groupid>org.apache.jmeter</groupid><br>         <artifactid>ApacheJMeter_core</artifactid><br>         <version>3.0</version><br>     </dependency><br>     <!-- https://mvnrepository.com/artifact/org.apache.jmeter/ApacheJMeter_java --><br>     <dependency><br>         <groupid>org.apache.jmeter</groupid><br>         <artifactid>ApacheJMeter_java</artifactid><br>         <version>3.0</version><br>     </dependency><br> </dependencies>

</li>
</ol>
<p></p>
<pre><code>

```java
import org.apache.jmeter.config.Arguments;
import org.apache.jmeter.protocol.java.sampler.AbstractJavaSamplerClient;
import org.apache.jmeter.protocol.java.sampler.JavaSamplerContext;
import org.apache.jmeter.samplers.SampleResult;

import com.seeks.support.lxcernointerface.LxcernoClientUtils;

public class JavaRequest extends AbstractJavaSamplerClient {

    SampleResult result;
    String param;

    @Override
    public void setupTest(JavaSamplerContext context) {
        result = new SampleResult();
        super.setupTest(context);
    }

    @Override
    public Arguments getDefaultParameters() {
        Arguments params = new Arguments();
        params.addArgument(&quot;arg1&quot;, &quot;0&quot;);
        return params;

    }

    @Override
    public SampleResult runTest(JavaSamplerContext arg0) {

        boolean success = true;
        result.sampleStart();
        param = arg0.getParameter(&quot;arg1&quot;);
        try {
            // do some test
        } catch (Exception e) {
            e.printStackTrace();
            success = false;
        } finally {
            result.sampleEnd();
            result.setSuccessful(success);
        }
        return result;

    }

    @Override
    public void teardownTest(JavaSamplerContext context) {
        super.teardownTest(context);
    }

}
</code></pre><p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/javaRequest.png" alt=""></p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Jmeter </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Swagger : API 设计工具介绍]]></title>
      <url>/2016/10/14/swagger-introduction/</url>
      <content type="html"><![CDATA[<p>Swagger 是一款基于 Node.js 的 API 设计工具，官方网站为 <a href="http://swagger.io" target="_blank" rel="external">swagger.io</a> 。Swagger Editor 能直观的生成 API 接口的说明，方便接口开发。</p>
<a id="more"></a>
<h3 id="Swagger-Editor"><a href="#Swagger-Editor" class="headerlink" title="Swagger Editor"></a>Swagger Editor</h3><p>Editor 可以在线使用 <a href="http://editor.swagger.io/#/" target="_blank" rel="external">http://editor.swagger.io/#/</a> ，也可以在本地环境运行，安装也很简单。</p>
<pre><code>git clone https://github.com/swagger-api/swagger-editor.git
cd swagger-editor
npm install
npm start
</code></pre><p>访问 <code>http://localhost:8080/</code> 可看到效果。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/swagger-editor.png" alt=""></p>
<p>swagger 使用 yaml 语法规范，简单的可参考官方示例，语法详细见 <a href="https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md" target="_blank" rel="external">https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md</a> 。</p>
<p>示例：</p>
<pre><code class="ymal">swagger: &quot;2.0&quot;
info:
  version: 1.0.0
  title: data-engine-api 接口
host: 127.0.0.1:8080
schemes:
  - http
basePath: /query
consumes:
  - application/json
produces:
  - application/json
paths:
  /entInfo:
    get:
      summary: 查询企业基本信息。
      description: description
      parameters:
        - name: entId
          in: query
          description: 唯一标识
          required: true
          type: string
        - name: mask
          in: query
          description: 数据集权限，以&#39;,&#39;分隔
          required: true
          type: string
        - name: entType
          in: query
          description: 企业类型.
          required: false
          type: string
      responses:
        200:
          description: An array of Characters
          schema:
            $ref: &quot;#/definitions/Info&quot;
          headers:
            Access-Control-Allow-Origin:
              description: The number of allowed requests in the current period
              type: string
            Access-Control-Allow-Headers:
              description: The number of remaining requests in the current period
              type: string
        400:
          description: You tried to teleport. That&#39;s just not allowed.
          schema:
            $ref: &quot;#/definitions/Error&quot;
        500:
          description: System error.
          schema:
            $ref: &quot;#/definitions/Error&quot;
        default:
          description: Unexpected errors
          schema:
            $ref: &quot;#/definitions/Error&quot;
  /changeDetails:
    get:
      summary: 变更详情
      description: |
        Gets `Person` objects.
        Optional query param of **size** determines
      parameters:
        - name: uid
          type: string
          required: true
          in: query
          description: 用户id
        - name: pripid
          type: string
          required: true
          in: query
          description: 企业唯一标识
        - name: startDate
          in: query
          required: true
          type: string
          description: 开始时间
        - name: endDate
          in: query
          type: string
          required: true
          description: 结束时间
      responses:
        200:
          description: Successful response
          schema:
            $ref: &quot;#/definitions/ChangeDetails&quot;

definitions:
  ChangeDetails:
    type: object
    properties:
      uid:
        type: string
        description: 用户id
      pripid:
        type: string
        description: 企业唯一标识
      changeDetails:
        type: array
        items:
          $ref: &quot;#/definitions/DataModel&quot;
  Info:
    type: object
    properties:
      basic:
        $ref: &quot;#/definitions/Basic&quot;
      priPerson:
        type: array
        items:
          $ref: &quot;#/definitions/PriPerson&quot;
      shareHolder:
        type: array
        items:
          $ref: &quot;#/definitions/ShareHolder&quot;
      priPersonInv:
        type: array
        items:
          $ref: &quot;#/definitions/PriPersonInv&quot;
      entInv:
        type: array
        items:
          $ref: &quot;#/definitions/EntInv&quot;
      priPersonPosition:
        type: array
        items:
          $ref: &quot;#/definitions/PriPersonPosition&quot;
      sharesImpawn:
        type: array
        items:
          $ref: &quot;#/definitions/SharesImpawn&quot;
      sharesFrost:
        type: array
        items:
          $ref: &quot;#/definitions/SharesFrost&quot;
      disSxbzxr:
        type: array
        items:
          $ref: &quot;#/definitions/DisSxbzxr&quot;
      bzxr:
        type: array
        items:
          $ref: &quot;#/definitions/Bzxr&quot;
      filiation:
        type: array
        items:
          $ref: &quot;#/definitions/Filiation&quot;
      morInfo:
        type: array
        items:
          $ref: &quot;#/definitions/MorInfo&quot;
      morGuaInfo:
        type: array
        items:
          $ref: &quot;#/definitions/MorGuaInfo&quot;
      alter:
        type: array
        items:
          $ref: &quot;#/definitions/Alter&quot;
      liquidation:
        type: array
        items:
          $ref: &quot;#/definitions/Liquidation&quot;
      orgCode:
        type: array
        items:
          $ref: &quot;#/definitions/OrgCode&quot;
      xzcf:
        type: array
        items:
          $ref: &quot;#/definitions/Xzcf&quot;
  Basic:
    type: object
    properties:
      name:
        type: string
        description: 法定代表人姓名
      entName:
        type: string
        description: 企业名称
      identity:
        type: string
        description: 个人识别码
      regNo:
        type: string
        description: 注册号
      oriRegNo:
        type: string
        description: 原注册号
      orgCodes:        
        type: string
        description: 组织机构代码
      regCap:          
        type: string
        description: 注册资本(万元)
      recCap:          
        type: string
        description: 实收资本(万元)
      regCapCur:       
        type: string
        description: 注册资本币种
      esDate:          
        type: string
        description: 开业日期
      opFrom:          
        type: string
        description: 经营期限自
      opTo:            
        type: string
        description: 经营期限至
      entType:         
        type: string
        description: 企业(机构)类型
      entStatus:       
        type: string
        description: 经营状态
      changeDate:      
        type: string
        description: 变更日期
      canDate:         
        type: string
        description: 注销日期
      revDate:         
        type: string
        description: 吊销日期
      dom:             
        type: string
        description: 住址
      abuItem:         
        type: string
        description: 许可经营项目
      cbuItem:         
        type: string
        description: 一般经营项目
      opScope:         
        type: string
        description: 经营(业务)范围
      opScoAndForm:    
        type: string
        description: 经营(业务)范围及方式
      regOrgCode:      
        type: string
        description: 注册地址行政区编号
      regOrgProvince:  
        type: string
        description: 所在省份
      ancheYear:       
        type: string
        description: 最后年检年度
      ancheDate:       
        type: string
        description: 最后年检日期
      industryPhyCode:
        type: string
        description: 行业门类代码
      industryCoCode:  
        type: string
        description: 国民经济行业代码
      empNum:          
        type: string
        description: 员工人数
      entNameEng:      
        type: string
        description: 企业英文名称
      tel:
        type: string
        description: 电话
      creditCode:
        type: string
        description: 信用代码
      province:        
        type: string
        description: 省节点编码
      oploc:           
        type: string
        description: 经营场所
      domDistrict:     
        type: string
        description: 住所所在行政区划
      pripid:
        type: string
        description: 唯一key
  PriPerson:
    type: object
    properties:
      name:
        type: string
        description: 人员姓名
      entName:
        type: string
  ShareHolder:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string
  PriPersonInv:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string
  EntInv:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string
  PriPersonPosition:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string
  SharesImpawn:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string      
  SharesFrost:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string
  DisSxbzxr:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string
  Bzxr:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string
  Filiation:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string
  MorInfo:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string        
  MorGuaInfo:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string
  Alter:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string  
  Liquidation:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string   
  OrgCode:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string        
  Xzcf:
    type: object
    properties:
      name:
        type: string
      entName:
        type: string
  DataModel:
    type: object
    properties:
      pripid:
        type: string
      table:
        type: string
      sequenceId:
        type: string
      changeItems:
        type: array
        items:
          $ref: &quot;#/definitions/ChangeItem&quot;
  ChangeItem:
    type: object
    properties:
      column:
        type: string
      newValue:
        type: string
      oldValue:
        type: string
      type:
        type: string
      date:
        type: string
      own:
        type: string
      key:
        type: string
      apprDate:
        type: string
  Error:
    type: object
    properties:
      code:
        type: string
        description: A machine readable application error code. Not to be confused with the HTTP status code in the response.
      result:
        type: object
</code></pre>
<h3 id="Swagger-UI"><a href="#Swagger-UI" class="headerlink" title="Swagger UI"></a>Swagger UI</h3><p>本地安装比较简单，按步骤执行命令应该没有问题，前提需要有 Node.js 环境。</p>
<pre><code>git clone git@github.com:swagger-api/swagger-ui.git
cd swagger-ui
npm install
npm run build
npm run serve
</code></pre><p>访问 <code>http://localhost:8080</code> 可看到 demo 。<br>如果有 docker 环境，那使用 docker 部署运行更加简单一些。</p>
<pre><code>sudo docker build -t swagger-ui .
sudo docker run -d -p 5000:8080 --name swagger-ui wagger-ui
</code></pre><p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/swagger-ui-index.png" alt=""></p>
<p>将自己写好的接口文件从 Editor 中导出，保存到 dist/ 下任意位置。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/swagger-editor-export.png" alt=""></p>
<p>在浏览器中输入路径即可看到自己的接口列表。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/swagger-ui-customiz.png" alt=""></p>
<p>在浏览器中可以直接进行调试，并可直观看到相关信息。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/swagger-ui-post.png" alt=""></p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> RESTful </tag>
            
            <tag> Swagger </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker : 删除所有为 none 的镜像]]></title>
      <url>/2016/10/12/docker-remove-images-with-none-tag/</url>
      <content type="html"><![CDATA[<p>在使用 Docker 时，如果创建镜像出错，会产生 REPOSITORY 和 TAG 为空的镜像，要删除这些镜像，可以使用</p>
<pre><code class="shell">sudo docker rmi image_id
</code></pre>
<p>如果这样的镜像有很多，删除就有点麻烦。我们可以利用一个小技巧来批量删除：</p>
<pre><code class="shell">sudo docker images | grep none | awk &#39;{print $3}&#39; | xargs sudo docker rmi -f
</code></pre>
]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java NIO 详解]]></title>
      <url>/2016/09/21/java-nio-introduction/</url>
      <content type="html"><![CDATA[<p>Java BIO 我们已经很熟悉了，它实现起来比较简单，一个线程只能维护一个连接。但是弊端也很明显，即服务器开销大，资源浪费严重。<br>Java NIO 是在JDK 1.4中引入的。Java NIO 弥补了原来的 I/O 的不足，它在标准 Java 代码中提供了高速的、面向块的 I/O。Java I/O 库与 Java NIO 最重要的区别是数据打包和传输的方式的不同，Java I/O 以<strong>流</strong>的方式处理数据，而 Java NIO 以<strong>块</strong>的方式处理数据。</p>
<p>先通过两张图对比一下。</p>
<p><img src="https://github.com/bsyonline/pic/blob/master/20191203/20191209205325.png?raw=true" style="width:800px"></p>
<p>Java NIO 加入了 selector，channel，buffer 三个组件。一个 client 有对应的 buffer ，buffer 有对应的 channel。一个线程维护一个 selector ，一个 selector 可以维护多个 channel。selector 通过事件机制，在多个 channel 间切换，有 IO 操作时，线程可以切换到对应的 channel 进行操作，如果没有 IO 操作，线程还可以做其他工作而不会阻塞，这样就大量的节省了服务器的资源。</p>
<p>下面我们通过代码对 Java I/O 和 Java NIO 进行说明。</p>
<pre><code class="java">/**
 * 使用IO读取指定文件的前1024个字节的内容。
 * @param args
 * @throws Exception
 */
public static void main(String[] args) throws Exception {
    FileInputStream is = new FileInputStream(&quot;GitHub.txt&quot;);

    byte[] buffer = new byte[8];

    is.read(buffer);

    System.out.println(new String(buffer));

    is.close();
}

/**
 * 使用NIO读取指定文件的前1024个字节的内容。
 * @param args
 * @throws Exception
 */
public static void main(String[] args) throws Exception {
    FileInputStream is = new FileInputStream(&quot;GitHub.txt&quot;);

    //为该文件输入流生成唯一的文件通道  FileChannel
    FileChannel channel = is.getChannel();

    //开辟一个长度为1024的字节缓冲区
    ByteBuffer buffer = ByteBuffer.allocate(8);

    channel.read(buffer);

    System.out.println(new String(buffer.array()));

    channel.close();
    is.close();
}
</code></pre>
<p>从上边的代码可以看出，Java NIO 的主要使用了 Channel 和 Buffer ，它们是 Java NIO 的核心。FileChannel 和 ByteBuffer 是 Channel 和 Buffer 最常用的实现类。<br>Java NIO 是 Java I/O 的补充而不是替代，在某些场景使用 Java I/O 要容易很多。例如一次读一行，使用 BufferedReader 的 readLine() 方法很容易，而要使用 Java NIO 则需要自己来判断一行从哪里结束。</p>
<h3 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h3><p>Channel 相当于 Java I/O 的流，Java NIO 所有的操作都由 Channel 开始的。</p>
<h3 id="Buffer"><a href="#Buffer" class="headerlink" title="Buffer"></a>Buffer</h3><p>Channel 提供了从源读取数据的渠道，而数据的操作都是由 Buffer 完成的。每个 Buffer 都有 capacity 、limit 、position 、mark 4 个属性。</p>
<ul>
<li>capacity<br>Buffer 的容量</li>
<li>limit<br>limit 是 Buffer 操作数据的范围。写数据时，limit 的上限等于 capacity，读数据时，limit 为有效数据的长度。</li>
<li>position<br>position 指示了 Buffer 中下一个可操作的数据的位置。</li>
<li>mark<br>临时的 position 。</li>
</ul>
<p>以上边代码为例。当 new 一个 ByteBuffer 时，首先将 capacity 和 limit 的大小都设置为 8 ，mark 为 -1， position 为 0 ，初始化完成 capacity 的大小就不变了。</p>
<p><img src="https://s1.ax1x.com/2020/03/16/8J1BrT.png" alt="8J1BrT.png" border="0" style="width:400px"><br>有了 Buffer 就可以开始写数据了。从 Chanel 读 5 个字节到 Buffer 中，position 变为 5 。<br><img src="https://s1.ax1x.com/2020/03/16/8J1Y5j.png" alt="8J1Y5j.png" border="0" style="width:400px"><br>现在要从 Buffer 中将数据写到 Chanel 中，需要执行 flip() 方法。执行 flip() 方法后，position 变为 0， limit 变为 5 。</p>
<p><img src="https://s1.ax1x.com/2020/03/16/8J14sK.png" alt="8J14sK.png" border="0" style="width:400px"><br>如果 Buffer 中写了 3 个字节到 Chanel 中，如果执行 clear() 方法，剩余的 2 个字节将被丢弃，Buffer 可重新读入数据。如果想保留 2 个字节后续处理，可执行 compact() ，Buffer 将拷贝 2 个字节到起始位置，将 position 置为 2 ，limit 置为 8 。<br><img src="https://s1.ax1x.com/2020/03/16/8J1LRI.png" alt="8J1LRI.png" border="0" style="width:400px"></p>
<h3 id="大文件处理"><a href="#大文件处理" class="headerlink" title="大文件处理"></a>大文件处理</h3><blockquote>
<p>关于 NIO MappedByteBuffer 的例子，我在测试的时候并没有得到和网上资料相同的结果，还不知道原因</p>
</blockquote>
<p>Java 中大文件处理通常会使用带缓冲的流，Java NIO 提供了 MappedByteBuffer 来处理大文件。MappedByteBuffer 继承自 ByteBuffer ，它使用 direct buffer 方式来读写文件，这种方式也叫做内存映射，没有 JVM 和操作系统之间的复制操作，直接调用系统底层的缓存，所以效率比较高。<br>我试了一下用 MappedByteBuffer 的方式复制文件，速度还没有使用 Java I/O 的 Buffered stream 快，不知道问题何在。</p>
<pre><code class="java">public static void foo1() throws IOException {
    long start = System.currentTimeMillis();
    BufferedInputStream bis = new BufferedInputStream(new FileInputStream(new File(&quot;spark-1.6.1-bin-hadoop2.6.tgz&quot;)));
    BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(&quot;spark1.tgz&quot;));
    int length;
    byte[] buffer = new byte[1024];
    while ((length = bis.read(buffer, 0, buffer.length)) != -1) {
        bos.write(buffer, 0, length);
    }
    long end = System.currentTimeMillis();
    System.out.println((end - start) + &quot;ms&quot;);
    bis.close();
    bos.close();
}

public static void foo4() throws IOException {
    long start = System.currentTimeMillis();
    String srcFile = &quot;spark-1.6.1-bin-hadoop2.6.tgz&quot;;
    String destFile = &quot;spark4.tgz&quot;;
    Path path = Paths.get(srcFile);
    FileOutputStream rafo = new FileOutputStream(destFile);
    FileChannel fci = FileChannel.open(path,StandardOpenOption.READ,StandardOpenOption.WRITE);
    FileChannel fco = rafo.getChannel();
    MappedByteBuffer mbbi = fci.map(FileChannel.MapMode.READ_ONLY, 0, path.toFile().length());
    fco.write(mbbi);
    long end = System.currentTimeMillis();
    System.out.println((end - start) + &quot;ms&quot;);
    fci.close();
    fco.close();
    rafo.close();
}
</code></pre>
<p>只能先理解一下概念。<br>在操作大文件的时候，如果文件大到无法放到内存，可以用 MappedByteBuffer 映射硬盘文件到内存(不是真放到内存)，处理可以简单一些。<br>网上另一个用法：</p>
<pre><code class="java">int length = 0x8FFFFFF;//一个byte占1B，所以共向文件中存128M的数据
try (FileChannel channel = FileChannel.open(Paths.get(&quot;src/c.txt&quot;),
        StandardOpenOption.READ, StandardOpenOption.WRITE);) {
    MappedByteBuffer mapBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, length);
    for (int i = 0; i &lt; length; i++) {
        mapBuffer.put((byte) 0);
    }
    for (int i = length / 2; i &lt; length / 2 + 4; i++) {
        //像数组一样访问
        System.out.println(mapBuffer.get(i));
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Netty </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
            <tag> NIO </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[死锁]]></title>
      <url>/2016/09/14/multi-thread-dead-lock/</url>
      <content type="html"><![CDATA[<p>死锁是2个以上的线程由于竞争同一资源形成阻塞。</p>
<h3 id="如何写一个死锁"><a href="#如何写一个死锁" class="headerlink" title="如何写一个死锁"></a>如何写一个死锁</h3><p>最后一个未阻塞的线程在调用 Condition.signal() / Condition.signalAll() / Object.notify() / notifyAll() 之前调用了 Condition.await() 或 Object.wait() 或调用了 Condition.signal() / Object.notify()，被通知的线程没有达到执行条件，又阻塞了。</p>
<pre><code class="java">class DeadLock implements Runnable {
    ReentrantLock lock = new ReentrantLock();
    Condition condition = lock.newCondition();

    @Override
    public void run(){
        try{
            lock.lock();
            condition.await();
        } finally {
            lock.unlock();
        }
    }

    public static void main(String[] args){
        DeadLock deadlock = new DeadLock();
        Thread t1 = new Thread(deadlock);
        Thread t2 = new Thread(deadlock);
        t1.start();
        t2.start();
    }
}
</code></pre>
<p>使用 jstack 工具查看：</p>
<pre><code>&quot;Thread-1&quot; #13 prio=5 os_prio=0 tid=0x00007f5b4815d000 nid=0x39c5 waiting on condition [0x00007f5b2621b000]
   java.lang.Thread.State: WAITING (parking)
    at sun.misc.Unsafe.park(Native Method)
    - parking to wait for  &lt;0x00000000d8093868&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    at com.chinadaas.riskbell.tools.DeadLockTest.run(DeadLockTest.java:20)
    at java.lang.Thread.run(Thread.java:745)

&quot;Thread-0&quot; #12 prio=5 os_prio=0 tid=0x00007f5b4815b000 nid=0x39c4 waiting on condition [0x00007f5b2631c000]
   java.lang.Thread.State: WAITING (parking)
    at sun.misc.Unsafe.park(Native Method)
    - parking to wait for  &lt;0x00000000d8093868&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
    at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
    at com.chinadaas.riskbell.tools.DeadLockTest.run(DeadLockTest.java:20)
    at java.lang.Thread.run(Thread.java:745)
</code></pre><p>如果线程是可以被打断的，可以使用程序打断死锁。(程序作为示例，执行时未达到效果。)</p>
<pre><code class="java">public void DeadlockChecker(){
    new Thread(new Runnable() {
        ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();
        @Override
        public void run() {
            while (true) {
                long[] deadlockThreadIds = threadMXBean.findDeadlockedThreads();
                if (deadlockThreadIds != null) {
                    ThreadInfo[] threadInfos = threadMXBean.getThreadInfo(deadlockThreadIds);
                    for (Thread t : Thread.getAllStackTraces().keySet()) {
                        for (int i = 0; i &lt; threadInfos.length; i++) {
                            System.out.println(threadInfos[i].getThreadId());
                            if (t.getId() == threadInfos[i].getThreadId()) {
                                t.interrupt();
                            }
                        }
                    }
                }
            }
        }
    }).start();
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux 定时任务 crontab 命令详解]]></title>
      <url>/2016/09/13/linux-crontab-introduction/</url>
      <content type="html"><![CDATA[<p>安装</p>
<pre><code>yum install crontabs
</code></pre><p>查看当前用户的定时任务</p>
<pre><code>crontab -l
</code></pre><p>启动定时任务</p>
<pre><code>5 3 * * * /u01/backup.sh
</code></pre><p>crontab 时间格式<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/crontab.png" alt=""></p>
<p>举例：</p>
<pre><code>每分钟执行一次            
*  *  *  *  *

每隔一小时执行一次        
00  *  *  *  *
or
* */1 * * *  (/表示频率)

每小时的 15 和 45 分各执行一次
15,45 * * * * （,表示并列）

在每天上午 8 - 11 时中间每小时 15 ，45分各执行一次
15,45 8-11 * * * command （-表示范围）

每个星期一的上午 8 点到 11 点的第 3 和第 15 分钟执行
3,15 8-11 * * 1 command

每隔两天的上午 8 点到 11 点的第 3 和第 15 分钟执行
3,15 8-11 */2 * * command
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL 备份与还原]]></title>
      <url>/2016/09/08/mysql-backup-and-restore/</url>
      <content type="html"><![CDATA[<p>使用 mysqldump 命令</p>
<p>备份</p>
<pre><code>mysqldump -uroot -p123456 -h 192.168.201.73 meta &gt; meta_dump_`date +%F`.sql
</code></pre><p>压缩备份</p>
<pre><code>mysqldump -uroot -p123456 -h 192.168.201.73 meta | gzip &gt; backupfile.sql.gz
</code></pre><p>还原</p>
<pre><code>mysql -uroot -p123456 -h192.168.201.74 meta &lt; backupfile.sql
</code></pre><p>顺便贴一下 mysqldump 的帮助文档。</p>
<pre><code>[ops@d20 ~]$ mysqldump
Usage: mysqldump [OPTIONS] database [tables]
OR     mysqldump [OPTIONS] --databases [OPTIONS] DB1 [DB2 DB3...]
OR     mysqldump [OPTIONS] --all-databases [OPTIONS]
For more options, use mysqldump --help
[ops@d20 ~]$ mysqldump --hrlp
mysqldump: unknown option &#39;--hrlp&#39;
[ops@d20 ~]$ mysqldump --help
mysqldump  Ver 10.13 Distrib 5.6.31, for Linux (x86_64)
Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Dumping structure and contents of MySQL databases and tables.
Usage: mysqldump [OPTIONS] database [tables]
OR     mysqldump [OPTIONS] --databases [OPTIONS] DB1 [DB2 DB3...]
OR     mysqldump [OPTIONS] --all-databases [OPTIONS]

Default options are read from the following files in the given order:
/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf
The following groups are read: mysqldump client
The following options may be given as the first argument:
--print-defaults        Print the program argument list and exit.
--no-defaults           Don&#39;t read default options from any option file,
                        except for login file.
--defaults-file=#       Only read default options from the given file #.
--defaults-extra-file=# Read this file after the global files are read.
--defaults-group-suffix=#
                        Also read groups with concat(group, suffix)
--login-path=#          Read this path from the login file.
  -A, --all-databases Dump all the databases. This will be same as --databases
                      with all databases selected.
  -Y, --all-tablespaces
                      Dump all the tablespaces.
  -y, --no-tablespaces
                      Do not dump any tablespace information.
  --add-drop-database Add a DROP DATABASE before each create.
  --add-drop-table    Add a DROP TABLE before each create.
                      (Defaults to on; use --skip-add-drop-table to disable.)
  --add-drop-trigger  Add a DROP TRIGGER before each create.
  --add-locks         Add locks around INSERT statements.
                      (Defaults to on; use --skip-add-locks to disable.)
  --allow-keywords    Allow creation of column names that are keywords.
  --apply-slave-statements
                      Adds &#39;STOP SLAVE&#39; prior to &#39;CHANGE MASTER&#39; and &#39;START
                      SLAVE&#39; to bottom of dump.
  --bind-address=name IP address to bind to.
  --character-sets-dir=name
                      Directory for character set files.
  -i, --comments      Write additional information.
                      (Defaults to on; use --skip-comments to disable.)
  --compatible=name   Change the dump to be compatible with a given mode. By
                      default tables are dumped in a format optimized for
                      MySQL. Legal modes are: ansi, mysql323, mysql40,
                      postgresql, oracle, mssql, db2, maxdb, no_key_options,
                      no_table_options, no_field_options. One can use several
                      modes separated by commas. Note: Requires MySQL server
                      version 4.1.0 or higher. This option is ignored with
                      earlier server versions.
  --compact           Give less verbose output (useful for debugging). Disables
                      structure comments and header/footer constructs.  Enables
                      options --skip-add-drop-table --skip-add-locks
                      --skip-comments --skip-disable-keys --skip-set-charset.
  -c, --complete-insert
                      Use complete insert statements.
  -C, --compress      Use compression in server/client protocol.
  -a, --create-options
                      Include all MySQL specific create options.
                      (Defaults to on; use --skip-create-options to disable.)
  -B, --databases     Dump several databases. Note the difference in usage; in
                      this case no tables are given. All name arguments are
                      regarded as database names. &#39;USE db_name;&#39; will be
                      included in the output.
  -#, --debug[=#]     This is a non-debug version. Catch this and exit.
  --debug-check       Check memory and open file usage at exit.
  --debug-info        Print some debug info at exit.
  --default-character-set=name
                      Set the default character set.
  --delayed-insert    Insert rows with INSERT DELAYED.
  --delete-master-logs
                      Delete logs on master after backup. This automatically
                      enables --master-data.
  -K, --disable-keys  &#39;/*!40000 ALTER TABLE tb_name DISABLE KEYS */; and
                      &#39;/*!40000 ALTER TABLE tb_name ENABLE KEYS */; will be put
                      in the output.
                      (Defaults to on; use --skip-disable-keys to disable.)
  --dump-slave[=#]    This causes the binary log position and filename of the
                      master to be appended to the dumped data output. Setting
                      the value to 1, will printit as a CHANGE MASTER command
                      in the dumped data output; if equal to 2, that command
                      will be prefixed with a comment symbol. This option will
                      turn --lock-all-tables on, unless --single-transaction is
                      specified too (in which case a global read lock is only
                      taken a short time at the beginning of the dump - don&#39;t
                      forget to read about --single-transaction below). In all
                      cases any action on logs will happen at the exact moment
                      of the dump.Option automatically turns --lock-tables off.
  -E, --events        Dump events.
  -e, --extended-insert
                      Use multiple-row INSERT syntax that include several
                      VALUES lists.
                      (Defaults to on; use --skip-extended-insert to disable.)
  --fields-terminated-by=name
                      Fields in the output file are terminated by the given
                      string.
  --fields-enclosed-by=name
                      Fields in the output file are enclosed by the given
                      character.
  --fields-optionally-enclosed-by=name
                      Fields in the output file are optionally enclosed by the
                      given character.
  --fields-escaped-by=name
                      Fields in the output file are escaped by the given
                      character.
  -F, --flush-logs    Flush logs file in server before starting dump. Note that
                      if you dump many databases at once (using the option
                      --databases= or --all-databases), the logs will be
                      flushed for each database dumped. The exception is when
                      using --lock-all-tables or --master-data: in this case
                      the logs will be flushed only once, corresponding to the
                      moment all tables are locked. So if you want your dump
                      and the log flush to happen at the same exact moment you
                      should use --lock-all-tables or --master-data with
                      --flush-logs.
  --flush-privileges  Emit a FLUSH PRIVILEGES statement after dumping the mysql
                      database.  This option should be used any time the dump
                      contains the mysql database and any other database that
                      depends on the data in the mysql database for proper
                      restore.
  -f, --force         Continue even if we get an SQL error.
  -?, --help          Display this help message and exit.
  --hex-blob          Dump binary strings (BINARY, VARBINARY, BLOB) in
                      hexadecimal format.
  -h, --host=name     Connect to host.
  --ignore-table=name Do not dump the specified table. To specify more than one
                      table to ignore, use the directive multiple times, once
                      for each table.  Each table must be specified with both
                      database and table names, e.g.,
                      --ignore-table=database.table.
  --include-master-host-port
                      Adds &#39;MASTER_HOST=&lt;host&gt;, MASTER_PORT=&lt;port&gt;&#39; to &#39;CHANGE
                      MASTER TO..&#39; in dump produced with --dump-slave.
  --insert-ignore     Insert rows with INSERT IGNORE.
  --lines-terminated-by=name
                      Lines in the output file are terminated by the given
                      string.
  -x, --lock-all-tables
                      Locks all tables across all databases. This is achieved
                      by taking a global read lock for the duration of the
                      whole dump. Automatically turns --single-transaction and
                      --lock-tables off.
  -l, --lock-tables   Lock all tables for read.
                      (Defaults to on; use --skip-lock-tables to disable.)
  --log-error=name    Append warnings and errors to given file.
  --master-data[=#]   This causes the binary log position and filename to be
                      appended to the output. If equal to 1, will print it as a
                      CHANGE MASTER command; if equal to 2, that command will
                      be prefixed with a comment symbol. This option will turn
                      --lock-all-tables on, unless --single-transaction is
                      specified too (in which case a global read lock is only
                      taken a short time at the beginning of the dump; don&#39;t
                      forget to read about --single-transaction below). In all
                      cases, any action on logs will happen at the exact moment
                      of the dump. Option automatically turns --lock-tables
                      off.
  --max-allowed-packet=#
                      The maximum packet length to send to or receive from
                      server.
  --net-buffer-length=#
                      The buffer size for TCP/IP and socket communication.
  --no-autocommit     Wrap tables with autocommit/commit statements.
  -n, --no-create-db  Suppress the CREATE DATABASE ... IF EXISTS statement that
                      normally is output for each dumped database if
                      --all-databases or --databases is given.
  -t, --no-create-info
                      Don&#39;t write table creation info.
  -d, --no-data       No row information.
  -N, --no-set-names  Same as --skip-set-charset.
  --opt               Same as --add-drop-table, --add-locks, --create-options,
                      --quick, --extended-insert, --lock-tables, --set-charset,
                      and --disable-keys. Enabled by default, disable with
                      --skip-opt.
  --order-by-primary  Sorts each table&#39;s rows by primary key, or first unique
                      key, if such a key exists.  Useful when dumping a MyISAM
                      table to be loaded into an InnoDB table, but will make
                      the dump itself take considerably longer.
  -p, --password[=name]
                      Password to use when connecting to server. If password is
                      not given it&#39;s solicited on the tty.
  -P, --port=#        Port number to use for connection.
  --protocol=name     The protocol to use for connection (tcp, socket, pipe,
                      memory).
  -q, --quick         Don&#39;t buffer query, dump directly to stdout.
                      (Defaults to on; use --skip-quick to disable.)
  -Q, --quote-names   Quote table and column names with backticks (`).
                      (Defaults to on; use --skip-quote-names to disable.)
  --replace           Use REPLACE INTO instead of INSERT INTO.
  -r, --result-file=name
                      Direct output to a given file. This option should be used
                      in systems (e.g., DOS, Windows) that use carriage-return
                      linefeed pairs (\r\n) to separate text lines. This option
                      ensures that only a single newline is used.
  -R, --routines      Dump stored routines (functions and procedures).
  --set-charset       Add &#39;SET NAMES default_character_set&#39; to the output.
                      (Defaults to on; use --skip-set-charset to disable.)
  --set-gtid-purged[=name]
                      Add &#39;SET @@GLOBAL.GTID_PURGED&#39; to the output. Possible
                      values for this option are ON, OFF and AUTO. If ON is
                      used and GTIDs are not enabled on the server, an error is
                      generated. If OFF is used, this option does nothing. If
                      AUTO is used and GTIDs are enabled on the server, &#39;SET
                      @@GLOBAL.GTID_PURGED&#39; is added to the output. If GTIDs
                      are disabled, AUTO does nothing. If no value is supplied
                      then the default (AUTO) value will be considered.
  --single-transaction
                      Creates a consistent snapshot by dumping all tables in a
                      single transaction. Works ONLY for tables stored in
                      storage engines which support multiversioning (currently
                      only InnoDB does); the dump is NOT guaranteed to be
                      consistent for other storage engines. While a
                      --single-transaction dump is in process, to ensure a
                      valid dump file (correct table contents and binary log
                      position), no other connection should use the following
                      statements: ALTER TABLE, DROP TABLE, RENAME TABLE,
                      TRUNCATE TABLE, as consistent snapshot is not isolated
                      from them. Option automatically turns off --lock-tables.
  --dump-date         Put a dump date to the end of the output.
                      (Defaults to on; use --skip-dump-date to disable.)
  --skip-opt          Disable --opt. Disables --add-drop-table, --add-locks,
                      --create-options, --quick, --extended-insert,
                      --lock-tables, --set-charset, and --disable-keys.
  -S, --socket=name   The socket file to use for connection.
  --secure-auth       Refuse client connecting to server if it uses old
                      (pre-4.1.1) protocol.
                      (Defaults to on; use --skip-secure-auth to disable.)
  --ssl               Enable SSL for connection (automatically enabled with
                      other flags).
  --ssl-ca=name       CA file in PEM format (check OpenSSL docs, implies
                      --ssl).
  --ssl-capath=name   CA directory (check OpenSSL docs, implies --ssl).
  --ssl-cert=name     X509 cert in PEM format (implies --ssl).
  --ssl-cipher=name   SSL cipher to use (implies --ssl).
  --ssl-key=name      X509 key in PEM format (implies --ssl).
  --ssl-crl=name      Certificate revocation list (implies --ssl).
  --ssl-crlpath=name  Certificate revocation list path (implies --ssl).
  --ssl-verify-server-cert
                      Verify server&#39;s &quot;Common Name&quot; in its cert against
                      hostname used when connecting. This option is disabled by
                      default.
  --ssl-mode=name     SSL connection mode.
  -T, --tab=name      Create tab-separated textfile for each table to given
                      path. (Create .sql and .txt files.) NOTE: This only works
                      if mysqldump is run on the same machine as the mysqld
                      server.
  --tables            Overrides option --databases (-B).
  --triggers          Dump triggers for each dumped table.
                      (Defaults to on; use --skip-triggers to disable.)
  --tz-utc            SET TIME_ZONE=&#39;+00:00&#39; at top of dump to allow dumping of
                      TIMESTAMP data when a server has data in different time
                      zones or data is being moved between servers with
                      different time zones.
                      (Defaults to on; use --skip-tz-utc to disable.)
  -u, --user=name     User for login if not current user.
  -v, --verbose       Print info about the various stages.
  -V, --version       Output version information and exit.
  -w, --where=name    Dump only selected records. Quotes are mandatory.
  -X, --xml           Dump a database as well formed XML.
  --plugin-dir=name   Directory for client-side plugins.
  --default-auth=name Default authentication client-side plugin to use.
  --enable-cleartext-plugin
                      Enable/disable the clear text authentication plugin.

Variables (--variable-name=value)
and boolean options {FALSE|TRUE}  Value (after reading options)
--------------------------------- ----------------------------------------
all-databases                     FALSE
all-tablespaces                   FALSE
no-tablespaces                    FALSE
add-drop-database                 FALSE
add-drop-table                    TRUE
add-drop-trigger                  FALSE
add-locks                         TRUE
allow-keywords                    FALSE
apply-slave-statements            FALSE
bind-address                      (No default value)
character-sets-dir                (No default value)
comments                          TRUE
compatible                        (No default value)
compact                           FALSE
complete-insert                   FALSE
compress                          FALSE
create-options                    TRUE
databases                         FALSE
debug-check                       FALSE
debug-info                        FALSE
default-character-set             utf8
delayed-insert                    FALSE
delete-master-logs                FALSE
disable-keys                      TRUE
dump-slave                        0
events                            FALSE
extended-insert                   TRUE
fields-terminated-by              (No default value)
fields-enclosed-by                (No default value)
fields-optionally-enclosed-by     (No default value)
fields-escaped-by                 (No default value)
flush-logs                        FALSE
flush-privileges                  FALSE
force                             FALSE
hex-blob                          FALSE
host                              (No default value)
include-master-host-port          FALSE
insert-ignore                     FALSE
lines-terminated-by               (No default value)
lock-all-tables                   FALSE
lock-tables                       TRUE
log-error                         (No default value)
master-data                       0
max-allowed-packet                25165824
net-buffer-length                 1046528
no-autocommit                     FALSE
no-create-db                      FALSE
no-create-info                    FALSE
no-data                           FALSE
order-by-primary                  FALSE
port                              0
quick                             TRUE
quote-names                       TRUE
replace                           FALSE
routines                          FALSE
set-charset                       TRUE
single-transaction                FALSE
dump-date                         TRUE
socket                            (No default value)
secure-auth                       TRUE
ssl                               FALSE
ssl-ca                            (No default value)
ssl-capath                        (No default value)
ssl-cert                          (No default value)
ssl-cipher                        (No default value)
ssl-key                           (No default value)
ssl-crl                           (No default value)
ssl-crlpath                       (No default value)
ssl-verify-server-cert            FALSE
tab                               (No default value)
triggers                          TRUE
tz-utc                            TRUE
user                              (No default value)
verbose                           FALSE
where                             (No default value)
plugin-dir                        (No default value)
default-auth                      (No default value)
enable-cleartext-plugin           FALSE
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Jmeter 使用入门]]></title>
      <url>/2016/09/07/jmeter-introduction/</url>
      <content type="html"><![CDATA[<p>Jmeter 是一款开源的压力测试工具，虽功能不及 Loadrunner 强大，但是对于一些简单的如接口api的测试完全够用。</p>
<h3 id="基本使用方法"><a href="#基本使用方法" class="headerlink" title="基本使用方法"></a>基本使用方法</h3><p>通常使用 Jmeter 通常需要以下几步。以 http api 接口测试为例：</p>
<ol>
<li>添加线程组<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/%E7%BA%BF%E7%A8%8B%E7%BB%84.png" alt=""></li>
<li>添加 Sampler，这里选择 Http请求<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/HTTP%E8%AF%B7%E6%B1%82.png" alt=""></li>
<li>添加 listener<br>Jmeter 提供了不同的 Listener 可以按需求添加。</li>
</ol>
<p>点击启动，将按照计划开始执行测试，完成后可看到报告。</p>
<h3 id="如何使用变量"><a href="#如何使用变量" class="headerlink" title="如何使用变量"></a>如何使用变量</h3><p>如果一个测试计划内容很多，有一些参数如 IP 等会出现多次，我们可以将这样的信息设置成用户定义变量。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/%E7%94%A8%E6%88%B7%E5%AE%9A%E4%B9%89%E7%9A%84%E5%8F%98%E9%87%8F.png" alt=""><br>定义之后，可以在其他地方通过 ${} 进行引用。</p>
<h3 id="如何使用函数"><a href="#如何使用函数" class="headerlink" title="如何使用函数"></a>如何使用函数</h3><p>Jmeter 提供了一些内置函数，点击 函数助手对话框 可查看内置函数的说明。<br>举个例子，如果我们在发送 http 请求时想使用更多的测试数据，而不是在参数栏将一组测试数据写死，可以将多组测试数据放在 csv 文件中，然后通过 __CSVRead() 函数来调用。</p>
<ol>
<li>在 HTTP请求中加入配置元件 CSV Data Set Config ，并在 fileName 中指定文件的全路径。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/%E4%BC%81%E4%B8%9A%E5%90%8D%E5%8D%95.png" alt=""></li>
<li>在 Http 参数列表中的 value 位置使用 ${__CSVRead(${entNameFile},0)} 。第一个参数是需要读取的 CSV 文件，第二个参数是每组数据的位置，CSV 文件中的测试数据默认使用 ‘,’ 分割，0 表示第一列数据。</li>
</ol>
<h3 id="OutOfMemoryError"><a href="#OutOfMemoryError" class="headerlink" title="OutOfMemoryError"></a>OutOfMemoryError</h3><p>在执行测试过程中，执行一段时间后出现 Java.lang.OutOfMemoryError: Java heap space 。解决方法参考如下：</p>
<ol>
<li>修改启动参数。<br>在 bin/jmeter 最后加入启动参数。<pre><code>java $ARGS $JVM_ARGS -Xms1G -Xmx5G -XX:MaxPermSize=512m -Dapple.laf.useScreenMenuBar=true $JMETER_OPTS -jar &quot;$PRGDIR/ApacheJMeter.jar&quot; &quot;$@&quot;
</code></pre></li>
<li>如果在计划中加入了察看结果树的 Listener ，将会有大量数据写入。通常在计划调试阶段使用，正式测试时应去掉。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Jmeter </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Scala 学习资料汇总]]></title>
      <url>/2016/09/05/scala-learning-resources/</url>
      <content type="html"><![CDATA[<p>收集了一些，准备。</p>
<ol>
<li><p><a href="http://learnyouahaskell.com/chapters" target="_blank" rel="external">http://learnyouahaskell.com/chapters</a><br>介绍 Haskell 的，了解函数式编程可以看。</p>
</li>
<li><p><a href="http://twitter.github.io/scala_school/zh_cn/" target="_blank" rel="external">Scala 课堂</a><br>twitter 的教程。</p>
</li>
<li><p><a href="http://hongjiang.info/scala/" target="_blank" rel="external">http://hongjiang.info/scala/</a><br>别人的博客。</p>
</li>
<li><p><a href="https://www.shiyanlou.com/courses/?course_type=all&amp;tag=Scala" target="_blank" rel="external">https://www.shiyanlou.com/courses/?course_type=all&amp;tag=Scala</a><br>动手做项目能更好的理解。</p>
</li>
<li><p>看书是必须的。<img src="http://new.51cto.com/files/uploadimg/20090526/0950191.jpg" alt="programming in scala"></p>
</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Scala </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Scala </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java Stream 详解]]></title>
      <url>/2016/08/20/java-stream-introduction/</url>
      <content type="html"><![CDATA[<p>Java Stream 是 jdk 1.8 加入的新 API ，目的是用来支持函数式编程，位于 java.util.stream 包下。</p>
<p>Stream 并不是集合，只是提供了针对于集合的函数式操作，如 Map-Rudeuce 转换。Stream 和集合的区别主要体现在一下几点：</p>
<ul>
<li>不存储数据<br>Stream 不是一个存储数据的数据结构，相反，它是通过一个计算操作的管道从源（数据结构，数组，I/O管道等）传输数据。</li>
<li>操作并不改变源</li>
<li>延迟处理<br>多数 Stream 操作，比如过滤、转换等都不是立即执行的，而是在最佳时机执行。例如，查找第一个有三个连续元音的字符串，Stream 操作分为 <em>中间操作</em> 和 <em>最终操作</em> , 中间操作始终是延迟处理的。</li>
<li>无限的<br>集合的 size 是有限的，Stream 是无限的。limit(n) 或 findFirst() 等短路操作可以让无限的 Stream 在有限的时间内完成计算。</li>
<li>可消耗的<br>像 Iterator 一样，Stream 中的元素在其生命周期内只能访问一次。</li>
</ul>
<h3 id="Stream-操作和管道"><a href="#Stream-操作和管道" class="headerlink" title="Stream 操作和管道"></a>Stream 操作和管道</h3><p>Stream 操作分为中间操作和最终操作，通过管道的被组合起来。一个 Stream 管道包含一个源，0 个或多个中间操作和一个最终操作。<br>中间操作会返回一个新的 Stream , 但并不是立即执行的。比如 filter() 方法不会执行过滤，而是在最终操作执行遍历时才创建一个由符合条件元素构成的新 Stream 。<br>最终操作会产生结果。最终操作被执行后，Stream 管道可以被消耗，并不能再被使用。如果你需要再次遍历相同的数据源，只能获取新的 Stream 。通常最终操作会在返回前完成遍历和计算，除了 iterator() 和 spliterator() 。these are provided as an “escape hatch” to enable arbitrary client-controlled pipeline traversals in the event that the existing operations are not sufficient to the task.<br>中间操作又分为有状态和无状态。无状态操作处理的元素之间彼此是相互独立的，如 filter 和 map 。有状态操作处理新元素则需要用到之前处理的元素的结果，如 distinct 和 sorted 。有状态操作需要针对全部元素处理得到结果，比如排序。所以在并行计算中，管道包含的中间操作需要多次传递和缓存数据。不论顺序还是并行处理，如果管道只包含无状态操作，则可以使用最少的数据缓存单次完成处理。<br>对于无限的 stream ，短路操作是必须的。如果中间操作是短路操作，将会返回一个有限 stream 作为结果，如果最终操作是短路操作，将会在有限时间内结束。</p>
<h3 id="并行化"><a href="#并行化" class="headerlink" title="并行化"></a>并行化</h3><p>所有的 stream 都可以串行或并行执行，jdk 默认使用串行处理 stream ，如果需要并行，可以指定使用并行方式处理，如 Collection.parallelStream() 。</p>
<pre><code class="java">int sumOfWeights = widgets.parallelStream()
                          .filter(b -&gt; b.getColor() == RED)
                          .mapToInt(b -&gt; b.getWeight())
                          .sum();
</code></pre>
<p>上边代码中，串行和并行的唯一区别就是使用 parallelStream() 代替 stream() 。</p>
<h3 id="Non-interference"><a href="#Non-interference" class="headerlink" title="Non-interference"></a>Non-interference</h3><p>大多数情况下，stream 操作接受的参数大多是 lambda 表达式，用来描述用户指定的行为。为了保证行为正确，这些参数必须是非干扰和无状态的。</p>
<h3 id="Stream-语法"><a href="#Stream-语法" class="headerlink" title="Stream 语法"></a>Stream 语法</h3><p>Stream 语法由源，中间操作和最终操作组成。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/stream.jpg" alt=""><br>从上图（图片来自<a href="http://ifeve.com/stream/" target="_blank" rel="external">http://ifeve.com/stream/</a>）可以看出，使用 Stream 的基本步骤：</p>
<ul>
<li>创建 Stream<br>红色框中语句生成的是一个包含所有 nums 变量的 Stream 。</li>
<li>转换 Stream<br>绿色框中语句把一个 Stream 转换成另外一个 Stream ，原 Stream 不变。</li>
<li>对 Stream 进行聚合（Reduce）操作<br>蓝色框中语句把 Stream 的里面包含的内容按照某种算法来汇聚成一个值。</li>
</ul>
<p><strong>创建</strong><br>获得 stream 的方法有如下几种：</p>
<ul>
<li>通过 Collection 的 parallelStream() 和 stream() 方法；</li>
<li>通过 Arrays.stream(Object[]) 方法；</li>
<li>通过 Stream 的静态工厂方法，如：Stream.of(Object[]), IntStream.range(int, int) or Stream.iterate(Object, UnaryOperator);</li>
<li>通过 BufferedReader.lines();</li>
<li>Stream<path></path> 可通过 File 类中的方法获得，如：list(Path dir) 或 lines(Path path) 等；</li>
<li>Random.ints() 可获得 IntStream ；</li>
<li>其他一下生成 stream 的方法，如：BitSet.stream(), Pattern.splitAsStream(java.lang.CharSequence), and JarFile.stream() 。</li>
</ul>
<p><strong>转换</strong></p>
<ol>
<li>distinct:<br>对于 Stream 中包含的元素进行去重操作（去重逻辑依赖元素的 equals 方法），新生成的 Stream 中没有重复的元素。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/distinct.jpg" alt=""></li>
<li>filter:<br>对于 Stream 中包含的元素使用给定的过滤函数进行过滤操作，新生成的 Stream 只包含符合条件的元素。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/filter.jpg" alt=""></li>
<li>map:<br>对于 Stream 中包含的元素使用给定的转换函数进行转换操作，新生成的 Stream 只包含转换生成的元素。这个方法有三个对于原始类型的变种方法，分别是：mapToInt，mapToLong 和mapToDouble 。这三个方法也比较好理解，比如 mapToInt 就是把原始 Stream 转换成一个新的 Stream ，这个新生成的 Stream 中的元素都是 int 类型。之所以会有这样三个变种方法，可以免除自动装箱/拆箱的额外消耗。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/map.jpg" alt=""></li>
<li>flatMap:<br>和 map 类似，不同的是其每个元素转换得到的是 Stream 对象，会把子 Stream 中的元素压缩到父集合中。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/flatMap.jpg" alt=""><br>光从文字描述，感觉 flatMap 还是很难理解，通过程序帮助理解。<br>```java<br>Stream<list<integer>&gt; nums = Stream.of(<pre><code> Arrays.asList(1),
 Arrays.asList(2, 3),
 Arrays.asList(4, 5, 6)
</code></pre>);</list<integer></li>
</ol>
<p>nums.flatMap(e -&gt; e.stream()).collect(Collectors.toList()).forEach(e -&gt; System.out.print(e + “,”));</p>
<pre><code>  输出结果为
```java
1,2,3,4,5,6,
</code></pre><p>  可以看出 flatMap 的作用是将源 Stream 中的 List 结构去掉，用 List 中的元素构成新的 List 。</p>
<ol>
<li><p>peek:<br>生成一个包含原 Stream 的所有元素的新 Stream ，同时会提供一个消费函数（ Consumer 实例）。新 Stream 每个元素被消费的时候都会执行给定的消费函数。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/peek.jpg" alt=""></p>
<p> 文字描述还是没有程序直观</p>
<pre><code class="java">Stream&lt;List&lt;Integer&gt;&gt; nums = Stream.of(
     Arrays.asList(1),
     Arrays.asList(2, 3),
     Arrays.asList(4, 5, 6)
);
nums.peek(e -&gt; System.out.println(e.size())) // 查看每个元素(list)的 size
     .map(e -&gt; e.get(0))
     .collect(Collectors.toList())
     .forEach(System.out::print);
);
</code></pre>
<p> peek 字面意思是窥视，通常也多用在 debug 中查看 Stream 的元素内容。</p>
</li>
<li>limit:<br>对一个 Stream 进行截断操作，获取其前 N 个元素，如果原 Stream 中包含的元素个数小于 N ，那就获取其所有的元素。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/limit.jpg" alt=""></li>
<li>skip:<br>返回一个丢弃原 Stream 的前 N 个元素后剩下元素组成的新 Stream ，如果原 Stream 中包含的元素个数小于 N ，那么返回空 Stream。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/skip.jpg" alt=""></li>
</ol>
<p><strong>聚合</strong><br>聚合也叫 fold ，是通过重复的组合操作将一个元素序列合并成单独的结果，比如求 sum 或找到一个数字集合的最大值。Stream 类有多种形式的通用聚合操作，如 reduce() 和 collect() ，还有很多特殊的聚合操作，如 sum() 和 count() ，这些只有 IntStream 、DoubleStream 和 LongSteam 类才有。<br>在 jdk 1.8 以前，要计算 sum 通常使用 for 循环：</p>
<pre><code class="java">int sum = 0;
for (int x : numbers) {
   sum += x;
}
</code></pre>
<p>使用 Stream 可以这样写：</p>
<pre><code class="java">int sum = numbers.stream().reduce(0, (x,y) -&gt; x + y);
</code></pre>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/reduce.png" alt=""></p>
<pre><code class="java">int sum = numbers.stream().reduce(0, Integer::sum);
</code></pre>
<p>可变聚合<br>可变聚合操作是将输入元素聚合到一个可变的结果容器中，如 Collection 或 StringBuilder 。<br>如果想将 Stream 中的字符串连接成一个长字符串，通常的做法是：</p>
<pre><code class="java">String concatenated = strings.reduce(&quot;&quot;, String::concat)；
</code></pre>
<p>collect() 的一般形式是：</p>
<pre><code class="java">&lt;R&gt; R collect(Supplier&lt;R&gt; supplier,
               BiConsumer&lt;R, ? super T&gt; accumulator,
               BiConsumer&lt;R, R&gt; combiner);
</code></pre>
<p>该操作需要 3 个函数：</p>
<ol>
<li>Supplier 创建一个新的结果容器的实例；</li>
<li>accumulator 将输入参数组织到结果容器中；</li>
<li>combiner 将结果容器中的内容合并生成另一个结果容器。</li>
</ol>
<p>将集合中的字符串全转成大写：</p>
<pre><code class="java">List&lt;String&gt; list = Lists.newArrayList(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);
List&lt;String&gt; list1 = list.stream().collect(() -&gt; new ArrayList&lt;&gt;(), (c, e) -&gt; c.add(e.toUpperCase()), (c1, c2) -&gt; c1.addAll(c2));
</code></pre>
<p>使用标准 Collector 重写：</p>
<pre><code class="java">List&lt;String&gt; list2 = list.stream().map(String::toUpperCase).collect(ArrayList::new, ArrayList::add, ArrayList::addAll);
</code></pre>
<p>还有更简化的写法，利用 collect() 的重载方法：</p>
<pre><code class="java">&lt;R, A&gt; R collect(Collector&lt;? super T, A, R&gt; collector);
</code></pre>
<pre><code class="java">List&lt;String&gt; list3 = list.stream().map(String::toUpperCase).collect(Collectors.toList());
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java8 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java 反射]]></title>
      <url>/2016/08/19/java-reflaction/</url>
      <content type="html"><![CDATA[<p>Java 反射是 jdk 1.5 加入新特性。Java 反射机制可以让我们在编译期 (Compile Time) 之外的运行期 (Runtime) 检查类，接口，变量以及方法的信息。反射还可以让我们在运行期实例化对象，调用方法，通过调用 get/set 方法获取变量的值。</p>
<p>如果我们要将一个对象 User 实例 A 的值赋给实例 B ，通常这样</p>
<pre><code class="java">public class User{
    String name;
    int age;
    //getter/setter
}

User A = new User();
A.setName(&quot;tom&quot;);
A.setAge(20);
User B = new User();
B.setName(A.getName());
B.setAge(A.getAge());
</code></pre>
<p>这样写非常简单，但是如果对象 User 的属性很多，那么写起来就比较麻烦了。于是可以利用反射来实现：</p>
<pre><code class="java">Class clazz = Class.forName(&quot;a.b.c.User&quot;);
Constructor constructor = clazz.getDeclaredConstructor();
Object B = constructor.newInstance();
Field[] fields = clazz.getDeclaredFields();
for (Field field : fields) {
    String fieldName = field.getName();
    String setMethodName = &quot;set&quot; + fieldName.substring(0, 1).toUpperCase() + fieldName.substring(1);
    String getMethodName = &quot;get&quot; + fieldName.substring(0, 1).toUpperCase() + fieldName.substring(1);
    Method setMethod = clazz.getDeclaredMethod(setMethodName, new Class[]{field.getType()});
    Method getMethod = clazz.getDeclaredMethod(getMethodName, new Class[]{});
    setMethod.invoke(B, getMethod.invoke(A, new Object[]{}));
}
</code></pre>
<p>使用反射实现，代码多了，但是好处是灵活性提高。不过并不建议这样使用，原因有二：</p>
<ul>
<li>代码不够精简</li>
<li>性能不高</li>
</ul>
<p>所以通常我们会借助第三方类库来实现。第三方类库有很多，以 commons.BeanUtils 为例：</p>
<pre><code class="java">BeanUtils.setProperty(B, field, BeanUtils.getProperty(user, field));
</code></pre>
<p>可以看到，代码精简了许多。</p>
<h3 id="高性能反射库-ReflectASM"><a href="#高性能反射库-ReflectASM" class="headerlink" title="高性能反射库 ReflectASM"></a>高性能反射库 ReflectASM</h3><p>关于反射，除了诸多优点，还有一个被人诟病的问题就是性能。不能否认，使用反射性能的确要慢一些，但是随着 Java 的不断优化，反射的速度也在不断提升。另外还是有一些反射库能帮助提升程序性能，比如 ReflectASM 。</p>
<p>ReflectASM 是通过字节码方式实现反射机制的反射库，写法比较简单，而且比 Java 自己的反射包和 commons.BeanUtils 等要快很多。</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;com.esotericsoftware.reflectasm&lt;/groupId&gt;
    &lt;artifactId&gt;reflectasm&lt;/artifactId&gt;
    &lt;version&gt;1.09&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><pre><code class="java">MethodAccess access = MethodAccess.get(User.class);
access.invoke(B, &quot;setName&quot;, access.invoke(A, &quot;getName&quot;));
</code></pre>
<p>虽然 RefectASM 速度快很多，但是在多次使用到相同的对象还是应该利用缓存才能进一步提升性能。</p>
<pre><code class="java">MethodAccess access = map.get(&quot;user&quot;);
if (access == null) {
    access = MethodAccess.get(User.class);
    map.put(&quot;user&quot;, access);
}
</code></pre>
<p>反射是一项非常有用的特性，能够在编程时解决很多特殊的问题，而性能会越来越快，所以应该合理大胆的使用反射。</p>
<hr>
<p>补充：关于使用 ReflectASM 的问题<br>使用 ReflectASM 创建类的实例</p>
<pre><code class="java">ConstructorAccess access = ConstructorAccess.get(User.class);
access.newInstance();
</code></pre>
<p>但是想调用带参数的构造器时，却没有找到方法。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[单机搭建 elk + logback 环境]]></title>
      <url>/2016/08/16/building-logging-system-with-elk/</url>
      <content type="html"><![CDATA[<p>elk是开源日志分析平台，由 <a href="http://www.elastic.co" target="_blank" rel="external">elastic</a> 公司的三款开源产品组成。</p>
<h3 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h3><p>下载elasticsearch、logstash、kibana。</p>
<h3 id="2-安装"><a href="#2-安装" class="headerlink" title="2. 安装"></a>2. 安装</h3><h4 id="2-1-elasticsearch"><a href="#2-1-elasticsearch" class="headerlink" title="2.1 elasticsearch"></a>2.1 elasticsearch</h4><p>解压</p>
<pre><code>tar -zxf elasticsearch-2.3.1.tar.gz
</code></pre><p><strong><em>elasticsearch-2.3.1/config/elasticsearch.yml</em></strong></p>
<pre><code>cluster.name: es
node.name: node1
network.host: node1
discovery.zen.ping.unicast.hosts: [&quot;node1&quot;]
</code></pre><p>启动</p>
<pre><code>bin/elasticsearch
</code></pre><h4 id="2-2-logstash"><a href="#2-2-logstash" class="headerlink" title="2.2 logstash"></a>2.2 logstash</h4><p>解压</p>
<pre><code>logstash-2.3.2.tar.gz
</code></pre><p>新建配置文件</p>
<pre><code>mkdir etc
cd etc
</code></pre><p><strong><em>my.conf</em></strong></p>
<pre><code>input {

    stdin {
    }

    redis {
        batch_count =&gt; 1
        data_type =&gt; &quot;list&quot;
        key =&gt; &quot;logstash&quot;
        host =&gt; &quot;127.0.0.1&quot;
        port =&gt; 6379
        db =&gt; 0
        threads =&gt; 1
    }

#    tcp {
#        host  =&gt; &quot;127.0.0.1&quot;
#        port  =&gt; 5678
#        codec =&gt; &quot;line&quot;
#    }

    log4j {
        mode =&gt; &quot;server&quot;
        host  =&gt; &quot;127.0.0.1&quot;
        port =&gt; 56789
        type =&gt; &quot;log4j&quot;
    }
}

output {
    stdout {
        codec =&gt; rubydebug
    }

    elasticsearch {
        hosts =&gt; [&quot;node1:9200&quot;]
        index =&gt; &quot;logstash&quot;
        document_type =&gt; &quot;log&quot;
        workers =&gt; 1
        flush_size =&gt; 20000
        idle_flush_time =&gt; 10
        template_overwrite =&gt; true
    }
}
</code></pre><p>启动</p>
<pre><code>bin/logstash agent -f ../etc/my.conf
</code></pre><h4 id="2-3-kibana"><a href="#2-3-kibana" class="headerlink" title="2.3 kibana"></a>2.3 kibana</h4><p>解压</p>
<pre><code>tar -zxf kibana-4.5.1-linux-x64.tar.gz
</code></pre><p><strong><em>config/kibana.yml</em></strong></p>
<pre><code>elasticsearch.url: &quot;http://node1:9200&quot;
</code></pre><p>启动</p>
<pre><code>bin/kibana
</code></pre><h3 id="3-收集日志"><a href="#3-收集日志" class="headerlink" title="3.收集日志"></a>3.收集日志</h3><h4 id="3-1-使用-log4j-收集日志"><a href="#3-1-使用-log4j-收集日志" class="headerlink" title="3.1 使用 log4j 收集日志"></a>3.1 使用 log4j 收集日志</h4><p>logstash 有 log4j 的 input 插件，所以使用 log4j 可以很容易将日志收集到 logstash 。</p>
<p><strong><em>Log4jTest.java</em></strong></p>
<pre><code class="java">import org.apache.log4j.Logger;
public class Log4jTest {
    private static Logger logger = Logger.getLogger(Log4jTest.class);

    public static void main(String[] args) {

        logger.debug(&quot;hello logstash, this is a message from log4j&quot;);

    }
}
</code></pre>
<p><strong><em>log4j.properties</em></strong></p>
<pre><code>log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d %p %t %c : %m%n

log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.file=../log/test.log
log4j.appender.file.maxFileSize=1024
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d %p %t %c : %m%n

# logstash配置
log4j.appender.logstash=org.apache.log4j.net.SocketAppender
log4j.appender.logstash.port=56789
log4j.appender.logstash.remoteHost=127.0.0.1

log4j.rootLogger=debug,stdout,file,logstash
</code></pre><p>运行程序可在 kibana 中看到日志。</p>
<h4 id="3-2-使用-logback-收集日志"><a href="#3-2-使用-logback-收集日志" class="headerlink" title="3.2 使用 logback 收集日志"></a>3.2 使用 logback 收集日志</h4><p>logstash 没有 logback 的插件，可以使用 tcp 方式收集日志（效果不好，官方也不建议在生产环境使用tcp方式）。</p>
<h5 id="3-2-1-tcp-方式"><a href="#3-2-1-tcp-方式" class="headerlink" title="3.2.1 tcp 方式"></a>3.2.1 tcp 方式</h5><p><strong><em>logback.xml</em></strong></p>
<pre><code>&lt;configuration&gt;

    &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
        &lt;!-- encoder 默认配置为PatternLayoutEncoder --&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;
    &lt;appender name=&quot;SOCKET&quot; class=&quot;ch.qos.logback.classic.net.SocketAppender&quot;&gt;
        &lt;remoteHost&gt;127.0.0.1&lt;/remoteHost&gt;
        &lt;port&gt;5678&lt;/port&gt;
        &lt;reconnectionDelay&gt;10000&lt;/reconnectionDelay&gt;
        &lt;includeCallerData&gt;true&lt;/includeCallerData&gt;
    &lt;/appender&gt;

    &lt;root level=&quot;INFO&quot;&gt;
        &lt;appender-ref ref=&quot;STDOUT&quot; /&gt;
        &lt;appender-ref ref=&quot;SOCKET&quot; /&gt;
    &lt;/root&gt;

&lt;/configuration&gt;
</code></pre><h5 id="3-2-2-logback-redis"><a href="#3-2-2-logback-redis" class="headerlink" title="3.2.2 logback + redis"></a>3.2.2 logback + redis</h5><p>使用 redis 作为消息队列，需要用到 logback-rides 的开源包。</p>
<p>安装redis</p>
<pre><code>tar -zxf redis-3.2.0.tar.gz
cd redis-3.2.0/
sudo make
sudo make install
</code></pre><p>注：如果logstash和redis不在同一台机器，需要修改<strong><em>redis.conf</em></strong></p>
<pre><code>#bind 127.0.0.1
protected-mode no
</code></pre><p>启动</p>
<pre><code>/usr/local/bin/redis-server
</code></pre><p><strong><em>pom.xml</em></strong></p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;com.cwbase&lt;/groupId&gt;
    &lt;artifactId&gt;logback-redis-appender&lt;/artifactId&gt;
    &lt;version&gt;1.1.5&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p><strong><em>LogbackTest.java</em></strong></p>
<pre><code class="java">import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class LogbackTest {

    static Logger logger = LoggerFactory.getLogger(LogbackTest.class);
    public static void main(String[] args) {
        logger.info(&quot;this log come from slf4j.&quot;);
    }
}
</code></pre>
<p><strong><em>logback.xml</em></strong></p>
<pre><code>&lt;configuration&gt;

    &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
        &lt;!-- encoder 默认配置为PatternLayoutEncoder --&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;appender name=&quot;LOGSTASH&quot; class=&quot;com.cwbase.logback.RedisAppender&quot;&gt;
        &lt;source&gt;mySource&lt;/source&gt;
        &lt;sourcePath&gt;mySourcePath&lt;/sourcePath&gt;
        &lt;type&gt;myApplication&lt;/type&gt;
        &lt;tags&gt;production&lt;/tags&gt;
        &lt;host&gt;127.0.0.1&lt;/host&gt;
        &lt;port&gt;6379&lt;/port&gt;
        &lt;key&gt;logstash&lt;/key&gt;
    &lt;/appender&gt;

    &lt;root level=&quot;INFO&quot;&gt;
        &lt;appender-ref ref=&quot;STDOUT&quot; /&gt;
        &lt;appender-ref ref=&quot;LOGSTASH&quot; /&gt;
    &lt;/root&gt;

&lt;/configuration&gt;
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HashMap 的工作原理]]></title>
      <url>/2016/08/09/how-hashmap-works/</url>
      <content type="html"><![CDATA[<p>HashMap 是最常用的集合类之一，在面试中也出镜率颇高。</p>
<h4 id="HashMap-和-Hashtable"><a href="#HashMap-和-Hashtable" class="headerlink" title="HashMap 和 Hashtable"></a>HashMap 和 Hashtable</h4><p>经常会问 <strong>HashMap 的特点</strong> 及 <strong>HashMap 和 Hashtable 的区别</strong> 等等，那么就先做一下简单总结。</p>
<table style="font-size:12px;color:#333333;border-width: 1px;border-color: #666666;border-collapse: collapse;"><tr><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;"></th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">HashMap</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">Hashtable</th></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">所在位置</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">实现 Map 接口，JDK 1.2 加入到 Java Collections Framework</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Hashtable 集成自 Dictionary ，JDK 1.2 实现了 Map 接口</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">是否支持 null key 或 null value</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">是</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">否</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">线程安全</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">不安全</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">安全</td></tr></table>

<p>以上是 3 点是我们耳熟能详的二者之间的区别，Hashtable 不是我们此篇的重点，暂且放在一旁。</p>
<h4 id="HashMap-的数据结构"><a href="#HashMap-的数据结构" class="headerlink" title="HashMap 的数据结构"></a>HashMap 的数据结构</h4><p>上边这个面试题是通常只是开胃菜，每个熟悉 Java 的人都能知晓。上题热身之后，经常会有这样的问题提出： <strong>HashMap 是如何存储数据的?</strong> Java8 中是通过数组链表和红黑树来实现的。<br><img src="https://s2.ax1x.com/2020/02/29/3sqfXT.png" alt="3sqfXT.png" border="0" style="width:600px"><br>Java8 中，当我们向 HashMap 中 put 元素时，会进行一下几步操作：</p>
<ol>
<li>首先判断数组是否初始化，如果没有初始化，会首先调用 resize() 对 Node<k,v>[] 数组进行初始化。</k,v></li>
<li>然后通过 hash(key) 定位到数组元素 Node<k,v>[i] ，如果 Node<k,v>[i] 为空，就创建一个新的 Node<k,v> 放到 Node<k,v>[i] 。</k,v></k,v></k,v></k,v></li>
<li>如果 Node<k,v>[i] 不为空，则判断 Node<k,v>[i] 的类型是否是 HashMap.TreeNode ，如果是就按照树的方式 put 新值。</k,v></k,v></li>
<li>如果 Node<k,v>[i] 的类型不是 HashMap.TreeNode ，就按照链表方式进行遍历，将新值加到链表末尾。</k,v></li>
<li>添加完成，再判断链表中元素的数量是否超过 treeify 的阈值，如果超过则进行 treeifyBin 操作。</li>
<li>最后再判断一下 HashMap 中元素的数量是否超过负载值，如果超过则再进行一次 resize() 。</li>
</ol>
<p><img src="https://s2.ax1x.com/2020/02/29/3sxupd.png" alt="3sxupd.png" border="0"></p>
<p>和之前的版本不同，为了避免单个 Node<k,v> 上的节点过多，导致遍历时间复杂度高，Java8 中对链表的数量超过阈值（默认时 8 ）时，会将链表转成红黑树，这个过程叫做 treeify() ，其流程如下。</k,v></p>
<p><img src="https://s2.ax1x.com/2020/02/29/3sza5D.png" alt="3sza5D.png" border="0" style="width: 400px"></p>
<blockquote>
<p>treeify 操作并不一定会将链表转成树，会根据 HashMap 中元素的数量是否超过 treeify 的最小阈值来决定。</p>
</blockquote>
<h4 id="resizing"><a href="#resizing" class="headerlink" title="resizing"></a>resizing</h4><p>什么是 resizing ？ 我们知道 HashMap 中数组的元素在 Node<k,v>[] 中的位置是通过 hash(key) 来确定的，如果多个元素的 hash(key) 相同，它们以链表或树的形式的会被存储在相同的位置，这个过程叫做<strong>哈希碰撞</strong>。如果 HashMap 中元素分布足够离散，那么不会出现哈希碰撞，时间复杂度为 O(1) 。如果元素不是离散分布，那么会频繁出现碰撞，数据在链表中存储，时间复杂度为 O(n) 。随着元素增多，哈希碰撞的几率会增加，为了减少碰撞的几率，当达到一定的阈值，HashMap 对 Node<k,v>[] 进行扩容，这个过程叫做 resizing 。Java8 中的 resizing 过程如下。</k,v></k,v></p>
<p><img src="https://s2.ax1x.com/2020/02/29/3yNs4P.png" alt="3yNs4P.png" border="0"></p>
<p>将旧的数组扩容成新的数组，旧数组中的元素需要重新放置到新数组中，这个过程不会再重新计算 hash(key) ，而是先遍历链表算出 hiTail 和 loTail ，然后根据 hiTail 和 loTail 得到元素在新数组中的位置。说简单点，由于扩容是向左移一位，那么不用每次都重新计算 hash(key) ，只要看左边新扩展的一位是 0 还是 1 , 0 就留在原位置，1 就将原位置索引加上原容量得到新位置的索引。计算结果参考下图：<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/hashmap_04.png" style="width: 850px"></p>
<blockquote>
<p>Java8 和之前的版本在实现上有很大的不同。Java8 之前，后加入的元素在链表的头部。Java8 是最先加入的元素在链表头部。</p>
</blockquote>
<p><strong>为什么使用 String 作为 key 是一个不错选择？</strong><br>其实，答案可以从上边获得。因为，String 是 final 的，并且有固定的 hashCode() 和 equals() 方法，所以能有效减少碰撞的发生，同时由于不可变，可以缓存 key 的 hashcode ，提高 get 对象的速度。同理，如果自定义对象作为 key ，应保证对象是不可变的，即保证 equals() 和 hashCode() 方法正确重写。</p>
<p><strong>多线程环境下 resize 导致 CPU 100%</strong><br>这个是 Java8 之前多线程环境下 HashMap 会出现一个问题，导致问题原因是在链表中后加入的元素会在链表的头部，在扩容通过遍历将旧数组中的元素移动到新数组中，在多线程中有可能出现环形链表，get 的时候导致死循环，最终导致 CPU 100% 。Java8 的 resize 不再使用这种方式，也就不会出现这个问题了。</p>
<p><strong>初始化容量的设计</strong><br>HashMap 的初始容量为 16 ，容量超过 75% 就会 resizing 。虽然 HashMap 的 resizing 性能在不断提升，但是如果能预估 HashMap 的大小，就能够避免不必要的 resizing 。比如，有 1000 个元素， 下面的写法必定会触发 resizing 。</p>
<pre><code class="java">Map map = new HashMap();
</code></pre>
<p>或</p>
<pre><code class="java">Map map = new HashMap(1000);
</code></pre>
<p>不考虑空间因素，2 倍 size 是最简单的方法。</p>
<pre><code class="java">Map map = new HashMap(1000 * 2);
</code></pre>
<p>但这样并不是太好，因为 HashMap 本身就不省空间。所以靠谱的做法还是自己算一个 init size 。</p>
<pre><code class="java">float size = 1000 / 0.75f;
Map map = new HashMap(size);
</code></pre>
<p>或</p>
<pre><code class="java">Map map = Maps.newHashMapWithExpectedSize(1000);
</code></pre>
<p><strong>Key 的设计</strong><br>我们知道 Map 获取元素是通过 Key 来比较的，Integer/String 这些常见的类型都可以作为 key 。这些类都有一个共同的特点，即重写了 hashCode() 和 equals() 方法，保证了 key 的离散，并且这些类是 final 的，保证不会有子类重写这些方法。如果需要使用自定义对象类型的 key ，最好还是要重写 hashcode 和 equals 方法来保证元素分布是离散的。</p>
<p><strong>几种同步的 HashMap 的区别</strong><br>Hashtable 对方法加 synchronized 。<br>Collections.synchronizedMap(new HashMap&lt;&gt;()); 使用 synchronized 代码块。<br>ConcurrentHashMap 利用分段锁，java8 之前是先根据 hash 定位到 segment 然后在 segment 内部使用 lock 加锁。Java8 是对 Node<k,v>[] 的元素（链表的第一个元素）用 CAS 加锁，在链表内部使用 synchronized 进行同步。</k,v></p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java 中的回调函数]]></title>
      <url>/2016/08/08/callback-in-java/</url>
      <content type="html"><![CDATA[<p>在 Spring 和 Hibernate 中有很多回调函数的用法，感觉使用起来非常方便，那么回调函数是如何实现的呢？</p>
<p>首先需要定义一个回调接口，比如：</p>
<pre><code class="java">public interface QueryCallback&lt;T&gt; {

    &lt;T&gt; List&lt;T&gt; query(Session session);

}
</code></pre>
<p>然后在定义的方法是调用接口方法。</p>
<pre><code class="java">public class Query {

    public List&lt;String&gt; queryForList(String sql, Callback callback){
        Session session = new Session();
        return callback.query(session);
    }

}
</code></pre>
<p>调用的时候就可以使用回调了。</p>
<pre><code class="java">String sql = &quot;select * from user&quot;;
List&lt;String&gt; list = new QueryDB().queryForList(sql, new Callback() {
    @Override
    public List query(Session session) {
        List&lt;String&gt; list = session.query(sql);
        return list;
    }
});
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java 关键字 volatile 详解]]></title>
      <url>/2016/08/08/java-volatile-introduction/</url>
      <content type="html"><![CDATA[<p>volatile 是 Java 语言的关键字，常常和 synchronized 进行比较。</p>
<p><strong>volatile 和 synchronized 简单比较</strong></p>
<table style="font-size:12px;color:#333333;border-width: 1px;border-color: #666666;border-collapse: collapse;width:100%"><tr><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;"></th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">volatile</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">synchronized</th></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">作用位置</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">变量</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">方法，代码块</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">同步对象</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">主内存和线程内存之间某个变量的值</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">主内存和线程内存之间所有变量的值</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">消耗资源</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">少</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">多</td></tr></table>


<p>volatile 不能像 synchronized 一样广泛的用于线程安全，因为 volatile 不能保证原子性，所以 volatile 不能保证线程安全。但是在某些特殊场景下使用 volatile 要比 synchronized 和锁简单和高效，还能使程序更加简单。</p>
<h5 id="内存可见性"><a href="#内存可见性" class="headerlink" title="内存可见性"></a><strong>内存可见性</strong></h5><p>Java 的每个线程都拥有自己的内存，在某个时间点，多个线程中间的同一个变量的值可能是不同的，volatile 的作用就是让变量对所有线程都是一致的，每次获得的都是该变量的最新值，即可见性。比如程序需要有一个标识来指示一个一次性操作，像资源初始化，那么使用 volatile 是非常方便的。</p>
<pre><code class="java">public class VolatileExample {
    volatile boolean init = false;

    public boolean isInit() {
        return init;
    }

    public void setInit(boolean init) {
        this.init = init;
    }

    public static void main(String[] args) throws InterruptedException {
        VolatileExample volatileExample = new VolatileExample();
        new Thread(() -&gt; {
            while (!volatileExample.isInit()) {
            }
            System.out.println(&quot;t2 completed&quot;);
        }, &quot;t2&quot;).start();

        Thread.sleep(5000);
        volatileExample.setInit(true);
        System.out.println(&quot;init = true&quot;);
    }
}
</code></pre>
<p>volatile 变量比使用 synchronized 代码要简单一些，在这种只有一种状态转换的情况使用 volatile 是合适的。</p>
<h5 id="禁止指令重排"><a href="#禁止指令重排" class="headerlink" title="禁止指令重排"></a><strong>禁止指令重排</strong></h5><p>volatile 的另一个作用是禁止指令重排。JVM 为了提高程序的执行效率，可能会对没有前后依赖关系的程序指令进行优化，从而改变执行的顺序。比如双重校验单例的代码：</p>
<pre><code>public class Singleton {
    private static volatile Singleton instance = null;

    public static Singleton getInstance() {
        if (instance == null) {
            sychornized(Singleton.class) {
                if (instance == null) {
                    instance = new Singleton(); 
                }
            }
        }
        return instance;
    }
}
</code></pre><p>instance = new Singleton() 并不是原子操作，它对应了 3 条 JVM 指令：</p>
<pre><code>memory = allocate();   //1：分配对象的内存空间 
ctorInstance(memory);  //2：初始化对象 
instance = memory;     //3：设置instance指向刚分配的内存地址
</code></pre><p>由于 2 和 3 并没有依赖顺序，所以如果 JVM 对其进行指令重排，顺序可能会变成 1 3 2 。如果在多线程的场景中，就可能出现 instance 不为空，但是还没有初始化完成的情况，所以为了避免出现此种问题，可以使用 volatile 来禁止指令重排。<br>在使用 volatile 关键字修饰变量后，JVM 会通过内存屏障来保证指令的顺序。</p>
<ol>
<li>在每个 volatile 写操作前插入 StoreStore 屏障，在写操作后插入 StoreLoad 屏障。</li>
<li>在每个 volatile 读操作前插入 LoadLoad 屏障，在读操作后插入 LoadStore 屏障。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[枚举单例读取配置文件]]></title>
      <url>/2016/08/02/reading-properties-with-enum/</url>
      <content type="html"><![CDATA[<p>枚举实现单例在《Effective in java》中提到过，好处是简洁，同时不会有序列化和反序列化的问题。<br><a id="more"></a><br>下面一个 enum 单例的实际示例，用来读取配置文件。</p>
<p><strong>config.properties</strong></p>
<pre><code class="java">host=htt://localhost
port=8080
</code></pre>
<p><strong>AppContext.java</strong></p>
<pre><code class="java">import java.util.ResourceBundle;

public enum  AppContext {

    INSTANCE;

    private volatile static ResourceBundle rb = ResourceBundle.getBundle(&quot;config&quot;);

    public String getValue(String key){
        return rb.getString(key);
    }
}
``

**client**
​```java
public class Client {

    public static void main(String[] args) {
        String host = AppContext.INSTANCE.getValue(&quot;host&quot;);
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Design Patterns </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[单例模式]]></title>
      <url>/2016/08/02/singleton-pattern/</url>
      <content type="html"><![CDATA[<p>单例模式是最简单的设计模式之一，用于保证系统中只有一个类的实例的场景。</p>
<p>单例模式的特点：</p>
<ul>
<li>只有一个实例</li>
<li>只能自己创建自己的实例</li>
<li>能够对外提供自己创建的实例</li>
</ul>
<h3 id="1-程序示例"><a href="#1-程序示例" class="headerlink" title="1. 程序示例"></a>1. 程序示例</h3><h4 id="1-1-懒汉式"><a href="#1-1-懒汉式" class="headerlink" title="1.1 懒汉式"></a>1.1 懒汉式</h4><p>在 Gof 的设计模式中介绍单例模式使用的说明代码叫做懒汉式，java 版代码如下：</p>
<pre><code class="java">public class Singleton {
    private static Singleton instance = null;
    private Singleton() {}
    public static Singleton getInstance() {
        if (instance == null) {
            instance = new Singleton();
        }
        return instance;
    }
}
</code></pre>
<p>这是最简单的代码实现，但是这个代码存在问题，即在多线程的程序中，不能保证一定是单例的。原因也很简单，代码被编译成字节码被执行，有可能在刚进入 if 判断后时间分片就用完了，另一个线程也进入 if 判断，从而创建多个实例。一种简单的处理方法是将方法同步。</p>
<pre><code class="java">synchronized public static Singleton getInstance() {
}
</code></pre>
<h4 id="1-2-饿汉式"><a href="#1-2-饿汉式" class="headerlink" title="1.2 饿汉式"></a>1.2 饿汉式</h4><p>另外还有一种比较常见的叫做饿汉式，这种方式更符合 java 的风格。</p>
<pre><code class="java">public class Singleton {
    private static final Singleton INSTANCE = new Singleton();

    private Singleton() {}

    public static Singleton getInstance() {
        return INSTANCE;
    }
}
</code></pre>
<h4 id="1-3-静态内部类"><a href="#1-3-静态内部类" class="headerlink" title="1.3 静态内部类"></a>1.3 静态内部类</h4><p>通常情况下，直接使用恶汉式是最安逸的，况且内存越来越不是瓶颈了。但是如果还对装载类时初始化耿耿于怀，可以使用这种方式。</p>
<pre><code class="java">public class Singleton {

    private Singleton() {}

    private static class SingletonHolder {
        private static final Singleton INSTANCE = new Singleton();
    }

    public static Singleton getInstance() {
        return SingletonHolder.INSTANCE;
    }
}
</code></pre>
<p>使用静态内部类的好处是不会在装载 Singleton 的时候就实例化，而是在调用 getInstance() 方法时才创建实例。</p>
<h4 id="1-4-枚举"><a href="#1-4-枚举" class="headerlink" title="1.4 枚举"></a>1.4 枚举</h4><p>在 jdk1.5 以后加入了枚举，也可以使用枚举来实现单例。</p>
<pre><code class="java">public enum Singleton {
    INSTANCE;
    public void whateverMethod(){

    }
}
</code></pre>
<p>使用 enum 方式创建单例的好处是简单，简单到让人看不懂。怎么使用可参考一个例子 <a href="../../../../2016/08/02/枚举单例读取配置文件/">枚举单例读取配置文件</a> 。</p>
<h4 id="1-5-双重校验锁"><a href="#1-5-双重校验锁" class="headerlink" title="1.5 双重校验锁"></a>1.5 双重校验锁</h4><p>网上很多单例的文章中都提到了双重校验锁的方式。这种方式出现的目的是对懒汉式进行优化。</p>
<pre><code class="java">public class Singleton {

    private volatile static Singleton instance;

    private Singleton() {}

    public static Singleton getInstance() {
        if (instance == null) {
            synchronized (Singleton.class) {
                if (instance == null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
</code></pre>
<p>在《java 与模式》一书中针对这种方式也做了分析，这种方式并不能真正达到效果，所以还是安心使用饿汉吧。</p>
<p>2016-08-08 补充：<br>网上一些资料中提到，自 JDK 1.5 以后，修复了 volatile 关键字的 bug ，所以，JDK 1.5 以后双重校验锁可以正常工作了。关于 volatile 关键字更多知识点，参考 <a href="../../../../2016/08/08/Java 关键字 volatile/">Java 关键字 volatile</a></p>
<h3 id="2-类图"><a href="#2-类图" class="headerlink" title="2. 类图"></a>2. 类图</h3><p>如果要画出常用设计模式的类图，单例无疑是最简单的了。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/singleton.png" alt="单例模式"></p>
]]></content>
      
        <categories>
            
            <category> Design Pattern </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[计算时间间隔]]></title>
      <url>/2016/07/29/calculate-date-interval/</url>
      <content type="html"><![CDATA[<p>在计算日期或是计算程序执行时间时，经常会需要计算两个时间或日期的间隔，通常可以通过一下几种方法实现。</p>
<h3 id="1-使用-Java-日期-api"><a href="#1-使用-Java-日期-api" class="headerlink" title="1. 使用 Java 日期 api"></a>1. 使用 Java 日期 api</h3><p>先计算出相差的毫秒值，再转化成天，小时，分，秒。<br>按时间进制自己算，代码略。</p>
<h3 id="2-使用-Joda-库"><a href="#2-使用-Joda-库" class="headerlink" title="2. 使用 Joda 库"></a>2. 使用 Joda 库</h3><pre><code class="java">DateTime dt1 = new DateTime(d1);
DateTime dt2 = new DateTime(d2);

int days = Days.daysBetween(dt1, dt2).getDays();
int hours = Hours.hoursBetween(dt1, dt2).getHours() % 24;
int minutes = Minutes.minutesBetween(dt1, dt2).getMinutes() % 60;
int seconds = Seconds.secondsBetween(dt1, dt2).getSeconds() % 60;
</code></pre>
<p>或<br>计算出两个时间的毫秒数</p>
<pre><code class="java">Interval interval = new Interval(start, end);
Period p = interval.toPeriod();
int days = p.getDays();
int hours = p.getHours();
int minutes = p.getMinutes();
int seconds = p.getSeconds();
</code></pre>
<h3 id="3-使用-TimeUnit"><a href="#3-使用-TimeUnit" class="headerlink" title="3. 使用 TimeUnit"></a>3. 使用 TimeUnit</h3><p>计算出两个时间的毫秒数，使用 java.util.concurrent 包下的 TimeUint 。</p>
<pre><code class="java">long diff = t2 - t1;
long days = TimeUnit.MILLISECONDS.toDays(diff);
long hours = TimeUnit.MILLISECONDS.toHours(diff) % 24;
long minutes = TimeUnit.MILLISECONDS.toMinutes(diff) % 60;
long seconds = TimeUnit.MILLISECONDS.toSeconds(diff) % 60;
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[面试题汇总]]></title>
      <url>/2016/07/24/interview-question/</url>
      <content type="html"><![CDATA[<p>把自己遇到和网上看到的一写面试题汇总了一下，帮助梳理和学习一些知识点。</p>
<h1 id="一-算法"><a href="#一-算法" class="headerlink" title="一. 算法"></a>一. 算法</h1><h2 id="1-1-排序"><a href="#1-1-排序" class="headerlink" title="1.1 排序"></a>1.1 排序</h2><h3 id="1）-时间复杂度"><a href="#1）-时间复杂度" class="headerlink" title="1） 时间复杂度"></a>1） 时间复杂度</h3><p>参考 <a href="../../../../2016/07/16/排序算法/">算法排序</a> 。</p>
<h3 id="2）-快速排序"><a href="#2）-快速排序" class="headerlink" title="2） 快速排序"></a>2） 快速排序</h3><p>参考 <a href="../../../../2016/07/16/快速排序/">快速排序</a> 。</p>
<h3 id="3）-冒泡排序"><a href="#3）-冒泡排序" class="headerlink" title="3） 冒泡排序"></a>3） 冒泡排序</h3><p>参考 <a href="../../../../2016/07/16/冒泡排序/">冒泡排序</a> 。</p>
<h3 id="4）-选择排序"><a href="#4）-选择排序" class="headerlink" title="4） 选择排序"></a>4） 选择排序</h3><p>参考 <a href="../../../../2016/07/16/选择排序/">选择排序</a> 。</p>
<h2 id="1-2-查找"><a href="#1-2-查找" class="headerlink" title="1.2 查找"></a>1.2 查找</h2><h3 id="1）-二分查找"><a href="#1）-二分查找" class="headerlink" title="1） 二分查找"></a>1） 二分查找</h3><p>参考 <a href="../../../../2016/07/16/二分查找/">二分查找</a> 。</p>
<h2 id="1-3-树"><a href="#1-3-树" class="headerlink" title="1.3 树"></a>1.3 树</h2><h3 id="1）-二叉树"><a href="#1）-二叉树" class="headerlink" title="1） 二叉树"></a>1） 二叉树</h3><p>参考 <a href="../../../../2016/07/16/二叉树/">二叉树</a> 。</p>
<h3 id="2）-红黑树"><a href="#2）-红黑树" class="headerlink" title="2） 红黑树"></a>2） 红黑树</h3><h1 id="二-Java-基础"><a href="#二-Java-基础" class="headerlink" title="二. Java 基础"></a>二. Java 基础</h1><h2 id="2-1-nio"><a href="#2-1-nio" class="headerlink" title="2.1 nio"></a>2.1 nio</h2><h2 id="2-2-线程"><a href="#2-2-线程" class="headerlink" title="2.2 线程"></a>2.2 线程</h2><h3 id="1）-线程有几种状态？"><a href="#1）-线程有几种状态？" class="headerlink" title="1） 线程有几种状态？"></a>1） 线程有几种状态？</h3><p>参考 <a href="../../../../2016/07/24/线程的状态/">线程的状态</a> 。</p>
<h3 id="2）-线程的优先级"><a href="#2）-线程的优先级" class="headerlink" title="2） 线程的优先级"></a>2） 线程的优先级</h3><p>Java 线程的优先级有10种，从1到10，默认为5。Java 线程的优先级具有继承性。</p>
<h2 id="2-3-JVM"><a href="#2-3-JVM" class="headerlink" title="2.3 JVM"></a>2.3 JVM</h2><h2 id="2-4-集合"><a href="#2-4-集合" class="headerlink" title="2.4 集合"></a>2.4 集合</h2><h3 id="1）-HashMap-工作原理"><a href="#1）-HashMap-工作原理" class="headerlink" title="1） HashMap 工作原理"></a>1） HashMap 工作原理</h3><p>参考 <a href="../../../../2016/08/09/HashMap 的工作原理/">HashMap 的工作原理</a></p>
<h3 id="2）-ConcurrentHashMap原理"><a href="#2）-ConcurrentHashMap原理" class="headerlink" title="2） ConcurrentHashMap原理"></a>2） ConcurrentHashMap原理</h3><p>参考 <a href="../../../../2016/08/09/HashMap 的工作原理/#concurrentHashMap-和-Hashtable-的区别">HashMap 的工作原理</a></p>
<h3 id="3）-某公司正在做一个寻找走失儿童的公益项目，现在有一个函数，可以输入两个图片，并返回这个儿童是否重复。请你设计一个系统，帮助他们寻找儿童。"><a href="#3）-某公司正在做一个寻找走失儿童的公益项目，现在有一个函数，可以输入两个图片，并返回这个儿童是否重复。请你设计一个系统，帮助他们寻找儿童。" class="headerlink" title="3） 某公司正在做一个寻找走失儿童的公益项目，现在有一个函数，可以输入两个图片，并返回这个儿童是否重复。请你设计一个系统，帮助他们寻找儿童。"></a>3） 某公司正在做一个寻找走失儿童的公益项目，现在有一个函数，可以输入两个图片，并返回这个儿童是否重复。请你设计一个系统，帮助他们寻找儿童。</h3><pre><code>网友可以同时上传一批图片
系统能够把所有图片分类并归为一组
网友上传图片后，网页要尽快返回该照片所在的组。
</code></pre><p>A：假设你现在有一个机器，请写出你的数据结构与处理流程，设计的思路。<br>B：如果你有多台机器，如果缩短请求的时间？</p>
<h1 id="三-设计模式"><a href="#三-设计模式" class="headerlink" title="三. 设计模式"></a>三. 设计模式</h1><h2 id="1）-单例模式"><a href="#1）-单例模式" class="headerlink" title="1） 单例模式"></a>1） 单例模式</h2><p>参考 <a href="../../../../2016/08/02/单例模式/">单例模式</a> 。</p>
<h1 id="四-大数据"><a href="#四-大数据" class="headerlink" title="四. 大数据"></a>四. 大数据</h1><h1 id="五-Linux"><a href="#五-Linux" class="headerlink" title="五. Linux"></a>五. Linux</h1>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[线程的状态]]></title>
      <url>/2016/07/23/thread-status/</url>
      <content type="html"><![CDATA[<p>参考 jdk 源码 java.lant.Thread.State 。Java 的线程有以下几种状态：</p>
<ul>
<li>NEW<br>线程未启动。</li>
<li>RUNNABLE<br>线程在 JVM 中运行，也可能在等待其他资源。</li>
<li>BLOCKED<br>线程阻塞并等待锁，在调用 wait() 方法后进入或重新进入同步方法。</li>
<li>WAITTING<br>线程在执行特定的方法如： Object.wait(), Thread.join(), LockSupport.park() 后等待另一个线程执行特定的方法，如：Object.notify()/Object.notifyAll() 。</li>
<li>TIMED_WAITTING<br>线程在执行特定方法后进入执行时间的等待状态，如： Thread.sleep(), Object.wait(), Thread.join(), LockSupport.parkNanos, LockSupport.parkUntil</li>
<li>TERMINATED<br>线程执行完成。</li>
</ul>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Gulp 环境安装]]></title>
      <url>/2016/07/20/gulp-install/</url>
      <content type="html"><![CDATA[<p>gulp是一个前端代码构建工具。安装gulp需要node.js环境，node.js环境安装参考 <a href="../../../../2016/07/16/node.js 环境安装/">node.js 环境安装</a> 。</p>
<h3 id="全局安装gulp命令行工具"><a href="#全局安装gulp命令行工具" class="headerlink" title="全局安装gulp命令行工具"></a>全局安装gulp命令行工具</h3><pre><code>npm install -g gulp
or
npm install --global gulp
</code></pre><h3 id="安装开发环境"><a href="#安装开发环境" class="headerlink" title="安装开发环境"></a>安装开发环境</h3><p>切换到项目目录安装开发环境。</p>
<pre><code>sudo npm install -save-dev gulp
</code></pre><p>如果网速慢，可以使用淘宝镜像。</p>
<pre><code>sudo npm install -g cnpm --registry=https://registry.npm.taobao.org
sudo cnpm install
</code></pre><h3 id="创建gulp文件"><a href="#创建gulp文件" class="headerlink" title="创建gulp文件"></a>创建gulp文件</h3><p>在项目根目录下创建gulpfile.js</p>
<pre><code>var gulp = require(&#39;gulp&#39;);

gulp.task(&#39;default&#39;, function() {
  // 将你的默认的任务代码放在这
});
</code></pre><h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><p>安装完成执行命令启动gulp。</p>
<pre><code>gulp
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Gulp </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[我的 hexo 我做主]]></title>
      <url>/2016/07/19/customize-hexo/</url>
      <content type="html"><![CDATA[<p>Maupassant 主题有一些细节对于强迫症晚期患者来说，不改实在是浑身难受，遂记录一下修改项和修改方案。</p>
<h3 id="1-修改-toc-的位置"><a href="#1-修改-toc-的位置" class="headerlink" title="1. 修改 toc 的位置"></a>1. 修改 toc 的位置</h3><p>toc 在正文的右上，占了正文的空间，在 toc 较长的情况下，正文不能很好的显示，所以将 toc 改为在文章开头显示。</p>
<pre><code class="css">.toc-article {
  border: 1px solid #bbb;
  border-radius: 7px;
  margin: 1.1em 0 0 2em;
  padding: 0.7em 0.7em 0 0.7em;
  max-width: 40%;
}

#toc {
  line-height: 1em;
  float: right;
  .toc {
    padding: 0;
    margin: 0.5em;
    line-height: 1.8em;
    li {
      list-style-type: none;
    }
  }

}
</code></pre>
<p>主要是去掉浮动和边框，在调整一下周围位置。</p>
<pre><code class="css">.toc-article {
  padding: 40px 0 0 0;
}

#toc {
  line-height: 1em;
  .toc {
    padding: 20px;
    line-height: 1.8em;
    li {
      list-style-type: none;
    }
  }

}
</code></pre>
<h3 id="2-去掉-toc-中的序号"><a href="#2-去掉-toc-中的序号" class="headerlink" title="2. 去掉 toc 中的序号"></a>2. 去掉 toc 中的序号</h3><pre><code class="css">#toc {
  line-height: 1em;
  .toc {
    padding: 20px;
    line-height: 1.8em;
    li {
      list-style-type: none;
      a {
        .toc-number {
          display: none;
        }
      }
    }
  }
  .toc-child {
    margin-left: 1em;
    padding-left: 0;
  }
}
</code></pre>
<h3 id="3-修改代码区样式"><a href="#3-修改代码区样式" class="headerlink" title="3. 修改代码区样式"></a>3. 修改代码区样式</h3><p>在将语言改成 zh_CN 后，代码区行高需要调整,去掉 <code>.codeblock</code> 的 line-height 属性,修改 <code>.codeblock.line</code> 的 height 属性。</p>
<pre><code class="css">figure.highlight,
.codeblock {
    background:     #f7f8f8;
    margin:         10px 0;
    /* line-height:    1.2em; */
    color:          #333;
    padding-top:    15px;
    overflow:       hidden;
    border: 1px solid #e5e5e5; /* 代码块加边框 */

    // All lines in gutter and code container
    .line {
        height:    2.1em;
        font-size: 13px;
    }
}
</code></pre>
<h3 id="4-去掉文章结尾-tags"><a href="#4-去掉文章结尾-tags" class="headerlink" title="4. 去掉文章结尾 tags"></a>4. 去掉文章结尾 tags</h3><p>tags 改成在文章开始位置显示，结尾的 tags 就没必要显示了，干脆隐藏掉。</p>
<pre><code class="css">.post {
  ...
  .tags{
    padding-bottom: 1em;
    height: 30px;
    a {
        display: none;
        margin-right: .5em;
        &amp;:before {
            font-family: &quot;FontAwesome&quot;;
            content: &quot;\f0c6&quot;;
            padding-right: 0.3em;
        }
    }
  }
}
</code></pre>
<p>调整分享按钮的位置</p>
<pre><code class="css">.article-share-link {
  margin-top: 1em;
}
</code></pre>
<h3 id="5-调整文章列表显示"><a href="#5-调整文章列表显示" class="headerlink" title="5. 调整文章列表显示"></a>5. 调整文章列表显示</h3><pre><code class="css">.post-content {
    padding-top: 10px;
}
</code></pre>
<h3 id="6-修改-table-样式"><a href="#6-修改-table-样式" class="headerlink" title="6. 修改 table 样式"></a>6. 修改 table 样式</h3><p>给 table 加上边框，将原有框线调细</p>
<pre><code class="css">table {
    th {
        font-weight: bold;
        padding: 5px 10px;
        border: 1px solid #909ba2;
    }
    td {
        padding: 5px 10px;
        border: 1px solid #909ba2;
    }
}
</code></pre>
<h3 id="7-列表去掉文章内容显示"><a href="#7-列表去掉文章内容显示" class="headerlink" title="7. 列表去掉文章内容显示"></a>7. 列表去掉文章内容显示</h3><p>去掉 index.jade 中引用 content 。</p>
<pre><code>for post in page.posts.toArray()
  .post
    .post-title
      include _partial/helpers
      a(href=url_for(post.path))
        +title(post)
        span.post-meta=post.date.format(config.date_format)
</code></pre>]]></content>
      
        <categories>
            
            <category> Wiki </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Jade 语法实践]]></title>
      <url>/2016/07/18/jade-practice/</url>
      <content type="html"><![CDATA[<p>jade 是一个模板引擎，可以通过 node.js 来使用。本来对前端技术了解不多，接触 jade 源于搭建 hexo 博客系统。maupassant 主题模板是基于 jade 的，所以想按自己的想法来定制 maupassant 主题简单了解了一下 jade 。</p>
<p>hexo 的 maupassant 主题是一个极简主题模板，安装也很简单，用起来不错，但是有些小地方还是想按照自己的想法改一改：</p>
<ol>
<li>默认只有归档，没有 tags 和 categories ，而且添加了 tags 和 categories 后不能显示 tags 和 categories 的列表；</li>
<li>每篇文章 tags 标签在文章末尾，希望 categories 一样在文章开头显示；</li>
</ol>
<h3 id="增加-tags-列表"><a href="#增加-tags-列表" class="headerlink" title="增加 tags 列表"></a>增加 tags 列表</h3><p>安装 hexo 和 maupassant 主题后在 themes/maupassant/_ config.yml 中添加 tags 和 categories 两个 menu，重启服务界面能看到 tags 和 categories 的菜单导航。但是点击会报找不到页面错误，所以还需要生成 tags/index和categories/index 。执行</p>
<pre><code>hexo new page tags
hexo new page categories
</code></pre><p>会生成 tags/index.md 和 categories/index.md 文件，重启后不会再报找不到页面的错误。<br>但 index.md 默认是空白页面，内容需要自己写，所以想参考 archive 来写一些内容。想显示的内容也很简单，首先就是列出所有 tags 或 categories ，然后能显示每个 tag 或category 下的文章数量。<br>网站的 tags 和 categories 不是固定的，所以在 index.md 中写死是不行的，需要利用模板来实现。看了看 maupassant 主题的 layout 结构，首先先参考 archive.jade 创建了一个 tags.jade 文件,只保留大的结构。</p>
<pre><code>extends base

block title
  title= page.tag + &#39; | &#39; + config.title
block content

  include _partial/paginator.jade
</code></pre><p>参考 archive.jade 代码，对网站所有 tag 进行分组，然后遍历显示。</p>
<pre><code>each tags in _.groupBy(site.tags.toArray(), function(p){return page.tag})
  ul.listing
    for tag in tags
      li
        h4
          a(href=url_for(tag.path))= _.split(tag.path,&#39;\/&#39;)[1]
</code></pre><p>最后一行代码等号后边是 tag 的名字，原本以为 tag.name 就可以了，但是重建之后发现不能正常显示。不明白原因，查看了 hexo 的文档，在 hexo 的变量声明中 tag 的名字是page.tag，猜测是在 post 页面中才能引用 tag 属性。查了文档也没找到正确的打开方式，忽然发现 tag.path 可以正常显示 tag 的路径，所以是否可以在 path 中将 tag 的 name 提取出来呢？于是查了一下<a href="https://lodash.com/docs" target="_blank" rel="external">https://lodash.com/docs</a>( archive.jade 里注释中有让看的，就看看喽)，还真有 spilt 的函数。改完重新生成，显示正常了(别忘了把 tag/index.md 的 layout 改成 tags 哈)。</p>
<h3 id="改变文章中-tags-的显示位置"><a href="#改变文章中-tags-的显示位置" class="headerlink" title="改变文章中 tags 的显示位置"></a>改变文章中 tags 的显示位置</h3><p>默认界面 tags 在文章结束坐下位置，但我期望在界面文章开始位置增加 tags 的显示，即在点击量统计的后边再增加显示 tags 内容。结合模板代码和界面的显示效果，可以大致定位到具体代码位置。文章正文默认使用的 post 模板，位于 themes/maupassant/layout/post.jade 。在文件15-19行是点击量统计的代码，所以在后面可添加 tags 显示代码。</p>
<pre><code>if page.tags.length &gt; 0
  span= &#39; | &#39;
  span.tag
    for tag in page.tags.toArray()
      i(class=[&#39;fa&#39;,&#39;fa-paperclip&#39;]) &amp;nbsp;
      a(href=url_for(tag.path))= tag.name + &#39;&#39;
</code></pre><p>jade 模板的语法有严格缩进要求，所以和上边的代码位置一致即可。<br>代码看起来很简单，但是改的时候还是费了一些周折。</p>
<pre><code>page.tags.toArray()
</code></pre><p>的写法参考上文</p>
<pre><code>page.categories.toArray()
</code></pre><p>很容易写出来。</p>
<pre><code>i(class=[&#39;fa&#39;,&#39;fa-paperclip&#39;]) &amp;nbsp;
</code></pre><p>是一个 i 标签，用于显示图标，渲染成 html 是</p>
<pre><code>&lt;i class=&quot;fa fa-paperclip&quot;&gt;&amp;nbsp;&lt;/i&gt;
</code></pre><p>如果不看 jade 的语法，只根据 post.jade 文件中的代码可以大致推测 jade 的语法规则比如</p>
<pre><code>span.category
</code></pre><p>渲染成 html 后是```<br><span class="category"></span></p>
<pre><code>但是单 class 属性图标无法正常显示，也试过
</code></pre><p>i.fa.fa-paperclip<br>或<br>i.fa i.fa-paperclip</p>
<pre><code>等等写法，均不能达到效果，只好去看 jade 的文档。在[http://jade-lang.com/reference/attributes/](http://jade-lang.com/reference/attributes/)中 **Class Attributes** 找到了多个 class 的语法说明，问题至此得以解决。
</code></pre>]]></content>
      
        <categories>
            
            <category> Wiki </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> Jade </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[一个shell脚本示例]]></title>
      <url>/2016/07/16/shell-execute-java/</url>
      <content type="html"><![CDATA[<p>一个通过shell执行java程序的示例。</p>
<pre><code class="shell">#!/usr/bin/env bash

#``倒引号中是需要执行命令
#找到文件名字，/opt/demo/current/bin/start.sh
SCRIPT_PATH=`readlink -f &quot;$0&quot;`
#可用于定位路径，不用写绝对路径，增加可移植性
cd `dirname ${SCRIPT_PATH}`
#定位到/opt/demo/current/
cd ..
#创建目录
mkdir -p logs

PID_FILE=logs/web.pid
PID=&quot;&quot;
#如果文件存在，则读文件
if [ -f $PID_FILE ]
    then
    PID=`cat $PID_FILE`
fi

#如果pid不为空，使用ps查进程
if [ ! &quot;$PID&quot; = &quot;&quot; ]
    then
    #查到任何信息都丢弃，如果查到信息返回0，输出提示消息，没查到返回1
    if ( /bin/ps -p $PID &gt;/dev/null 2&gt;&amp;1 )
        then
        echo &quot;already started, pid = $PID&quot;
        exit 1
    fi
fi

CP=&quot;etc&quot;
#将target/classes加到classpath
if [ -d target/classes ]
    then
    CP=$CP:target/classes
fi

#将lib目录下的所有jar包加到classpath
for jar in `/bin/ls -1 lib/*.jar`
do
    CP=$CP:$jar
done

#执行java命令,$@表示所有的参数列表
java -cp $CP com.daas.cfg.Main $@ &amp;

#记录最后运行的后台Process的PID
PID=$!
#记录最后运行的命令的结束代码（返回值）
CODE=$?
#0 表示成功
if [ &quot;$CODE&quot; = &quot;0&quot; ]
    then
    #将pid写到文件
    echo $PID &gt;$PID_FILE
    echo &quot;started, PID=$PID&quot;
fi
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Shell </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[shell:autobak.sh]]></title>
      <url>/2016/07/16/auto-backup-with-shell/</url>
      <content type="html"><![CDATA[<pre><code>#!/bin/sh
# backup

DATE=$(date +%F)

# 判断目录是否存在并且有执行权限
if [ ! -x &quot;/test/backup&quot; ]
then
        mkdir /test/backup
fi

# 判断文件是否存在
if [ ! -f &quot;/test/backup/$1.error&quot; ]
then
        touch &quot;/test/backup/$1.error&quot;
fi

/bin/tar -cf /test/backup/$1.$DATE.tar $1 &gt; /dev/null 2&gt;&gt; /test/backup/$1.error
/bin/gzip /test/backup/$1.$DATE.tar

if [ $? -eq 0 ]
then
        echo &quot;$1 backup successfully&quot;
else
        echo &quot;ERROR: $1 $DATE backup&quot; &gt;&gt; /test/backup/$1.error
fi
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Ubuntu 16.04 软件安装及配置]]></title>
      <url>/2016/07/15/ubuntu-16.04-software-installation-and-configuration/</url>
      <content type="html"><![CDATA[<h3 id="0-更新源"><a href="#0-更新源" class="headerlink" title="0. 更新源"></a>0. 更新源</h3><pre><code>sudo cp /etc/apt/sources.list /etc/apt/sources.list_bak
</code></pre><pre><code>deb http://mirrors.sohu.com/ubuntu/ xenial-updates main restricted
deb-src http://mirrors.sohu.com/ubuntu/ xenial-updates main restricted
deb http://mirrors.sohu.com/ubuntu/ xenial universe
deb-src http://mirrors.sohu.com/ubuntu/ xenial universe
deb http://mirrors.sohu.com/ubuntu/ xenial-updates universe
deb-src http://mirrors.sohu.com/ubuntu/ xenial-updates universe
deb http://mirrors.sohu.com/ubuntu/ xenial multiverse
deb-src http://mirrors.sohu.com/ubuntu/ xenial multiverse
deb http://mirrors.sohu.com/ubuntu/ xenial-updates multiverse
deb-src http://mirrors.sohu.com/ubuntu/ xenial-updates multiverse
deb http://mirrors.sohu.com/ubuntu/ xenial-backports main restricted universe multiverse
deb-src http://mirrors.sohu.com/ubuntu/ xenial-backports main restricted universe multiverse

deb http://mirror.bjtu.edu.cn/ubuntu/ xenial main multiverse restricted universe
deb http://mirror.bjtu.edu.cn/ubuntu/ xenial-backports main multiverse restricted universe
deb http://mirror.bjtu.edu.cn/ubuntu/ xenial-proposed main multiverse restricted universe
deb http://mirror.bjtu.edu.cn/ubuntu/ xenial-security main multiverse restricted universe
deb http://mirror.bjtu.edu.cn/ubuntu/ xenial-updates main multiverse restricted universe
deb-src http://mirror.bjtu.edu.cn/ubuntu/ xenial main multiverse restricted universe
deb-src http://mirror.bjtu.edu.cn/ubuntu/ xenial-backports main multiverse restricted universe
deb-src http://mirror.bjtu.edu.cn/ubuntu/ xenial-proposed main multiverse restricted universe
deb-src http://mirror.bjtu.edu.cn/ubuntu/ xenial-security main multiverse restricted universe
deb-src http://mirror.bjtu.edu.cn/ubuntu/ xenial-updates main multiverse restricted universe
</code></pre><pre><code>sudo apt-get update
</code></pre><p>###1. 安装搜狗输入法</p>
<blockquote>
<p>sudo apt-get install fcitx libssh2-1</p>
</blockquote>
<p>####1.1 下载deb包</p>
<p>####1.2 安装</p>
<blockquote>
<p>sudo dpkg -i sogoupinyin_2.0.0.0072_amd64.deb</p>
<p>####1.3 设置<br>打开语言支持，键盘输入法系统选择fcitx。<br>    打开fcitx配置，添加搜狗输入法，注销后生效。</p>
</blockquote>
<p>###2. 安装Unity Tweak Tool<br>启动器图标单击收起。minimize single window applications on click</p>
<p>###3. 删除libreoffice</p>
<blockquote>
<p>sudo apt-get remove libreoffice-common</p>
<p>###4. 删除Amazon的链接<br>sudo apt-get remove unity-webapps-common</p>
<p>###5. 深度清理用不上的应用程序<br>sudo apt-get remove thunderbird totem rhythmbox empathy brasero simple-scan gnome-mahjongg aisleriot gnome-mines cheese transmission-common gnome-orca webbrowser-app gnome-sudoku  landscape-client-ui-install</p>
<p>sudo apt-get remove onboard deja-dup</p>
</blockquote>
<p>###6. 安装Terminator</p>
<p>###7. 安装WPS Office</p>
<pre><code>sudo dpkg -i wps-office_10.1.0.5444~a20_amd64.deb
</code></pre><p>wps不能输入中文</p>
<pre><code>sudo gedit /usr/bin/wps

#!/bin/bash
export XMODIFIERS=&quot;@im=fcitx&quot;
export QT_IM_MODULE=&quot;fcitx&quot;
gOpt=
#gOptExt=-multiply
gTemplateExt=(&quot;wpt&quot; &quot;dot&quot; &quot;dotx&quot;)
</code></pre><p>###8. 安装git</p>
<blockquote>
<p>sudo apt-get install git</p>
<p>###9. 安装Java</p>
<p>###10. 安装字体</p>
<p>####10.1 将windows字体拷贝到/usr/share/fonts/windows/</p>
<p>####10.2 修改权限</p>
<pre><code>sudo chmod 664 /usr/share/fonts/windows/*
</code></pre><p>####10.3 安装</p>
<pre><code>cd /usr/share/fonts/windows/
sudo mkfontscale
sudo mkfontdir
sudo fc-cache -fv
</code></pre><p>###11. 安装haroopad<br>编辑区主题 paraiso-darkdark</p>
<p>###12. 安装unrar<br>sudo apt-get install unrar</p>
<p>###13. 安装idea</p>
<p>###14. 安装mysql客户端navicat</p>
<p>###15. 安装maven</p>
<p>###16. 安装vmware</p>
<p>###17. 安装docker 未完成</p>
<p>###18. 安装node.js</p>
<p>###19. 安装gulp</p>
<p>###20. linux版百度网盘 bcloud</p>
<p>###21. thunderbird</p>
<p>####21.1 添加插件<br>Thunderbird Conversations<br>Manually Sort Folders<br>Color Folders<br>Extra Folder Columns<br>LookOut<br>ViewAbout<br>Theme Font &amp; Size Changer  </p>
</blockquote>
<p>####21.2 去除签名档之前的分割符<br>mail.identity.default.suppress_signature_separator=true</p>
<p>###22. 关闭系统错误报告</p>
<blockquote>
<p>sudo rm /var/crash/*<br>    sudo gedit /etc/default/apport</p>
</blockquote>
<p>修改enabled=1为enabled=0</p>
<p>###23. dash不搜索第三方应用</p>
<blockquote>
<p>wget -q -O - <a href="https://fixUbuntu.com/fixubuntu.sh" target="_blank" rel="external">https://fixUbuntu.com/fixubuntu.sh</a> | bash</p>
</blockquote>
<p>###24. chrome</p>
<pre><code>sudo wget https://repo.fdzh.org/chrome/google-chrome.list -P /etc/apt/sources.list.d/
wget -q -O - https://dl.google.com/linux/linux_signing_key.pub  | sudo apt-key add -
sudo apt-get update
sudo apt-get install google-chrome-stable
</code></pre><h3 id="25-plank"><a href="#25-plank" class="headerlink" title="25. plank"></a>25. plank</h3><p>安装</p>
<pre><code>sudo add-apt-repository ppa:docky-core/stable
sudo apt-get update
sudo apt-get install plank
</code></pre><p>设置开机启动<br>dash中搜索启动应用程序，添加plank路径/usr/bin/plank</p>
<h3 id="26-关闭utc"><a href="#26-关闭utc" class="headerlink" title="26. 关闭utc"></a>26. 关闭utc</h3><p>/etc/default/rcS</p>
<pre><code>utc=no
</code></pre><h3 id="27-uGet"><a href="#27-uGet" class="headerlink" title="27. uGet"></a>27. uGet</h3><h3 id="28-fileZilla"><a href="#28-fileZilla" class="headerlink" title="28. fileZilla"></a>28. fileZilla</h3><h3 id="29-MySQL-Workbench"><a href="#29-MySQL-Workbench" class="headerlink" title="29. MySQL Workbench"></a>29. MySQL Workbench</h3>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Ubuntu </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Ubuntu14.04 + ssh 镜像]]></title>
      <url>/2016/07/15/docker-ubuntu14.04-with-ssh/</url>
      <content type="html"><![CDATA[<h3 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h3><pre><code>mkdir ubuntu
cd ubuntu
touch Dockerfile run.sh sources.list authorized_keys
</code></pre><p><strong><em>Dockerfile</em></strong></p>
<pre><code>FROM ubuntu:14.04

MAINTAINER rolex

RUN rm /etc/apt/sources.list

ADD sources.list /etc/apt/sources.list

RUN apt-get update



RUN sudo apt-get install -y openssh-server
RUN mkdir -p /var/run/sshd
RUN mkdir -p /root/.ssh

RUN sed -ri &#39;s/session required pam_loginuid.so/#session required pam_loginuid.so/g&#39; /etc/pam.d/sshd

ADD authorized_keys /root/.ssh/authorized_keys
ADD run.sh /run.sh
RUN chmod 755 /run.sh

RUN groupadd dockerone
RUN useradd -g dockerone dockerone
RUN echo &quot;dockerone:dockerone&quot; | chpasswd

RUN echo &quot;root:dockerone&quot; | chpasswd

EXPOSE 22

CMD [&quot;/run.sh&quot;]
</code></pre><p><strong><em>run.sh</em></strong></p>
<pre><code>#!/bin/bash

/usr/sbin/sshd -D
</code></pre><p><strong><em>sources.list</em></strong></p>
<pre><code>deb http://mirrors.163.com/ubuntu/ trusty main restricted universe multiverse
deb http://mirrors.163.com/ubuntu/ trusty-security main restricted universe multiverse
deb http://mirrors.163.com/ubuntu/ trusty-updates main restricted universe multiverse
deb http://mirrors.163.com/ubuntu/ trusty-proposed main restricted universe multiverse
deb http://mirrors.163.com/ubuntu/ trusty-backports main restricted universe multiverse
</code></pre><p><strong><em>authorized_keys</em></strong></p>
<pre><code>ssh-keygen -t rsa
cat ~/.ssh/id_rsa.pub &gt; authorized_keys
</code></pre><h3 id="2-创建镜像"><a href="#2-创建镜像" class="headerlink" title="2. 创建镜像"></a>2. 创建镜像</h3><pre><code>sudo docker build -t ubuntu_14.04 .
</code></pre><h3 id="3-测试"><a href="#3-测试" class="headerlink" title="3. 测试"></a>3. 测试</h3><pre><code>sudo docker run -d -p 10122:22 ubuntu_14.04

ssh dockerone@localhost -p 10122
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[spring-data-elasticsearch 示例说明]]></title>
      <url>/2016/07/15/spring-data-elasticsearch/</url>
      <content type="html"><![CDATA[<h3 id="POM依赖"><a href="#POM依赖" class="headerlink" title="POM依赖"></a>POM依赖</h3><pre><code>&lt;properties&gt;
    &lt;java-version&gt;1.7&lt;/java-version&gt;
    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
    &lt;spring.version&gt;4.1.2.RELEASE&lt;/spring.version&gt;
    &lt;elasticsearch.version&gt;1.4.4&lt;/elasticsearch.version&gt;
    &lt;spring-data-elasticsearch.version&gt;1.3.4.RELEASE&lt;/spring-data-elasticsearch.version&gt;
&lt;/properties&gt;
&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework&lt;/groupId&gt;
        &lt;artifactId&gt;spring-context&lt;/artifactId&gt;
        &lt;version&gt;${spring.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework&lt;/groupId&gt;
        &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt;
        &lt;version&gt;${spring.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework&lt;/groupId&gt;
        &lt;artifactId&gt;spring-aop&lt;/artifactId&gt;
        &lt;version&gt;${spring.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework&lt;/groupId&gt;
        &lt;artifactId&gt;spring-core&lt;/artifactId&gt;
        &lt;version&gt;${spring.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework&lt;/groupId&gt;
        &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;
        &lt;version&gt;${spring.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt;
        &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt;
        &lt;version&gt;${elasticsearch.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.data&lt;/groupId&gt;
        &lt;artifactId&gt;spring-data-elasticsearch&lt;/artifactId&gt;
        &lt;version&gt;${spring-data-elasticsearch.version}&lt;/version&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre><h3 id="spring-配置文件"><a href="#spring-配置文件" class="headerlink" title="spring 配置文件"></a>spring 配置文件</h3><ol>
<li><p>beans.xml</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xmlns:context=&quot;http://www.springframework.org/schema/context&quot;
    xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
     http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd&quot;&gt;
 &lt;context:annotation-config /&gt;
 &lt;!-- 自动扫描所有注解该路径 --&gt;
 &lt;!-- &lt;context:component-scan base-package=&quot;com.sf.heros.mq.*&quot; /&gt; --&gt;
 &lt;context:property-placeholder location=&quot;classpath:/config.properties&quot; /&gt;

 &lt;import resource=&quot;elasticsearch.xml&quot; /&gt;
&lt;/beans&gt;
</code></pre></li>
<li><p>elasticsearch.xml</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
    xmlns:elasticsearch=&quot;http://www.springframework.org/schema/data/elasticsearch&quot;
    xsi:schemaLocation=&quot;http://www.springframework.org/schema/data/elasticsearch http://www.springframework.org/schema/data/elasticsearch/spring-elasticsearch-1.0.xsd
     http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd&quot;&gt;

 &lt;elasticsearch:transport-client id=&quot;client&quot; cluster-name=&quot;daas&quot; cluster-nodes=&quot;192.168.11.11:9300&quot;/&gt;

 &lt;bean name=&quot;elasticsearchTemplate&quot; class=&quot;org.springframework.data.elasticsearch.core.ElasticsearchTemplate&quot;&gt;
     &lt;constructor-arg name=&quot;client&quot; ref=&quot;client&quot;/&gt;
 &lt;/bean&gt;
 &lt;bean name=&quot;entQueryService&quot; class=&quot;com.rolex.se.sample.service.EntQueryService&quot;&gt;
     &lt;property name=&quot;repository&quot; ref=&quot;entQueryRepository&quot;/&gt;
     &lt;property name=&quot;elasticsearchTemplate&quot; ref=&quot;elasticsearchTemplate&quot;/&gt;
 &lt;/bean&gt;

 &lt;elasticsearch:repositories base-package=&quot;com.rolex.se.sample.dao&quot;/&gt;
&lt;/beans&gt;
</code></pre><h3 id="类"><a href="#类" class="headerlink" title="类"></a>类</h3></li>
<li>实体类<br>```java<br>import org.springframework.data.annotation.Id;<br>import org.springframework.data.elasticsearch.annotations.*;</li>
</ol>
<p>import java.util.*;</p>
<p>@Document(indexName = “pen”,type = “pen” , shards = 1, replicas = 0, indexStoreType = “memory”, refreshInterval = “-1”)<br>public class Pen {</p>
<pre><code>@Id
private String id;
private String name;
private Long price;
@Field(type = FieldType.String, index = FieldIndex.not_analyzed)
private Set&lt;String&gt; type = new HashSet&lt;String&gt;();

public Set&lt;String&gt; getType() {
    return type;
}

public void setType(Set&lt;String&gt; type) {
    this.type = type;
}

public Pen(){}

public Pen(String id, String name) {
    this.id = id;
    this.name = name;
}

public String getId() {
    return id;
}

public void setId(String id) {
    this.id = id;
}

public String getName() {
    return name;
}

public void setName(String name) {
    this.name = name;
}

public Long getPrice() {
    return price;
}

public void setPrice(Long price) {
    this.price = price;
}
</code></pre><p>}</p>
<pre><code>
2. 查询类
```java
import org.springframework.data.elasticsearch.entities.Pen;
import org.springframework.data.elasticsearch.repository.ElasticsearchRepository;

public interface PenRepository extends ElasticsearchRepository&lt;Pen,String&gt; {
}
</code></pre><ol>
<li>测试类<br>```java<br>import org.elasticsearch.index.query.BoolQueryBuilder;<br>import org.elasticsearch.index.query.QueryBuilders;<br>import org.junit.Before;<br>import org.junit.Test;<br>import org.junit.runner.RunWith;<br>import org.springframework.data.elasticsearch.entities.Pen;<br>import org.springframework.test.context.ContextConfiguration;<br>import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;</li>
</ol>
<p>import javax.annotation.Resource;<br>import java.util.*;</p>
<p>@RunWith(SpringJUnit4ClassRunner.class)<br>@ContextConfiguration(“classpath:/springContext-test.xml”)<br>public class PenRepositoryTest {</p>
<pre><code>@Resource
private PenRepository penRepository;

@Before
public void emptyData(){
    penRepository.deleteAll();
}

@Test
public void shouldIndexSingleBookEntity(){

    Pen pen = new Pen();
    pen.setId(&quot;123455&quot;);
    pen.setName(&quot;LIMY&quot;);
    Set&lt;String&gt; types = new HashSet&lt;String&gt;();
    types.add(&quot;E_PRI_PERSON.NAME&quot;);
    types.add(&quot;E_INV_INVESTMENT.SUBCONAM&quot;);
    pen.setType(types);
    //Indexing using sampleArticleRepository
    penRepository.save(pen);
    //lets try to search same record in elasticsearch
    Pen pen2 = penRepository.findOne(pen.getId());

    BoolQueryBuilder query = QueryBuilders.boolQuery();
        query.must(QueryBuilders.queryString(&quot;E_PRI_PERSON.NAME&quot;).field(&quot;pen.type&quot;))
        .must(QueryBuilders.queryString(&quot;E_INV_INVESTMENT.SUBCONAM&quot;).field(&quot;pen.type&quot;));



    Iterable&lt;Pen&gt; res = penRepository.search(query);

    Iterator&lt;Pen&gt; it = res.iterator();

    while (it.hasNext()){
        System.out.println(it.next().getType());
    }

}
</code></pre><p>}<br>```</p>
]]></content>
      
        <categories>
            
            <category> Spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
            <tag> Spring </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[IDEA + Maven + Jetty 热部署]]></title>
      <url>/2016/07/15/jetty-hot-deployment/</url>
      <content type="html"><![CDATA[<p>####1. 集成</p>
<p>pom.xml</p>
<pre><code>&lt;build&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.mortbay.jetty&lt;/groupId&gt;
            &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt;
            &lt;version&gt;8.1.15.v20140411&lt;/version&gt;
            &lt;configuration&gt;
                &lt;connectors&gt;
                    &lt;!-- 修改端口 --&gt;
                    &lt;connector implementation=&quot;org.eclipse.jetty.server.nio.SelectChannelConnector&quot;&gt;
                        &lt;port&gt;8080&lt;/port&gt;
                    &lt;/connector&gt;
                &lt;/connectors&gt;
                &lt;stopKey&gt;exit&lt;/stopKey&gt;
                &lt;stopPort&gt;9090&lt;/stopPort&gt;
                &lt;scanIntervalSeconds&gt;10&lt;/scanIntervalSeconds&gt;
                &lt;webAppConfig&gt;
                    &lt;!-- 热部署 --&gt;
                    &lt;defaultsDescriptor&gt;src/main/resources/webdefault.xml&lt;/defaultsDescriptor&gt;
                    &lt;contextPath&gt;/redis-doc&lt;/contextPath&gt;
                &lt;/webAppConfig&gt;
            &lt;/configuration&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Meven </tag>
            
            <tag> Jetty </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[spring-data-redis示例说明]]></title>
      <url>/2016/07/15/spring-data-redis/</url>
      <content type="html"><![CDATA[<p>###1. POM</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.data&lt;/groupId&gt;
    &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt;
    &lt;version&gt;1.6.4.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;redis.clients&lt;/groupId&gt;
    &lt;artifactId&gt;jedis&lt;/artifactId&gt;
    &lt;version&gt;2.6.2&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>###2. 配置文件</p>
<p>####2.1 redis.xml</p>
<pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd
       http://www.springframework.org/schema/context
       http://www.springframework.org/schema/context/spring-context-4.0.xsd&quot;&gt;


    &lt;context:property-placeholder location=&quot;classpath:config.properties&quot;/&gt;
    &lt;bean id=&quot;jedisPoolConfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt;
        &lt;property name=&quot;maxTotal&quot; value=&quot;${redis.cache.pool.maxTotal}&quot; /&gt;
        &lt;property name=&quot;maxIdle&quot; value=&quot;${redis.cache.pool.maxIdle}&quot; /&gt;
        &lt;property name=&quot;maxWaitMillis&quot; value=&quot;${redis.cache.pool.maxWaitMillis}&quot; /&gt;
        &lt;property name=&quot;testOnBorrow&quot; value=&quot;${redis.cache.pool.testOnBorrow}&quot; /&gt;
    &lt;/bean&gt;

    &lt;bean id=&quot;redisTemplate&quot; class=&quot;org.springframework.data.redis.core.RedisTemplate&quot;&gt;
        &lt;property name=&quot;keySerializer&quot;&gt;
            &lt;bean class=&quot;org.springframework.data.redis.serializer.StringRedisSerializer&quot;/&gt;
        &lt;/property&gt;
        &lt;property name=&quot;valueSerializer&quot;&gt;
            &lt;bean class=&quot;org.springframework.data.redis.serializer.JdkSerializationRedisSerializer&quot;/&gt;
        &lt;/property&gt;
        &lt;property name=&quot;connectionFactory&quot; ref=&quot;jedisConnectionFactory&quot;/&gt;
    &lt;/bean&gt;

    &lt;bean id=&quot;jedisConnectionFactory&quot; class=&quot;org.springframework.data.redis.connection.jedis.JedisConnectionFactory&quot;&gt;
        &lt;property name=&quot;hostName&quot; value=&quot;${redis.cache.ip}&quot; /&gt;
        &lt;property name=&quot;port&quot; value=&quot;${redis.cache.port}&quot; /&gt;
        &lt;property name=&quot;usePool&quot; value=&quot;${redis.cache.usePool}&quot;/&gt;
        &lt;property name=&quot;poolConfig&quot; ref=&quot;jedisPoolConfig&quot; /&gt;
    &lt;/bean&gt;

    &lt;bean id=&quot;queryCacheRepository&quot; class=&quot;com.daas.data.dao.repository.QueryCacheRepository&quot;&gt;&lt;/bean&gt;

&lt;/beans&gt;
</code></pre>
<p>####2.2 properties文件</p>
<p>#redis配置</p>
<pre><code>redis.cache.pool.maxTotal=1024
redis.cache.pool.maxIdle=200
redis.cache.pool.maxWaitMillis=1000
redis.cache.pool.testOnBorrow=true
redis.cache.ip=192.168.11.21
redis.cache.port=6379
redis.cache.usePool=true
</code></pre><p>###3. 类</p>
<p>####3.1 实体类</p>
<pre><code class="java">/*
 * @(#)QueryCache.java    1.0 2016/3/8
 *
 */
package com.daas.data.engine.entity.redis;

import java.io.Serializable;

/**
 * Created with IntelliJ IDEA.
 * User: rolex
 * Date: 2016/3/8
 * version: 1.0
 */
public class QueryCache implements Serializable{

    String id;
    String value;

    public String getValue() {
        return value;
    }

    public void setValue(String value) {
        this.value = value;
    }

    public String getId() {
        return id;
    }

    public void setId(String id) {
        this.id = id;
    }
}
</code></pre>
<p>####3.2 查询类</p>
<pre><code class="java">/*
 * @(#)QueryCacheRepository.java    1.0 2016/3/8
 *
 */
package com.daas.data.dao.repository;

import com.daas.data.engine.entity.redis.QueryCache;
import org.springframework.data.redis.core.RedisTemplate;

import javax.annotation.Resource;

/**
 * Created with IntelliJ IDEA.
 * User: rolex
 * Date: 2016/3/8
 * version: 1.0
 */
public class QueryCacheRepository {

    @Resource
    private RedisTemplate&lt;String, QueryCache&gt; redisTemplate;

    public void set(QueryCache qc){
        redisTemplate.opsForValue().set(qc.getId(), qc);

    }

    public QueryCache get(String id){
        return redisTemplate.opsForValue().get(id);
    }
}
</code></pre>
<p>####3.3 测试类</p>
<pre><code class="java">/*
 * @(#)DataBusinessTest.java    1.0 2016/3/4
 *
 */
package com.daas.data.business;

import com.daas.data.dao.repository.QueryCacheRepository;
import com.daas.data.engine.entity.redis.QueryCache;
import org.elasticsearch.search.aggregations.InternalAggregation;
import org.hamcrest.core.IsEqual;
import org.junit.Before;
import org.junit.Test;
import org.junit.runner.RunWith;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.test.context.ContextConfiguration;
import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;

import javax.annotation.Resource;
import java.io.IOException;

import static org.junit.Assert.assertThat;


/**
 * Created with IntelliJ IDEA.
 * User: rolex
 * Date: 2016/3/4
 * version: 1.0
 */
@RunWith(SpringJUnit4ClassRunner.class)
@ContextConfiguration(&quot;classpath:redis-test.xml&quot;)
public class RedisServiceTest {


    @Resource
    QueryCacheRepository queryCacheRepository;

    @Before
    public void before() {
        QueryCache qc = new QueryCache();
        qc.setId(&quot;123&quot;);
        qc.setValue(&quot;test&quot;);
        queryCacheRepository.set(qc);
    }

    @Test
    public void testGet() throws IOException {
        QueryCache qc = queryCacheRepository.get(&quot;123&quot;);
        System.out.println(qc.getValue());
        assertThat(qc.getValue(), new IsEqual(&quot;test&quot;));

    }

}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Spring </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Spring </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[创建 tomcat 镜像]]></title>
      <url>/2016/07/15/docker-tomcat-image/</url>
      <content type="html"><![CDATA[<h3 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h3><p>1.1 创建制作 docker 镜像的工作目录和文件</p>
<pre><code>mkdir dorckerfiles
cd dockerfiles
touch Dockerfile run.sh
</code></pre><p><strong><em>Dockerfile</em></strong></p>
<pre><code>FROM ubuntu_14.04

MAINTAINER rolex

ENV DEBIAN_FRONTEND noninteractive

RUN echo &quot;Asia/Beijing&quot; &gt; /etc/timezone &amp;&amp; dpkg-reconfigure -f noninteractive tzdata

RUN apt-get install -yq --no-install-recommends wget pwgen ca-certificates &amp;&amp; apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*

ENV CATALINA_HOME /tomcat
ENV JAVA_HOME /jdk

ADD apache-tomcat-8.0.35 /tomcat
ADD jdk1.8.0_74 /jdk

#ADD create_tomcat_admin_user.sh /create_tomcat_admin_user.sh
ADD run.sh /run.sh

RUN chmod +x /*.sh
RUN chmod +x /tomcat/bin/*.sh

EXPOSE 8080

CMD [&quot;/run.sh&quot;]
</code></pre><p><strong><em>run.sh</em></strong></p>
<pre><code>#!/bin/bash

/user/sbin/sshd -D &amp;
exec ${CATALINA_HOME}/bin/catalina.sh run
</code></pre><p>1.2 下载 tomcat 和 jdk</p>
<h3 id="2-制作镜像"><a href="#2-制作镜像" class="headerlink" title="2. 制作镜像"></a>2. 制作镜像</h3><pre><code>sudo docker build -t tomcat8_on_ubuntu .
</code></pre><h3 id="3-运行镜像"><a href="#3-运行镜像" class="headerlink" title="3. 运行镜像"></a>3. 运行镜像</h3><pre><code>sudo docker run -p 32700:8080 tomcat8_on_ubuntu
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Windows 安装 compass and scss]]></title>
      <url>/2016/07/15/installing-compass-and-scss-on-windows/</url>
      <content type="html"><![CDATA[<h3 id="1-安装ruby"><a href="#1-安装ruby" class="headerlink" title="1. 安装ruby"></a>1. 安装ruby</h3><p>compass 是 ruby 的插件，需要先安装 ruby 环境。</p>
<ol>
<li>下载ruby</li>
</ol>
<p><a href="http://rubyinstaller.org/" target="_blank" rel="external">http://rubyinstaller.org/</a></p>
<ol>
<li>添加环境变量<br>安装完成后添加环境变量<pre><code>RUBY_HOME=D:\Ruby23-x64
path=$path;%RUBY_HOME%\bin
</code></pre>执行ruby -v 显示版本号则安装成功。</li>
</ol>
<h3 id="2-添加证书"><a href="#2-添加证书" class="headerlink" title="2. 添加证书"></a>2. 添加证书</h3><ol>
<li>下载证书</li>
</ol>
<p>从<a href="http://curl.haxx.se/ca/cacert.pem" target="_blank" rel="external">http://curl.haxx.se/ca/cacert.pem</a>下载证书，保存到ruby安装目录。</p>
<ol>
<li>添加环境变量<pre><code>SSL_CERT_FILE=D:\Ruby23-x64\cacert.pem
</code></pre><h3 id="3-修改源"><a href="#3-修改源" class="headerlink" title="3. 修改源"></a>3. 修改源</h3><pre><code>gem sources --remove https://rubygems.org/
gem sources -a https://ruby.taobao.org/
gem sources -l
</code></pre><h3 id="4-安装compass"><a href="#4-安装compass" class="headerlink" title="4. 安装compass"></a>4. 安装compass</h3><pre><code>gem install compass
</code></pre>sass -v显示版本号则安装成功。正常情况compass和scss都会安装。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Compass </tag>
            
            <tag> Scss </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch 添加 head 插件]]></title>
      <url>/2016/07/15/docker-elasticsearch-head-plugin/</url>
      <content type="html"><![CDATA[<h3 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h3><pre><code>mkdir dockerfiles/elasticsearch
touch Dockerfile
wget -O elasticsearch-head-master.zip -c https://codeload.github.com/mobz/elasticsearch-head/zip/master
</code></pre><p><strong><em>Dockerfile</em></strong></p>
<pre><code>FROM elasticsearch
MAINTAINER rolex

ADD elasticsearch-head-master.zip /elasticsearch-head-master.zip

RUN /usr/share/elasticsearch/bin/plugin install file:/elasticsearch-head-master.zip

RUN rm -f /elasticsearch-head-master.zip

EXPOSE 9200 9300

CMD [/usr/share/elasticsearch/bin/elasticsearch]
</code></pre><h3 id="2-创建docker镜像"><a href="#2-创建docker镜像" class="headerlink" title="2. 创建docker镜像"></a>2. 创建docker镜像</h3><pre><code>sudo docker build -t elasticsearch-2.3 .
</code></pre><h3 id="3-启动"><a href="#3-启动" class="headerlink" title="3. 启动"></a>3. 启动</h3><pre><code>sudo docker run elasticsearch-2.3 --publish=[19200:9200,19300:9300]
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[使用 docker + redis 学习 redis-cli]]></title>
      <url>/2016/07/15/docker-build-redis/</url>
      <content type="html"><![CDATA[<p>有时我们不想在自己机器上安装redis环境又想快速开始redis-cli实践，如果安装了docker环境，那么redis的环境将非常容易搭建。</p>
<h3 id="1-下载redis的docker镜像"><a href="#1-下载redis的docker镜像" class="headerlink" title="1. 下载redis的docker镜像"></a>1. 下载redis的docker镜像</h3><pre><code class="shell">sudo docker pull redis
</code></pre>
<h3 id="2-启动redis-server"><a href="#2-启动redis-server" class="headerlink" title="2. 启动redis server"></a>2. 启动redis server</h3><pre><code class="shell">sudo docker run -d --name redisone redis redis-server
</code></pre>
<h3 id="3-启动redis-cli"><a href="#3-启动redis-cli" class="headerlink" title="3. 启动redis cli"></a>3. 启动redis cli</h3><pre><code class="shell">sudo docker run -it --link redisone redis redic-cli -h redisone -p 6379
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Redis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch-2.2.0 安装]]></title>
      <url>/2016/07/14/elasticsearch-2.1.1-installation/</url>
      <content type="html"><![CDATA[<h3 id="1-下载"><a href="#1-下载" class="headerlink" title="1. 下载"></a>1. 下载</h3><p><a href="https://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.2.0/elasticsearch-2.2.0.tar.gz" title="elasticsearch-2.2.0" target="_blank" rel="external">https://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.2.0/elasticsearch-2.2.0.tar.gz</a></p>
<h3 id="2-安装"><a href="#2-安装" class="headerlink" title="2. 安装"></a>2. 安装</h3><pre><code>tar -zxf elasticsearch-2.2.0.tar.gz
</code></pre><h3 id="3-配置"><a href="#3-配置" class="headerlink" title="3. 配置"></a>3. 配置</h3><blockquote>
<p>vi ./config/elasticsearch.yml</p>
</blockquote>
<pre><code>cluster.name: elsticsearch  
node.name: chinadaas01
network.host: 192.168.200.163
discovery.zen.ping.unicast.hosts: [&quot;192.168.200.163&quot;,&quot;192.168.200.164&quot;,&quot;192.168.200.165&quot;,&quot;192.168.200.166&quot;]
</code></pre><h3 id="4-安装插件"><a href="#4-安装插件" class="headerlink" title="4. 安装插件"></a>4. 安装插件</h3><h4 id="4-1-下载"><a href="#4-1-下载" class="headerlink" title="4.1 下载"></a>4.1 下载</h4><blockquote>
<p>wget <a href="https://github.com/mobz/elasticsearch-head.git" target="_blank" rel="external">https://github.com/mobz/elasticsearch-head.git</a></p>
<h4 id="4-2-安装"><a href="#4-2-安装" class="headerlink" title="4.2 安装"></a>4.2 安装</h4><p>elasticsearch提供了两种安装方式，在线安装总失败，所以选离线安装。<br>./bin/plugin install file:./elasticsearch-head-master.zip</p>
</blockquote>
<h3 id="5-集群搭建"><a href="#5-集群搭建" class="headerlink" title="5. 集群搭建"></a>5. 集群搭建</h3><p>其他机器执行相同配置，ip和node.name改成对应机器的ip。</p>
<h3 id="6-启动"><a href="#6-启动" class="headerlink" title="6. 启动"></a>6. 启动</h3><blockquote>
<p>./bin/elasticsearch &amp;</p>
</blockquote>
<p>浏览器中使用 <code>http://192.168.200.163:9200/_plugin/head/</code> 可看到界面</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Elasticsearch-1.4.1 集群环境搭建]]></title>
      <url>/2016/07/14/elasticsearch-1.4.1-cluster/</url>
      <content type="html"><![CDATA[<p>CentOS 6.4，机器 node3（10.20.20.203）,node4（10.20.20.204）</p>
<h3 id="1-安装jdk"><a href="#1-安装jdk" class="headerlink" title="1. 安装jdk"></a>1. 安装jdk</h3><p>已安装跳过。</p>
<h3 id="2-下载"><a href="#2-下载" class="headerlink" title="2. 下载"></a>2. 下载</h3><p><a href="https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.4.1.tar.gz" title="elasticsearch-1.4.1" target="_blank" rel="external">https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.4.1.tar.gz</a></p>
<h3 id="3-解压"><a href="#3-解压" class="headerlink" title="3. 解压"></a>3. 解压</h3><pre><code>tar -zxf elasticsearch-1.4.1.tar.gz
</code></pre><h3 id="4-配置"><a href="#4-配置" class="headerlink" title="4. 配置"></a>4. 配置</h3><p>分别修改2台机器配置</p>
<p>node3</p>
<pre><code>cluster.name: elasticsearch
node.name: node3
network.host: 10.20.20.203  
discovery.zen.ping.unicast.hosts: [&quot;10.20.20.203&quot;]
</code></pre><p>node4</p>
<pre><code>cluster.name: elasticsearch
node.name: node4
network.host: 10.20.20.204  
discovery.zen.ping.unicast.hosts: [&quot;10.20.20.204&quot;]
</code></pre><h3 id="5-安装插件"><a href="#5-安装插件" class="headerlink" title="5. 安装插件"></a>5. 安装插件</h3><h4 id="5-1-下载"><a href="#5-1-下载" class="headerlink" title="5.1 下载"></a>5.1 下载</h4><pre><code>wget https://github.com/mobz/elasticsearch-head.git
</code></pre><h4 id="5-2-安装"><a href="#5-2-安装" class="headerlink" title="5.2 安装"></a>5.2 安装</h4><p>将插件elasticsearch-head-master.zip拷贝到plugin,解压缩</p>
<pre><code>unzip elasticsearch-head-master.zip
mv elasticsearch-head-master head
</code></pre><p>2台机器执行相同操作</p>
<h3 id="6-启动"><a href="#6-启动" class="headerlink" title="6. 启动"></a>6. 启动</h3><pre><code>./bin/elasticsearch &amp;
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Elastic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Github + Hexo 搭建 Markdown 博客系统]]></title>
      <url>/2016/07/14/building-blog-with-hexo-on-github/</url>
      <content type="html"><![CDATA[<p>为了更好的积累和保存学习笔记，需要满足以下要求：</p>
<ol>
<li>免费；</li>
<li>界面漂亮</li>
<li>能使用markdown语法书写；</li>
<li>能够导出到evernote。</li>
</ol>
<p>试了很多markdown的博客系统，在线编辑器，markdown软件，都无法满足，后来发现了Hexo。</p>
<p>Hexo是一个 markdown 博客系统，初步了解优点如下：</p>
<ol>
<li>没有数据库，直接保存 markdown 文件，所以迁移应该很方便；</li>
<li>可以自选theme；</li>
<li>在没有网络主机的情况下，可在本地搭建博客系统，通过github页可以实现远程备份；</li>
<li>开源。</li>
</ol>
<p>以上基本可以满足个人需求。</p>
<h2 id="如何搭建本地Hexo环境？"><a href="#如何搭建本地Hexo环境？" class="headerlink" title="如何搭建本地Hexo环境？"></a>如何搭建本地Hexo环境？</h2><p>搭建Hexo环境很简单，Hexo是基于nodejs的，所以首先需要有node环境，如何安装node可参考<a href="www.aaa.com">源码编译安装nodejs</a>。</p>
<h3 id="1-安装Hexo"><a href="#1-安装Hexo" class="headerlink" title="1. 安装Hexo"></a>1. 安装Hexo</h3><pre><code class="shell">npm install hexo -g
</code></pre>
<h3 id="2-升级"><a href="#2-升级" class="headerlink" title="2. 升级"></a>2. 升级</h3><pre><code class="shell">npm update hexo -g
</code></pre>
<h3 id="3-初始化"><a href="#3-初始化" class="headerlink" title="3. 初始化"></a>3. 初始化</h3><pre><code class="shell">mkdir hexo
cd hexo
hexo init
</code></pre>
<h3 id="4-生成"><a href="#4-生成" class="headerlink" title="4. 生成"></a>4. 生成</h3><pre><code class="shell">hexo generate
or
hexo g
</code></pre>
<h3 id="5-启动服务"><a href="#5-启动服务" class="headerlink" title="5. 启动服务"></a>5. 启动服务</h3><pre><code class="shell">hexo server
or
hexo s
</code></pre>
<p>启动后可在<a href="http://localhost:4000" target="_blank" rel="external">http://localhost:4000</a>访问。</p>
<h2 id="如何更换主题"><a href="#如何更换主题" class="headerlink" title="如何更换主题"></a>如何更换主题</h2><p>Hexo有很多主题，<a href="https://hexo.io/themes/" target="_blank" rel="external">https://hexo.io/themes/</a>网站上列举了一些主题，并带有效果展示。如果没有中意的主题，可以继续google一下。</p>
<p>安装主题方法也很简单，以 maupassant 为例：</p>
<h3 id="1-下载主题"><a href="#1-下载主题" class="headerlink" title="1. 下载主题"></a>1. 下载主题</h3><pre><code class="shell">cd hexo/themes
git clone git@github.com:tufu9441/maupassant-hexo.git maupassant
npm install hexo-renderer-jade --save
npm install hexo-renderer-sass --save
</code></pre>
<h3 id="2-更换主题"><a href="#2-更换主题" class="headerlink" title="2. 更换主题"></a>2. 更换主题</h3><pre><code class="shell">vi hexo/_config.yml

language: zh-CN
theme: maupassant
</code></pre>
<p>从新启动后可看到效果。</p>
<h2 id="第一篇博客"><a href="#第一篇博客" class="headerlink" title="第一篇博客"></a>第一篇博客</h2><p>现在可以开始写第一篇博客了，使用</p>
<pre><code class="shell">hexo new helloworld
or
hexo n helloworld
</code></pre>
<p>就创建了一篇新博客，存放在 <strong>hexo/source/_posts/</strong> 下，刷新网页可看到效果。</p>
<h2 id="部署到github"><a href="#部署到github" class="headerlink" title="部署到github"></a>部署到github</h2><p>使用github的好处除了进行远程备份之外，还能直接通过github网站访问博客，非常方便。</p>
<h3 id="1-修改配置"><a href="#1-修改配置" class="headerlink" title="1. 修改配置"></a>1. 修改配置</h3><pre><code class="shell">vi hexo/_config.yml

url: http://bysonline.github.io
deploy:
  type: git
  repository: git@github.com:bsyonline/bsyonline.github.io.git
  branch: master
</code></pre>
<h3 id="2-部署"><a href="#2-部署" class="headerlink" title="2. 部署"></a>2. 部署</h3><pre><code class="shell">hexo g
hexo d
</code></pre>
<p>完成之后可以访问bsyonline.github.io看到效果。<br>注：github的仓库名字必须是xxx.github.io</p>
<p>至此，本地的hexo博客系统就搭建好了。</p>
]]></content>
      
        <categories>
            
            <category> Wiki </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hexo </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL-5.7.11-winx64 zip版安装]]></title>
      <url>/2016/06/22/mysql-5.7.11-winx64-zip-installation/</url>
      <content type="html"><![CDATA[<p>OS : Windows 10 x64</p>
<h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><p>解压路径为 <strong>%MYSQL_HOME%</strong></p>
<h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p>add <strong>%MYSQL_HOME%\bin</strong> to path</p>
<h3 id="修改my-ini"><a href="#修改my-ini" class="headerlink" title="修改my.ini"></a>修改my.ini</h3><p>拷贝my-default.ini为my.ini</p>
<pre><code>basedir = D:\Program Files\MySQL\mysql-5.7.11-winx64
datadir =  D:\Program Files\MySQL\mysql-5.7.11-winx64\data
port = 3306
</code></pre><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><pre><code>mysqld --initialize --user=mysql --console
</code></pre><p>记录末尾的初始密码</p>
<h3 id="安装服务"><a href="#安装服务" class="headerlink" title="安装服务"></a>安装服务</h3><pre><code>mysqld --install MySQL
</code></pre><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><pre><code>net start mysql
</code></pre><h3 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h3><pre><code>mysql -u root -p
</code></pre><h3 id="修改密码"><a href="#修改密码" class="headerlink" title="修改密码"></a>修改密码</h3><pre><code>set password for root@localhost = password(&#39;123456&#39;);
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MySQL </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Node.js 环境安装]]></title>
      <url>/2016/06/18/node.js-installation/</url>
      <content type="html"><![CDATA[<h3 id="1-下载最新版本源代码"><a href="#1-下载最新版本源代码" class="headerlink" title="1. 下载最新版本源代码"></a>1. 下载最新版本源代码</h3><h3 id="2-解压安装"><a href="#2-解压安装" class="headerlink" title="2. 解压安装"></a>2. 解压安装</h3><pre><code>tar -zxf node-v5.11.0.tar.gz
cd node-v5.11.0
sudo ./configure
sudo make
sudo make install
</code></pre><p>使用<code>node -v</code>输出版本信息则安装成功。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Nodejs </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark SQL 简单实践]]></title>
      <url>/2016/05/31/spark-sql-practice/</url>
      <content type="html"></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark 调优]]></title>
      <url>/2016/05/27/spark-tuning/</url>
      <content type="html"><![CDATA[<p>Spark 调优最重要的就是序列化和内存调优。通常情况下，使用 Kryo 序列化库就可以解决大多数的性能问题，但有时可能还需要配合其他手段。</p>
<h3 id="内存调优"><a href="#内存调优" class="headerlink" title="内存调优"></a><strong>内存调优</strong></h3><p>Spark 是基于内存的，所以合理地管理内存会提高程序的性能。想要有效地管理内存，就要知道对象占用了多少内存，访问对象的开销以及 GC 的执行情况。</p>
<p>首先，要知道对象占了多少内存，我们需要清楚有哪些地方会消耗掉内存。默认情况下，Java 可以快速访问对象，但是需要消耗的空间是原生数据类型2-5倍。Java 对象为什么会比原生数据类型多消耗这么多空间呢？原因有以下几点：</p>
<ul>
<li>每个 Java 对象都有一个“对象头”，对象头大约 16 个字节，包含类似指向类的指针信息。如果一个对象很小，对象头可能比对象包含的数据还要大。</li>
<li>Java 的 String 在原始的 String 数据上会额外占用大约 40 字节 ，用来存储如长度之类的信息。由于 Java 使用 UTF-16 编码，所以每个字符会占用 2 个字节。一个 10 个字符的 String 大概会占用 60 个字节。</li>
<li>HashMap 和 LinkedList 这样常见的数据结构使用了链表数据结构，每一个 entry 都是一个包装对象，这些对象不光包含对象头，还包含了指向下一个对象的引用，这个引用会额外占用 8 个字节。</li>
<li>常见的原始数据类型集合都会以包装类形式存储，比如 Integer。</li>
</ul>
<p>因此，降低内存消耗的一种方法是不使用带有头和额外开销的数据结构。比如</p>
<ul>
<li>使用数组和原始数据类型代替集合和包装类。</li>
<li>尽量避免嵌套的数据结构。</li>
<li>使用数值型和枚举型代替字符串作为 id 。</li>
<li>对于内存小于 32 G的机器，使用 JVM 的 <code>XX:+UseCompressedOops</code> 参数限制引用长度为 4 字节。</li>
</ul>
<p>在 Spark 中内存被用来执行计算（shuffle、join、sort、aggregations）和存储数据（缓存和广播数据）。执行计算和存储数据使用的是同一块区域（M），如果执行计算的内存没有被使用，存储数据可以占用这些内存，反之，执行计算也可以使用没有被存储占用的内存。如果一个程序没有使用缓存，那么程序可以将所有内存用来执行计算。虽然执行计算可以释放存储以获取更多的内存，但是缓存在不超过阈值（R）的情况下，才会被释放。</p>
<p>关于内存的划分，Spark 提供了两个参数，但大多数场景下，用户是不需要调整 Spark 的配置的。</p>
<ul>
<li>spark.memory.fraction  默认为 0.6 ，即 M 的 60% 。剩余的 40% 空间用来存储。</li>
<li>spark.memory.storageFraction 默认为 0.5 ，即 R 占 M 的 50% 。 </li>
</ul>
<h3 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h3><p>当您的程序中存储的 RDDs 有很大的“搅动”时，JVM 垃圾收集可能会成为一个问题。当 Java 需要清除旧对象为新对象腾出空间时，它需要跟踪所有的 Java 对象并找到未使用的对象。这里要记住的要点是，垃圾收集的成本与 Java 对象的数量成比例，所以使用较少对象的数据结构（例如，一个 Ints 数组而不是一个 LinkedList ）可以大大降低这个成本。一种更好的方法是将以序列化的形式存储对象，如上所述：现在每个RDD分区只会有一个对象（一个字节数组）。在尝试其他技术之前，如果GC是一个问题，首先要尝试的是使用序列化缓存。</p>
<p>GC调优的第一步是收集有关垃圾收集发生频率和花费的时间的统计信息。这可以通过添加 <code>-verbose:gc</code> <code>-XX:+PrintGCDetails</code> <code>-XX:+printgctimetstamp</code> 选项来完成。</p>
<p>在进行调优之前，需要了解 Java 的 GC 模型。</p>
<ul>
<li>Java 堆空间分为两个区域，分别是 Young 和 Old。Young 用来保存寿命较短的对象，而 Old 则用来保存具有较长寿命的对象。</li>
<li>Young 被进一步划分为三个区域：Eden, Survivor1, Survivor2 。</li>
<li>当 Eden 满时，会运行一次小的 GC ，Eden 和 Survivor1 中没有被回收的对象被复制到 Survivor2 。当对象寿命足够长或 Survivor2 满了，对象将被移到 Old 。最后，当 Old 接近饱和时，将调用 full GC 。</li>
</ul>
<p>在Spark中，GC 调优的目标是确保长寿的 RDD 只存储在 Old 中，同时 Young 有足够的空间来存储寿命较短的 RDD 。这样有助于避免在执行期间调用 full GC 来回收临时对象。以下方法可以参考：</p>
<ul>
<li>通过收集 GC 统计信息检查是否有太多的 GC。如果在任务执行过程中多次出现 full GC，说明没有足够的内存可用来执行任务。</li>
<li>如果有大量的小 GC ，可以调整 Eden 的大小。可以将 Eden 的大小设置为任务所需要内存的最大值。如果将 Eden 的大小确定为 E ，那么 Young 的大小可以设置为 -Xmn=4/3 E。例如，从 HDFS 上读取数据，可以根据 HDFS 使用的数据块来估算需要的内存。如果有 3-4 个 HDFS 数据块，每个块的大小是 128 M，那么需要的 Eden 大小大概是 4 * 3 * 128  M 。（压缩块的大小是普通块大小的 2-3 倍）</li>
<li>在打印的 GC 统计数据中，如果 Old 快满了，那么通过降低 <code>spark.memory.fraction</code> 来减少用于缓存的内存的数量或者减小 <code>-Xmn</code> 的值。如果无效，可以尝试调大 JVM 的 NewRatio 参数。</li>
<li>使用 G1 垃圾回收器。设置参数 <code>-XX:+UseG1GC</code> 。使用 <code>-XX: g1heap</code> 增加 G1 的大小。</li>
</ul>
<p>剩下的工作就是在我们修改 GC 的参数后，GC 统计信息是否有变化。</p>
<h3 id="并行度"><a href="#并行度" class="headerlink" title="并行度"></a>并行度</h3><p>Spark 的 shuffle 操作会在每一个任务中创建散列表进行计算，所以结果会很大，有时候会出现 OutOfMemoryError 。这时我们可以增加任务的并行度使每个 shuffle 的输入更小，执行的更快。shuffle 操作的默认使用父 RDD 的分区数量，可以通过修改 <code>spark.default.parallelism</code> 或方法输入参数来改变默认数量。一般推荐的数量是每个 CPU  2-3 个任务。</p>
<h3 id="数据位置"><a href="#数据位置" class="headerlink" title="数据位置"></a>数据位置</h3>]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[spring boot cache （redis）使用]]></title>
      <url>/2016/05/26/spring-boot-cache/</url>
      <content type="html"><![CDATA[<h3 id="1-pom-xml"><a href="#1-pom-xml" class="headerlink" title="1. pom.xml"></a>1. pom.xml</h3><pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre><h3 id="2-cachemanager"><a href="#2-cachemanager" class="headerlink" title="2. cachemanager"></a>2. cachemanager</h3><pre><code>import org.springframework.cache.CacheManager;
import org.springframework.cache.annotation.EnableCaching;
import org.springframework.cache.interceptor.KeyGenerator;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.data.redis.cache.RedisCacheManager;
import org.springframework.data.redis.core.RedisTemplate;

import java.lang.reflect.Method;

@Configuration
@EnableCaching
public class RedisCache {
    @Bean
    public CacheManager cacheManager(
            @SuppressWarnings(&quot;rawtypes&quot;) RedisTemplate redisTemplate) {
        return new RedisCacheManager(redisTemplate);
    }

    /**
     * 自定义key的生成策略
     * @return
     */
    @Bean
    public KeyGenerator myKeyGenerator(){
        return new KeyGenerator() {
            @Override
            public Object generate(Object target, Method method, Object... params) {
                StringBuilder sb = new StringBuilder();
                for (Object obj : params) {
                    sb.append(obj.toString());
                }
                return sb.toString();
            }
        };
    }
}
</code></pre><h3 id="3-方法上添加注解"><a href="#3-方法上添加注解" class="headerlink" title="3. 方法上添加注解"></a>3. 方法上添加注解</h3><pre><code>@Cacheable(value = &quot;entInfo&quot;, keyGenerator = &quot;myKeyGenerator&quot;)
public EntMultipleInfo findEntInfo(String entName) {
    looger.info(&quot;no cache&quot;);
}
</code></pre><blockquote>
<p>在调用方法前会先去查询是否有缓存。<br>对象需要能够序列化</p>
</blockquote>
<h3 id="4-application-properties"><a href="#4-application-properties" class="headerlink" title="4. application.properties"></a>4. application.properties</h3><pre><code>spring.redis.database= 3
spring.redis.host=192.168.11.21
spring.redis.port=6379
spring.redis.pool.max-idle=8
spring.redis.pool.min-idle=0
spring.redis.pool.max-active=8
spring.redis.pool.max-wait=-1
</code></pre>]]></content>
      
        <categories>
            
            <category> Spring Boot </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spring Boot </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark 存储管理]]></title>
      <url>/2016/05/20/spark-store-management/</url>
      <content type="html"><![CDATA[<p>将数据集持久化或缓存到内存里是 Spark 的重要能力之一。在持久化数据集时，在内存中参与计算的数据集被存储在每一个节点上，其他的 action 可以快速的重用这些数据集。缓存是迭代算法和快速交互的关键。</p>
<h3 id="数据块"><a href="#数据块" class="headerlink" title="数据块"></a>数据块</h3><h3 id="持久化数据集"><a href="#持久化数据集" class="headerlink" title="持久化数据集"></a>持久化数据集</h3><p>使用 <code>persist()</code> 或 <code>cache()</code> 方法可以持久化数据集。Spark 会在第一次计算时将数据集保存在节点的内存中。如果任何一个数据集分区丢失，Spark 会自动使用创建改数据集的转换重新计算。</p>
<p>不同的数据集可以使用不同存储级别，可以自行选择。<code>persist()</code> 可以使用 StorgaeLevel 对象设置存储级别，<code>cache()</code> 就是使用的默认的存储级别，<code>StorageLevel.MEMORY_ONLY</code>（将序列化对象保存在内存中）。</p>
<table class="table table-bordered table-striped table-condensed"><tr><th>Storage Level</th><th>Meaning</th></tr><tr><td>MEMORY_ONLY</td><td>默认的存储级别，数据集以非序列化 Java 对象保存在 JVM 中。如果数据集不能放到内存里，则一写分区不会被缓存，而是在每次使用时重新计算。</td></tr><tr><td>MEMORY_AND_DISK</td><td>数据集以非序列化 Java 对象保存在 JVM 中。如果分区不能放到内存中则放到磁盘上，每次使用时从磁盘读取。</td></tr><tr><td>MEMORY_ONLY_SER  (Java and Scala)</td><td>数据集以序列化 Java 对象（字节数组）方式保存。这种方式相对于非序列化对象来说更节省空间，但同时反序列化也更耗 CPU 。</td></tr><tr><td>MEMORY_AND_DISK_SER  (Java and Scala)</td><td>和 MEMORY_ONLY_SER 类似，但是会将无法放到内存中的分区保存到磁盘而不是重新计算。</td></tr><tr><td>DISK_ONLY</td><td>保存数据集到磁盘。</td></tr><tr><td>MEMORY_ONLY_2, MEMORY_AND_DISK_2, etc. </td><td>和上边类似，但是会在两个集群节点之间复制分区，保证有 2 份拷贝。</td></tr><tr><td>OFF_HEAP (experimental)</td><td>和 MEMORY_ONLY_SER 类似，但是会将数据保存在 <a href="https://spark.apache.org/docs/2.1.1/configuration.html#memory-management" target="_blank" rel="external">off-heap memory</a>。 </td></tr></table>

<p>那如何选择存储级别呢？</p>
<p>Spark 的存储级别是为了在内存使用和 CPU 效率之间达到平衡。可以通过以下步骤来选择：</p>
<ul>
<li>数据集可以全部缓存到内存中，使用默认存储级别会获得最佳性能</li>
<li>否则，使用 <code>MEMORY_ONLY_SER</code> 并选择一个高效的序列化库</li>
<li>通常不要将数据集持久化到磁盘上，除非重新计算数据集开销大于从磁盘读取数据</li>
<li>使用复制的存储级别可以在出错时快速恢复而不用等待计算丢失的分区</li>
</ul>
<p>对于持久化的数据，Spark 会自动监控每个节点的缓存，按照最近被使用算法删除旧的分区。</p>
<h3 id="持久化-shuffle"><a href="#持久化-shuffle" class="headerlink" title="持久化 shuffle"></a>持久化 shuffle</h3><p>Spark 会在执行 shuffle 操作时自动持久化一些中间数据。这样可以避免 shuffle 失败时重新计算整个输入。如果确定结果会被重用，建议对数据集进行持久化。</p>
<h3 id="共享变量"><a href="#共享变量" class="headerlink" title="共享变量"></a>共享变量</h3><p>通常，函数传递到 Spark 集群节点执行，函数中使用所有变量的独立副本，这些变量被拷贝到每一个节点，集群节点上的变量变更不会影响驱动程序，因为读写共享的变量访问时低效的。但 Spark 提供了两种有限类型的共享变量：广播变量和累加器。</p>
<h4 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h4><p>广播变量允许程序保持一份只读的变量缓存在机器上，而不是把变量拷贝到任务中。Spark 的 action 是分阶段执行的，每个阶段任务需要使用的数据被自动广播。广播数据以序列化的形式缓存并在任务执行前反序列化。但多个阶段的任务需要相同的数据时，广播变量更加有效。当广播变量创建后，会在方法中代替变量值，以保证不会被多次发送。广播变量在发送到节点后不能再被修改。</p>
]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark Shuffle 操作]]></title>
      <url>/2016/05/20/spark-shuffle/</url>
      <content type="html"><![CDATA[<p>Shuffle 是 Spark 中重新分布数据的机制，它会在机器之间复制数据，是一个复杂且开销很大的操作。</p>
]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Fabric安装]]></title>
      <url>/2016/05/17/fabric-installation/</url>
      <content type="html"><![CDATA[<h3 id="1-安装依赖包"><a href="#1-安装依赖包" class="headerlink" title="1. 安装依赖包"></a>1. 安装依赖包</h3><pre><code class="shell">sudo rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm  
sudo yum install -y python-devel  
sudo yum install -y gcc  
sudo yum install -y wget  
sudo yum install -y python-pip
</code></pre>
<h3 id="2-安装fabric"><a href="#2-安装fabric" class="headerlink" title="2. 安装fabric"></a>2. 安装fabric</h3><pre><code class="shell">sudo pip install fabric
</code></pre>
<h3 id="3-验证"><a href="#3-验证" class="headerlink" title="3. 验证"></a>3. 验证</h3><pre><code class="shell">python -c &quot;from fabric.api import * ; print env.version&quot;
</code></pre>
<p>输出版本信息则安装成功。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Fabric </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Gitlab 安装]]></title>
      <url>/2016/05/16/gitlab-installation/</url>
      <content type="html"><![CDATA[<h3 id="1-安装依赖"><a href="#1-安装依赖" class="headerlink" title="1. 安装依赖"></a>1. 安装依赖</h3><pre><code>sudo yum install curl openssh-server openssh-clients postfix cronie
sudo service postfix start  
sudo chkconfig postfix on  
sudo lokkit -s http -s ssh
</code></pre><h3 id="2-添加GitLab-package-server"><a href="#2-添加GitLab-package-server" class="headerlink" title="2. 添加GitLab package server"></a>2. 添加GitLab package server</h3><pre><code>curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash  
sudo yum install gitlab-ce-8.5.0-ce.1.el6.x86_64
</code></pre><h3 id="3-安装"><a href="#3-安装" class="headerlink" title="3. 安装"></a>3. 安装</h3><pre><code>sudo rpm -i gitlab-ce-8.5.0-ce.1.el6.x86_64.rpm
</code></pre><h3 id="4-配置"><a href="#4-配置" class="headerlink" title="4. 配置"></a>4. 配置</h3><pre><code>sudo gitlab-ctl reconfigure
</code></pre><h3 id="5-配置邮件服务"><a href="#5-配置邮件服务" class="headerlink" title="5. 配置邮件服务"></a>5. 配置邮件服务</h3><pre><code>sudo yum install postfix
yum install cyrus*
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Git </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark 调度管理]]></title>
      <url>/2016/05/14/spark-job-scheduling/</url>
      <content type="html"><![CDATA[<h3 id="Spark-Application-之间的调度"><a href="#Spark-Application-之间的调度" class="headerlink" title="Spark Application 之间的调度"></a>Spark Application 之间的调度</h3><p>每个 Spark 程序会获得一个独立的 JVM 来执行任务和存储数据。当多个 Spark 程序共享集群资源，不同的集群管理器会有不同的调度策略。<a id="more"></a></p>
<p><strong>静态资源分配</strong></p>
<p>最简单的方式是静态划分所有可用的集群资源。这种方式，每个 Spark 程序被分配它可用的最大资源，并在整个声明周期都占有这些资源。这种方式在 Spark Standalone 、YARN 和 <a href="https://spark.apache.org/docs/1.6.3/running-on-mesos.html#mesos-run-modes" target="_blank" rel="external">coarse-grained Mesos</a> 模式中。</p>
<ul>
<li>Standalone mode 模式默认提交的任务是按照 FIFO 的顺序执行，执行期间占有所有可用的节点。通过修改 <code>spark.cores.max</code> 和 <code>spark.executor.memory</code> 参数可以修改程序可使用的节点数和内存。</li>
<li>YARN 模式通过设置 <code>--num-executors</code> 选项控制 Executor 的数量，使用 <code>--executor-memory</code> 和 <code>--executor-cores</code> 选项控制 Executor 可用的资源。</li>
</ul>
<blockquote>
<p>不管使用何种方式，都不能在程序之间共享内存。</p>
</blockquote>
<p><strong>动态资源分配</strong></p>
<p>Spark 提供了一种按照负载动态分配资源的方式，当程序不在使用资源的时候将资源还给集群，这种特性在多个程序共享集群资源的时候是非常有用的。这个特性是默认关闭的，可以在所有 coarse-grained cluster managers 上设置启用。</p>
<p>Spark 程序可在等待被调度的任务被挂起的时候动态请求额外的 Executor 。Spark 以轮询的方式请求 Executor ，在任务被挂起到达一定时间时，请求才真正触发。每次触发请求的 Executor 数量以指数递增。这样做的原因是考虑到应用在开始阶段只需要较少的 Executor ，当确实需要大量的 Executor 时，指数递增能够快速提升处理能力。</p>
<p>相对来时 Spark 的释放策略要简单的多，当闲置超过一定时间 Executor 会被释放。在大多是情况下，任务被挂起说明资源不足，闲置说明资源过剩，所以 Executor 的申请和释放是互斥的。</p>
<p>静态分配资源时，相关的程序正常退出或出错，Executor 都会退出，两种情况下和 Executor 相关的状态不会再被使用，可以安全的移除。但是动态分配资源时，Executor 退出时程序还在运行，如果程序访问该 Executor 保存的状态，就会重新计算。比如，在 shuffle 期间，Spark 先将 map 写到本地磁盘，然后其他 Executor 可以访问计算结果。在 shuffle 完成之前，Executor 会被移除，完成后，shuffle 的结果将不可访问，如果其他的 Executor 要访问，就需要重新计算。因此，Spark 提供了额外的 shuffle 服务来保存 shuffle 文件，即使 Executor 退出，也可以通过该服务访问 shuffle 文件，因为 shuffle 服务是独立于程序和 Executor 的。</p>
<h3 id="Application-内的调度"><a href="#Application-内的调度" class="headerlink" title="Application 内的调度"></a>Application 内的调度</h3><p><strong>调度流程</strong></p>
<p>Spark 是按照 DAG 图来进行的任务调度的。调度可分为两部分： DAGScheduler 和 TaskScheduler 。DAGScheduler 负责 stage 级别的调度， TaskScheduler 负责 task 级别的调度。</p>
<p>① Spark 程序每一个 action 都会提交给 DAGScheduler 一个 job，DAGScheduler 首先需要逆向遍历 RDD 依赖链，划分出 stage 并确定 stage 之间的依赖关系。Spark 有两种类型的 stage ： ShuffleMapStage 和 ResultStage 。Wide Dependency 会产生 shuffle 操作，shuffle 操作的结果是生成 ShuffleRDD ，其依赖关系是 ShuffleDependency 。Spark 通过 ShuffleDependency 来划分 stage，stage 的边界是从 ShuffleRDD 的父 RDD 开始计算的。</p>
<blockquote>
<p>Narrow Dependency 指子 RDD 只依赖父 RDD 的一个或几个 partition 。</p>
<p>Wide Dependency 指子 RDD 只依赖父 RDD 的所有的 partition 。</p>
</blockquote>
<p>② 划分好 stage ，Spark 会生成 FinalStage 并提交。根据依赖关系，判断 FinalStage 的父 stage 结果是否可用，如果父 stage 的结果不可用，则尝试迭代提交父 stage 。如果所有的父 stage 结果都可用，则提交 FinalStage 。③ stage 按 partition 数量拆分出 task 放入 TaskSet 提交给 TaskScheduler ，至此 DAGScheduler 调度结束。④ TaskScheduler 和 TaskSetManager 根据资源情况将 task 调度到最佳的 Executor 上进行计算。⑤ DAGScheduler 和 TaskScheduler 通过回调函数获取 Task 和 TaskSet 的状态，以及 Executor 的状态。当 Task 执行完成后，DAGScheduler 会获取 Task 执行结果。对于非 FinalStage 的 Task ，返回的是 MapStatus 对象，存储的是计算结果的位置信息，而对于 ResultTask 类型的 Task 返回的是结果本身，如果结果比较小，则直接放在 DirectTaskResult 中，如果结果很大，则将结果存储在 BlockManager 中，然后将 BlockId 返回给 DAGScheduler 。 </p>
<p><strong>调度策略</strong></p>
<p>在 Spark 程序内部，多个线程提交的任务可以并行执行，是线程安全的。默认的 Spark 任务调度策略是 FIFO 。每个任务被划分到 stage 中，stage 开始时第一个任务获得优先权，然后是第二个，以此类推。如果一个任务没有使用全部资源，下一个任务可以立刻开始执行。如果前边的任务占用了全部的资源，后边的任务只能等待前边的任务完成后再开始执行。</p>
<p>Spark 可以通过配置 <code>spark.scheduler.mode</code>  为 FAIR 来让任务公平共享资源。在公平模式下，在任务长时间运行时新提交一个较小的任务也能够马上开始执行，不需要等待之前的任务执行完成再开始执行。和 Hadoop Fair scheduler 类似，公平调用支持将作业分组到调度池中，并且为每个调度池分配不同的选项，比如将重要的任务放在优先级高的池中或是将不同用户的任务放在各自的池中。调度池有 3 个配置选项：</p>
<ul>
<li>schedulingMode 可配置任务在池内的调度策略。</li>
<li>weight 可配置池的获得的资源，即优先级。</li>
<li>minShare 可配置池的最小资源。</li>
</ul>
<p>默认情况下，池的属性为 <code>scheduling mode FIFO weight 1 minShare 0</code> 。</p>
]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark 序列化]]></title>
      <url>/2016/05/11/spark-data-serialization/</url>
      <content type="html"><![CDATA[<p>序列化对任何分布式系统的性能来说都至关重要。序列化对象慢或占用大量的字节将大大降低计算的性能。通常在 Spark 程序中，我们需要首先将序列化调整到最优。Spark 提供了两个序列化类库，以便在易用性和效率之间达到平衡。</p>
<p>默认的，Spark 序列化对象使用 Java 的 ObjectOutputStream ，可以作用于任何实现了 java.io.Serializable 接口的类。虽然 Java 的序列化很灵活，但是性能较低同时占用字节数很大。</p>
<p>Spark 使用 Kryo 序列化来提高序列化的性能。它比 Java 序列化更快占用字节数更少。但是 Kryo 并不支持所有的Serializable 类型，需要手动注册。</p>
<p>要使用 Kryo 作为序列化库，需要配置 </p>
<pre><code class="scala">conf.set(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;)
</code></pre>
<p>这个配置不仅用于节点之间 shuffle 数据，还会影响 RDDs 序列化到磁盘。因为要手动注册，所以 Kryo 不是默认的序列化方案，但还是推荐使用 Kryo ，尤其是网络密集型程序。从 Spark 2.0.0 开始，简单类型，简单类型的数组及字符串的 shuffle 操作时使用 Kryo。</p>
<p>通过以下方式对自定义类进行注册，如果对象很大，需要加上 spark.kryoserializer.buffer 的配置。</p>
<pre><code class="scala">val conf = new SparkConf().setMaster(...).setAppName(...).set(&quot;spark.kryoserializer.buffer&quot;, &quot;64m&quot;)
conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))
val sc = new SparkContext(conf)
</code></pre>
<p>如果不注册自定义类，Kryo 仍然会工作，不过需要将每一个对象的完全的类名保存起来，这会非常浪费资源。</p>
]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark 运行模式]]></title>
      <url>/2016/05/07/spark-cluster-manager-types/</url>
      <content type="html"><![CDATA[<!-- toc -->
<p>Spark 程序是一组运行在集群上的独立进程，进程之间通过 SparkContext 协调。Spark 程序包含两部分：Driver 程序（SparkContext）和 Executor 。SparkContext 能连接多种类型的 Cluster Manager （spark standalone cluster、Mesos、YARN），虽然 cluster manager 的类型多样，但是 Spark 运行机制基本相同。<a id="more"></a>Driver 程序由用户启动，通过资源调度模块和 Executor 通信。在连接到 Cluster Manager 后，Spark 获得集群 Worker 节点上的 Executor （负责计算和存储数据的进程），将需要运行的代码发送到 Executor ，然后 SparkContext 发送 Task 到 Executor 去执行。示意如图：</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20170531/234941814.png" alt="mark"></p>
<p>每个 Spark 程序有自己的 Executor 进程，并且在程序生命周期内都是相互独立的，这也意味着不同的 Spark 程序之间无法共享数据，除非借助其他存储系统，如 HDFS 。</p>
<p>Spark 对于 Cluster Manager 是不可知的，只要能获取到 Executor 进程并能相互通信即可，所以更换Cluster Manager 并不需要修改程序。</p>
<p>在整个生命周期内，Worker 节点和 Driver 程序之间需要保持联通。</p>
<p>在距离 Worker 的机器上运行 Driver 程序会更有效率。</p>
<h3 id="Local-模式"><a href="#Local-模式" class="headerlink" title="Local 模式"></a>Local 模式</h3><p>本地运行，可快速验证代码。</p>
<h3 id="Spark-Standalone-模式"><a href="#Spark-Standalone-模式" class="headerlink" title="Spark Standalone 模式"></a>Spark Standalone 模式</h3><p>Spark 提供的一种简单部署模式，通常用来进行测试。</p>
<h3 id="YARN-模式"><a href="#YARN-模式" class="headerlink" title="YARN 模式"></a>YARN 模式</h3><p>通过 YARN 来调度 Spark 程序所需要的资源。YARN 模式有两种模式来启动 Spark 程序：YARN Cluster 和 YARN Client 。在 Cluster 模式中，Driver 程序运行在 master 进程中，程序初始化完成后 Client 可以结束。在 Client 模式中，Driver 程序运行在 client 进程中，master 只负责向 YARN 请求资源。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/spark-on-yarn.png" alt=""></p>
<p>YARN cluster：</p>
<ol>
<li>Client 通过 YARN Client 向 Resource Manager 提交 Spark 程序，Resource Manager 在集群中启动一个 Spark Application Master ，注册到 Resource Manager 并初始化 SparkContext 。</li>
<li>Spark Application Master 通过 Resource Manager 在分配的 YARN 节点中启动 Container 。</li>
<li>在 Container 中运行 Task 。</li>
</ol>
<p>YARN client：</p>
<ol>
<li>Client 在本地初始化 SparkContext 。</li>
<li>通过 YARN Client 在随机一个 YARN 节点上启动 Spark Application Master 。</li>
<li>Spark Application Master 通过 Resource Manager 在分配的 YARN 节点中启动 Container 。</li>
<li>在 Container 中运行 Task 。</li>
</ol>
<h3 id="几种模式比较"><a href="#几种模式比较" class="headerlink" title="几种模式比较"></a>几种模式比较</h3><h4 id="环境变量传递"><a href="#环境变量传递" class="headerlink" title="环境变量传递"></a>环境变量传递</h4><p>SparkContext 在初始化过程中需要将环境变量传递给 Executor ，如何将环境变量设置到 Executor 的环境中，取决于 Executor 的启动方式。</p>
<ul>
<li>Local 模式在单机运行，不存在环境变量传递的问题。</li>
<li>Spark Standalone 模式中，环境变量被封装在 org.apache.spark.deploy.Command 类中，由 Spark Master 通过 Actor 转发给合适的 Worker ，Worker 通过 ExecutorRunner 构建 java.lang.Process ，再传递给 java.lang.ProcessBuilder.environment 。</li>
<li>YARN 模式中，环境变量首先通过 YARN client 设置到 Spark Application Manager 的运行环境中，在通过 ExecutorRunnable 设置到运行 Executor 的 ContainerLaunchContext 中。</li>
</ul>
<h4 id="包分发"><a href="#包分发" class="headerlink" title="包分发"></a>包分发</h4><ul>
<li>Local 和 Standalone 模式是单机或整个环境部署多个节点，所以不需要分发。</li>
</ul>
<ul>
<li>YARN 模式中，运行库和程序运行依赖的文件首先通过 HDFS 客户端 API 上传到作业 .sparkStaging 目录下，然后将对应的文件和 URL 映射关系通知 YARN ，YARN 的 Node Manager 在启动 Container 的时候会从指定的 URL 下载文件。Spark Application Manager 在创建 Executor 的 Container 的时候通过 setLocalResources 设置 Executor 的环境变量。</li>
</ul>
<h3 id="术语表："><a href="#术语表：" class="headerlink" title="术语表："></a>术语表：</h3><table>
<thead>
<tr>
<th>Term</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>Application</td>
<td>由 Driver 程序和 Executors 组成。</td>
</tr>
<tr>
<td>Application jar</td>
<td>包含用户程序代码和依赖的 jar 包，Hadoop 和 Spark 的 libraries 应该排除在外，因为它们会在运行时被加入。</td>
</tr>
<tr>
<td>Driver program</td>
<td>运行主函数的进程。</td>
</tr>
<tr>
<td>Cluster manager</td>
<td>在集群中获取资源的扩展服务 (e.g. standalone manager, Mesos, YARN)。</td>
</tr>
<tr>
<td>Deploy mode</td>
<td>Distinguishes where the driver process runs. In “cluster” mode, the framework launches the driver inside of the cluster. In “client” mode, the submitter launches the driver outside of the cluster.</td>
</tr>
<tr>
<td>Worker node</td>
<td>集群中任何可以运行 application code 的节点。</td>
</tr>
<tr>
<td>Executor</td>
<td>在 Worker 节点上由程序启动的进程，负责执行 Task 和存储数据。</td>
</tr>
<tr>
<td>Task</td>
<td>发送给 Executor 的一个 work 单元。</td>
</tr>
<tr>
<td>Job</td>
<td>有多个 Task 组成由 Spark action 触发的并行计算单元。</td>
</tr>
<tr>
<td>Stage</td>
<td>每个 job 中，相同的 task 组成的集合。Stage 之间相互依赖。</td>
</tr>
</tbody>
</table>
]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Oracle 分页 sql 模板]]></title>
      <url>/2016/05/05/oracle-pagination/</url>
      <content type="html"><![CDATA[<p>Oracle通过ROWNUM进行分页，通过子查询实现。</p>
<pre><code class="sql">SELECT *
FROM (SELECT
        A.*,
        ROWNUM RN
      FROM (
        SELECT * FORM t
      ) A
      WHERE ROWNUM &lt;= 100)
WHERE RN &gt;= 0
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Oracle </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark 入门]]></title>
      <url>/2016/05/05/spark-introduction/</url>
      <content type="html"><![CDATA[<p>spark 环境搭建完成后，就可以搭建 spark 的开发环境进一步学习 spark 了。</p>
<h3 id="几种构建方式差异"><a href="#几种构建方式差异" class="headerlink" title="几种构建方式差异"></a>几种构建方式差异</h3><p>搭建 spark 的开发环境有多种方式，各有利弊。</p>
<ul>
<li>使用 maven 构建</li>
<li>创建 scala 工程</li>
<li>使用 sbt 构建</li>
</ul>
<p><strong>使用 maven 构建</strong></p>
<p>使用 maven 方式构建项目，在 Java 开发中十分常见，所以可以平滑过度，只需要添加 scala-tools 和 scala-library 的依赖，其他和 Java 无异。<br>但是使用缺点就是各个环境的 jar 的版本不好控制，一不小心就会报各种各样的找不到包的错误，因为 spark 和 scala 不同版本编译包是不兼容的。</p>
<p><strong>创建 scala 工程</strong><br>这种方式使用起来比较繁琐，因为各种环境，路径都需要自己配置，但优点是只要包导入没问题，基本不会出现版本问题。</p>
<p><strong>使用 sbt 构建</strong><br>sbt 是 scala 官方推出的构建工具，和 maven 使用方式类似，除了第一次下载时间超超超级长之外，其他都比较方便，各种资料介绍 sbt 的也最多，所以推荐使用。</p>
<p>综合各种，这里还是使用第三种方式。</p>
<h3 id="构建-IDEA-SBT-环境"><a href="#构建-IDEA-SBT-环境" class="headerlink" title="构建 IDEA + SBT 环境"></a>构建 IDEA + SBT 环境</h3><h4 id="1-安装-sbt"><a href="#1-安装-sbt" class="headerlink" title="1. 安装 sbt"></a>1. 安装 sbt</h4><p>下载 sbt 包并解压，配置环境变量</p>
<pre><code>SBT_HOME=/u01/sbt
PAHT=$SBT_HOME/bin:$PATH
export SBT_HOME PATH
</code></pre><p>其他参考 <a href="http://www.scala-sbt.org/download.html" target="_blank" rel="external">http://www.scala-sbt.org/download.html</a> 。</p>
<h4 id="2-修改国内源"><a href="#2-修改国内源" class="headerlink" title="2. 修改国内源"></a>2. 修改国内源</h4><p>sbt 需要先下载依赖的 jar 包，但是下载速度太慢，可以更换成国内的源提高速度。<br>在 ~/.sbt 下创建 repositories 文件</p>
<pre><code>[repositories]
#local
public: http://maven.aliyun.com/nexus/content/groups/public/
typesafe:http://dl.bintray.com/typesafe/ivy-releases/ , [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext], bootOnly
ivy-sbt-plugin:http://dl.bintray.com/sbt/sbt-plugin-releases/, [organization]/[module]/(scala_[scalaVersion]/)(sbt_[sbtVersion]/)[revision]/[type]s/[artifact](-[classifier]).[ext]
sonatype-oss-releases
maven-central
sonatype-oss-snapshots
</code></pre><h4 id="3-创建工程"><a href="#3-创建工程" class="headerlink" title="3. 创建工程"></a>3. 创建工程</h4><p>先使用 IDEA 选择 SBT 方式创建工程，然后在终端切换到项目目录运行 sbt</p>
<pre><code>sbt
&gt; compile
</code></pre><p>依赖下载完成，开发环境就搭建好了。</p>
<blockquote>
<p>使用 IDEA 为什么还要使用命令行？</p>
<p>IDEA 中 sbt 默认使用国外的源，所以下载速度很慢，命令行方式由于修改了国内的源，所以下载速度快很多。而且先通过 IDEA 创建工程，也不用自己再去创建 build.sbt 等文件。</p>
</blockquote>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>拷贝 $SPARK_HOME/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java 到工程中。</p>
<h4 id="1-使用-sbt-编译打包"><a href="#1-使用-sbt-编译打包" class="headerlink" title="1. 使用 sbt 编译打包"></a>1. 使用 sbt 编译打包</h4><pre><code>sbt compile package
</code></pre><p>生成的 jar 包默认路径为 target/scala-2.10 下。</p>
<h4 id="2-添加部署脚本"><a href="#2-添加部署脚本" class="headerlink" title="2. 添加部署脚本"></a>2. 添加部署脚本</h4><pre><code class="shell">#!/usr/bin/env bash

SCRIPT_PATH=`readlink -f &quot;$0&quot;`;
cd `dirname ${SCRIPT_PATH}`

/u01/spark/bin/spark-submit --name JavaWordCount  \
--class com.sparkone.test.JavaWordCount \
--master spark://localhost:7077 \
--executor-memory 512M \
../target/scala-2.10/sparkone_2.10-1.0.jar hdfs://localhost:9000/user/rolex/input/NOTICE.txt
</code></pre>
<p>执行即可在单机环境执行测试。</p>
]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark standalone 安装]]></title>
      <url>/2016/05/04/spark-standalone-installation/</url>
      <content type="html"><![CDATA[<p>spark standalone 即伪分布式部署,即在单节点部署 spark ,部署方式比较简单。</p>
<h3 id="1-下载-spark-安装包"><a href="#1-下载-spark-安装包" class="headerlink" title="1. 下载 spark 安装包"></a>1. 下载 spark 安装包</h3><p><a href="http://www.apache.org/dyn/closer.lua/spark/spark-1.6.1/spark-1.6.1-bin-hadoop2.6.tgz" target="_blank" rel="external">http://www.apache.org/dyn/closer.lua/spark/spark-1.6.1/spark-1.6.1-bin-hadoop2.6.tgz</a></p>
<h3 id="2-解压"><a href="#2-解压" class="headerlink" title="2. 解压"></a>2. 解压</h3><pre><code>tar -zxf spark-1.6.1-bin-hadoop2.6.tgz
</code></pre><h3 id="3-修改配置文件"><a href="#3-修改配置文件" class="headerlink" title="3. 修改配置文件"></a>3. 修改配置文件</h3><p>在 $SPARK_HOME/conf/spark-env.sh 后添加如下配置。</p>
<pre><code>export SPARK_MASTER_IP=localhost
export SPARK_MASTER_PORT=7077
export SPARK_WORKER_CORES=1
export SPARK_WORKER_INSTANCES=1
export SPARK_WORKER_MEMORY=512M
</code></pre><p>spark 有默认配置，如果不显式配置，也是可以运行的。</p>
<h3 id="4-启动"><a href="#4-启动" class="headerlink" title="4. 启动"></a>4. 启动</h3><pre><code>./sbin/start-all.sh
</code></pre><p>启动后可访问<a href="http://localhost:8080" target="_blank" rel="external">http://localhost:8080</a>查看信息</p>
<h3 id="5-启动-shell"><a href="#5-启动-shell" class="headerlink" title="5. 启动 shell"></a>5. 启动 shell</h3><pre><code>./bin/spark-shell --master spark://localhost:7077
</code></pre><h3 id="6-测试"><a href="#6-测试" class="headerlink" title="6. 测试"></a>6. 测试</h3><p>执行 wordcount 程序，需要先启动 hadoop ，</p>
<pre><code>val rdd=sc.textFile(&quot;hdfs://localhost:9000/user/rolex/input/NOTICE.txt&quot;)
rdd.cache()
val wordcount=rdd.flatMap(_.split(&quot; &quot;)).map(x=&gt;(x,1)).reduceByKey(_+_)
wordcount.take(10)
val wordsort=wordcount.map(x=&gt;(x._2,x._1)).sortByKey(false).map(x=&gt;(x._2,x._1))
wordsort.take(10)
</code></pre><p>执行详细结果如下：</p>
<pre><code>scala&gt; val rdd=sc.textFile(&quot;hdfs://localhost:9000/user/rolex/input/NOTICE.txt&quot;)
rdd: org.apache.spark.rdd.RDD[String] = hdfs://localhost:9000/user/rolex/input/NOTICE.txt MapPartitionsRDD[5] at textFile at &lt;console&gt;:27

scala&gt; rdd.cache()
res1: rdd.type = hdfs://localhost:9000/user/rolex/input/NOTICE.txt MapPartitionsRDD[5] at textFile at &lt;console&gt;:27

scala&gt; val wordcount=rdd.flatMap(_.split(&quot; &quot;)).map(x=&gt;(x,1)).reduceByKey(_+_)
wordcount: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[8] at reduceByKey at &lt;console&gt;:29

scala&gt; wordcount.take(10)
res2: Array[(String, Int)] = Array((Apache,1), (developed,1), (This,1), (includes,1), (Software,1), (The,1), ((http://www.apache.org/).,1), (by,1), (software,1), (product,1))

scala&gt; val wordsort=wordcount.map(x=&gt;(x._2,x._1)).sortByKey(false).map(x=&gt;(x._2,x._1))
wordsort: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[13] at map at &lt;console&gt;:31

scala&gt; wordsort.take(10)
res3: Array[(String, Int)] = Array((Apache,1), (developed,1), (This,1), (includes,1), (Software,1), (The,1), ((http://www.apache.org/).,1), (by,1), (software,1), (product,1))
</code></pre>]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Spark </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Ubuntu 16.04 安装 oracle instant client]]></title>
      <url>/2016/04/19/ubuntu-16.04-install-oracle-instant-client/</url>
      <content type="html"><![CDATA[<h3 id="1-安装alien"><a href="#1-安装alien" class="headerlink" title="1. 安装alien"></a>1. 安装alien</h3><pre><code>sudo apt-get install alien
</code></pre><h3 id="2-下载oracle-instant-client"><a href="#2-下载oracle-instant-client" class="headerlink" title="2. 下载oracle instant client"></a>2. 下载oracle instant client</h3><p>oracle-instantclient12.1-basic-12.1.0.2.0-1.x86_64.rpm<br>oracle-instantclient12.1-devel-12.1.0.2.0-1.x86_64.rpm<br>oracle-instantclient12.1-sqlplus-12.1.0.2.0-1.x86_64.rpm</p>
<h3 id="3-安装"><a href="#3-安装" class="headerlink" title="3. 安装"></a>3. 安装</h3><pre><code>sudo alien -i *.rpm
</code></pre><h3 id="4-配置环境变量"><a href="#4-配置环境变量" class="headerlink" title="4. 配置环境变量"></a>4. 配置环境变量</h3><pre><code>echo &#39;export ORACLE_HOME=/usr/lib/oracle/12.1/client64&#39; &gt; /etc/profile.d/oracle.sh
echo &#39;export ORACLE_BASE=/usr/lib/oracle/12.1&#39; &gt;&gt; /etc/profile.d/oracle.sh
echo &#39;export LD_LIBRARY_PATH=$ORACLE_HOME/lib:$LD_LIBRARY_PATH&#39; &gt;&gt; /etc/profile.d/oracle.sh
echo &#39;export NLS_LANG=AMERICAN_AMERICA.AL32UTF8&#39; &gt;&gt; /etc/profile.d/oracle.sh
echo &#39;export PATH=$ORACLE_HOME/bin:$PATH&#39; &gt;&gt; /etc/profile.d/oracle.sh
source /etc/profile
</code></pre><h3 id="5-解决上下左右键乱码"><a href="#5-解决上下左右键乱码" class="headerlink" title="5. 解决上下左右键乱码"></a>5. 解决上下左右键乱码</h3><pre><code>sudo apt-get install rlwrap
echo &quot;alias sqlplus=&#39;rlwrap sqlplus&#39;&quot; &gt;&gt; ~/.bashrc
source /etc/profile
</code></pre><h3 id="6-测试"><a href="#6-测试" class="headerlink" title="6. 测试"></a>6. 测试</h3><pre><code>sqlplus username/passwd@//hostname:post/sid
</code></pre>]]></content>
      
        <categories>
            
            <category> Databases </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Ubuntu </tag>
            
            <tag> Oracle </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[jQuery 常用操作操作]]></title>
      <url>/2016/04/16/jquery-practice/</url>
      <content type="html"><![CDATA[<p>jQuery 的常用操作整理一下，备忘。</p>
<h3 id="遍历-json-map"><a href="#遍历-json-map" class="headerlink" title="遍历 json map"></a>遍历 json map</h3><pre><code class="js">$.each(map,function(key,values){     
    console.log(key);     
    $(values).each(function(){     
        console.log(&quot;/t&quot; + this);     
    });     
 });
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> jQuery </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Oracle Clob 格式处理]]></title>
      <url>/2016/04/11/oracle-clob-operating/</url>
      <content type="html"><![CDATA[<pre><code>try {
    Clob clob = resultSet.getClob(&quot;FCT_PARTY&quot;);
    if (clob != null &amp;&amp; clob.length() &gt; 0) {
        char[] c = new char[(int) clob.length()];
        Reader reader = clob.getCharacterStream();
        reader.read(c);
        fygg.setParty(new String(c));
        reader.close();
    }
} catch (IOException e) {
    logger.error(&quot;column {}.FCT_PARTY read failed.&quot;, tableName, e);
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Oracle </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[/etc/profile 和 /etc/profile.d 的区别]]></title>
      <url>/2016/03/30/difference-between-profile-and-profile.d/</url>
      <content type="html"><![CDATA[<ol>
<li><p>两个文件都是设置环境变量文件的，/etc/profile是永久性的环境变量,是全局变量，/etc/profile.d/设置所有用户生效  </p>
</li>
<li><p>/etc/profile.d/比/etc/profile好维护，不想要什么变量直接删除/etc/profile.d/下对应的shell脚本即可，不用像/etc/profile需要改动此文件</p>
</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Oracle 日期转换]]></title>
      <url>/2016/03/24/oracle-date-format/</url>
      <content type="html"><![CDATA[<p>Oracle 日期转换示例。</p>
<h3 id="1-英语日期格式转换"><a href="#1-英语日期格式转换" class="headerlink" title="1. 英语日期格式转换"></a>1. 英语日期格式转换</h3><pre><code class="sql">SELECT
  TO_DATE(SUBSTR(&#39;29-JAN-16 03.09.31.030943000 PM&#39;, 0, 9), &#39;dd-MON-yy&#39;, &#39;NLS_DATE_LANGUAGE = American&#39;) d1,
  TO_CHAR(sysdate, &#39;DD-MON-YY&#39;, &#39;NLS_DATE_LANGUAGE = American&#39;) d2,
  TO_CHAR(sysdate, &#39;DD-MON-YY&#39;) d3
FROM dual
</code></pre>
<table>
<thead>
<tr>
<th>d1</th>
<th>d2</th>
<th>d3</th>
</tr>
</thead>
<tbody>
<tr>
<td>2016-01-29 00:00:00</td>
<td>01-JUL-16</td>
<td>01-7月 -16</td>
</tr>
</tbody>
</table>
<h3 id="2-将字符串转成date"><a href="#2-将字符串转成date" class="headerlink" title="2. 将字符串转成date"></a>2. 将字符串转成date</h3><pre><code class="sql">SELECT TO_DATE(SUBSTR(&#39;2016年08月12日&#39;, 0, 11), &#39;yyyy&quot;年&quot;mm&quot;月&quot;dd&quot;日&quot;&#39;) from dual
</code></pre>
]]></content>
      
        <categories>
            
            <category> Databases </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Oracle </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Git 使用]]></title>
      <url>/2016/03/16/git-introduce/</url>
      <content type="html"><![CDATA[<h4 id="1-生成rsa密钥对。"><a href="#1-生成rsa密钥对。" class="headerlink" title="1. 生成rsa密钥对。"></a>1. 生成rsa密钥对。</h4><p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/1.png" alt="1"></p>
<h4 id="2-将公钥上传到github。"><a href="#2-将公钥上传到github。" class="headerlink" title="2. 将公钥上传到github。"></a>2. 将公钥上传到github。</h4><h4 id="3-在github上创建新repository，名字haro。本地初始化并添加远程仓库。"><a href="#3-在github上创建新repository，名字haro。本地初始化并添加远程仓库。" class="headerlink" title="3. 在github上创建新repository，名字haro。本地初始化并添加远程仓库。"></a>3. 在github上创建新repository，名字haro。本地初始化并添加远程仓库。</h4><h4 id="4-提交代码到本地master分支，再推送到远程仓库"><a href="#4-提交代码到本地master分支，再推送到远程仓库" class="headerlink" title="4. 提交代码到本地master分支，再推送到远程仓库"></a>4. 提交代码到本地master分支，再推送到远程仓库</h4><h4 id="5-创建dev分支"><a href="#5-创建dev分支" class="headerlink" title="5. 创建dev分支"></a>5. 创建dev分支</h4><h4 id="6-切换到dev分支，修改提交，合并到master分支，推送到远程仓库。"><a href="#6-切换到dev分支，修改提交，合并到master分支，推送到远程仓库。" class="headerlink" title="6. 切换到dev分支，修改提交，合并到master分支，推送到远程仓库。"></a>6. 切换到dev分支，修改提交，合并到master分支，推送到远程仓库。</h4><h4 id="7-远程覆盖本地"><a href="#7-远程覆盖本地" class="headerlink" title="7. 远程覆盖本地"></a>7. 远程覆盖本地</h4><h4 id="8-克隆远程仓库到本地"><a href="#8-克隆远程仓库到本地" class="headerlink" title="8. 克隆远程仓库到本地"></a>8. 克隆远程仓库到本地</h4><h4 id="9-删除远程分支"><a href="#9-删除远程分支" class="headerlink" title="9. 删除远程分支"></a>9. 删除远程分支</h4><h4 id="10-设置忽略文件"><a href="#10-设置忽略文件" class="headerlink" title="10. 设置忽略文件"></a>10. 设置忽略文件</h4><p>在仓库目录创建.gitignore文件，文件内容如下:</p>
<pre><code>.idea/     --忽略.idea目录
.iml     --忽略.iml文件  
target/  
.gitignore
</code></pre><p><em>该方式对所在目录和子目录有效。</em></p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Git </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Nexus 伺服搭建]]></title>
      <url>/2016/02/22/building-nexus-server/</url>
      <content type="html"><![CDATA[<h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>下载最新的 Nexus OSS</p>
<pre><code>wget http://www.sonatype.org/downloads/nexus-latest-bundle.tar.gz
</code></pre><h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><pre><code>tar -zxf nexus-latest-bundle.tar.gz  
mv nexus-2.11.1-01 nexus2

chown -R nexus2
chown -R sonatype-work
</code></pre><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><pre><code>cd nexus2
./bin/nexus start
</code></pre><h3 id="安装服务"><a href="#安装服务" class="headerlink" title="安装服务"></a>安装服务</h3><p>修改 <code>bin/nexus</code> 的 <code>RUN_AS_USER=root</code></p>
<p>创建服务</p>
<pre><code>ln -s /usr/nexus2/bin/nexus /etc/init.d/nexus
source /etc/profile
</code></pre><p>启动服务</p>
<pre><code>service nexus start
</code></pre><p>开机启动</p>
<pre><code>chkconfig --add nexus  
chkconfig --levels 345 nexus on
</code></pre><h3 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h3><p>在浏览器中输入 <a href="http://192.168.1.201:8081/nexus/" target="_blank" rel="external">http://192.168.1.201:8081/nexus/</a><br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/9.png" alt="img"></p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>管理员账号 admin ，默认密码 admin123 ，通过右上角登录。</p>
<h3 id="添加代理仓库"><a href="#添加代理仓库" class="headerlink" title="添加代理仓库"></a>添加代理仓库</h3><p>点击左侧的 Repositories ，然后再点击右侧的 Add ，会弹出下拉菜单，选择 Proxy Repository ，如下配置。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/10.png" alt="https://raw.githubusercontent.com/bsyonline/pic/master/10.png"><br>选中 Public Repositories ，将新建的 Proxy Repository 加入到 Public Repositories 组，并 Update Index 。<br><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/11.png" alt="https://raw.githubusercontent.com/bsyonline/pic/master/11.png"></p>
<h3 id="配置-maven"><a href="#配置-maven" class="headerlink" title="配置 maven"></a>配置 maven</h3><p>修改 maven 的 <strong>settings.xml</strong> 文件</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;

&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot;
          xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
          xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt;
    &lt;!--设置本地仓库地址--&gt;      
    &lt;localRepository&gt;D:\mvn\repository&lt;/localRepository&gt;
    &lt;pluginGroups&gt;
        &lt;pluginGroup&gt;org.mortbay.jetty&lt;/pluginGroup&gt;
    &lt;/pluginGroups&gt;
    &lt;proxies&gt;
    &lt;/proxies&gt;
    &lt;!--设置 Nexus 认证信息--&gt;
    &lt;servers&gt;
        &lt;server&gt;
            &lt;id&gt;local-repo&lt;/id&gt;
            &lt;username&gt;admin&lt;/username&gt;
            &lt;password&gt;admin123&lt;/password&gt;
        &lt;/server&gt;
    &lt;/servers&gt;
    &lt;!--设置 Nexus 镜像，只要本地没对应的，则到 Nexus 去找--&gt;
    &lt;mirrors&gt;
        &lt;!-- mirrorOf 会按照 id 匹配查找 --&gt;
        &lt;mirror&gt;
            &lt;id&gt;local-repo&lt;/id&gt;
            &lt;mirrorOf&gt;local-repo&lt;/mirrorOf&gt;
            &lt;url&gt;http://192.168.0.201:8081/nexus/content/groups/public&lt;/url&gt;
        &lt;/mirror&gt;
        &lt;mirror&gt;
            &lt;id&gt;spring-milestone&lt;/id&gt;
            &lt;mirrorOf&gt;spring-milestone&lt;/mirrorOf&gt;
            &lt;url&gt;http://192.168.0.201:8081/nexus/content/repositories/spring-milestone/&lt;/url&gt;
        &lt;/mirror&gt;
        &lt;mirror&gt;
            &lt;id&gt;spring-snapshot&lt;/id&gt;
            &lt;mirrorOf&gt;spring-snapshot&lt;/mirrorOf&gt;
            &lt;url&gt;http://192.168.0.201:8081/nexus/content/repositories/spring-snapshot/&lt;/url&gt;
        &lt;/mirror&gt;
    &lt;/mirrors&gt;
    &lt;profiles&gt;
        &lt;profile&gt;
            &lt;id&gt;local-repo&lt;/id&gt;
            &lt;properties&gt;
                &lt;downloadSources&gt;true&lt;/downloadSources&gt;
                &lt;downloadJavadocs&gt;true&lt;/downloadJavadocs&gt;
            &lt;/properties&gt;
            &lt;!-- nexus 配置了三个 proxy 分别是 aliyun, spring-milestone, spring-snapshot --&gt;
            &lt;repositories&gt;
                &lt;repository&gt;
                    &lt;id&gt;local-repo&lt;/id&gt;
                    &lt;name&gt;Local Repository&lt;/name&gt;
                    &lt;url&gt;http://192.168.0.201:8081/nexus/content/groups/public&lt;/url&gt;
                    &lt;releases&gt;
                        &lt;enabled&gt;true&lt;/enabled&gt;
                        &lt;updatePolicy&gt;never&lt;/updatePolicy&gt;
                    &lt;/releases&gt;
                    &lt;snapshots&gt;
                        &lt;enabled&gt;true&lt;/enabled&gt;
                        &lt;updatePolicy&gt;always&lt;/updatePolicy&gt;
                    &lt;/snapshots&gt;
                &lt;/repository&gt;
                &lt;repository&gt;
                    &lt;id&gt;spring-milestone&lt;/id&gt;
                    &lt;name&gt;Spring Milestone Repository&lt;/name&gt;
                    &lt;url&gt;http://192.168.0.201:8081/nexus/content/repositories/spring-milestone/&lt;/url&gt;
                    &lt;releases&gt;
                        &lt;enabled&gt;true&lt;/enabled&gt;
                    &lt;/releases&gt;
                    &lt;snapshots&gt;
                        &lt;enabled&gt;false&lt;/enabled&gt;
                    &lt;/snapshots&gt;
                    &lt;layout&gt;default&lt;/layout&gt;
                &lt;/repository&gt;
                &lt;repository&gt;
                    &lt;id&gt;spring-snapshot&lt;/id&gt;
                    &lt;name&gt;Spring Snapshot Repository&lt;/name&gt;
                    &lt;url&gt;http://192.168.0.201:8081/nexus/content/repositories/spring-snapshot/&lt;/url&gt;
                    &lt;releases&gt;
                        &lt;enabled&gt;false&lt;/enabled&gt;
                    &lt;/releases&gt;
                    &lt;snapshots&gt;
                        &lt;enabled&gt;true&lt;/enabled&gt;
                    &lt;/snapshots&gt;
                    &lt;layout&gt;default&lt;/layout&gt;
                &lt;/repository&gt;
            &lt;/repositories&gt;
            &lt;pluginRepositories&gt;
                &lt;pluginRepository&gt;
                    &lt;id&gt;local-repo&lt;/id&gt;
                    &lt;url&gt;http://192.168.0.201:8081/nexus/content/groups/public&lt;/url&gt;
                    &lt;releases&gt;
                        &lt;enabled&gt;true&lt;/enabled&gt;
                        &lt;updatePolicy&gt;daily&lt;/updatePolicy&gt;
                    &lt;/releases&gt;
                    &lt;snapshots&gt;
                        &lt;enabled&gt;true&lt;/enabled&gt;
                        &lt;updatePolicy&gt;always&lt;/updatePolicy&gt;
                    &lt;/snapshots&gt;
                &lt;/pluginRepository&gt;
            &lt;/pluginRepositories&gt;
        &lt;/profile&gt;
        &lt;!-- 代码检查 --&gt;
        &lt;profile&gt;
            &lt;id&gt;sonar&lt;/id&gt;
            &lt;activation&gt;
                &lt;activeByDefault&gt;false&lt;/activeByDefault&gt;
            &lt;/activation&gt;
            &lt;properties&gt;
                &lt;sonar.jdbc.url&gt;jdbc:mysql://192.168.0.201:3306/sonar?useUnicode=true&amp;amp;characterEncoding=utf8&amp;amp;rewriteBatchedStatements=true&lt;/sonar.jdbc.url&gt;
                &lt;sonar.jdbc.driver&gt;com.mysql.jdbc.Driver&lt;/sonar.jdbc.driver&gt;
                &lt;sonar.jdbc.username&gt;sonar&lt;/sonar.jdbc.username&gt;
                &lt;sonar.jdbc.password&gt;sonar&lt;/sonar.jdbc.password&gt;
                &lt;sonar.host.url&gt;http://192.168.0.201:9000&lt;/sonar.host.url&gt;
            &lt;/properties&gt;
        &lt;/profile&gt;
    &lt;/profiles&gt;
    &lt;activeProfiles&gt;
        &lt;activeProfile&gt;local-repo&lt;/activeProfile&gt;
    &lt;/activeProfiles&gt;
&lt;/settings&gt;
</code></pre><p>第一次安装后，nexus 伺服仓库是空的，通过maven下载jar包显示从伺服仓库下载，实际还是从公网下载，然后保存到本地，以后再下载相同的 jar 包就直接从伺服仓库下载了。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Git </tag>
            
            <tag> Nexus </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[JAXB 操作 xml]]></title>
      <url>/2016/02/20/jaxb/</url>
      <content type="html"><![CDATA[<h3 id="使用-XmlRootElement-和-XmlElement-标示根节点对象和属性节点对象"><a href="#使用-XmlRootElement-和-XmlElement-标示根节点对象和属性节点对象" class="headerlink" title="使用 @XmlRootElement 和 @XmlElement 标示根节点对象和属性节点对象"></a>使用 @XmlRootElement 和 @XmlElement 标示根节点对象和属性节点对象</h3><pre><code class="java">@XmlRootElement(name = &quot;DATA&quot;)
public class Data {

    List&lt;DataItem&gt; dataItems;

    public Data() {
    }

    @XmlElement(name = &quot;ITEM&quot;)
    public List&lt;DataItem&gt; getDataItems() {
        return dataItems;
    }

    public void setDataItems(List&lt;DataItem&gt; dataItems) {
        this.dataItems = dataItems;
    }
}
</code></pre>
<h3 id="xml-转对象"><a href="#xml-转对象" class="headerlink" title="xml 转对象"></a>xml 转对象</h3><pre><code class="java">public static Data fromXml(String xml){
    Data data = null;
    try {
        JAXBContext context = JAXBContext.newInstance(Data.class);
        Unmarshaller unmarshaller = context.createUnmarshaller();
        data = (Data) unmarshaller.unmarshal(new StringReader(xml));
    } catch (JAXBException e) {
        e.printStackTrace();
    }
    return data;
}
</code></pre>
<h3 id="对象转-xml"><a href="#对象转-xml" class="headerlink" title="对象转 xml"></a>对象转 xml</h3><pre><code class="java">    public static void toXml(String path) {
        try {
            JAXBContext context = JAXBContext.newInstance(Data.class);
            Marshaller marshaller = context.createMarshaller();
            marshaller.marshal(fromXml(xml), new File(path));
        } catch (JAXBException e) {
            e.printStackTrace();
        }
    }
</code></pre>
<h3 id="设置-xml-节点的顺序"><a href="#设置-xml-节点的顺序" class="headerlink" title="设置 xml 节点的顺序"></a>设置 xml 节点的顺序</h3><pre><code class="java">@XmlType(propOrder = {&quot;orderList&quot;, &quot;basic&quot;, &quot;shareholder&quot;, &quot;person&quot;})
public class DataItem {

    OrderList orderList;
    Basic basic;
    Shareholder shareholder;
    Person person;

     //getter and setter
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> JAXB </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Sqlplus 执行文件]]></title>
      <url>/2016/02/13/sqlplus-execute-file/</url>
      <content type="html"><![CDATA[<p>使用客户端工具导入数据量大时会卡死，所以改用命令行执行。</p>
<ol>
<li>连接数据库<pre><code>sqlplus user/password@192.168.11.15:1521/orcl
</code></pre></li>
<li>执行文件<pre><code>SQL&gt; @D:\a.sql
</code></pre></li>
</ol>
]]></content>
      
        <categories>
            
            <category> Databases </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Oracle </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Maven 打包专题]]></title>
      <url>/2016/01/29/building-package-with-maven/</url>
      <content type="html"><![CDATA[<h3 id="可执行jar包"><a href="#可执行jar包" class="headerlink" title="可执行jar包"></a>可执行jar包</h3><p><strong><em>pom.xml</em></strong></p>
<pre><code>&lt;build&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
            &lt;configuration&gt;
                &lt;descriptorRefs&gt;
                    &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;
                &lt;/descriptorRefs&gt;
                &lt;archive&gt;
                    &lt;manifest&gt;
                        &lt;mainClass&gt;com.rolex.tools.Ashbringer&lt;/mainClass&gt;
                    &lt;/manifest&gt;
                &lt;/archive&gt;
            &lt;/configuration&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;
</code></pre><p>使用命令</p>
<pre><code>mvn assembly:assembly
</code></pre><p>可生成可执行 jar 包。<br>将打包和 maven 的 package 阶段绑定，加入</p>
<pre><code>&lt;executions&gt;
    &lt;execution&gt;
        &lt;id&gt;make-assembly&lt;/id&gt;
        &lt;phase&gt;package&lt;/phase&gt;
        &lt;goals&gt;
            &lt;goal&gt;attached&lt;/goal&gt;
        &lt;/goals&gt;
    &lt;/execution&gt;
&lt;/executions&gt;
</code></pre><p>可以直接使用</p>
<pre><code>mvn package
</code></pre><p>打包。<br>配置文件是打在 jar 包里边的，所以想灵活的使用外部配置文件，此方法并不合适。</p>
<h3 id="jar-包"><a href="#jar-包" class="headerlink" title="jar 包"></a>jar 包</h3><p><strong><em>jar-with-dependencies</em></strong></p>
<pre><code>&lt;assembly xmlns=&quot;http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3&quot;
          xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
          xsi:schemaLocation=&quot;http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.3 http://maven.apache.org/xsd/assembly-1.1.3.xsd&quot;&gt;
    &lt;!-- TODO: a jarjar format would be better --&gt;
    &lt;id&gt;jar-with-dependencies&lt;/id&gt;
    &lt;formats&gt;
        &lt;format&gt;jar&lt;/format&gt;
    &lt;/formats&gt;
    &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt;
    &lt;dependencySets&gt;
        &lt;dependencySet&gt;
            &lt;outputDirectory&gt;/&lt;/outputDirectory&gt;
            &lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt;
            &lt;unpack&gt;true&lt;/unpack&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependencySet&gt;
    &lt;/dependencySets&gt;
&lt;/assembly&gt;
</code></pre><h3 id="包含第三方-jar"><a href="#包含第三方-jar" class="headerlink" title="包含第三方 jar"></a>包含第三方 jar</h3><p>如果在项目中使用中央仓库没有的第三方 jar 或是自己开发的 jar ，可以使用系统路径的方式引入。</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;com.rolex.jmeter.test&lt;/groupId&gt;
    &lt;artifactId&gt;jmeter-test&lt;/artifactId&gt;
    &lt;version&gt;1.0.0&lt;/version&gt;
    &lt;scope&gt;system&lt;/scope&gt;
    &lt;systemPath&gt;${project.basedir}/libs/certNoToMd5.jar&lt;/systemPath&gt;
&lt;/dependency&gt;
</code></pre>
<p>这样可以引入仓库中没有的 jar 。<br>但是，这样写在打包的时候并不会将外部 jar 打到 jar 中，在执行是会报找不到定义的类的异常。解决方案有两种:</p>
<ol>
<li>将目录移到 resources 下。</li>
<li>在 pom.xml 中加入 resources 配置<pre><code>&lt;build&gt;
 &lt;resources&gt;
     &lt;resource&gt;
         &lt;targetPath&gt;libs/&lt;/targetPath&gt;
         &lt;directory&gt;libs/&lt;/directory&gt;
         &lt;includes&gt;
             &lt;include&gt;**/certNoToMd5.jar&lt;/include&gt;
         &lt;/includes&gt;
     &lt;/resource&gt;
 &lt;/resources&gt;
&lt;/build&gt;
</code></pre></li>
</ol>
<h3 id="war-包"><a href="#war-包" class="headerlink" title="war 包"></a>war 包</h3><h3 id="ear-包"><a href="#ear-包" class="headerlink" title="ear 包"></a>ear 包</h3><h3 id="tar-gz"><a href="#tar-gz" class="headerlink" title="tar.gz"></a>tar.gz</h3><p>针对开发、测试、生产环境各自有一套配置文件是，可将工程打 tgz 包部署，解压后使用软连接引用不同环境的配置。<br>文件目录如下：</p>
<pre><code>project
    bin/
    etc/
    lib/
    sql/
    src/main/assembly/assembly.xml
    src/main/java
    src/main/resources
    target/
    pom.xml
    README.md
</code></pre><p><strong><em>pom.xml</em></strong></p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.rolex.maven.samples&lt;/groupId&gt;
    &lt;artifactId&gt;maven-samples&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

    &lt;properties&gt;
        &lt;maven.build.timestamp.format&gt;yyyyMMddHHmm&lt;/maven.build.timestamp.format&gt;
        &lt;java-version&gt;1.8&lt;/java-version&gt;
    &lt;/properties&gt;

    &lt;profiles&gt;
        &lt;!-- 防止idea每次更新pom都重置jdk设置 --&gt;
        &lt;profile&gt;
            &lt;id&gt;jdk-1.8&lt;/id&gt;
            &lt;activation&gt;
                &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
                &lt;jdk&gt;${java-version}&lt;/jdk&gt;
            &lt;/activation&gt;
            &lt;properties&gt;
                &lt;maven.compiler.source&gt;${java-version}&lt;/maven.compiler.source&gt;
                &lt;maven.compiler.target&gt;${java-version}&lt;/maven.compiler.target&gt;
                &lt;maven.compiler.compilerVersion&gt;${java-version}&lt;/maven.compiler.compilerVersion&gt;
            &lt;/properties&gt;
        &lt;/profile&gt;
    &lt;/profiles&gt;

    &lt;dependencies&gt;
        ...
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;!-- 编译插件 --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;source&gt;${java-version}&lt;/source&gt;
                    &lt;target&gt;${java-version}&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;!-- 解决依赖jar包插件 --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;copy-dependencies&lt;/id&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;copy-dependencies&lt;/goal&gt;
                        &lt;/goals&gt;
                        &lt;configuration&gt;
                            &lt;!-- 将jar拷贝到lib目录 --&gt;
                            &lt;outputDirectory&gt;${project.basedir}/lib&lt;/outputDirectory&gt;
                            &lt;overWriteReleases&gt;false&lt;/overWriteReleases&gt;
                            &lt;overWriteSnapshots&gt;true&lt;/overWriteSnapshots&gt;
                        &lt;/configuration&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
            &lt;!-- 打tgz包插件 --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt;
                    &lt;finalName&gt;${project.artifactId}-${maven.build.timestamp}&lt;/finalName&gt;
                    &lt;descriptors&gt;
                        &lt;descriptor&gt;src/main/assembly/assembly.xml&lt;/descriptor&gt;
                    &lt;/descriptors&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;make-assembly&lt;/id&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;single&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

    &lt;repositories&gt;
        &lt;!-- 设置中央仓库 --&gt;
        &lt;repository&gt;
            &lt;id&gt;spring-snapshots&lt;/id&gt;
            &lt;name&gt;Spring Snapshots&lt;/name&gt;
            &lt;url&gt;https://repo.spring.io/libs-snapshot&lt;/url&gt;
            &lt;snapshots&gt;
                &lt;enabled&gt;true&lt;/enabled&gt;
            &lt;/snapshots&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;
&lt;/project&gt;
</code></pre><p><strong><em>assembly.xml</em></strong></p>
<pre><code>&lt;assembly xmlns=&quot;http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2&quot;
          xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
          xsi:schemaLocation=&quot;http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2 http://maven.apache.org/xsd/assembly-1.1.2.xsd&quot;&gt;
    &lt;id&gt;distribution&lt;/id&gt;
    &lt;formats&gt;
        &lt;format&gt;tgz&lt;/format&gt;
    &lt;/formats&gt;
    &lt;fileSets&gt;
        &lt;fileSet&gt;
            &lt;directory&gt;${project.basedir}&lt;/directory&gt;
            &lt;outputDirectory&gt;/&lt;/outputDirectory&gt;
            &lt;includes&gt;
                &lt;!-- 需要打进tgz包的文件和目录 --&gt;
                &lt;include&gt;lib/**/*&lt;/include&gt;
                &lt;include&gt;bin/**/*&lt;/include&gt;
                &lt;include&gt;sql/**/*&lt;/include&gt;
                &lt;include&gt;etc/**/*&lt;/include&gt;
                &lt;include&gt;README*&lt;/include&gt;
            &lt;/includes&gt;
        &lt;/fileSet&gt;
        &lt;fileSet&gt;
            &lt;directory&gt;${project.basedir}/target/classes&lt;/directory&gt;
            &lt;outputDirectory&gt;/target/classes&lt;/outputDirectory&gt;
            &lt;includes&gt;
                &lt;include&gt;**/*.class&lt;/include&gt;
            &lt;/includes&gt;
        &lt;/fileSet&gt;
    &lt;/fileSets&gt;
&lt;/assembly&gt;
</code></pre><p>assembly 的详细属性说明参考<a href="http://maven.apache.org/plugins/maven-assembly-plugin/assembly.html" target="_blank" rel="external">http://maven.apache.org/plugins/maven-assembly-plugin/assembly.html</a></p>
<p>使用命令</p>
<pre><code>mvn clean package
</code></pre><p>可生成 tgz 包。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Maven </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[多线程下载]]></title>
      <url>/2015/12/18/mutil-threading-download/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<pre><code class="java">import java.io.InputStream;
import java.io.RandomAccessFile;
import java.net.URL;
import java.net.URLConnection;

public class MutiThreadDownloadTest {

     /**
     * @param args
     */
     public static void main(String[] args) {
          String urlString = &quot;http://www.7-zip.org/a/7z920-x64.msi&quot;;
          String path = &quot;D:\\7z.msi&quot;;
          try {
               new MutiThreadDownloadTest().new MutiThreadDownload(urlString, path, 3).download();
          } catch (Exception e) {
               e.printStackTrace();
          }
     }

     class MutiThreadDownload {
          private String urlString;// 下载路径
          private String path;// 文件存储路径
          private int threadNum;// 线程数量
          private int fileSize;// 文件大小

          public MutiThreadDownload(String urlString, String path, int threadNum) {
               super();
               this.urlString = urlString;
               this.path = path;
               this.threadNum = threadNum;
          }

          public void download() throws Exception {
               URL url = new URL(urlString);
               URLConnection conn = url.openConnection();
               fileSize = conn.getContentLength();// 获取文件大小
               RandomAccessFile destFile = new RandomAccessFile(path, &quot;rw&quot;);// 创建空文件
               // 设置下载文件相同大小
               destFile.setLength(fileSize);
               destFile.close();
               // 计算每个线程的下载大小
               int sizePerThread = fileSize / threadNum;
               // 开启线程
               for (int i = 0; i &lt; threadNum; i++) {
                    // 计算每条线程的下载的开始位置
                    int startPos = i * sizePerThread;// 开始位置
                    int endPos = sizePerThread * (i + 1) - 1;// 结束位置

                    new DownloadThread(startPos,endPos,urlString,path).start();
               }
               destFile.close();
               conn = null;
          }

     }

     class DownloadThread extends Thread {
          // 定义下载的起始点
          private long startPos;
          // 定义下载的结束点
          private long endPos;
          private String urlString;
          private String path;

          // 构造器，传入输入流，输出流和下载起始点、结束点
          public DownloadThread(long startPos, long endPos, String urlString, String path) {
               // 输出该线程负责下载的字节位置
               System.out.println(&quot;startPos=&quot;+startPos + &quot; - endPos:&quot; + endPos);
               this.startPos = startPos;
               this.endPos = endPos;
               this.urlString = urlString;
               this.path = path;
          }

          public void run() {
               URL url = null;
               URLConnection conn = null;
               InputStream is = null;
               RandomAccessFile out = null;
               try {
                    url = new URL(urlString);
                    conn = url.openConnection();
                    is = conn.getInputStream();
                    byte[] buffer = new byte[1024];
                    int hasRead = 0;
                    // 读取网络数据，并写入本地文件
                    int length = 0;
                    out = new RandomAccessFile(path, &quot;rw&quot;);
                    is.skip(this.startPos);//流从什么位置读
                    out.seek(startPos);//文件从什么位置写

                    // 读取网络数据，并写入本地文件
                    while (length &lt; endPos - startPos
                              &amp;&amp; (hasRead = is.read(buffer)) &gt; 0) {
                         out.write(buffer, 0, hasRead);
                         // 累计该线程下载的总大小
                         length += hasRead;
                    }
                    System.out.println(&quot;线程:&quot; + Thread.currentThread().getId() + &quot;下载完成!&quot;);
               } catch (Exception ex) {
                    ex.printStackTrace();
               }
               // 使用finally块来关闭当前线程的输入流、输出流
               finally {
                    try {
                         if (out != null) {
                              out.close();
                         }
                         if (is != null) {
                              is.close();
                         }
                         if (conn != null){
                              conn = null;
                         }
                    } catch (Exception ex) {
                         ex.printStackTrace();
                    }
               }
          }
     }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Concurrent </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java URL下载 zip]]></title>
      <url>/2015/12/16/download-and-operating-zip-in-java/</url>
      <content type="html"><![CDATA[<pre><code class="java">import java.io.BufferedInputStream;
import java.io.BufferedOutputStream;
import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.FileReader;
import java.io.InputStream;
import java.io.OutputStream;
import java.net.URL;
import java.net.URLConnection;
import java.util.zip.ZipEntry;
import java.util.zip.ZipInputStream;

public class CilentTest {

     public static void main(String[] args) throws Exception {
          String urlString = &quot;http://115.182.16.65:9090/ONOFFIQWS/download/1485356343/151030183903530378126.zip&quot;;
          String path = &quot;D:\\test.zip&quot;;
          download(urlString, path);

          unzip(path);

          String savePath = path.substring(0, path.lastIndexOf(File.separator))
                    + File.separator + &quot;temp&quot;;
          read(savePath);

          removeDir(new File(path));
          removeDir(new File(savePath));

     }

     /**
     * 下载文件
     *
     * @param urlString
     *            文件地址
     * @param path
     *            本地存放路径
     * @throws Exception
     */
     public static final void download(String urlString, String path)
               throws Exception {
          InputStream in = null;
          OutputStream out = null;
          int connectTimeout = 30 * 1000; // 连接超时:30s
          int readTimeout = 1 * 1000 * 1000; // IO超时:1min
          byte[] buffer = new byte[8 * 1024]; // IO缓冲区:8KB

          URL url = new URL(urlString);
          File file = new File(path);
          URLConnection conn = url.openConnection();

          conn.setConnectTimeout(connectTimeout);
          conn.setReadTimeout(readTimeout);
          conn.connect();

          in = conn.getInputStream();
          out = new FileOutputStream(file);

          while (true) {
               int bytes = in.read(buffer);
               if (bytes == -1) {
                    break;
               }
               out.write(buffer, 0, bytes);

          }

          in.close();
          out.close();
     }

     /**
     * 解压缩zip
     *
     * @param path
     *            文件路径
     */
     public static void unzip(String path) {
          final int buffer = 2048;
          int count = -1;
          int index = -1;

          // 解压缩路径 .\temp
          String savePath = path.substring(0, path.lastIndexOf(File.separator))
                    + File.separator + &quot;temp&quot; + File.separator;

          File temPath = new File(savePath);
          // 创建temp文件夹
          if (!temPath.exists()) {
               temPath.mkdirs();
          }

          try {
               BufferedOutputStream bos = null;
               ZipEntry entry = null;
               FileInputStream fis = new FileInputStream(path);
               ZipInputStream zis = new ZipInputStream(
                         new BufferedInputStream(fis));

               while ((entry = zis.getNextEntry()) != null) {

                    String tempFile = entry.getName();

                    index = tempFile.lastIndexOf(&quot;/&quot;);
                    if (index &gt; -1) {
                         tempFile = tempFile.substring(index + 1);
                    }
                    tempFile = savePath + tempFile;
                    File f = new File(tempFile);
                    f.createNewFile();

                    FileOutputStream fos = new FileOutputStream(f);
                    bos = new BufferedOutputStream(fos, buffer);

                    byte data[] = new byte[buffer];
                    while ((count = zis.read(data, 0, buffer)) != -1) {
                         bos.write(data, 0, count);
                    }

                    bos.flush();
                    bos.close();
               }

               zis.close();

          } catch (Exception e) {
               e.printStackTrace();
          }
     }

     /**
     * 读目录下所有文件内容
     *
     * @param path
     *            文件夹
     * @throws Exception
     */
     public static final void read(String path) throws Exception {
          File dir = new File(path);
          if (!dir.exists()) {
               throw new RuntimeException(&quot;doss not exist&quot;);
          }
          if (dir.isDirectory()) {
               File[] files = dir.listFiles();
               for (File f : files) {
                    StringBuffer sb = new StringBuffer();
                    String filePath = path + File.separator + f.getName();
                    BufferedReader br = new BufferedReader(new FileReader(filePath));
                    String s = null;
                    while ((s = br.readLine()) != null) {
                         sb.append(s);
                    }
                    System.out.println(sb.toString());
                    br.close();
               }
          } else {
               throw new RuntimeException(&quot;dose not a directory&quot;);
          }
     }

     /**
     * 递归删除文件夹
     *
     * @param path
     *            文件夹
     */
     public static final void removeDir(File path) {
          if (!path.exists()) {
               throw new RuntimeException(&quot;doss not exist&quot;);
          }
          if (path.isFile()) {
               path.delete();
               return;
          }
          File[] files = path.listFiles();
          for (int i = 0; i &lt; files.length; i++) {
               removeDir(files[i]);
          }
          path.delete();
     }

}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[编译 hadoop-1.2.1 eclipse 插件]]></title>
      <url>/2015/11/25/hadoop-1.2.1-eclipse-plugin-compilation/</url>
      <content type="html"><![CDATA[<h3 id="1-安装"><a href="#1-安装" class="headerlink" title="1. 安装"></a>1. 安装</h3><p>需要安装 ant 环境，Ubuntu 默认已经安装了 ant ，如果没有，执行下面命令安装。</p>
<pre><code>sudo apt-get install ant
</code></pre><h3 id="1-1-下载和解压"><a href="#1-1-下载和解压" class="headerlink" title="1.1 下载和解压"></a>1.1 下载和解压</h3><pre><code>wget https://archive.apache.org/dist/hadoop/common/hadoop-1.2.1/hadoop-1.2.1.tar.gz
tar -zxf hadoop-1.2.1.tar.gz
</code></pre><h3 id="2-修改配置文件"><a href="#2-修改配置文件" class="headerlink" title="2. 修改配置文件"></a>2. 修改配置文件</h3><h4 id="2-1-hadoop-1-2-1-src-contrib-eclipse-plugin-build-xml"><a href="#2-1-hadoop-1-2-1-src-contrib-eclipse-plugin-build-xml" class="headerlink" title="2.1 hadoop-1.2.1\src\contrib\eclipse-plugin\build.xml"></a>2.1 <strong>hadoop-1.2.1\src\contrib\eclipse-plugin\build.xml</strong></h4><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;

&lt;!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the &quot;License&quot;); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
--&gt;

&lt;project default=&quot;jar&quot; name=&quot;eclipse-plugin&quot;&gt;

  &lt;import file=&quot;../build-contrib.xml&quot;/&gt;

  &lt;path id=&quot;eclipse-sdk-jars&quot;&gt;
    &lt;fileset dir=&quot;${eclipse.home}/plugins/&quot;&gt;
      &lt;include name=&quot;org.eclipse.ui*.jar&quot;/&gt;
      &lt;include name=&quot;org.eclipse.jdt*.jar&quot;/&gt;
      &lt;include name=&quot;org.eclipse.core*.jar&quot;/&gt;
      &lt;include name=&quot;org.eclipse.equinox*.jar&quot;/&gt;
      &lt;include name=&quot;org.eclipse.debug*.jar&quot;/&gt;
      &lt;include name=&quot;org.eclipse.osgi*.jar&quot;/&gt;
      &lt;include name=&quot;org.eclipse.swt*.jar&quot;/&gt;
      &lt;include name=&quot;org.eclipse.jface*.jar&quot;/&gt;

      &lt;include name=&quot;org.eclipse.team.cvs.ssh2*.jar&quot;/&gt;
      &lt;include name=&quot;com.jcraft.jsch*.jar&quot;/&gt;
    &lt;/fileset&gt;
  &lt;/path&gt;

  &lt;!-- Override classpath to include Eclipse SDK jars --&gt;
  &lt;path id=&quot;classpath&quot;&gt;
    &lt;pathelement location=&quot;${build.classes}&quot;/&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build/classes&quot;/&gt;
    &lt;path refid=&quot;eclipse-sdk-jars&quot;/&gt;
     &lt;fileset dir=&quot;${hadoop.root}/&quot;&gt;
      &lt;include name=&quot;*.jar&quot;/&gt;
&lt;/fileset&gt;
  &lt;/path&gt;

  &lt;!-- Skip building if eclipse.home is unset. --&gt;
  &lt;target name=&quot;check-contrib&quot; unless=&quot;eclipse.home&quot;&gt;
    &lt;property name=&quot;skip.contrib&quot; value=&quot;yes&quot;/&gt;
    &lt;echo message=&quot;eclipse.home unset: skipping eclipse plugin&quot;/&gt;
  &lt;/target&gt;

&lt;target name=&quot;compile&quot; depends=&quot;init, ivy-retrieve-common&quot; unless=&quot;skip.contrib&quot;&gt;
    &lt;echo message=&quot;contrib: ${name}&quot;/&gt;
    &lt;javac
     encoding=&quot;${build.encoding}&quot;
     srcdir=&quot;${src.dir}&quot;
     includes=&quot;**/*.java&quot;
     destdir=&quot;${build.classes}&quot;
     debug=&quot;${javac.debug}&quot;
     deprecation=&quot;${javac.deprecation}&quot;&gt;
     &lt;classpath refid=&quot;classpath&quot;/&gt;
    &lt;/javac&gt;
  &lt;/target&gt;

  &lt;!-- Override jar target to specify manifest --&gt;
  &lt;target name=&quot;jar&quot; depends=&quot;compile&quot; unless=&quot;skip.contrib&quot;&gt;
    &lt;mkdir dir=&quot;${build.dir}/lib&quot;/&gt;
     &lt;!--
    &lt;copy file=&quot;${hadoop.root}/build/hadoop-core-${version}.jar&quot; tofile=&quot;${build.dir}/lib/hadoop-core.jar&quot; verbose=&quot;true&quot;/&gt;
    &lt;copy file=&quot;${hadoop.root}/build/ivy/lib/Hadoop/common/commons-cli-${commons-cli.version}.jar&quot;  todir=&quot;${build.dir}/lib&quot; verbose=&quot;true&quot;/&gt;--&gt;
     &lt;copy file=&quot;${hadoop.root}/hadoop-core-${version}.jar&quot; tofile=&quot;${build.dir}/lib/hadoop-core.jar&quot; verbose=&quot;true&quot;/&gt;
    &lt;copy file=&quot;${hadoop.root}/lib/commons-cli-1.2.jar&quot;  todir=&quot;${build.dir}/lib&quot; verbose=&quot;true&quot;/&gt;
    &lt;copy file=&quot;${hadoop.root}/lib/commons-lang-2.4.jar&quot;  todir=&quot;${build.dir}/lib&quot; verbose=&quot;true&quot;/&gt;
    &lt;copy file=&quot;${hadoop.root}/lib/commons-configuration-1.6.jar&quot;  todir=&quot;${build.dir}/lib&quot; verbose=&quot;true&quot;/&gt;
    &lt;copy file=&quot;${hadoop.root}/lib/jackson-mapper-asl-1.8.8.jar&quot;  todir=&quot;${build.dir}/lib&quot; verbose=&quot;true&quot;/&gt;
    &lt;copy file=&quot;${hadoop.root}/lib/jackson-core-asl-1.8.8.jar&quot;  todir=&quot;${build.dir}/lib&quot; verbose=&quot;true&quot;/&gt;
    &lt;copy file=&quot;${hadoop.root}/lib/commons-httpclient-3.0.1.jar&quot;  todir=&quot;${build.dir}/lib&quot; verbose=&quot;true&quot;/&gt;
    &lt;jar
      jarfile=&quot;${build.dir}/hadoop-${name}-${version}.jar&quot;
      manifest=&quot;${root}/META-INF/MANIFEST.MF&quot;&gt;
      &lt;fileset dir=&quot;${build.dir}&quot; includes=&quot;classes/ lib/&quot;/&gt;
      &lt;fileset dir=&quot;${root}&quot; includes=&quot;resources/ plugin.xml&quot;/&gt;
    &lt;/jar&gt;
  &lt;/target&gt;

&lt;/project&gt;
</code></pre><h4 id="2-2-hadoop-1-2-1-src-contrib-build-contrib-xml"><a href="#2-2-hadoop-1-2-1-src-contrib-build-contrib-xml" class="headerlink" title="2.2 hadoop-1.2.1\src\contrib\build-contrib.xml"></a>2.2 <strong>hadoop-1.2.1\src\contrib\build-contrib.xml</strong></h4><pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;

&lt;!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the &quot;License&quot;); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
--&gt;

&lt;!-- Imported by contrib/*/build.xml files to share generic targets. --&gt;

&lt;project name=&quot;hadoopbuildcontrib&quot; xmlns:ivy=&quot;antlib:org.apache.ivy.ant&quot;&gt;

  &lt;property name=&quot;name&quot; value=&quot;${ant.project.name}&quot;/&gt;
  &lt;property name=&quot;root&quot; value=&quot;${basedir}&quot;/&gt;
  &lt;property name=&quot;version&quot; value=&quot;1.2.1&quot;/&gt;
  &lt;property name=&quot;ivy.version&quot; value=&quot;2.1.0&quot;/&gt;
  &lt;property name=&quot;eclipse.home&quot; location=&quot;D:/Program Files/eclipse-jee-indigo-SR2-win32-x86_64&quot;/&gt;
  &lt;property name=&quot;hadoop.root&quot; location=&quot;D:/hadoop/hadoop-1.2.1&quot;/&gt;

  &lt;!-- Load all the default properties, and any the user wants    --&gt;
  &lt;!-- to contribute (without having to type -D or edit this file --&gt;
  &lt;property file=&quot;${user.home}/${name}.build.properties&quot; /&gt;
  &lt;property file=&quot;${root}/build.properties&quot; /&gt;
  &lt;property file=&quot;${hadoop.root}/build.properties&quot; /&gt;

  &lt;property name=&quot;src.dir&quot;  location=&quot;${root}/src/java&quot;/&gt;
  &lt;property name=&quot;src.test&quot; location=&quot;${root}/src/test&quot;/&gt;
  &lt;property name=&quot;src.test.data&quot; location=&quot;${root}/src/test/data&quot;/&gt;
  &lt;!-- Property added for contrib system tests --&gt;
  &lt;property name=&quot;build-fi.dir&quot; location=&quot;${hadoop.root}/build-fi&quot;/&gt;
  &lt;property name=&quot;system-test-build-dir&quot; location=&quot;${build-fi.dir}/system&quot;/&gt;
  &lt;property name=&quot;src.test.system&quot; location=&quot;${root}/src/test/system&quot;/&gt;

  &lt;property name=&quot;src.examples&quot; location=&quot;${root}/src/examples&quot;/&gt;

  &lt;available file=&quot;${src.examples}&quot; type=&quot;dir&quot; property=&quot;examples.available&quot;/&gt;
  &lt;available file=&quot;${src.test}&quot; type=&quot;dir&quot; property=&quot;test.available&quot;/&gt;

  &lt;!-- Property added for contrib system tests --&gt;
  &lt;available file=&quot;${src.test.system}&quot; type=&quot;dir&quot;
      property=&quot;test.system.available&quot;/&gt;

  &lt;property name=&quot;conf.dir&quot; location=&quot;${hadoop.root}/conf&quot;/&gt;
  &lt;property name=&quot;test.junit.output.format&quot; value=&quot;plain&quot;/&gt;
  &lt;property name=&quot;test.output&quot; value=&quot;no&quot;/&gt;
  &lt;property name=&quot;test.timeout&quot; value=&quot;900000&quot;/&gt;
  &lt;property name=&quot;build.contrib.dir&quot; location=&quot;${hadoop.root}/build/contrib&quot;/&gt;
  &lt;property name=&quot;build.dir&quot; location=&quot;${hadoop.root}/build/contrib/${name}&quot;/&gt;
  &lt;property name=&quot;build.classes&quot; location=&quot;${build.dir}/classes&quot;/&gt;
  &lt;property name=&quot;build.test&quot; location=&quot;${build.dir}/test&quot;/&gt;
  &lt;property name=&quot;build.examples&quot; location=&quot;${build.dir}/examples&quot;/&gt;
  &lt;property name=&quot;hadoop.log.dir&quot; location=&quot;${build.dir}/test/logs&quot;/&gt;
  &lt;!-- all jars together --&gt;
  &lt;property name=&quot;javac.deprecation&quot; value=&quot;off&quot;/&gt;
  &lt;property name=&quot;javac.debug&quot; value=&quot;on&quot;/&gt;
  &lt;property name=&quot;build.ivy.lib.dir&quot; value=&quot;${hadoop.root}/build/ivy/lib&quot;/&gt;

  &lt;property name=&quot;javadoc.link&quot;
            value=&quot;http://java.sun.com/j2se/1.4/docs/api/&quot;/&gt;

  &lt;property name=&quot;build.encoding&quot; value=&quot;ISO-8859-1&quot;/&gt;

  &lt;fileset id=&quot;lib.jars&quot; dir=&quot;${root}&quot; includes=&quot;lib/*.jar&quot;/&gt;

  &lt;!-- Property added for contrib system tests --&gt;
  &lt;property name=&quot;build.test.system&quot; location=&quot;${build.dir}/system&quot;/&gt;
  &lt;property name=&quot;build.system.classes&quot;
      location=&quot;${build.test.system}/classes&quot;/&gt;

   &lt;!-- IVY properties set here --&gt;
  &lt;property name=&quot;ivy.dir&quot; location=&quot;ivy&quot; /&gt;
  &lt;!-- loglevel take values like default|download-only|quiet --&gt;
  &lt;property name=&quot;loglevel&quot; value=&quot;quiet&quot;/&gt;
  &lt;property name=&quot;ivysettings.xml&quot; location=&quot;${hadoop.root}/ivy/ivysettings.xml&quot;/&gt;
  &lt;loadproperties srcfile=&quot;${ivy.dir}/libraries.properties&quot;/&gt;
  &lt;loadproperties srcfile=&quot;${hadoop.root}/ivy/libraries.properties&quot;/&gt;
  &lt;property name=&quot;ivy.jar&quot; location=&quot;${hadoop.root}/ivy/ivy-${ivy.version}.jar&quot;/&gt;
  &lt;property name=&quot;ivy_repo_url&quot;
     value=&quot;http://repo2.maven.org/maven2/org/apache/ivy/ivy/${ivy.version}/ivy-${ivy.version}.jar&quot; /&gt;
  &lt;property name=&quot;build.dir&quot; location=&quot;build&quot; /&gt;
  &lt;property name=&quot;build.ivy.dir&quot; location=&quot;${build.dir}/ivy&quot; /&gt;
  &lt;property name=&quot;build.ivy.lib.dir&quot; location=&quot;${build.ivy.dir}/lib&quot; /&gt;
  &lt;property name=&quot;build.ivy.report.dir&quot; location=&quot;${build.ivy.dir}/report&quot; /&gt;
  &lt;property name=&quot;common.ivy.lib.dir&quot; location=&quot;${build.ivy.lib.dir}/${ant.project.name}/common&quot;/&gt;

  &lt;!--this is the naming policy for artifacts we want pulled down--&gt;
  &lt;property name=&quot;ivy.artifact.retrieve.pattern&quot;
                   value=&quot;${ant.project.name}/[conf]/[artifact]-[revision].[ext]&quot;/&gt;

  &lt;!-- the normal classpath --&gt;
  &lt;path id=&quot;contrib-classpath&quot;&gt;
    &lt;pathelement location=&quot;${build.classes}&quot;/&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build/tools&quot;/&gt;
    &lt;fileset refid=&quot;lib.jars&quot;/&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build/classes&quot;/&gt;
    &lt;fileset dir=&quot;${hadoop.root}/lib&quot;&gt;
      &lt;include name=&quot;**/*.jar&quot; /&gt;
    &lt;/fileset&gt;
    &lt;path refid=&quot;${ant.project.name}.common-classpath&quot;/&gt;
    &lt;pathelement path=&quot;${clover.jar}&quot;/&gt;
  &lt;/path&gt;

  &lt;!-- the unit test classpath --&gt;
  &lt;path id=&quot;test.classpath&quot;&gt;
    &lt;pathelement location=&quot;${build.test}&quot; /&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build/test/classes&quot;/&gt;
    &lt;pathelement location=&quot;${hadoop.root}/src/contrib/test&quot;/&gt;
    &lt;pathelement location=&quot;${conf.dir}&quot;/&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build&quot;/&gt;
    &lt;pathelement location=&quot;${build.examples}&quot;/&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build/examples&quot;/&gt;
    &lt;path refid=&quot;contrib-classpath&quot;/&gt;
  &lt;/path&gt;

  &lt;!-- The system test classpath --&gt;
  &lt;path id=&quot;test.system.classpath&quot;&gt;
    &lt;pathelement location=&quot;${hadoop.root}/src/contrib/${name}/src/test/system&quot; /&gt;
    &lt;pathelement location=&quot;${build.test.system}&quot; /&gt;
    &lt;pathelement location=&quot;${build.test.system}/classes&quot;/&gt;
    &lt;pathelement location=&quot;${build.examples}&quot;/&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build-fi/system/classes&quot; /&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build-fi/system/test/classes&quot; /&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build-fi&quot; /&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build-fi/tools&quot; /&gt;
    &lt;pathelement location=&quot;${hadoop.home}&quot;/&gt;
    &lt;pathelement location=&quot;${hadoop.conf.dir}&quot;/&gt;
    &lt;pathelement location=&quot;${hadoop.conf.dir.deployed}&quot;/&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build&quot;/&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build/examples&quot;/&gt;
    &lt;pathelement location=&quot;${hadoop.root}/build-fi/test/classes&quot; /&gt;
    &lt;path refid=&quot;contrib-classpath&quot;/&gt;
    &lt;fileset dir=&quot;${hadoop.root}/src/test/lib&quot;&gt;
      &lt;include name=&quot;**/*.jar&quot; /&gt;
      &lt;exclude name=&quot;**/excluded/&quot; /&gt;
    &lt;/fileset&gt;
    &lt;fileset dir=&quot;${hadoop.root}/build-fi/system&quot;&gt;
       &lt;include name=&quot;**/*.jar&quot; /&gt;
       &lt;exclude name=&quot;**/excluded/&quot; /&gt;
     &lt;/fileset&gt;
    &lt;fileset dir=&quot;${hadoop.root}/build-fi/test/testjar&quot;&gt;
      &lt;include name=&quot;**/*.jar&quot; /&gt;
      &lt;exclude name=&quot;**/excluded/&quot; /&gt;
    &lt;/fileset&gt;
    &lt;fileset dir=&quot;${hadoop.root}/build/contrib/${name}&quot;&gt;
      &lt;include name=&quot;**/*.jar&quot; /&gt;
      &lt;exclude name=&quot;**/excluded/&quot; /&gt;
    &lt;/fileset&gt;
  &lt;/path&gt;

  &lt;!-- to be overridden by sub-projects --&gt;
  &lt;target name=&quot;check-contrib&quot;/&gt;
  &lt;target name=&quot;init-contrib&quot;/&gt;

  &lt;!-- ====================================================== --&gt;
  &lt;!-- Stuff needed by all targets                            --&gt;
  &lt;!-- ====================================================== --&gt;
  &lt;target name=&quot;init&quot; depends=&quot;check-contrib&quot; unless=&quot;skip.contrib&quot;&gt;
    &lt;echo message=&quot;contrib: ${name}&quot;/&gt;
    &lt;mkdir dir=&quot;${build.dir}&quot;/&gt;
    &lt;mkdir dir=&quot;${build.classes}&quot;/&gt;
    &lt;mkdir dir=&quot;${build.test}&quot;/&gt;
    &lt;!-- The below two tags  added for contrib system tests --&gt;
    &lt;mkdir dir=&quot;${build.test.system}&quot;/&gt;
    &lt;mkdir dir=&quot;${build.system.classes}&quot;/&gt;
    &lt;mkdir dir=&quot;${build.examples}&quot;/&gt;
    &lt;mkdir dir=&quot;${hadoop.log.dir}&quot;/&gt;
    &lt;antcall target=&quot;init-contrib&quot;/&gt;
  &lt;/target&gt;


  &lt;!-- ====================================================== --&gt;
  &lt;!-- Compile a Hadoop contrib&#39;s files                       --&gt;
  &lt;!-- ====================================================== --&gt;
  &lt;target name=&quot;compile&quot; depends=&quot;init, ivy-retrieve-common&quot; unless=&quot;skip.contrib&quot;&gt;
    &lt;echo message=&quot;contrib: ${name}&quot;/&gt;
    &lt;javac
     encoding=&quot;${build.encoding}&quot;
     srcdir=&quot;${src.dir}&quot;
     includes=&quot;**/*.java&quot;
     destdir=&quot;${build.classes}&quot;
     debug=&quot;${javac.debug}&quot;
     deprecation=&quot;${javac.deprecation}&quot;&gt;
     &lt;classpath refid=&quot;contrib-classpath&quot;/&gt;
    &lt;/javac&gt;
  &lt;/target&gt;


  &lt;!-- ======================================================= --&gt;
  &lt;!-- Compile a Hadoop contrib&#39;s example files (if available) --&gt;
  &lt;!-- ======================================================= --&gt;
  &lt;target name=&quot;compile-examples&quot; depends=&quot;compile&quot; if=&quot;examples.available&quot;&gt;
    &lt;echo message=&quot;contrib: ${name}&quot;/&gt;
    &lt;javac
     encoding=&quot;${build.encoding}&quot;
     srcdir=&quot;${src.examples}&quot;
     includes=&quot;**/*.java&quot;
     destdir=&quot;${build.examples}&quot;
     debug=&quot;${javac.debug}&quot;&gt;
     &lt;classpath refid=&quot;contrib-classpath&quot;/&gt;
    &lt;/javac&gt;
  &lt;/target&gt;


  &lt;!-- ================================================================== --&gt;
  &lt;!-- Compile test code                                                  --&gt;
  &lt;!-- ================================================================== --&gt;
  &lt;target name=&quot;compile-test&quot; depends=&quot;compile-examples&quot; if=&quot;test.available&quot;&gt;
    &lt;echo message=&quot;contrib: ${name}&quot;/&gt;
    &lt;javac
     encoding=&quot;${build.encoding}&quot;
     srcdir=&quot;${src.test}&quot;
     includes=&quot;**/*.java&quot;
     excludes=&quot;system/**/*.java&quot;
     destdir=&quot;${build.test}&quot;
     debug=&quot;${javac.debug}&quot;&gt;
    &lt;classpath refid=&quot;test.classpath&quot;/&gt;
    &lt;/javac&gt;
  &lt;/target&gt;

  &lt;!-- ================================================================== --&gt;
  &lt;!-- Compile system test code                                           --&gt;
  &lt;!-- ================================================================== --&gt;
  &lt;target name=&quot;compile-test-system&quot; depends=&quot;compile-examples&quot;
     if=&quot;test.system.available&quot;&gt;
    &lt;echo message=&quot;contrib: ${name}&quot;/&gt;
    &lt;javac
       encoding=&quot;${build.encoding}&quot;
       srcdir=&quot;${src.test.system}&quot;
       includes=&quot;**/*.java&quot;
       destdir=&quot;${build.system.classes}&quot;
       debug=&quot;${javac.debug}&quot;&gt;
      &lt;classpath refid=&quot;test.system.classpath&quot;/&gt;
    &lt;/javac&gt;
  &lt;/target&gt;

  &lt;!-- ====================================================== --&gt;
  &lt;!-- Make a Hadoop contrib&#39;s jar                            --&gt;
  &lt;!-- ====================================================== --&gt;
  &lt;target name=&quot;jar&quot; depends=&quot;compile&quot; unless=&quot;skip.contrib&quot;&gt;
    &lt;echo message=&quot;contrib: ${name}&quot;/&gt;
    &lt;jar
      jarfile=&quot;${build.dir}/hadoop-${name}-${version}.jar&quot;
      basedir=&quot;${build.classes}&quot;     
    /&gt;
  &lt;/target&gt;


  &lt;!-- ====================================================== --&gt;
  &lt;!-- Make a Hadoop contrib&#39;s examples jar                   --&gt;
  &lt;!-- ====================================================== --&gt;
  &lt;target name=&quot;jar-examples&quot; depends=&quot;compile-examples&quot;
          if=&quot;examples.available&quot; unless=&quot;skip.contrib&quot;&gt;
    &lt;echo message=&quot;contrib: ${name}&quot;/&gt;
    &lt;jar jarfile=&quot;${build.dir}/hadoop-${name}-examples-${version}.jar&quot;&gt;
      &lt;fileset dir=&quot;${build.classes}&quot;&gt;
      &lt;/fileset&gt;
      &lt;fileset dir=&quot;${build.examples}&quot;&gt;
      &lt;/fileset&gt;
    &lt;/jar&gt;
  &lt;/target&gt;

  &lt;!-- ====================================================== --&gt;
  &lt;!-- Package a Hadoop contrib                               --&gt;
  &lt;!-- ====================================================== --&gt;
  &lt;target name=&quot;package&quot; depends=&quot;jar, jar-examples&quot; unless=&quot;skip.contrib&quot;&gt;
    &lt;mkdir dir=&quot;${dist.dir}/contrib/${name}&quot;/&gt;
    &lt;copy todir=&quot;${dist.dir}/contrib/${name}&quot; includeEmptyDirs=&quot;false&quot; flatten=&quot;true&quot;&gt;
      &lt;fileset dir=&quot;${build.dir}&quot;&gt;
        &lt;include name=&quot;hadoop-${name}-${version}.jar&quot; /&gt;
      &lt;/fileset&gt;
    &lt;/copy&gt;
  &lt;/target&gt;

  &lt;!-- ================================================================== --&gt;
  &lt;!-- Run unit tests                                                     --&gt;
  &lt;!-- ================================================================== --&gt;
  &lt;target name=&quot;test&quot; depends=&quot;compile-test, compile&quot; if=&quot;test.available&quot;&gt;
    &lt;echo message=&quot;contrib: ${name}&quot;/&gt;
    &lt;delete dir=&quot;${hadoop.log.dir}&quot;/&gt;
    &lt;mkdir dir=&quot;${hadoop.log.dir}&quot;/&gt;
    &lt;junit
      printsummary=&quot;yes&quot; showoutput=&quot;${test.output}&quot;
      haltonfailure=&quot;no&quot; fork=&quot;yes&quot; maxmemory=&quot;512m&quot;
      errorProperty=&quot;tests.failed&quot; failureProperty=&quot;tests.failed&quot;
      timeout=&quot;${test.timeout}&quot;&gt;

      &lt;sysproperty key=&quot;test.build.data&quot; value=&quot;${build.test}/data&quot;/&gt;
      &lt;sysproperty key=&quot;build.test&quot; value=&quot;${build.test}&quot;/&gt;
      &lt;sysproperty key=&quot;src.test.data&quot; value=&quot;${src.test.data}&quot;/&gt;
      &lt;sysproperty key=&quot;contrib.name&quot; value=&quot;${name}&quot;/&gt;

      &lt;!-- requires fork=yes for:
        relative File paths to use the specified user.dir
        classpath to use build/contrib/*.jar
      --&gt;
      &lt;sysproperty key=&quot;user.dir&quot; value=&quot;${build.test}/data&quot;/&gt;

      &lt;sysproperty key=&quot;fs.default.name&quot; value=&quot;${fs.default.name}&quot;/&gt;
      &lt;sysproperty key=&quot;hadoop.test.localoutputfile&quot; value=&quot;${hadoop.test.localoutputfile}&quot;/&gt;
      &lt;sysproperty key=&quot;hadoop.log.dir&quot; value=&quot;${hadoop.log.dir}&quot;/&gt;
      &lt;sysproperty key=&quot;taskcontroller-path&quot; value=&quot;${taskcontroller-path}&quot;/&gt;
      &lt;sysproperty key=&quot;taskcontroller-ugi&quot; value=&quot;${taskcontroller-ugi}&quot;/&gt;
      &lt;classpath refid=&quot;test.classpath&quot;/&gt;
      &lt;formatter type=&quot;${test.junit.output.format}&quot; /&gt;
      &lt;batchtest todir=&quot;${build.test}&quot; unless=&quot;testcase&quot;&gt;
        &lt;fileset dir=&quot;${src.test}&quot;
                 includes=&quot;**/Test*.java&quot; excludes=&quot;**/${test.exclude}.java, system/**/*.java&quot; /&gt;
      &lt;/batchtest&gt;
      &lt;batchtest todir=&quot;${build.test}&quot; if=&quot;testcase&quot;&gt;
        &lt;fileset dir=&quot;${src.test}&quot; includes=&quot;**/${testcase}.java&quot; excludes=&quot;system/**/*.java&quot; /&gt;
      &lt;/batchtest&gt;
    &lt;/junit&gt;
    &lt;antcall target=&quot;checkfailure&quot;/&gt;
  &lt;/target&gt;

  &lt;!-- ================================================================== --&gt;
  &lt;!-- Run system tests                                                   --&gt;
  &lt;!-- ================================================================== --&gt;
  &lt;target name=&quot;test-system&quot; depends=&quot;compile, compile-test-system, jar&quot;
     if=&quot;test.system.available&quot;&gt;
     &lt;delete dir=&quot;${build.test.system}/extraconf&quot;/&gt;
     &lt;mkdir dir=&quot;${build.test.system}/extraconf&quot;/&gt;
     &lt;property name=&quot;test.src.dir&quot; location=&quot;${hadoop.root}/src/test&quot;/&gt;
     &lt;property name=&quot;test.junit.printsummary&quot; value=&quot;yes&quot; /&gt;
     &lt;property name=&quot;test.junit.haltonfailure&quot; value=&quot;no&quot; /&gt;
     &lt;property name=&quot;test.junit.maxmemory&quot; value=&quot;512m&quot; /&gt;
     &lt;property name=&quot;test.junit.fork.mode&quot; value=&quot;perTest&quot; /&gt;
     &lt;property name=&quot;test.all.tests.file&quot; value=&quot;${test.src.dir}/all-tests&quot; /&gt;
     &lt;property name=&quot;test.build.dir&quot; value=&quot;${hadoop.root}/build/test&quot;/&gt;
     &lt;property name=&quot;basedir&quot; value=&quot;${hadoop.root}&quot;/&gt;
     &lt;property name=&quot;test.timeout&quot; value=&quot;900000&quot;/&gt;
     &lt;property name=&quot;test.junit.output.format&quot; value=&quot;plain&quot;/&gt;
     &lt;property name=&quot;test.tools.input.dir&quot; value=&quot;${basedir}/src/test/tools/data&quot;/&gt;
     &lt;property name=&quot;c++.src&quot; value=&quot;${basedir}/src/c++&quot;/&gt;
     &lt;property name=&quot;test.include&quot; value=&quot;Test*&quot;/&gt;
     &lt;property name=&quot;c++.libhdfs.src&quot; value=&quot;${c++.src}/libhdfs&quot;/&gt;
     &lt;property name=&quot;test.build.data&quot; value=&quot;${build.test.system}/data&quot;/&gt;
     &lt;property name=&quot;test.cache.data&quot; value=&quot;${build.test.system}/cache&quot;/&gt;
     &lt;property name=&quot;test.debug.data&quot; value=&quot;${build.test.system}/debug&quot;/&gt;
     &lt;property name=&quot;test.log.dir&quot; value=&quot;${build.test.system}/logs&quot;/&gt;
     &lt;patternset id=&quot;empty.exclude.list.id&quot; /&gt;
        &lt;exec executable=&quot;sed&quot; inputstring=&quot;${os.name}&quot;
            outputproperty=&quot;nonspace.os&quot;&gt;
          &lt;arg value=&quot;s/ /_/g&quot;/&gt;
        &lt;/exec&gt;
     &lt;property name=&quot;build.platform&quot;
         value=&quot;${nonspace.os}-${os.arch}-${sun.arch.data.model}&quot;/&gt;
     &lt;property name=&quot;build.native&quot;
         value=&quot;${hadoop.root}/build/native/${build.platform}&quot;/&gt;
     &lt;property name=&quot;lib.dir&quot; value=&quot;${hadoop.root}/lib&quot;/&gt;
     &lt;property name=&quot;install.c++.examples&quot;
         value=&quot;${hadoop.root}/build/c++-examples/${build.platform}&quot;/&gt;
    &lt;condition property=&quot;tests.testcase&quot;&gt;
       &lt;and&gt;
         &lt;isset property=&quot;testcase&quot; /&gt;
       &lt;/and&gt;
    &lt;/condition&gt;
     &lt;property name=&quot;test.junit.jvmargs&quot; value=&quot;-ea&quot; /&gt;
    &lt;macro-system-test-runner test.file=&quot;${test.all.tests.file}&quot;
                     classpath=&quot;test.system.classpath&quot;
                     test.dir=&quot;${build.test.system}&quot;
                     fileset.dir=&quot;${hadoop.root}/src/contrib/${name}/src/test/system&quot;
                     hadoop.conf.dir.deployed=&quot;${hadoop.conf.dir.deployed}&quot;&gt;
  &lt;/macro-system-test-runner&gt;
  &lt;/target&gt;

  &lt;macrodef name=&quot;macro-system-test-runner&quot;&gt;
    &lt;attribute name=&quot;test.file&quot; /&gt;
    &lt;attribute name=&quot;classpath&quot; /&gt;
    &lt;attribute name=&quot;test.dir&quot; /&gt;
    &lt;attribute name=&quot;fileset.dir&quot; /&gt;
    &lt;attribute name=&quot;hadoop.conf.dir.deployed&quot; default=&quot;&quot; /&gt;
    &lt;sequential&gt;
      &lt;delete dir=&quot;@{test.dir}/data&quot;/&gt;
      &lt;mkdir dir=&quot;@{test.dir}/data&quot;/&gt;
      &lt;delete dir=&quot;@{test.dir}/logs&quot;/&gt;
      &lt;mkdir dir=&quot;@{test.dir}/logs&quot;/&gt;
      &lt;copy file=&quot;${test.src.dir}/hadoop-policy.xml&quot;
        todir=&quot;@{test.dir}/extraconf&quot; /&gt;
      &lt;copy file=&quot;${test.src.dir}/fi-site.xml&quot;
        todir=&quot;@{test.dir}/extraconf&quot; /&gt;
      &lt;junit showoutput=&quot;${test.output}&quot;
        printsummary=&quot;${test.junit.printsummary}&quot;
        haltonfailure=&quot;${test.junit.haltonfailure}&quot;
        fork=&quot;yes&quot;
        forkmode=&quot;${test.junit.fork.mode}&quot;
        maxmemory=&quot;${test.junit.maxmemory}&quot;
        dir=&quot;${basedir}&quot; timeout=&quot;${test.timeout}&quot;
        errorProperty=&quot;tests.failed&quot; failureProperty=&quot;tests.failed&quot;&gt;
        &lt;jvmarg value=&quot;${test.junit.jvmargs}&quot; /&gt;
        &lt;sysproperty key=&quot;java.net.preferIPv4Stack&quot; value=&quot;true&quot;/&gt;
        &lt;sysproperty key=&quot;test.build.data&quot; value=&quot;@{test.dir}/data&quot;/&gt;
        &lt;sysproperty key=&quot;test.tools.input.dir&quot; value = &quot;${test.tools.input.dir}&quot;/&gt;
        &lt;sysproperty key=&quot;test.cache.data&quot; value=&quot;${test.cache.data}&quot;/&gt;
        &lt;sysproperty key=&quot;test.debug.data&quot; value=&quot;${test.debug.data}&quot;/&gt;
        &lt;sysproperty key=&quot;hadoop.log.dir&quot; value=&quot;@{test.dir}/logs&quot;/&gt;
        &lt;sysproperty key=&quot;test.src.dir&quot; value=&quot;@{fileset.dir}&quot;/&gt;
        &lt;sysproperty key=&quot;taskcontroller-path&quot; value=&quot;${taskcontroller-path}&quot;/&gt;
        &lt;sysproperty key=&quot;taskcontroller-ugi&quot; value=&quot;${taskcontroller-ugi}&quot;/&gt;
        &lt;sysproperty key=&quot;test.build.extraconf&quot; value=&quot;@{test.dir}/extraconf&quot; /&gt;
        &lt;sysproperty key=&quot;hadoop.policy.file&quot; value=&quot;hadoop-policy.xml&quot;/&gt;
        &lt;sysproperty key=&quot;java.library.path&quot;
          value=&quot;${build.native}/lib:${lib.dir}/native/${build.platform}&quot;/&gt;
        &lt;sysproperty key=&quot;install.c++.examples&quot; value=&quot;${install.c++.examples}&quot;/&gt;
        &lt;syspropertyset dynamic=&quot;no&quot;&gt;
          &lt;propertyref name=&quot;hadoop.tmp.dir&quot;/&gt;
        &lt;/syspropertyset&gt;
        &lt;!-- set compile.c++ in the child jvm only if it is set --&gt;
        &lt;syspropertyset dynamic=&quot;no&quot;&gt;
          &lt;propertyref name=&quot;compile.c++&quot;/&gt;
        &lt;/syspropertyset&gt;
        &lt;!-- Pass probability specifications to the spawn JVM --&gt;
        &lt;syspropertyset id=&quot;FaultProbabilityProperties&quot;&gt;
          &lt;propertyref regex=&quot;fi.*&quot;/&gt;
        &lt;/syspropertyset&gt;
        &lt;sysproperty key=&quot;test.system.hdrc.deployed.hadoopconfdir&quot;
                     value=&quot;@{hadoop.conf.dir.deployed}&quot; /&gt;
        &lt;classpath refid=&quot;@{classpath}&quot;/&gt;
        &lt;formatter type=&quot;${test.junit.output.format}&quot; /&gt;
        &lt;batchtest todir=&quot;@{test.dir}&quot; unless=&quot;testcase&quot;&gt;
          &lt;fileset dir=&quot;@{fileset.dir}&quot;
            excludes=&quot;**/${test.exclude}.java aop/** system/**&quot;&gt;
            &lt;patternset&gt;
              &lt;includesfile name=&quot;@{test.file}&quot;/&gt;
            &lt;/patternset&gt;
          &lt;/fileset&gt;
        &lt;/batchtest&gt;
        &lt;batchtest todir=&quot;@{test.dir}&quot; if=&quot;testcase&quot;&gt;
          &lt;fileset dir=&quot;@{fileset.dir}&quot; includes=&quot;**/${testcase}.java&quot;/&gt;
        &lt;/batchtest&gt;
      &lt;/junit&gt;
      &lt;antcall target=&quot;checkfailure&quot;/&gt;
    &lt;/sequential&gt;
  &lt;/macrodef&gt;


  &lt;target name=&quot;checkfailure&quot; if=&quot;tests.failed&quot;&gt;
    &lt;touch file=&quot;${build.contrib.dir}/testsfailed&quot;/&gt;
    &lt;fail unless=&quot;continueOnFailure&quot;&gt;Contrib Tests failed!&lt;/fail&gt;
  &lt;/target&gt;

  &lt;!-- ================================================================== --&gt;
  &lt;!-- Clean.  Delete the build files, and their directories              --&gt;
  &lt;!-- ================================================================== --&gt;
  &lt;target name=&quot;clean&quot;&gt;
    &lt;echo message=&quot;contrib: ${name}&quot;/&gt;
    &lt;delete dir=&quot;${build.dir}&quot;/&gt;
  &lt;/target&gt;

  &lt;target name=&quot;ivy-probe-antlib&quot; &gt;
    &lt;condition property=&quot;ivy.found&quot;&gt;
      &lt;typefound uri=&quot;antlib:org.apache.ivy.ant&quot; name=&quot;cleancache&quot;/&gt;
    &lt;/condition&gt;
  &lt;/target&gt;


  &lt;target name=&quot;ivy-download&quot; description=&quot;To download ivy &quot; unless=&quot;offline&quot;&gt;
    &lt;get src=&quot;${ivy_repo_url}&quot; dest=&quot;${ivy.jar}&quot; usetimestamp=&quot;true&quot;/&gt;
  &lt;/target&gt;

  &lt;target name=&quot;ivy-init-antlib&quot; depends=&quot;ivy-download,ivy-probe-antlib&quot; unless=&quot;ivy.found&quot;&gt;
    &lt;typedef uri=&quot;antlib:org.apache.ivy.ant&quot; onerror=&quot;fail&quot;
      loaderRef=&quot;ivyLoader&quot;&gt;
      &lt;classpath&gt;
        &lt;pathelement location=&quot;${ivy.jar}&quot;/&gt;
      &lt;/classpath&gt;
    &lt;/typedef&gt;
    &lt;fail &gt;
      &lt;condition &gt;
        &lt;not&gt;
          &lt;typefound uri=&quot;antlib:org.apache.ivy.ant&quot; name=&quot;cleancache&quot;/&gt;
        &lt;/not&gt;
      &lt;/condition&gt;
      You need Apache Ivy 2.0 or later from http://ant.apache.org/
      It could not be loaded from ${ivy_repo_url}
    &lt;/fail&gt;
  &lt;/target&gt;

  &lt;target name=&quot;ivy-init&quot; depends=&quot;ivy-init-antlib&quot;&gt;
    &lt;ivy:configure settingsid=&quot;${ant.project.name}.ivy.settings&quot; file=&quot;${ivysettings.xml}&quot;/&gt;
  &lt;/target&gt;

  &lt;target name=&quot;ivy-resolve-common&quot; depends=&quot;ivy-init&quot;&gt;
    &lt;ivy:resolve settingsRef=&quot;${ant.project.name}.ivy.settings&quot; conf=&quot;common&quot; log=&quot;${loglevel}&quot;/&gt;
  &lt;/target&gt;

  &lt;target name=&quot;ivy-retrieve-common&quot; depends=&quot;ivy-resolve-common&quot;
    description=&quot;Retrieve Ivy-managed artifacts for the compile/test configurations&quot;&gt;
    &lt;ivy:retrieve settingsRef=&quot;${ant.project.name}.ivy.settings&quot;
      pattern=&quot;${build.ivy.lib.dir}/${ivy.artifact.retrieve.pattern}&quot; sync=&quot;true&quot; log=&quot;${loglevel}&quot;/&gt;
    &lt;ivy:cachepath pathid=&quot;${ant.project.name}.common-classpath&quot; conf=&quot;common&quot; /&gt;
  &lt;/target&gt;
&lt;/project&gt;
</code></pre><h4 id="2-3-hadoop-1-2-1-src-contrib-eclipse-plugin-META-INF-MANIFEST-MF"><a href="#2-3-hadoop-1-2-1-src-contrib-eclipse-plugin-META-INF-MANIFEST-MF" class="headerlink" title="2.3 hadoop-1.2.1\src\contrib\eclipse-plugin\META-INF\MANIFEST.MF"></a>2.3 <strong>hadoop-1.2.1\src\contrib\eclipse-plugin\META-INF\MANIFEST.MF</strong></h4><pre><code>Manifest-Version: 1.0
Bundle-ManifestVersion: 2
Bundle-Name: MapReduce Tools for Eclipse
Bundle-SymbolicName: org.apache.hadoop.eclipse;singleton:=true
Bundle-Version: 0.18
Bundle-Activator: org.apache.hadoop.eclipse.Activator
Bundle-Localization: plugin
Require-Bundle: org.eclipse.ui,
org.eclipse.core.runtime,
org.eclipse.jdt.launching,
org.eclipse.debug.core,
org.eclipse.jdt,
org.eclipse.jdt.core,
org.eclipse.core.resources,
org.eclipse.ui.ide,
org.eclipse.jdt.ui,
org.eclipse.debug.ui,
org.eclipse.jdt.debug.ui,
org.eclipse.core.expressions,
org.eclipse.ui.cheatsheets,
org.eclipse.ui.console,
org.eclipse.ui.navigator,
org.eclipse.core.filesystem,
org.apache.commons.logging
Eclipse-LazyStart: true
Bundle-ClassPath: classes/,lib/hadoop-core.jar,lib/jackson-core-asl-1.8.8.jar ,lib/jackson-mapper-asl-1.8.8.jar, lib/commons-configuration-1.6.jar,lib/commons-lang-2.4.jar, lib/commons-httpclient-3.0.1.jar,lib/commons-cli-1.2.jar
Bundle-Vendor: Apache Hadoop
</code></pre><h3 id="3-编译"><a href="#3-编译" class="headerlink" title="3. 编译"></a>3. 编译</h3><p>配置文件修改完成后，使用ant进行编译（过程需要联网）。</p>
<pre><code>ant D:\hadoop\hadoop-1.2.1\src\contrib\eclipse-plugin\build.xml
</code></pre>]]></content>
      
        <categories>
            
            <category> Big Data </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Bloom Filter]]></title>
      <url>/2015/11/24/Bloom-Filter/</url>
      <content type="html"><![CDATA[<p>bloom filter是一种节省空间的数据结构。</p>
<p>内在表现为m个比特位的数组。</p>
<p>优势在于大小固定且在初始化时被设置。</p>
<p>一个典型的bloom filter包含add和contrans操作，和set类似。</p>
<pre><code>class BloomFilter&lt;E&gt; {
     public BloomFilter(int m, int k) { ... }
     public void add(E obj) { ... }
     public boolean contains(E obj) { ... }
}
</code></pre><p>初始状态时，Bloom Filter是一个包含m位的位数组，每一位都置为0。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/2.png" alt="1"></p>
<p>对于任意元素x，bloom filter将其使用hash函数计算k个索引，存放在数组中，每个位置的值为1。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/3.png" alt="2"></p>
<p>判断一个元素y是否属于集合时，对y进行k次hash函数计算，如果所有索引位置在数组中的值都为1，则y属于这个集合。如果有任意个索引位置的值为0，则y不属于这个集合。</p>
<p><img src="https://raw.githubusercontent.com/bsyonline/pic/master/20181014/4.png" alt="1"></p>
<p>增加元素到bloom filter中不会改变其大小，只会改变误报率。</p>
<p>误报率的近似值为0.7*(m/n)</p>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Data Structures </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[读书笔记：hadoop 权威指南（Hadoop The Definitive Guide）]]></title>
      <url>/2015/11/19/hadoop-the-definitive-guide-notes/</url>
      <content type="html"><![CDATA[<h3 id="第3章-Hadoop分布式文件系统"><a href="#第3章-Hadoop分布式文件系统" class="headerlink" title="第3章 Hadoop分布式文件系统"></a>第3章 Hadoop分布式文件系统</h3><h4 id="3-1-Hadoop的概念"><a href="#3-1-Hadoop的概念" class="headerlink" title="3.1 Hadoop的概念"></a>3.1 Hadoop的概念</h4><h5 id="3-1-1-数据块"><a href="#3-1-1-数据块" class="headerlink" title="3.1.1 数据块"></a>3.1.1 数据块</h5><p>数据块默认大小64M，修改？？？<br>修改数据块的大小是为了减少磁盘寻址时间带来的消耗，但块过大会使map的数量变少（map一次处理一个block），MapReduce的效率降低。</p>
<h5 id="3-1-2-NameNode和DataNode"><a href="#3-1-2-NameNode和DataNode" class="headerlink" title="3.1.2 NameNode和DataNode"></a>3.1.2 NameNode和DataNode</h5><p>HDFS的特点是采用主从结构（Master/Slave）。NameNode存储2类文件：命名空间镜像文件和操作日志文件，用于记录文件系统数及树的文件和目录。NameNode是HDFS的核心，NameNode损坏将导致整个HDFS不可用。所以需要进行备份，备份的机制有2种：将NameNode信息同时写入NFS和使用SecondaryNameNode。SecondaryNameNode通常在单独节点运行，因为需要大量的CUP与和NameNode相同大小的内存用于进行命名空间合并。SecondaryNameNode的数据滞后于NameNode，所以在恢复时需要将NFS的数据拷贝到SecondaryNameNode。</p>
<h5 id="3-1-3-命令行"><a href="#3-1-3-命令行" class="headerlink" title="3.1.3 命令行"></a>3.1.3 命令行</h5><pre><code>hadoop fs [-fs &lt;local | file system URI&gt;] [-conf &lt;configuration file&gt;]
[-D &lt;property=value&gt;] [-ls &lt;path&gt;] [-lsr &lt;path&gt;] [-du &lt;path&gt;]
[-dus &lt;path&gt;] [-mv &lt;src&gt; &lt;dst&gt;] [-cp &lt;src&gt; &lt;dst&gt;] [-rm [-skipTrash] &lt;src&gt;]
[-rmr [-skipTrash] &lt;src&gt;] [-put &lt;localsrc&gt; ... &lt;dst&gt;] [-copyFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]
[-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;] [-get [-ignoreCrc] [-crc] &lt;src&gt; &lt;localdst&gt;
[-getmerge &lt;src&gt; &lt;localdst&gt; [addnl]] [-cat &lt;src&gt;]
[-copyToLocal [-ignoreCrc] [-crc] &lt;src&gt; &lt;localdst&gt;] [-moveToLocal &lt;src&gt; &lt;localdst&gt;]
[-mkdir &lt;path&gt;] [-report] [-setrep [-R] [-w] &lt;rep&gt; &lt;path/file&gt;]
[-touchz &lt;path&gt;] [-test -[ezd] &lt;path&gt;] [-stat [format] &lt;path&gt;]
[-tail [-f] &lt;path&gt;] [-text &lt;path&gt;]
[-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]
[-chown [-R] [OWNER][:[GROUP]] PATH...]
[-chgrp [-R] GROUP PATH...]
[-count[-q] &lt;path&gt;]
[-help [cmd]]
</code></pre>]]></content>
      
        <categories>
            
            <category> Big Data </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hive-0.9.0 安装]]></title>
      <url>/2015/11/12/hive-0.9.0-installation/</url>
      <content type="html"><![CDATA[<h4 id="1-解压缩"><a href="#1-解压缩" class="headerlink" title="1. 解压缩"></a><strong>1. 解压缩</strong></h4><pre><code>[rolex@node2 hive]$ pwd  
/usr/hive
[rolex@node2 hive]$ tar -zxf hive-0.9.0.tar.gz
</code></pre><h4 id="2-配置环境变量"><a href="#2-配置环境变量" class="headerlink" title="2. 配置环境变量"></a><strong>2. 配置环境变量</strong></h4><pre><code>[rolex@node2 hive]$ sudo echo &quot;HIVE_HOME=/usr/hive/hive-0.9.0&quot;&gt;/etc/profile.d/hive.sh
[rolex@node2 hive]$ sudo echo &#39;PATH=$PATH:$HIVE_HOME/bin&#39;&gt;&gt;/etc/profile.d/hive.sh
[rolex@node2 hive]$ sudo echo &quot;export HIVE_HOME PATH&quot;&gt;&gt;/etc/profile.d/hive.sh
[rolex@node2 hive]$ . /etc/profile
</code></pre><h4 id="3-配置文件"><a href="#3-配置文件" class="headerlink" title="3. 配置文件"></a><strong>3. 配置文件</strong></h4><pre><code>[rolex@node2 conf]$ pwd
/usr/hive/hive-0.9.0/conf
[rolex@node2 conf]$ cp hive-default.xml.template hive-default.xml
[rolex@node2 conf]$ cp hive-env.sh.template hive-env.sh
[rolex@node2 conf]$ cp hive-log4j.properties.template hive-log4j.properties
[rolex@node2 conf]$ cp hive-exec-log4j.properties.template hive-exec-log4j.properties
[rolex@node2 conf]$ cp hive-default.xml.template hive-site.xml
</code></pre><h4 id="4-启动"><a href="#4-启动" class="headerlink" title="4. 启动"></a><strong>4. 启动</strong></h4><pre><code>[rolex@node2 bin]$ pwd
/usr/hive/hive-0.9.0/bin
[rolex@node2 bin]$ ./hive
Logging initialized using configuration in file:/usr/hive/hive-0.9.0/conf/hive-log4j.properties
Hive history file=/tmp/rolex/hive_job_log_rolex_201511061336_165277921.txt
hive&gt;
</code></pre><h4 id="5-测试"><a href="#5-测试" class="headerlink" title="5. 测试"></a><strong>5. 测试</strong></h4><pre><code>hive&gt; show databases;
OK
default
Time taken: 0.101 seconds
hive&gt; CREATE TABLE x (a INT);
OK
Time taken: 0.702 seconds
hive&gt; SELECT * FROM x;
OK
Time taken: 0.283 seconds
hive&gt; DROP TABLE x;
OK
Time taken: 1.059 seconds
hive&gt; exit;
</code></pre><blockquote>
<p>Tips：在配置 hadoop-2.6.2 和 hive-1.2.2 启动 hive 时遇到 2 个小问题：</p>
<ol>
<li>Relative path in absolute URI: ${system:java.io.tmpdir%7D/$%7Bsystem:user.name%7D<br>把 <code>./conf/hive-site.xml</code> 中的 ${system:java.io.tmpdir} 替换成具体的路径。</li>
<li>Found class jline.Terminal, but interface was expected<br>jar 包版本问题，把 <code>./lib/jline-2.12.jar</code> 拷贝到 <code>hadoop-2.6.2/share/hadoop/yarn/lib/</code> ，删除原来的 <code>jline-0.9.94.jar</code>，重启 hadoop。</li>
</ol>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Big Data </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hive </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[排序算法]]></title>
      <url>/2015/11/11/sorting/</url>
      <content type="html"><![CDATA[<h4 id="排序算法"><a href="#排序算法" class="headerlink" title="排序算法"></a>排序算法</h4><table style="font-size:12px;color:#333333;border-width: 1px;border-color: #666666;border-collapse: collapse;"><tr><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;" rowspan="2">Algorithms</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;" colspan="3">Time Complexity</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">Space Complexity</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;" rowspan="2">Stable/Unstable</th></tr><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">Best</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">Average</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">Worst</th><th style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #dedede;">Worst</th><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><a href="../../../../2014/04/26/bubble-sort/">BubbleSort</a></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(n)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O(n^2)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O(n^2)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(1)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Stable</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><a href="../../../../2020/02/08/insertion-sort/">Insertion Sort</a></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(n)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O(n^2)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O(n^2)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(1)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Stable</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><a href="../../../../2020/02/08/selection-sort/">Selection Sort</a></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O(n^2)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O(n^2)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O(n^2)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(1)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Unstable</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><a href="../../../../2020/02/08/shell-sort/">Shell Sort</a></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(n)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O((n<em>log(n))^2)</em></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O((nlog(n))^2)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(1)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Unstable</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><a href="../../../../2014/04/22/quicksort/">Quicksort</a></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffff66;">O(n<em>log(n))</em></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffff66;">O(nlog(n))</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O(n^2)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffff66;">O(log(n))</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Unstable</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><a href="../../../../2020/02/08/mergesort/">Mergesort</a></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffff66;">O(n<em>log(n))</em></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffff66;">O(nlog(n))</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffff66;">O(n<em>log(n))</em></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O(n)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Stable</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><a href="../../../../2020/02/08/heapsort/">Heapsort</a></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffff66;">O(nlog(n))</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffff66;">O(n<em>log(n))</em></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffff66;">O(nlog(n))</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(1)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Unstable</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><a href="../../../../2020/02/08/bucket-sort/">Bucket Sort</a></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(n+k)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(n+k)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O(n^2)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O(n)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Stable</td></tr><tr><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;"><a href="../../../../2020/02/08/radix-sort/">Radix Sort</a></td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(nk)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(nk)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ccffcc;">O(nk)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ff9966;">O(n+k)</td><td style="border-width: 1px;padding: 8px;border-style: solid;border-color: #666666;background-color: #ffffff;">Stable</td></tr></table>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hbase Shell 操作]]></title>
      <url>/2015/11/05/hbase-shell/</url>
      <content type="html"><![CDATA[<h3 id="帮助文档"><a href="#帮助文档" class="headerlink" title="帮助文档:"></a>帮助文档:</h3><pre><code class="shell">Group name: general
Commands: status, version, whoami

Group name: ddl
Commands: alter, alter_async, alter_status, create, describe, disable, disable_all, drop, drop_all, enable, enable_all, exists, is_disabled, is_enabled, list, show_filters

Group name: dml
Commands: count, delete, deleteall, get, get_counter, incr, put, scan, truncate, truncate_preserve

Group name: tools
Commands: assign, balance_switch, balancer, close_region, compact, flush, hlog_roll, major_compact, move, split, unassign, zk_dump

Group name: replication
Commands: add_peer, disable_peer, enable_peer, list_peers, list_replicated_tables, remove_peer, start_replication, stop_replication

Group name: snapshot
Commands: clone_snapshot, delete_snapshot, list_snapshots, restore_snapshot, snapshot

Group name: security
Commands: grant, revoke, user_permission
</code></pre>
<h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><h4 id="put-循环插入记录"><a href="#put-循环插入记录" class="headerlink" title="put : 循环插入记录"></a>put : 循环插入记录</h4><pre><code class="shell">for i in &#39;a&#39;..&#39;z&#39; do for j in &#39;a&#39;..&#39;z&#39; do put &#39;t1&#39;, &quot;row#{i}#{j}&quot;, &quot;F:#{j}&quot;, &quot;#{j}&quot; end end
</code></pre>
<h4 id="alter-修改表结构"><a href="#alter-修改表结构" class="headerlink" title="alter : 修改表结构"></a>alter : 修改表结构</h4><pre><code class="shell">disable &#39;t1&#39;
alter &#39;t1&#39;,{NAME =&gt; &#39;F&#39;}
enable &#39;t1&#39;
</code></pre>
<h4 id="scan-扫描前10条记录"><a href="#scan-扫描前10条记录" class="headerlink" title="scan: 扫描前10条记录"></a>scan: 扫描前10条记录</h4><pre><code class="shell">scan &#39;t1&#39;, {LIMIT =&gt; 10}
</code></pre>
<h4 id="扫描F-a-F-c的记录"><a href="#扫描F-a-F-c的记录" class="headerlink" title="扫描F:a-F:c的记录"></a>扫描F:a-F:c的记录</h4><pre><code class="shell">scan &#39;t1&#39;, {COLUMNS =&gt; [&#39;F:a&#39;,&#39;F:c&#39;]}
</code></pre>
<h4 id="扫描行健范围"><a href="#扫描行健范围" class="headerlink" title="扫描行健范围"></a>扫描行健范围</h4><pre><code class="shell">scan &#39;t1&#39;,{STARTROW =&gt; &#39;row-aa&#39;, STOPROW =&gt; &#39;row-az&#39;}
</code></pre>
<h4 id="删除某列"><a href="#删除某列" class="headerlink" title="删除某列"></a>删除某列</h4><pre><code class="shell">deleteall &#39;t1&#39;,&#39;row1&#39;,&#39;f:A&#39;
</code></pre>
]]></content>
      
        <categories>
            
            <category> Big Data </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hbase </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hbase-0.98.17-hadoop2 安装]]></title>
      <url>/2015/11/01/hbase-0.98.17-hadoop2-installation/</url>
      <content type="html"><![CDATA[<h4 id="1-下载解压"><a href="#1-下载解压" class="headerlink" title="1. 下载解压"></a><strong>1. 下载解压</strong></h4><pre><code>tar -zxf hbase-0.98.17-hadoop2-bin.tar.gz
</code></pre><h4 id="2-修改配置"><a href="#2-修改配置" class="headerlink" title="2. 修改配置"></a><strong>2. 修改配置</strong></h4><p>hbase-env.sh</p>
<pre><code>export JAVA_HOME=/usr/java/jdk1.6.0_45
</code></pre><p>hbase-site.xml</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.rootdir&lt;/name&gt;
        &lt;value&gt;hdfs://node1:8020/hbase&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.master&lt;/name&gt;
        &lt;value&gt;hdfs://node1:60000/hbase&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
        &lt;value&gt;node1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>检查jar包</p>
<p>检查/usr/hbase/hbase-0.98.17-hadoop2/lib下hadoopjar包的版本是否和安装的hadoop一致。如不一致需要将$HADOOP_HOME/share/hadoop下的hadoop*.jar拷贝到$HBASE_HOME/lib下。</p>
<pre><code>find $HADOOP_HOME/share/hadoop -name &quot;hadoop*.jar&quot; | xargs -i cp {} $HABASE_HOME/lib
</code></pre><h4 id="4-格式化namenode并删除原有数据信息（可选）"><a href="#4-格式化namenode并删除原有数据信息（可选）" class="headerlink" title="4. 格式化namenode并删除原有数据信息（可选）"></a><strong>4. 格式化namenode并删除原有数据信息（可选）</strong></h4><blockquote>
<p>如之前装过其他版本hadoop或hbase，建议执行该步操作</p>
</blockquote>
<h4 id="5-启动"><a href="#5-启动" class="headerlink" title="5. 启动"></a><strong>5. 启动</strong></h4><pre><code>./start-hbase.sh
./local-regionservers.sh start 1
./local-master-backup.sh start 1
./hbase shell
</code></pre>]]></content>
      
        <categories>
            
            <category> Big Data </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hbase </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hbase 0.94.26 伪分布模式安装]]></title>
      <url>/2015/10/27/hbase-0.94.26-pseudo-distributed-intallation/</url>
      <content type="html"><![CDATA[<h4 id="1-解压缩"><a href="#1-解压缩" class="headerlink" title="1. 解压缩"></a><strong>1. 解压缩</strong></h4><pre><code>tar -zxvf hbase-0.94.26.tar.gz
</code></pre><h4 id="2-修改配置文件"><a href="#2-修改配置文件" class="headerlink" title="2. 修改配置文件"></a><strong>2. 修改配置文件</strong></h4><p>hbase-env.sh</p>
<pre><code># The java implementation to use.  Java 1.6 required.
export JAVA_HOME=/usr/java/jdk1.6.0_45/
# Extra Java CLASSPATH elements.  Optional.
export HBASE_CLASSPATH=/user/hadoop/hadoop-1.2.1/conf
# Tell HBase whether it should manage it&#39;s own instance of Zookeeper or not.
export HBASE_MANAGES_ZK=true
</code></pre><p>hbase-site.xml</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.rootdir&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000/hbase&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
        &lt;value&gt;localhost&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h4 id="3-运行"><a href="#3-运行" class="headerlink" title="3. 运行"></a><strong>3. 运行</strong></h4><pre><code>/usr/hadoop/hadoop-1.2.1/bin
[rolex@node2 bin]$ ./start-all.sh （先运行hdfs）
/usr/hbase/hbase-0.94.27/bin
[rolex@node2 bin]$ ./start-hbase.sh （启动hbase）
[rolex@node2 bin]$ ./local-master-backup.sh start 1  （启动master备份）
[rolex@node2 bin]$ ./local-regionservers.sh start 1  （启动regionserver）
</code></pre>]]></content>
      
        <categories>
            
            <category> Big Data </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hbase </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop 练习]]></title>
      <url>/2015/10/22/hadoop-practice/</url>
      <content type="html"><![CDATA[<ol>
<li><p>根据lac_id和start_time知道用户当时的位置，根据staytime知道用户各个基站的逗留时长。根据轨迹合并连续基站的staytime。最终得到每一个用户按时间排序在每一个基站驻留时长。</p>
<p>13429100031 22554 8 2013-03-11 08:55:19.151754088 571 571 282 571<br>13429100082 22540 8 2013-03-11 08:58:20.152622488 571 571 270 571<br>13429100082 22691 8 2013-03-11 08:56:37.149593624 571 571 103 571<br>13429100087 22705 8 2013-03-11 08:56:51.139539816 571 571 220 571<br>13429100087 22540 8 2013-03-11 08:55:45.150276800 571 571 66 571<br>13429100082 22540 8 2013-03-11 08:55:38.140225200 571 571 133 571<br>13429100140 26642 9 2013-03-11 09:02:19.151754088 571 571 18 571<br>13429100082 22691 8 2013-03-11 08:57:32.151754088 571 571 287 571<br>13429100189 22558 8 2013-03-11 08:56:24.139539816 571 571 48 571<br>13429100349 22503 8 2013-03-11 08:54:30.152622440 571 571 211 571  </p>
</li>
</ol>
<pre><code>product_no lac_id moment start_time user_id county_id staytime city_id
</code></pre><ol>
<li><p>计算第四列每个元素出现的个数</p>
<p>a,b,c,d<br>b,b,f,e<br>a,a,c,f<br>b,b,f,a<br>b,b,f,e</p>
</li>
<li><p>计算高峰时间段（如上午10点-11点）哪张表被访问的最频繁，以及这段时间访问这张表最多的用户，以及这个用户的总时间开销。</p>
<p> TableName(表名)，Time(时间)，User(用户)，TimeSpan(时间开销)<br> t1 09:59:20 u1 1<br> t2 10:02:20 u4 2<br> t1 10:12:20 u3 3<br> t2 10:22:20 u3 2<br> t2 10:32:20 u2 5<br> t3 10:42:20 u1 2<br> t3 10:52:20 u2 7<br> t4 10:22:20 u1 9<br> t1 10:32:20 u4 2</p>
</li>
<li><p>输出不在Order的customer</p>
</li>
</ol>
<ol>
<li>输入2天股价波动</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Big Data </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop 2.6.2 安装]]></title>
      <url>/2015/10/20/hadoop-2.6.2-installation/</url>
      <content type="html"><![CDATA[<h4 id="1-下载"><a href="#1-下载" class="headerlink" title="1. 下载"></a><strong>1. 下载</strong></h4><p><a href=""></a></p>
<h4 id="2-解压缩"><a href="#2-解压缩" class="headerlink" title="2. 解压缩"></a><strong>2. 解压缩</strong></h4><pre><code>tar -zxf hadoop-2.6.2.tar.gz
</code></pre><h4 id="3-修改配置文件"><a href="#3-修改配置文件" class="headerlink" title="3. 修改配置文件"></a><strong>3. 修改配置文件</strong></h4><p>./etc/hadoop/core-site.xml</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>./etc/hadoop/hdfs-site.xml</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>./etc/hadoop/mapred-site.xml</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>./etc/hadoop/yarn-site.xml</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h4 id="4-设置互信"><a href="#4-设置互信" class="headerlink" title="4. 设置互信"></a><strong>4. 设置互信</strong></h4><pre><code>ssh-keygen -t dsa -P &#39;&#39; -f ~/.ssh/id_dsa  
cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys  
chmod 600 ~/.ssh/authorized_keys
</code></pre><h4 id="5-格式化-namenode"><a href="#5-格式化-namenode" class="headerlink" title="5. 格式化 namenode"></a><strong>5. 格式化 namenode</strong></h4><pre><code>./bin/hdfs namenode -format
</code></pre><h4 id="6-启动-yarn"><a href="#6-启动-yarn" class="headerlink" title="6. 启动 yarn"></a><strong>6. 启动 yarn</strong></h4><pre><code>./sbin/start-yarn.sh
</code></pre><h4 id="7-启动-hdfs"><a href="#7-启动-hdfs" class="headerlink" title="7. 启动 hdfs"></a><strong>7. 启动 hdfs</strong></h4><pre><code>./sbin/start-dfs.sh
</code></pre><h4 id="8-执行-wordcount"><a href="#8-执行-wordcount" class="headerlink" title="8. 执行 wordcount"></a><strong>8. 执行 wordcount</strong></h4><pre><code>./bin/hdfs dfs -mkdir /user  
./bin/hdfs dfs -mkdir /user/rolex  
./bin/hdfs dfs -mkdir /user/rolex/input  
./bin/hdfs dfs -put ./NOTICE.txt /user/rolex/input/  

./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.2.jar wordcount /user/rolex/input/NOTICE.txt /user/rolex/output/

./bin/hdfs dfs -cat /user/rolex/output/part-r-00000
</code></pre>]]></content>
      
        <categories>
            
            <category> Big Data </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop 2.2.0 安装]]></title>
      <url>/2015/10/13/hadoop-2.2.0-installation/</url>
      <content type="html"><![CDATA[<h3 id="1-下载"><a href="#1-下载" class="headerlink" title="1. 下载"></a>1. 下载</h3><p><a href="https://archive.apache.org/dist/hadoop/common/hadoop-2.2.0/hadoop-2.2.0.tar.gz" title="hadoop-2.2.0" target="_blank" rel="external">https://archive.apache.org/dist/hadoop/common/hadoop-2.2.0/hadoop-2.2.0.tar.gz</a></p>
<h3 id="2-解压"><a href="#2-解压" class="headerlink" title="2. 解压"></a>2. 解压</h3><pre><code>tar -zxf hadoop-2.2.0.tar.gz
</code></pre><h3 id="3-配置环境变量"><a href="#3-配置环境变量" class="headerlink" title="3. 配置环境变量"></a>3. 配置环境变量</h3><pre><code>HADOOP_HOME=/usr/hadoop/hadoop-2.2.0  
配置文件路径 $HADOOP_HOME/etc/hadoop
</code></pre><h3 id="4-修改配置文件"><a href="#4-修改配置文件" class="headerlink" title="4. 修改配置文件"></a>4. 修改配置文件</h3><h4 id="4-1-修改core-site-xml"><a href="#4-1-修改core-site-xml" class="headerlink" title="4.1 修改core-site.xml"></a>4.1 修改core-site.xml</h4><p>./etc/hadoop/core-site.xml</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://node1:8020&lt;/value&gt;`  
      &lt;/property&gt;
      &lt;property&gt;
          &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
          &lt;value&gt;/home/tmp/hadoop2.0&lt;/value&gt;
      &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;io.file.buffer.size&lt;/name&gt;
        &lt;value&gt;131072&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h4 id="4-2-修改-hdfs-site-xml"><a href="#4-2-修改-hdfs-site-xml" class="headerlink" title="4.2 修改 hdfs-site.xml"></a>4.2 修改 hdfs-site.xml</h4><p>./etc/hadoop/hdfs-site.xml</p>
<pre><code>&lt;configuration&gt;
      &lt;property&gt;
          &lt;name&gt;dfs.replication&lt;/name&gt;
              &lt;value&gt;1&lt;/value&gt;
      &lt;/property&gt;
      &lt;property&gt;
          &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
          &lt;value&gt;/usr/hadoop/hadoop-2.2.0/name&lt;/value&gt;
      &lt;/property&gt;
      &lt;property&gt;
          &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
          &lt;value&gt;/usr/hadoop/hadoop-2.2.0/data&lt;/value&gt;
      &lt;/property&gt;
      &lt;property&gt;
          &lt;name&gt;dfs.permissions&lt;/name&gt;
          &lt;value&gt;false&lt;/value&gt;
      &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h4 id="4-3-修改-mapred-site-xml"><a href="#4-3-修改-mapred-site-xml" class="headerlink" title="4.3 修改 mapred-site.xml"></a>4.3 修改 mapred-site.xml</h4><p>./etc/hadoop/mapred-site.xml</p>
<pre><code>&lt;configuration&gt;
      &lt;property&gt;
          &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
          &lt;value&gt;yarn&lt;/value&gt;
      &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h4 id="4-4-修改-yarn-site-xml"><a href="#4-4-修改-yarn-site-xml" class="headerlink" title="4.4 修改 yarn-site.xml"></a>4.4 修改 yarn-site.xml</h4><p>./etc/hadoop/yarn-site.xml</p>
<pre><code>&lt;configuration&gt;
      &lt;property&gt;
          &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
        &lt;value&gt;node1:8032&lt;/value&gt;
      &lt;/property&gt;
      &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
        &lt;value&gt;node1:8030&lt;/value&gt;
      &lt;/property&gt;
      &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
        &lt;value&gt;node1:8031&lt;/value&gt;
      &lt;/property&gt;
      &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
        &lt;value&gt;node1:8033&lt;/value&gt;
      &lt;/property&gt;
      &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
        &lt;value&gt;node1:8088&lt;/value&gt;
      &lt;/property&gt;
      &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler&lt;/value&gt;
      &lt;/property&gt;
      &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
      &lt;/property&gt;
      &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
      &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h3 id="5-设置互信"><a href="#5-设置互信" class="headerlink" title="5. 设置互信"></a>5. 设置互信</h3><h4 id="5-1-生成-ssh-key"><a href="#5-1-生成-ssh-key" class="headerlink" title="5.1 生成 ssh key"></a>5.1 生成 ssh key</h4><pre><code>ssh-keygen -t dsa -P &#39;&#39; -f ~/.ssh/id_dsa  
cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys  
chmod 0600 ~/.ssh/authorized_keys
</code></pre><h4 id="5-2-测试-ssh"><a href="#5-2-测试-ssh" class="headerlink" title="5.2 测试 ssh"></a>5.2 测试 ssh</h4><blockquote>
<p>ssh localhost</p>
<h3 id="6-格式化-namenode"><a href="#6-格式化-namenode" class="headerlink" title="6. 格式化 namenode"></a>6. 格式化 namenode</h3><pre><code>./bin/hdfs namenode -format
</code></pre><h3 id="7-启动-namenode-和-datanode"><a href="#7-启动-namenode-和-datanode" class="headerlink" title="7. 启动 namenode 和 datanode"></a>7. 启动 namenode 和 datanode</h3><pre><code>./sbin/hadoop-daemon.sh start namenode  
./sbin/hadoop-daemon.sh start datanode  
./sbin/yarn-daemon.sh start resourcemanager  
./sbin/yarn-daemon.sh start nodemanager  
./sbin/yarn-daemon.sh start proxyserver  
./sbin/mr-jobhistory-daemon.sh start historyserver
</code></pre><h3 id="8-验证"><a href="#8-验证" class="headerlink" title="8. 验证"></a>8. 验证</h3><pre><code>./bin/hdfs dfs -mkdir /user/rolex/input/  
./bin/hdfs dfs -put ../README.txt /user/rolex/input/  
./bin/hadoop jar ../share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar grep /user/rolex/input/README.txt /user/rolex/output/ &#39;code&#39;  
./bin/hdfs dfs -cat /user/rolex/output/part-r-00000
</code></pre><h3 id="9-关闭"><a href="#9-关闭" class="headerlink" title="9. 关闭"></a>9. 关闭</h3><pre><code>./sbin/hadoop-daemon.sh stop namenode  
./sbin/hadoop-daemon.sh stop datanode  
./sbin/yarn-daemon.sh stop resourcemanager  
./sbin/yarn-daemon.sh stop nodemanager  
./sbin/yarn-daemon.sh stop proxyserver  
./sbin/mr-jobhistory-daemon.sh stop historyserver
</code></pre></blockquote>
]]></content>
      
        <categories>
            
            <category> Big Data </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Hadoop </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[查找文件中 abc 出现的次数]]></title>
      <url>/2015/09/16/word-count-in-file/</url>
      <content type="html"><![CDATA[<p>linux查找字符串的几种方法。</p>
<h3 id="1"><a href="#1" class="headerlink" title="1."></a>1.</h3><pre><code>grep -o abc file | wc -l
</code></pre><h3 id="2"><a href="#2" class="headerlink" title="2."></a>2.</h3><pre><code>awk -v RS=&#39;abc&#39; &#39;END {print --NR}&#39; file
</code></pre><h3 id="3"><a href="#3" class="headerlink" title="3."></a>3.</h3><pre><code>awk -v RS=&quot;@#$j&quot; &#39;{print gsub(/abc/,&quot;&amp;&quot;)}&#39; NOTICE
</code></pre><h3 id="4"><a href="#4" class="headerlink" title="4."></a>4.</h3><pre><code>grep -c &quot;abc&quot; NOTICE
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HTTP 上传文件原理]]></title>
      <url>/2015/08/30/principle-of-upload-files/</url>
      <content type="html"><![CDATA[<ol>
<li>通过 request.getInputStream() 来得到上传的整个 post 实体的流</li>
<li>用 request.getHeader(“Content-Type”) 来取得实体内容的分界字符串</li>
<li>然后根据 http 协议，分析取得的上传的实体流</li>
<li>把文件部分给筛出来在服务器端保存到磁盘文件中</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[拷贝 vmware 文件方式创建虚拟机]]></title>
      <url>/2015/08/29/creating-vm-with-copying-files/</url>
      <content type="html"><![CDATA[<h3 id="vmware打开文件"><a href="#vmware打开文件" class="headerlink" title="vmware打开文件"></a>vmware打开文件</h3><h3 id="查看ifconfig-a发现没有eth0网卡"><a href="#查看ifconfig-a发现没有eth0网卡" class="headerlink" title="查看ifconfig -a发现没有eth0网卡"></a>查看ifconfig -a发现没有eth0网卡</h3><h4 id="打开-etc-udev-rules-d-70-persistent-net-rules文件，将eth1改成eth0。"><a href="#打开-etc-udev-rules-d-70-persistent-net-rules文件，将eth1改成eth0。" class="headerlink" title="打开 /etc/udev/rules.d/70-persistent-net.rules文件，将eth1改成eth0。"></a>打开 /etc/udev/rules.d/70-persistent-net.rules文件，将eth1改成eth0。</h4><h4 id="将-etc-sysconfig-network-scripts-ifcfg-eth0中的HWADDR改成当前虚拟机的mac地址。"><a href="#将-etc-sysconfig-network-scripts-ifcfg-eth0中的HWADDR改成当前虚拟机的mac地址。" class="headerlink" title="将/etc/sysconfig/network-scripts/ifcfg-eth0中的HWADDR改成当前虚拟机的mac地址。"></a>将/etc/sysconfig/network-scripts/ifcfg-eth0中的HWADDR改成当前虚拟机的mac地址。</h4><h3 id="reboot"><a href="#reboot" class="headerlink" title="reboot"></a>reboot</h3>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> VMware </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[添加 sudo 权限]]></title>
      <url>/2015/08/09/grant-sudo-privileges-to-an-existing-user/</url>
      <content type="html"><![CDATA[<p>错误消息：xxx is not in the sudoers file</p>
<pre><code>su root
visudo
</code></pre><p>root ALL=(ALL) ALL下添加一行</p>
<pre><code>xxx  ALL=(ALL) ALL
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[字符界面安装 VMware Tools]]></title>
      <url>/2015/08/04/installing-vmware-tools-in-cmd/</url>
      <content type="html"><![CDATA[<h3 id="1-挂载cdrom"><a href="#1-挂载cdrom" class="headerlink" title="1. 挂载cdrom"></a>1. 挂载cdrom</h3><pre><code>cd /mnt
mkdir cdrom
mount /dev/cdrom /mnt/cdrom
</code></pre><h3 id="2-拷贝vmwaretools"><a href="#2-拷贝vmwaretools" class="headerlink" title="2. 拷贝vmwaretools"></a>2. 拷贝vmwaretools</h3><pre><code>cp /mnt/cdrom/VMwareTools-9.6.1-1378637.tar.gz /tmp
tar -zxvf /tmp/VMwareTools-9.6.1-1378637.tar.gz
cd /tmp/vmware-tools-distrib/
./vmware-install.pl
</code></pre><h3 id="3-默认一路回车-yes"><a href="#3-默认一路回车-yes" class="headerlink" title="3. 默认一路回车+yes"></a>3. 默认一路回车+yes</h3><p>少perl包</p>
<pre><code>yum install perl gcc kernel-devel
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> VMware </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux 安装图形界面]]></title>
      <url>/2015/08/01/installing-gui-on-centos/</url>
      <content type="html"><![CDATA[<pre><code class="shell">yum -y groupinstall Desktop
yum -y groupinstall &quot;X Window System&quot;
yum install libXfont-1.4.5-*
yum install libX11
startx
</code></pre>
<p>切换界面失败</p>
<pre><code class="shell">chkconfig --level 35 haldaemon on
chkconfig --level 35 messagebus on
</code></pre>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CentOS 6.5 minimal安装]]></title>
      <url>/2015/07/26/centos-6.5-minimal-installation/</url>
      <content type="html"><![CDATA[<h3 id="1-安装eth0"><a href="#1-安装eth0" class="headerlink" title="1. 安装eth0"></a>1. 安装eth0</h3><p><strong>/etc/sysconfig/network-scripts/ifcfg-eth0</strong></p>
<pre><code>ONBOOT=yes
BOOTPROTO=static
IPADDR=192.168.1.64
GATEWAY=192.168.1.1
</code></pre><h3 id="2-创建用户和组"><a href="#2-创建用户和组" class="headerlink" title="2. 创建用户和组"></a>2. 创建用户和组</h3><pre><code class="shell">groupadd rolex  
useradd -g rolex rolex  
passwd rolex
</code></pre>
<h3 id="3-添加sudo权限"><a href="#3-添加sudo权限" class="headerlink" title="3. 添加sudo权限"></a>3. 添加sudo权限</h3><pre><code class="shell">visudo

rolex    ALL=(ALL)    ALL
rolex    ALL=NOPASSWD:    ALL
</code></pre>
<h3 id="4-安装ftp"><a href="#4-安装ftp" class="headerlink" title="4. 安装ftp"></a>4. 安装ftp</h3><p>参考 <a href="../../../../2016/07/16/CentOS 6.5 minimal 安装ftp/">CentOS 6.5 minimal 安装ftp</a> 。</p>
<h3 id="5-安装JDK"><a href="#5-安装JDK" class="headerlink" title="5. 安装JDK"></a>5. 安装JDK</h3><p>参考 <a href="../../../../2016/07/16/CentOS 6.5 安装JDK/">CentOS 6.5 安装JDK</a> 。</p>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CentOS 6.5 minimal安装ftp]]></title>
      <url>/2015/07/20/centos-6.5-minimal-install-ftp/</url>
      <content type="html"><![CDATA[<h3 id="1-配置DNS"><a href="#1-配置DNS" class="headerlink" title="1. 配置DNS"></a>1. 配置DNS</h3><p><strong>/etc/resolv.conf</strong></p>
<pre><code class="shell">nameserver 8.8.8.8
nameserver 4.4.4.4
</code></pre>
<p>###2. 安装ftp</p>
<pre><code class="shell">yum install vsftpd
</code></pre>
<p>###3. 放开home路径权限</p>
<pre><code class="shell">setsebool -P  ftp_home_dir  on
</code></pre>
<p>###4. 虚拟机ftp配置</p>
<p>系统装完，可以ping通，但是ftp不通，错误消息如下：</p>
<p>状态:      尝试连接“ECONNREFUSED - Connection refused by server”失败</p>
<p>google说可能是端口没开或占用</p>
<p>所以检查一下</p>
<pre><code class="shell">netstat -na --ip
</code></pre>
<p>21端口果然没有，打开ftp</p>
<pre><code class="shell">service vsftpd start
</code></pre>
<p>再连ftp，错误消息如下：</p>
<p>命令:      USER root<br>响应:      530 Permission denied.</p>
<p>用的root用户，vsftp默认关闭root用户，所以打开root用户<br>修改文件 <strong>/etc/vsftpd.ftpusers</strong> 和 <strong>/etc/vsftpd.user_list</strong></p>
<p>响应: 553 Could not create file.<br>错误: 严重文件传输错误</p>
<p>执行命令</p>
<pre><code class="shell">setsebool allow_ftpd_full_access 1
setsebool allow_ftpd_use_cifs 1
setsebool allow_ftpd_use_nfs 1
setsebool ftp_home_dir 1
setsebool httpd_enable_ftp_server 1
setsebool tftp_anon_write 1
service vsftpd restart
</code></pre>
<p>###5. vsftp上传文件限制</p>
<p>553 Could not create file.</p>
<pre><code class="shell">/usr/sbin/setsebool -P ftp_home_dir 1
/usr/sbin/setsebool allow_ftpd_full_access 1
/usr/sbin/setsebool allow_ftpd_use_cifs 1
/usr/sbin/setsebool allow_ftpd_use_nfs 1
/usr/sbin/setsebool -P ftp_home_dir 1
/usr/sbin/setsebool httpd_enable_ftp_server 1
/usr/sbin/setsebool tftp_anon_write 1
/usr/sbin/service vsftpd restart
</code></pre>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CentOS 6.5 安装JDK]]></title>
      <url>/2015/07/16/centos-6.5-install-jdk/</url>
      <content type="html"><![CDATA[<h3 id="1-下载"><a href="#1-下载" class="headerlink" title="1. 下载"></a>1. 下载</h3><h4 id="1-1-安装wget"><a href="#1-1-安装wget" class="headerlink" title="1.1 安装wget"></a>1.1 安装wget</h4><pre><code class="shell">yum install -y wget
</code></pre>
<h4 id="1-2-下载JDK"><a href="#1-2-下载JDK" class="headerlink" title="1.2 下载JDK"></a>1.2 下载JDK</h4><pre><code class="shell">wget &quot;http://download.oracle.com/otn-pub/java/jdk/8u20-b26/jdk-8u20-linux-x64.tar.gz&quot;
</code></pre>
<h3 id="2-解压"><a href="#2-解压" class="headerlink" title="2. 解压"></a>2. 解压</h3><pre><code class="shell">tar -zxf jdk-8u20-linux-x64.tar.gz
</code></pre>
<h3 id="3-配置环境变量"><a href="#3-配置环境变量" class="headerlink" title="3. 配置环境变量"></a>3. 配置环境变量</h3><pre><code class="shell">echo &quot;JAVA_HOME=/usr/java/jdk1.8.0_20&quot; &gt; /etc/profile.d/java.sh  
echo &#39;\$JAVA_HOME/bin:$PATH&#39; &gt;&gt; /etc/profile.d/java.sh  
echo &#39;export JAVA_HOME PATH&#39; &gt;&gt; /etc/profile.d/java.sh
</code></pre>
]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> CentOS </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Zookeeper-3.4.6 安装]]></title>
      <url>/2015/07/14/zookeeper-3.4.6-installation/</url>
      <content type="html"><![CDATA[<p>zookeeper 集群安装可以参考<a href="http://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html#sc_systemReq" target="_blank" rel="external">http://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html#sc_systemReq</a>。</p>
<h3 id="1-环境变量"><a href="#1-环境变量" class="headerlink" title="1. 环境变量"></a>1. 环境变量</h3><p>zookeeper 是 Java 语言编写的，所以首先需要安装 Java 运行环境。</p>
<pre><code>sudo echo &quot;ZOOKEEPER_HOME=/usr/zookeeper/zookeeper-3.4.6&quot;&gt;/etc/profile.d/zookeeper.sh
sudo echo &#39;PATH=\$PATH :$ZOOKEEPER_HOME/bin&#39;&gt;&gt;/etc/profile.d/zookeeper.sh
. /etc/profile
</code></pre><h3 id="2-配置文件"><a href="#2-配置文件" class="headerlink" title="2. 配置文件"></a>2. 配置文件</h3><p>下载 zookeeper 。</p>
<pre><code>wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz
</code></pre><p>解压</p>
<pre><code>tar -zxf zookeeper-3.4.6.tar.gz
</code></pre><p>修改配置文件。</p>
<pre><code>cp /usr/zookeeper/zookeeper-3.4.6/conf/zoo_sample.cfd /usr/zookeeper/zookeeper-3.4.6/conf/zoo.cfd
</code></pre><p>添加集群配置信息。</p>
<pre><code># The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just
# example sakes.
dataDir=/tmp/zookeeper
# the port at which the clients will connect
clientPort=2181
# the maximum number of client connections.
# increase this if you need to handle more clients
#maxClientCnxns=60
#
# Be sure to read the maintenance section of the
# administrator guide before turning on autopurge.
#
# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
#
# The number of snapshots to retain in dataDir
#autopurge.snapRetainCount=3
# Purge task interval in hours
# Set to &quot;0&quot; to disable auto purge feature
#autopurge.purgeInterval=1
server.1=192.168.0.201:2888:3888
server.2=192.168.0.202:2888:3888
server.3=192.168.0.203:2888:3888
</code></pre><blockquote>
<p>集群配置的格式为 <code>server.id=host:port:port</code> ，host 是节点的主机地址，第一个 port 是 follow 服务器和 leader 服务器的通信端口，第二个 port 是 leader 选举使用的通信端口。</p>
</blockquote>
<p>添加机器id</p>
<p>在 dataDir 下创建 myid 文件，文件中只有一行，记录机器的编号。编号必须是 1 - 255 之间的整数，必须唯一。</p>
<p>其他机器节点做相同操作，并拷贝配置文件到其他节点。</p>
<h3 id="3-启动"><a href="#3-启动" class="headerlink" title="3. 启动"></a>3. 启动</h3><pre><code>cd zookeeper-3.4.6/bin
./zkServer.sh start
</code></pre><blockquote>
<p>停止 zookeeper 命令是 <code>zkServer.sh stop</code></p>
</blockquote>
<p>测试一下</p>
<pre><code>[root@node1 conf]# telnet 192.168.0.201 2181
Trying 192.168.0.201...
Connected to 192.168.0.201.
Escape character is &#39;^]&#39;.
stat
Zookeeper version: 3.4.6-1569965, built on 02/20/2014 09:09 GMT
Clients:
 /192.168.0.201:46827[0](queued=0,recved=1,sent=0)

Latency min/avg/max: 0/0/0
Received: 1
Sent: 0
Connections: 1
Outstanding: 0
Zxid: 0x0
Mode: follower
Node count: 4
Connection closed by foreign host.
</code></pre><p>看到类似信息则集群启动。</p>
<blockquote>
<p>集群配置了 3 个节点，启动 1 台时集群不可用，启动 2 台时就可以看到类似上边的信息。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Big Data </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[交换两个数]]></title>
      <url>/2015/04/16/algorithm-change-numbers-position/</url>
      <content type="html"><![CDATA[<p>有两个数 a 和 b ,不使用新的变量，交换 a 和 b 的值。<br><a id="more"></a></p>
<pre><code class="java">    a=5,b=10
    a=a+b    a=15 b=10
    a=b-a    a=-5 b=10
    b=a+b    b=5 a=-5
    a=b-a    a=10 b=5
</code></pre>
<pre><code class="java">    a=1,b=10
    a=a+b    a=11 b=10
    a=b-a    a=-9 b=10
    b=a+b    b=1 a=-9
    a=b-a    a=10 b=1
</code></pre>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[字符串处理1]]></title>
      <url>/2015/04/09/algorithm-string-1/</url>
      <content type="html"><![CDATA[<p>一个5位数，判断它是不是回文数。即12321是回文数，个位与万位相同，十位与千位相同。</p>
<pre><code>public class Prog0409 {

    public static void main(String[] args) {
          Prog0409 prog = new Prog0409();
          System.out.println(prog.print(12331));
    }

     public boolean print(int n){
          String s = String.valueOf(n);
          if(s.length() != 5){
               return false;
          }else{
               if((s.charAt(0)==s.charAt(4)) &amp;&amp; (s.charAt(1) == s.charAt(3))){
                    return true;
               }else{
                    return false;
               }
          }
     }

}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[阶乘]]></title>
      <url>/2015/04/08/algorithm-factorial/</url>
      <content type="html"><![CDATA[<p>求1+2!+3!+…+20!的和</p>
<pre><code class="java">public class Prog0408 {

    public static void main(String[] args) {
          Prog0408 prog = new Prog0408();
          System.out.println(prog.print(20));
    }

     public int print(int n){
          int r=0;
          for(int i=1;i&lt;=n;i++){
               r += factorial(i);
          }
          return r;
     }

     public int factorial(int n){
          int r = 1;
          for(int i=1;i&lt;=n;i++){
               r = r * i;
          }
          return r;
     }


}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[猴子吃桃问题]]></title>
      <url>/2015/04/05/algorithm-peach-monkeys-problems/</url>
      <content type="html"><![CDATA[<p>猴子吃桃问题：猴子第一天摘下若干个桃子，当即吃了一半，还不瘾，又多吃了一个。第二天早上又将剩下的桃子吃掉一半，又多吃了一个。以后每天早上都吃了前一天剩下的一半零一个。到第10天早上想再吃时，见只剩下一个桃子了。求第一天共摘了多少</p>
<pre><code>public class Prog0405 {

    public static void main(String[] args) {
        Prog0405 prog = new Prog0405();
        System.out.println(prog.count(0));
    }

    public int count(int day){
        if(day == 9){
            return 1;
        }else{
            return (count(day+1) + 1) * 2;
        }
    }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[完全平方数]]></title>
      <url>/2015/04/02/algorithm-perfect-square/</url>
      <content type="html"><![CDATA[<pre><code>import java.util.ArrayList;
import java.util.List;
import java.util.regex.Pattern;

public class Algo0402 {

    public static void main(String[] args) {
        Algo0402 algo = new Algo0402();
        List list = algo.fullSquare(1000);
        System.out.println(list);

        System.out.println(algo.isInteger(&quot;-2&quot;));

        for(int i=0;i&lt;=1000;i++){
            if(list.contains(i+100)&amp;&amp;list.contains(i+168)){
                System.out.print(i + &quot;,&quot;);
            }
        }
    }

    public List&lt;Integer&gt; fullSquare(int n){
        List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();
        for(int i=0;i&lt;=Math.sqrt(n);i++) {
            list.add(i*i);
        }
        return list;
    }

    public boolean isInteger(String s){
        Pattern p = Pattern.compile(&quot;^[+]?[\\d]*$&quot;);
        return p.matcher(s).matches();
    }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[字符串2]]></title>
      <url>/2015/03/30/algorithm-string-2/</url>
      <content type="html"><![CDATA[<p>输入一行字符，分别统计出其中英文字母、空格、数字和其它字符的个数</p>
<pre><code>import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;

public class Prog0330 {
    public static void main(String[] args) throws IOException {
        Prog0330 t = new Prog0330();
        BufferedReader br = new BufferedReader(new InputStreamReader(System.in));
        String s = br.readLine();
        t.wordCount(s);
    }

    public void wordCount(String s){
        int wordCount=s.length();
        int digitCount = 0;
        int letterCount = 0;
        int spaceCount = 0;
        int otherCount = 0;
        for(int i=0;i&lt;wordCount;i++){
            char c = s.charAt(i);
            if(Character.isDigit(c)){
                digitCount += 1;
            }else if(Character.isLetter(c)){
                letterCount += 1;
            }else if(Character.isSpaceChar(c)){
                spaceCount += 1;
            }else{
                otherCount += 1;
            }
        }

        System.out.println(&quot;wordCount=&quot;+wordCount);
        System.out.println(&quot;digitCount=&quot;+digitCount);
        System.out.println(&quot;letterCount=&quot;+letterCount);
        System.out.println(&quot;spaceCount=&quot;+spaceCount);
        System.out.println(&quot;otherCount=&quot;+otherCount);
    }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[完数]]></title>
      <url>/2015/03/28/algorithm-perfect-number/</url>
      <content type="html"><![CDATA[<p>完数，所有的真因子（即除了自身以外的约数）的和（即因子函数），恰好等于它本身</p>
<pre><code>import java.util.ArrayList;
import java.util.List;

public class Algo0328 {

    public static void main(String[] args) {
        Algo0328 p = new Algo0328();
        System.out.println(p.perfectNumber(1000));
    }

    public List&lt;Integer&gt; perfectNumber(int n){
        List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();
        for(int i=1;i&lt;n;i++){
            if(i == sum(i)){
                list.add(i);
            }
        }
        return list;
    }

    public int sum(int n){
        int sum = 0;
        for(int i=1;i&lt;n;i++){
            if(n % i == 0){
                sum += i;
            }
        }
        return sum;
    }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[最大公约数]]></title>
      <url>/2015/03/27/algorithm-greatest-common-divisor/</url>
      <content type="html"><![CDATA[<pre><code>public class Algo0327 {

    public static void main(String[] args) {
        Algo0327 g = new Algo0327();
        System.out.println(g.gcd(319, 377));
        System.out.println(g.lcm(18, 20));
    }

    public int gcd(int m, int n) {
        int big;
        int small;
        int result;
        if (m &gt; n) {
            big = m;
            small = n;
        } else {
            big = n;
            small = m;
        }
        if (big % small != 0) {
            result = gcd(small, big % small);
        } else {
            result = small;
        }
        return result;

    }

    public int lcm(int m, int n) {
        int g = gcd(m, n);
        return m * n / g;
    }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[分解质因数]]></title>
      <url>/2015/03/26/algorithm-prime-number/</url>
      <content type="html"><![CDATA[<p>每个合数都可以写成几个质数相乘的形式。其中每个质数都是这个合数的因数，叫做这个合数的分解质因数。如 90 = 2 <em> 3 </em> 5</p>
<p>1.给点数n，求1到n的所有素数。<br>2.如果n不是素数，用第一个质数2开始除，能整除则商继续用从2开始除。<br>3.如果不能整除，换下一个质数，直到商等于质数。</p>
<pre><code>import java.util.ArrayList;
import java.util.List;

public class Algo0326 {

    private boolean flag = false;

    public static void main(String[] args) {
        Algo0326 qf = new Algo0326();
        qf.print(5);

    }

    private void print(int n) {
        List list = prime(n);
        if (list != null &amp;&amp; list.size() &gt; 0) {
            System.out.print(n + &quot; = &quot;);
            decom(n, list);
        }
    }

    private void decom(int n, List list) {
        if (!list.contains(n)) {
            for (int i = 0; i &lt; list.size(); i++) {
                if (!flag) {
                    int p = (Integer) list.get(i);
                    if (n % p == 0) {
                        System.out.print(p + &quot; * &quot;);
                        decom(n / p, list);
                    }
                } else {
                    break;
                }
            }
        } else {
            System.out.print(n);
            flag = true;
        }
    }

    public List prime(int n) {
        List list = new ArrayList();
        for (int i = 2; i &lt;= n; i++) {
            int j;
            for (j = 2; j &lt;= Math.sqrt(i); j++) {
                if (i % j == 0) {
                    break;
                }
            }
            if (j &gt; Math.sqrt(i)) {
                list.add(i);
            }
        }
        return list;
    }

}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[水仙花数]]></title>
      <url>/2015/03/25/algorithm-narcissistic-number/</url>
      <content type="html"><![CDATA[<p>水仙花数是指一个 n 位数 ( n≥3 )，它的每个位上的数字的 n 次幂之和等于它本身。（例如：1^3 + 5^3+ 3^3 = 153）</p>
<pre><code>public class Algo0325 {

    public static void main(String[] args) {
        for (int i = 100; i &lt; 1000; i++) {
            int h = i / 100;
            int t = (i - h * 100) / 10;
            int o = (i - h * 100 - t * 10);
            if ((Math.pow(h, 3) + Math.pow(t, 3) + Math.pow(o, 3)) == i) {
                System.out.print(i + &quot;, &quot;);
            }
        }
    }

}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[素数]]></title>
      <url>/2015/03/24/algorithm-prime/</url>
      <content type="html"><![CDATA[<p>素数：除了1和它本身以外不再有其他的因数。</p>
<pre><code>public class Algo0324 {

    public static void main(String[] args) {
        Algo0324 p = new Algo0324();
        long l1 = System.currentTimeMillis();
        p.print(10, 200);
        long l2 = System.currentTimeMillis();

        System.out.println(&quot;&quot;);
        long l3 = System.currentTimeMillis();
        p.print1(10, 200);
        long l4 = System.currentTimeMillis();
        System.out.println(&quot;&quot;);
        System.out.println(&quot;print用时&quot; + (l2 - l1) + &quot;s&quot;);
        System.out.println(&quot;print1用时&quot; + (l4 - l3) + &quot;s&quot;);
    }

    public void print(int start, int end) {
        int[] arr = new int[end - start + 1];
        int count = 0;
        for (int i = start; i &lt;= end; i++) {
            arr[count] = i;
            count++;
        }
        for (int i = arr[0]; i &lt;= arr[arr.length - 1]; i++) {
            int j;
            for (j = 2; j &lt;= Math.sqrt(i); j++) {
                if (i % j == 0) {
                    break;
                }
            }
            if (j &gt; Math.sqrt(i)) {
                System.out.print(i + &quot;,&quot;);
            }
        }
    }

    public void print1(int start, int end) {
        int[] arr = new int[(end - start + 1) / 2];
        int begin = 0;
        if (start % 2 == 0) {
            begin = start + 1;
        } else {
            begin = start;
        }
        for (int i = 0; i &lt; arr.length; i++) {
            arr[i] = begin + i * 2;
        }


        for (int i = 0; i &lt;= arr.length - 1; i++) {
            int j;
            if (arr[i] &gt; 0) {
                for (j = 2; j &lt;= Math.sqrt(arr[i]); j++) {
                    if (arr[i] % j == 0) {
                        setValue(arr, i);
                        break;
                    }
                }
                if (j &gt; Math.sqrt(arr[i])) {
                    if (arr[i] &gt; 0) {
                        System.out.print(arr[i] + &quot;,&quot;);
                    }
                }
            }
        }
    }

    private void setValue(int[] arr, int currentIndex) {
        int currentValue = arr[currentIndex];
        int count = 2;
        while ((currentIndex + count * currentValue) &lt; arr.length) {
            arr[currentIndex + count * currentValue] = 0;
            count = count + 2;
        }
        arr[currentIndex] = 0;
    }

}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[斐波那契数列]]></title>
      <url>/2015/03/23/algorithm-fibonacci/</url>
      <content type="html"><![CDATA[<p>有一对兔子，从出生后第3个月起每个月都生一对兔子，小兔子长到第三个月后每个月又生一对兔子，假如兔子都不死，问每个月的兔子总数为多少？</p>
<table>
<thead>
<tr>
<th style="text-align:center">月份</th>
<th style="text-align:center">1</th>
<th style="text-align:center">2</th>
<th style="text-align:center">3</th>
<th style="text-align:center">4</th>
<th style="text-align:center">5</th>
<th style="text-align:center">6</th>
<th style="text-align:center">7</th>
<th style="text-align:center">8</th>
<th style="text-align:center">9</th>
<th style="text-align:center">10</th>
<th style="text-align:center">11</th>
<th style="text-align:center">12</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">小兔子对数</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">3</td>
<td style="text-align:center">5</td>
<td style="text-align:center">8</td>
<td style="text-align:center">13</td>
<td style="text-align:center">21</td>
<td style="text-align:center">34</td>
<td style="text-align:center">55</td>
</tr>
<tr>
<td style="text-align:center">中兔子对数</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">3</td>
<td style="text-align:center">5</td>
<td style="text-align:center">8</td>
<td style="text-align:center">13</td>
<td style="text-align:center">21</td>
<td style="text-align:center">34</td>
</tr>
<tr>
<td style="text-align:center">大兔子对数</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">3</td>
<td style="text-align:center">5</td>
<td style="text-align:center">8</td>
<td style="text-align:center">13</td>
<td style="text-align:center">21</td>
<td style="text-align:center">34</td>
<td style="text-align:center">55</td>
</tr>
<tr>
<td style="text-align:center">总对数</td>
<td style="text-align:center">1</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
<td style="text-align:center">3</td>
<td style="text-align:center">5</td>
<td style="text-align:center">8</td>
<td style="text-align:center">13</td>
<td style="text-align:center">21</td>
<td style="text-align:center">34</td>
<td style="text-align:center">55</td>
<td style="text-align:center">89</td>
<td style="text-align:center">144</td>
</tr>
</tbody>
</table>
<pre><code>public class Algo0323 {

    public static void main(String[] args) {
        Algo0323 f = new Algo0323();
        for (int i = 0; i &lt; 20; i++) {
            System.out.print(f.fibonacci(i) + &quot;,&quot;);
        }
    }

    public int fibonacci(int month) {
        if (month == 0) {
            return 0;
        } else if (month == 1 || month == 2) {
            return 1;
        } else {
            return fibonacci(month - 1) + fibonacci(month - 2);
        }
    }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[多线程]]></title>
      <url>/2015/03/13/multi-thread-1/</url>
      <content type="html"><![CDATA[<p>编写一个程序，开启3个线程，这3个线程的ID分别为A、B、C，每个线程将自己的ID在屏幕上打印10遍，要求输出结果必须按ABC的顺序显示；如：ABCABC….依次递推。</p>
<pre><code class="java">public class JoinTest {

    class A extends Thread {
        public void run() {
            System.out.print(&quot;A&quot;);
        }
    }

    class B extends Thread {
        public void run() {
            System.out.print(&quot;B&quot;);
        }
    }

    class C extends Thread {
        public void run() {
            System.out.print(&quot;C&quot;);
        }
    }

    public void run(Thread thread) throws InterruptedException {
        Thread t = new Thread(thread);
        t.start();
        t.join();
    }

    public Thread get(int i) {
        Thread t = null;
        switch (i % 3) {
            case 0:
                t = new A();
                break;
            case 1:
                t = new B();
                break;
            case 2:
                t = new C();
                break;
        }
        return t;

    }

    public void print() throws InterruptedException {
        for (int i = 0; i &lt; 30; i++) {
            run(get(i));
        }
    }

    public static void main(String[] args) throws InterruptedException {
        new JoinTest().print();
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Concurrent </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[生产者消费者（BlockingQueue）]]></title>
      <url>/2015/02/16/producer-and-consumer-question-with-blocking-queue/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<pre><code class="java">public class ProducerAndConsumerInBlockingQueue {

    public static void main(String[] args) {
        BlockingQueue&lt;Integer&gt; queue = new ArrayBlockingQueue&lt;Integer&gt;(10);

         new Thread(new ProducerAndConsumerInBlockingQueue().new Producer(queue)).start();
         new Thread(new ProducerAndConsumerInBlockingQueue().new Consumer(queue)).start();

    }

    class Producer implements Runnable {

        BlockingQueue&lt;Integer&gt; queue;

         public Producer(BlockingQueue&lt;Integer&gt; queue) {
            this.queue = queue;
         }

        public void run() {
            while (true) {
                int i = new Random().nextInt();
                 try {
                    queue.put(i);
                     System.out.println(&quot;加入元素：&quot; + i + &quot;queue size=&quot; + queue.size());
                     Thread.sleep(1000);
                 } catch (InterruptedException e) {
                    e.printStackTrace();
                 }
            }
        }
    }

    class Consumer implements Runnable {

        BlockingQueue&lt;Integer&gt; queue;

         public Consumer(BlockingQueue&lt;Integer&gt; queue) {
            this.queue = queue;
         }

        public void run() {
            while (true) {
                try {
                    Integer i = queue.take();
                    System.out.println(&quot;取出元素：&quot; + i + &quot;queue size=&quot; + queue.size());
                    Thread.sleep(1000);
                 } catch (InterruptedException e) {
                    e.printStackTrace();
                 }
            }
        }
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Google 地图求两点之间距离]]></title>
      <url>/2014/12/16/google-maps-distance-between-tow-points/</url>
      <content type="html"><![CDATA[<p>地球是一个近乎标准的椭球体，它的赤道半径为6378.140千米，极半径为6356.755千米，平均半径6371.004千米。如果我们假设地球是一个完美的球体，那么它的半径就是地球的平均半径，记为R。如果以0度经线为基准，那么根据地球表面任意两点的经纬度就可以计算出这两点间的地表距离（这里 忽略地球表面地形对计算带来的误差，仅仅是理论上的估算值）。设第一点A的经纬度为(LonA, LatA)，第二点B的经纬度为(LonB, LatB)，按照0度经线的基准，东经取经度的正值(Longitude)，西经取经度负值(-Longitude)，北纬取90-纬度值(90- Latitude)，南纬取90+纬度值(90+Latitude)，则经过上述处理过后的两点被计为(MLonA, MLatA)和(MLonB, MLatB)。那么根据三角推导，可以得到计算两点距离的如下公式：</p>
<pre><code>C = sin(MLatA)*sin(MLatB)*cos(MLonA-MLonB) + cos(MLatA)*cos(MLatB)

Distance = R*Arccos(C)*Pi/180
</code></pre><p>这里，R和Distance单位是相同，如果是采用6371.004千米作为半径，那么Distance就是千米为单位，如果要使用其他单位，比如mile，还需要做单位换算，1千米=0.621371192mile<br>如果仅对经度作正负的处理，而不对纬度作90-Latitude(假设都是北半球，南半球只有澳洲具有应用意义)的处理，那么公式将是：</p>
<pre><code>C = sin(LatA)*sin(LatB) + cos(LatA)*cos(LatB)*cos(MLonA-MLonB)

Distance = R*Arccos(C)*Pi/180
</code></pre><p>以上通过简单的三角变换就可以推出。</p>
<pre><code>var EARTH_RADIUS = 6378.137;
function rad(d){
    return d * Math.PI / 180.0;
}

function GetDistance(lat1, lng1, lat2, lng2){
    var radLat1 = rad(lat1);
    var radLat2 = rad(lat2);
    var a = radLat1 - radLat2;
    var b = rad(lng1) - rad(lng2);
    var s = 2 * Math.asin(Math.sqrt(Math.pow(Math.sin(a/2),2) +
Math.cos(radLat1)*Math.cos(radLat2)*Math.pow(Math.sin(b/2),2)));
    s = s * EARTH_RADIUS;
    s = Math.round(s * 10000) / 10000;
    return s;
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> GIS </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[全排列]]></title>
      <url>/2014/10/16/algorithm-full-permutation/</url>
      <content type="html"><![CDATA[<pre><code>public void perm(int[] arr,int start,int end){
     if(start==end){
          for(int i=0;i&lt;arr.length;i++){
               System.out.print(arr[i]);
          }
          System.out.println();
     }else{
          for(int i=start;i&lt;=end;i++){
               swap(arr,start,i);
               perm(arr,start+1;end);
               swap(arr,start,i);
          }
     }
}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux ftp 问题汇总]]></title>
      <url>/2014/07/16/linux-ftp-practice/</url>
      <content type="html"><![CDATA[<p>####虚拟机ftp配置</p>
<p>今天在 vmware 上装 contos，系统装完，可以ping通，但是ftp不通，错误消息如下：</p>
<blockquote>
<p>状态:      尝试连接“ECONNREFUSED - Connection refused by server”失败</p>
</blockquote>
<p>google说可能是端口没开或占用</p>
<p>所以检查一下</p>
<pre><code>#netstat -na --ip
</code></pre><p>21端口果然没有，打开ftp</p>
<pre><code># service vsftpd start
</code></pre><p>再连ftp，错误消息如下：</p>
<blockquote>
<p>命令:      USER root<br>响应:      530 Permission denied.</p>
</blockquote>
<p>用的root用户，vsftp默认关闭root用户，所以打开root用户<br>修改文件 <strong><code>/etc/vsftpd.ftpusers</code></strong> 和 <strong><code>/etc/vsftpd.user_list</code></strong></p>
<blockquote>
<p>响应: 553 Could not create file.<br>错误: 严重文件传输错误</p>
</blockquote>
<p>执行命令</p>
<pre><code>setsebool allow_ftpd_full_access 1
setsebool allow_ftpd_use_cifs 1
setsebool allow_ftpd_use_nfs 1
setsebool ftp_home_dir 1
setsebool httpd_enable_ftp_server 1
setsebool tftp_anon_write 1
service vsftpd restart
</code></pre><p>####vsftp上传文件限制</p>
<blockquote>
<p>553 Could not create file.</p>
</blockquote>
<pre><code>[root@node3 vsftpd]# /usr/sbin/setsebool -P ftp_home_dir 1
[root@node3 vsftpd]# setsebool allow_ftpd_full_access 1
[root@node3 vsftpd]# setsebool allow_ftpd_use_cifs 1
[root@node3 vsftpd]# setsebool allow_ftpd_use_nfs 1
[root@node3 vsftpd]# setsebool -P ftp_home_dir 1
[root@node3 vsftpd]# setsebool httpd_enable_ftp_server 1
[root@node3 vsftpd]# setsebool tftp_anon_write 1
[root@node3 vsftpd]# service vsftpd restart
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Bubble Sort]]></title>
      <url>/2014/04/26/bubble-sort/</url>
      <content type="html"><![CDATA[<p>冒泡排序（Bubble Sort）是一种比较简单的排序。它的原理是依次比较相邻的两个元素，如果他们的顺序相反，就交换位置，依次类推，直到最后一个元素。这是一轮比较，经过一轮比较之后，最后一个元素为最大。如果有 n 个数，需要循环 n-1 轮，每次循环中只需要比较未排序部分，即 n-1-i 。</p>
<p><img src="https://s2.ax1x.com/2020/02/11/1TMcpF.png" alt="1TMcpF.png" border="0"></p>
<p>正常情况下，需要循环 n-1 轮，但是如果在一次循环中没有比较，那么说明已是有序，后边再继续循环也没有意思，直接退出即可。</p>
<p>冒泡排序的时间复杂度为 O(n^2)。</p>
<pre><code>public class BubbleSortExample {
    public static void main(String[] args) {
        int[] arr = {6, 2, 4, 7, 1};
        bubbleSort(arr);
        System.out.println(Arrays.toString(arr));
    }

    /**
     * 1. n 个数只需要循环 n-1 次
     * 2. 每次循环中只需要比较为排序部分，即 n-1-i
     * 3. 如果在一次循环中没有比较，则已是有序
     * 4. 时间复杂度为 O(n^2)
     *
     * @param arr
     */
    public static void bubbleSort(int[] arr) {
        boolean flag = false;
        for (int i = 0; i &lt; arr.length - 1; i++) {
            for (int j = 0; j &lt; arr.length - 1 - i; j++) {
                if (arr[j] &gt; arr[j + 1]) {
                    int tmp = arr[j + 1];
                    arr[j + 1] = arr[j];
                    arr[j] = tmp;
                    flag = true;
                }
                System.out.println(&quot;第&quot; + (i + 1) + &quot;轮-第&quot; + (j + 1) + &quot;次：&quot; + Arrays.toString(arr));
            }
            if (!flag) {
                break;
            } else {
                flag = false;
            }
        }
    }

}
</code></pre>]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Quicksort]]></title>
      <url>/2014/04/22/quicksort/</url>
      <content type="html"><![CDATA[<p>找到一个基准点，将数组分成两段，将左边大于基准点的数挪到右边，将右边小于基准点的数挪到左边<br>使用递归<br>时间复杂度为 O(n * logn)</p>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Binary Search]]></title>
      <url>/2014/04/17/binary-search/</url>
      <content type="html"><![CDATA[<p>二分查找，又叫折半查找，时间复杂度为 O(logn)</p>
<p><strong>groovy 版</strong></p>
<pre><code class="java">def s = [1, 2, 3, 4, 5, 6, 7, 8, 9] as int[]

def binarySearch(int[] a, int b) {
    int low = 0;
    int high = a.length - 1
    while (low &lt; high) {
        int middle = (low + high) / 2 as int
        if (b &lt; a[middle]) {
            high = middle - 1
            continue
        }
        if (b &gt; a[middle]) {
            low = middle + 1
            continue
        }
        if (b == a[middle]) {
            return middle
        }
    }
    return -1
}

println binarySearch(s, 80)
</code></pre>
<p><strong>Java 版</strong></p>
<p>迭代：</p>
<pre><code class="java">public class BinarySearch {
    public int search(int[] arr, int x) {
        if (arr == null || arr.length == 0) {
            return -1;
        }
        int low = 0;
        int high = arr.length - 1;
        while (low &lt; high) {
            int middle = (low + high) / 2;
            if (x &gt; arr[middle]) {
                low = middle + 1;
                continue;
            }
            if (x &lt; arr[middle]) {
                high = middle - 1;
                continue;
            }
            if (x == arr[middle]) {
                return middle;
            }
        }
        return -1;
    }
}
</code></pre>
<p>递归：</p>
<pre><code class="java">public class BinarySearch {
    public int search(int[] arr, int start, int end, int x) {
        if (arr == null || arr.length == 0) {
            return -1;
        }
        int low = start;
        int high = end;
        int middle = (low + high) / 2;
        while (low &lt;= high) {
            if (x == arr[middle]) {
                return middle;
            }
            if (x &lt; arr[middle]) {
                return search(arr, start, middle - 1, x);
            }
            if (x &gt; arr[middle]) {
                return search(arr, middle + 1, high, x);
            }
        }
        return -1;
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Binary Tree]]></title>
      <url>/2014/04/16/binary-tree/</url>
      <content type="html"><![CDATA[<h2 id="二叉树概念"><a href="#二叉树概念" class="headerlink" title="二叉树概念"></a>二叉树概念</h2><ul>
<li>前序遍历（ DLR）也叫做先根遍历，可记做根左右。 前序遍历首先访问根结点然后遍历左子树，最后遍历右子树。在遍历左、右子树时，仍然先访问根结点，然后遍历左子树，最后遍历右子树。  </li>
<li>中序遍历，也叫中根遍历，遍历顺序为 左子树 -根 -右子树。  </li>
<li>后序遍历，也叫后根遍历，遍历顺序为 左子树 -右子树 -根。  </li>
</ul>
<h2 id="同构"><a href="#同构" class="headerlink" title="同构"></a>同构</h2><p>同构指两棵树的结构，包括子树的结构相似，节点的值可以不同。</p>
<pre><code class="java">    class BinaryTree{
        char value
        BinaryTree left
        BinaryTree right
    }

    def g = new BinaryTree(value:&#39;G&#39;)
    def f = new BinaryTree(value:&#39;F&#39;)
    def e = new BinaryTree(value:&#39;E&#39;)
    def d = new BinaryTree(value:&#39;D&#39;)
    def c = new BinaryTree(value:&#39;C&#39;,left: f,right: g)
    def b = new BinaryTree(value:&#39;B&#39;,left: d,right: e)
    def a = new BinaryTree(value:&#39;A&#39;,left: b,right: c)

    def g1 = new BinaryTree(value:&#39;g&#39;)
    def f1 = new BinaryTree(value:&#39;f&#39;)
    def e1 = new BinaryTree(value:&#39;e&#39;)
    def d1 = new BinaryTree(value:&#39;d&#39;)
    def c1 = new BinaryTree(value:&#39;c&#39;,left: f1)
    def b1 = new BinaryTree(value:&#39;b&#39;,left: d1,right: e1)
    def a1 = new BinaryTree(value:&#39;a&#39;,left: b1,right: c1)


    def boolean like(BinaryTree a, BinaryTree b){
        if(a==null &amp;&amp; b==null){
            return true
        }else{
            if(a!=null &amp;&amp; b!=null){
                return like(a.left,b.left) &amp; like(a.right,b.right)
            }else{
                return false
            }
        }
    }
    println preorder(a)
    println postorder(a)
    println middleorder(a)
    println like(a,a1)
</code></pre>
<h2 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h2><p><strong>Groovy 版</strong></p>
<pre><code class="java">def String preorder(BinaryTree tree){
        String s = &#39;&#39;
        if(tree != null){
                s += tree.value
                s += preorder(tree.left)
                s += preorder(tree.right)
        }
        return s
}

def String postorder(BinaryTree tree){
        String s = &#39;&#39;
        if(tree != null){
                s += postorder(tree.left)
                s += postorder(tree.right)
                s += tree.value
        }
        return s
}

def String middleorder(BinaryTree tree){
        String s = &#39;&#39;
        if(tree != null){
                s += middleorder(tree.left)
                s += tree.value
                s += middleorder(tree.right)
        }
        return s
}
</code></pre>
<p><strong>Java 版</strong></p>
<pre><code class="java">package com.rolex.algorithm;

/**
 * 二叉树遍历
 * &lt;p/&gt;
 * User: rolex
 * Date: 2015/4/12
 * version: 1.0
 */
public class Algo0412 {

    public static void main(String[] args) {
        Algo0412 algo = new Algo0412();
        BinaryTree d = new BinaryTree(&#39;D&#39;);
        BinaryTree e = new BinaryTree(&#39;E&#39;);
        BinaryTree f = new BinaryTree(&#39;F&#39;);
        BinaryTree g = new BinaryTree(&#39;G&#39;);
        BinaryTree c = new BinaryTree(&#39;C&#39;, f, g);
        BinaryTree b = new BinaryTree(&#39;B&#39;, d, e);
        BinaryTree a = new BinaryTree(&#39;A&#39;, b, c);

        System.out.println(&quot;preorder : &quot; + algo.preorder(a));
        System.out.println(&quot;inorder : &quot; + algo.inorder(a));
        System.out.println(&quot;postorder : &quot; + algo.postorder(a));
    }

    public String preorder(BinaryTree t) {
        if (t == null) {
            return &quot;&quot;;
        }
        String s = &quot;&quot;;
        s += t.getValue();
        s += preorder(t.getLeft());
        s += preorder(t.getRight());
        return s;
    }

    public String inorder(BinaryTree t) {
        if (t == null) {
            return &quot;&quot;;
        }
        String s = &quot;&quot;;
        s += inorder(t.getLeft());
        s += t.getValue();
        s += inorder(t.getRight());
        return s;
    }

    public String postorder(BinaryTree t) {
        if (t == null) {
            return &quot;&quot;;
        }
        String s = &quot;&quot;;
        s += postorder(t.getLeft());
        s += postorder(t.getRight());
        s += t.getValue();
        return s;
    }
}

class BinaryTree {
    private BinaryTree left;
    private BinaryTree right;
    private char value;

    public BinaryTree(char c, BinaryTree left, BinaryTree right) {
        this.value = c;
        this.left = left;
        this.right = right;
    }

    public BinaryTree(char c) {
        this(c, null, null);
    }

    public void setLeft(BinaryTree left) {
        this.left = left;
    }

    public BinaryTree getLeft() {
        return left;
    }

    public void setRight(BinaryTree right) {
        this.right = right;
    }

    public BinaryTree getRight() {
        return right;
    }

    public void setValue(char c) {
        this.value = c;
    }

    public char getValue() {
        return value;
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Data Structure and Algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Interview </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[IDEA 内存溢出解决办法]]></title>
      <url>/2014/01/13/idea-out-of-memory/</url>
      <content type="html"><![CDATA[<h3 id="1-使用-idea64-exe-启动"><a href="#1-使用-idea64-exe-启动" class="headerlink" title="1. 使用 idea64.exe 启动"></a>1. 使用 idea64.exe 启动</h3><h3 id="2-修改-bin-目录下的-idea-exe-vmoptions-文件"><a href="#2-修改-bin-目录下的-idea-exe-vmoptions-文件" class="headerlink" title="2. 修改 bin 目录下的 idea.exe.vmoptions 文件"></a>2. 修改 bin 目录下的 idea.exe.vmoptions 文件</h3><pre><code>-Xms128m
-Xmx1024m
</code></pre><h3 id="3-添加运行VM参数"><a href="#3-添加运行VM参数" class="headerlink" title="3. 添加运行VM参数"></a>3. 添加运行VM参数</h3><pre><code> -server -XX:PermSize=512M -XX:MaxPermSize=1024m
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> IDEA </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Maven 设置编译器等级]]></title>
      <url>/2014/01/10/setting-up-compiler-level-in-maven/</url>
      <content type="html"><![CDATA[<p>在pom.xml中加入</p>
<pre><code>&lt;build&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
            &lt;version&gt;2.3.2&lt;/version&gt;
            &lt;configuration&gt;
                &lt;source&gt;1.7&lt;/source&gt;
                &lt;target&gt;1.7&lt;/target&gt;
            &lt;/configuration&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Maven </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[经纬度查省市县（逆编码）]]></title>
      <url>/2013/07/16/reverse-geo-code/</url>
      <content type="html"><![CDATA[<p>阿里云提供的接口</p>
<p><a href="http://gc.ditu.aliyun.com/regeocoding?l=&quot;+lat+&quot;,&quot;+lng+&quot;&amp;type=010" target="_blank" rel="external">http://gc.ditu.aliyun.com/regeocoding?l=”+lat+”,”+lng+”&amp;type=010</a><br>type=010 兴趣点（poi）100代表道路，010代表POI，001代表门址，111可以同时显示前三项</p>
<p><a href="http://gc.ditu.aliyun.com/jsdoc/geocode_api.html" target="_blank" rel="external">api 文档</a> 参考。</p>
<p>行政区划：<br><a href="http://recode.ditu.aliyun.com/dist_query?l=39.938133,116.395739" target="_blank" rel="external">http://recode.ditu.aliyun.com/dist_query?l=39.938133,116.395739</a><br>l 参数定义：纬度，经度</p>
<pre><code class="java">public String[] getArea(float lng, float lat){
    String[] arr = new String[3];
    String path=&quot;http://gc.ditu.aliyun.com/regeocoding?l=&quot;+lat+&quot;,&quot;+lng+&quot;&amp;type=010&quot;;
    URL url= null;
    try {
        url = new URL(path);
        HttpURLConnection conn=(HttpURLConnection) url.openConnection();
        conn.setRequestMethod(&quot;GET&quot;);
        conn.setConnectTimeout(5000);
        String jsonString = &quot;&quot;;
        if(conn.getResponseCode()==200){
            BufferedReader is=new BufferedReader(new InputStreamReader(conn.getInputStream(),&quot;UTF-8&quot;));
            String str;
            if((str=is.readLine())!=null)
            {
                jsonString += str;
            }

            is.close();

            JSONObject jsonObject = JSONObject.fromObject(jsonString);
            String addrList =  jsonObject.getString(&quot;addrList&quot;);

            JSONArray jsonarry = JSONArray.fromObject(addrList);
            String poi = null;
            for(int i = 0;i&lt;jsonarry.size();i++){
                JSONObject jsonObject2 = jsonarry.getJSONObject(i);
                poi =  jsonObject2.getString(&quot;admName&quot;);
            }
            System.out.println(&quot;----------&quot;+poi);

            if(!&quot;&quot;.equals(poi)){
                String[] area = poi.split(&quot;,&quot;);
                arr[0] = area[0];
                arr[1] = area[1];

                if(area.length == 3) {
                    arr[2] = area[2];
                }

            }

        }
    } catch (Exception e) {
        e.printStackTrace();
    }
    return arr;
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Java </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlackBerry 开发：九宫格]]></title>
      <url>/2012/05/21/blackberry-gridview/</url>
      <content type="html"><![CDATA[<pre><code class="JAVA">/**
 *
 * @author Rolex
 * @date 2011-9-21
 */
public class HomeScreen extends MainScreen{

        public HomeScreen() {
          HorizontalBitmapFieldSet set1 = new HorizontalBitmapFieldSet();
          BitmapBackgroundButtonField bitmap1 = new BitmapBackgroundButtonField(&quot;登录&quot;,Field.FOCUSABLE,Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon.png&quot;),Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon_login.png&quot;));
          bitmap1.setChangeListener(new FieldChangeListener() {

                public void fieldChanged(Field field, int context) {
                      pushScreen(new com.unionpay.mobilepay.mpos.profile.TabScreen(null));

                }
          });
          BitmapBackgroundButtonField bitmap2 = new BitmapBackgroundButtonField(&quot;注册&quot;,Field.FOCUSABLE,Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon.png&quot;),Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon_register.png&quot;));
          bitmap2.setChangeListener(new FieldChangeListener() {

                public void fieldChanged(Field field, int context) {
                      pushScreen(new com.unionpay.mobilepay.mpos.profile.TabScreen(null));

                }
          });
          BitmapBackgroundButtonField bitmap3 = new BitmapBackgroundButtonField(&quot;帮助&quot;,Field.FOCUSABLE,Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon.png&quot;),Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon_help.png&quot;));
          bitmap3.setChangeListener(new FieldChangeListener() {

                public void fieldChanged(Field field, int context) {
                      Dialog.alert(&quot;help&quot;);

                }
          });
          set1.add(bitmap1);
          set1.add(bitmap2);
          set1.add(bitmap3);
          HorizontalBitmapFieldSet set2 = new HorizontalBitmapFieldSet();
          BitmapBackgroundButtonField bitmap4 = new BitmapBackgroundButtonField(&quot;交易管理&quot;,Field.FOCUSABLE,Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon.png&quot;),Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon_transaction.png&quot;));
          bitmap4.setChangeListener(new FieldChangeListener() {

                public void fieldChanged(Field field, int context) {
                      pushScreen(new TradePay());

                }
          });
          BitmapBackgroundButtonField bitmap5 = new BitmapBackgroundButtonField(&quot;银行卡管理&quot;,Field.FOCUSABLE,Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon.png&quot;),Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon_bankcard.png&quot;));
          bitmap5.setChangeListener(new FieldChangeListener() {

                public void fieldChanged(Field field, int context) {
                      pushScreen(new CardManager());

                }
          });
          BitmapBackgroundButtonField bitmap6 = new BitmapBackgroundButtonField(&quot;用户管理&quot;,Field.FOCUSABLE,Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon.png&quot;),Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon_profile.png&quot;));
          bitmap6.setChangeListener(new FieldChangeListener() {

                public void fieldChanged(Field field, int context) {
                      pushScreen(new TabScreenIn(null));

                }
          });
          set2.add(bitmap4);
          set2.add(bitmap5);
          set2.add(bitmap6);
          HorizontalBitmapFieldSet set3 = new HorizontalBitmapFieldSet();
          BitmapBackgroundButtonField bitmap7 = new BitmapBackgroundButtonField(&quot;关于&quot;,Field.FOCUSABLE,Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon.png&quot;),Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon_about.png&quot;));
          bitmap7.setChangeListener(new FieldChangeListener() {

                public void fieldChanged(Field field, int context) {
                      Dialog.alert(&quot;login&quot;);

                }
          });
          BitmapBackgroundButtonField bitmap8 = new BitmapBackgroundButtonField(&quot;设置&quot;,Field.FOCUSABLE,Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon.png&quot;),Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon_settings.png&quot;));
          bitmap8.setChangeListener(new FieldChangeListener() {

                public void fieldChanged(Field field, int context) {
                      Dialog.alert(&quot;reg&quot;);

                }
          });
          BitmapBackgroundButtonField bitmap9 = new BitmapBackgroundButtonField(&quot;更多&quot;,Field.FOCUSABLE,Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon.png&quot;),Bitmap.getBitmapResource(&quot;com/unionpay/mobilepay/mpos/image/home/icon_more.png&quot;));
          bitmap9.setChangeListener(new FieldChangeListener() {

                public void fieldChanged(Field field, int context) {
                      Dialog.alert(&quot;help&quot;);

                }
          });
          set3.add(bitmap7);
          set3.add(bitmap8);
          set3.add(bitmap9);
          add(set1);
          add(set2);
          add(set3);

        }

        public static void pushScreen(MainScreen screen){
          UiApplication.getUiApplication().pushScreen(screen);
        }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlackBerry </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlackBerry 开发：XML 解析]]></title>
      <url>/2012/05/14/blackberry-parse-xml/</url>
      <content type="html"><![CDATA[<pre><code class="Java">public class XmlParser {
    /**
     * 递归方法，用于将每一个节点元素遍历出来放入到hashtable（注：bb的api基于JDK1.3，不支持hashmap，泛型等）中
     *
     * @param node
     *            document中的节点
     * @param depth
     *            节点的深度，用于做递归
     */
    public static void fetchNode(Node node, int depth, Hashtable ht) {
        /*
         * 判断是否为一个node，如过是一个节点，找到所有的子节点和子节点的数量。
         * 如果一个节点是一个文本节点，则将其放入到hashtable中，如果是一个元素节点， 则将该节点放入hashtable中，
         * 并对其子元素进行递归，直到遍历到最后一个文本 元素，递归结束。
         */
        if (node.getNodeType() == Node.ELEMENT_NODE) {
            // 如果是一个节点，找到所有的子节点
            NodeList childNodes = node.getChildNodes();
            int numChildren = childNodes.getLength();

            Node firstChild = childNodes.item(0);
            if (numChildren == 1 &amp;&amp; firstChild.getNodeType() == Node.TEXT_NODE) {
                  ht.put(node.getNodeName(),
                              firstChild.getNodeValue() == null ? &quot;&quot; : firstChild
                                          .getNodeValue());
            } else {
                  ht.put(node.getNodeName(),
                              firstChild.getNodeValue() == null ? &quot;&quot; : firstChild
                                          .getNodeValue());
                  for (int i = 0; i &lt; numChildren; ++i) {
                        fetchNode(childNodes.item(i), depth + 1, ht);
                  }
            }
        } else {
            // 如果不是node，那就是一个value
            String nodeValue = node.getNodeValue();
            // 如果不value不是空，则放入hashtable中
            if (nodeValue.trim().length() != 0) {
                  ht.put(node.getNodeName(), node.getNodeValue() == null ? &quot;&quot;
                              : node.getNodeValue());
            }
        }
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlackBerry </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlackBerry 开发：虚拟键盘]]></title>
      <url>/2012/05/02/blackberry-virtual-keyboard/</url>
      <content type="html"><![CDATA[<pre><code class="JAVA">import java.io.InputStream;

import javax.microedition.media.Player;
import javax.microedition.media.control.VolumeControl;

import net.rim.device.api.system.Application;
import net.rim.device.api.system.Display;
import net.rim.device.api.system.KeyListener;
import net.rim.device.api.ui.Color;
import net.rim.device.api.ui.Field;
import net.rim.device.api.ui.FieldChangeListener;
import net.rim.device.api.ui.FocusChangeListener;
import net.rim.device.api.ui.Graphics;
import net.rim.device.api.ui.Keypad;
import net.rim.device.api.ui.Manager;
import net.rim.device.api.ui.VirtualKeyboard;
import net.rim.device.api.ui.component.EditField;
import net.rim.device.api.ui.component.LabelField;
import net.rim.device.api.ui.component.PasswordEditField;
import net.rim.device.api.ui.container.HorizontalFieldManager;
import net.rim.device.api.ui.container.PopupScreen;
import net.rim.device.api.ui.container.VerticalFieldManager;

public class TestScreen extends PopupScreen implements FieldChangeListener,KeyListener {


   PasswordEditField passwd;//输入框
   VerticalFieldManager vfm;//密码键盘的布局
   HorizontalFieldManager buttonHfm;//按钮的水平布局
   VerticalFieldManager numVfm;//数字键盘的垂直布局
   VerticalFieldManager charVfm;//字母键盘垂直布局
   VerticalFieldManager bcharVfm;//字母键盘垂直布局
   VerticalFieldManager signVfm;//符号键盘的水平布局
   CustomButtonField button1;
   CustomButtonField button2;
   CustomButtonField button3;
   VirtualKeyboard virtKbd;//虚拟键盘
   CustomButtonField cbf;

   EditField _edit;
   EditField _edit1;

   public TestScreen(EditField edit,EditField edit1) {
          super(new VerticalFieldManager()
          {
          }
          );
          _edit = edit;
          _edit1 = edit1;
          virtKbd = this.getVirtualKeyboard();//获得当前屏幕的虚拟键盘

          vfm = new VerticalFieldManager();
          LabelField label = new LabelField(&quot;密码键盘&quot;);
          passwd = new PasswordEditField();
          passwd.setFocusListener(new FocusChangeListener() {
               public void focusChanged(Field field, int eventType) {
                       if(eventType == FOCUS_GAINED){
                            //virtKbd.setVisibility(VirtualKeyboard.HIDE_FORCE);
                       }
                  }
        });
          buttonHfm = new HorizontalFieldManager();
          button1 = new CustomButtonField(&quot;数字&quot;, CustomButtonField.BUTTON, Field.FOCUSABLE);
          button1.setChangeListener(this);
          button2 = new CustomButtonField(&quot;字母&quot;, CustomButtonField.BUTTON, Field.FOCUSABLE);
          button2.setChangeListener(this);
          button3 = new CustomButtonField(&quot;符号&quot;, CustomButtonField.BUTTON, Field.FOCUSABLE);
          button3.setChangeListener(this);
          buttonHfm.add(button1);
          buttonHfm.add(button2);
          buttonHfm.add(button3);
          numVfm = new VerticalFieldManager(Manager.FIELD_HCENTER);
          charVfm = new VerticalFieldManager(Manager.FIELD_HCENTER);
          bcharVfm = new VerticalFieldManager(Manager.FIELD_HCENTER);
          signVfm = new VerticalFieldManager(Manager.FIELD_HCENTER);

          String num[] = KeyboardUtil.randomArray(new String[] { &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, &quot;8&quot;,
                       &quot;9&quot;, &quot;0&quot;, &quot;确定&quot;, &quot;←&quot; });
          HorizontalFieldManager h1 = new HorizontalFieldManager();
          HorizontalFieldManager h2 = new HorizontalFieldManager();
          HorizontalFieldManager h3 = new HorizontalFieldManager();
          cbf = new CustomButtonField(num[0], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          h1.add(cbf);
          cbf = new CustomButtonField(num[1], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          h1.add(cbf);
          cbf = new CustomButtonField(num[2], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          h1.add(cbf);
          cbf = new CustomButtonField(num[3], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          h1.add(cbf);
          cbf = new CustomButtonField(num[4], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          h2.add(cbf);
          cbf = new CustomButtonField(num[5], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          h2.add(cbf);
          cbf = new CustomButtonField(num[6], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          h2.add(cbf);
          cbf = new CustomButtonField(num[7], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          h2.add(cbf);
          cbf = new CustomButtonField(num[8], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          h3.add(cbf);
          cbf = new CustomButtonField(num[9], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          h3.add(cbf);
          cbf = new CustomButtonField(num[10], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          h3.add(cbf);
          cbf = new CustomButtonField(num[11], CustomButtonField.SIGN, Field.FOCUSABLE);
         cbf.setChangeListener(this);
         h3.add(cbf);
          numVfm.add(h1);
          numVfm.add(h2);
          numVfm.add(h3);
         //字母键盘
         HorizontalFieldManager hfm = new HorizontalFieldManager(Manager.FIELD_HCENTER);

           // Rectangular button
         cbf = new CustomButtonField(&quot;q&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
         cbf.setChangeListener(this);
           hfm.add(cbf);
           cbf = new CustomButtonField(&quot;w&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm.add(cbf);
           cbf = new CustomButtonField(&quot;e&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm.add(cbf);
           cbf = new CustomButtonField(&quot;r&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm.add(cbf);
           cbf = new CustomButtonField(&quot;t&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm.add(cbf);
           cbf = new CustomButtonField(&quot;y&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm.add(cbf);
           cbf = new CustomButtonField(&quot;u&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm.add(cbf);
           cbf = new CustomButtonField(&quot;i&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm.add(cbf);
           cbf = new CustomButtonField(&quot;o&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm.add(cbf);
           cbf = new CustomButtonField(&quot;p&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm.add(cbf);

           HorizontalFieldManager hfm1 = new HorizontalFieldManager(Manager.FIELD_HCENTER);

           // Rectangular button
           cbf = new CustomButtonField(&quot;a&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm1.add(cbf);
           cbf = new CustomButtonField(&quot;s&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm1.add(cbf);
           cbf = new CustomButtonField(&quot;d&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm1.add(cbf);
           cbf = new CustomButtonField(&quot;f&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm1.add(cbf);
           cbf = new CustomButtonField(&quot;g&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm1.add(cbf);
           cbf = new CustomButtonField(&quot;h&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm1.add(cbf);
           cbf = new CustomButtonField(&quot;j&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm1.add(cbf);
           cbf = new CustomButtonField(&quot;k&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm1.add(cbf);
           cbf = new CustomButtonField(&quot;l&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm1.add(cbf);
           cbf = new CustomButtonField(&quot;←&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm1.add(cbf);

           HorizontalFieldManager hfm2 = new HorizontalFieldManager(Manager.FIELD_HCENTER);
           cbf = new CustomButtonField(&quot;↑&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm2.add(cbf);
           // Rectangular button
           cbf = new CustomButtonField(&quot;z&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm2.add(cbf);
           cbf = new CustomButtonField(&quot;x&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm2.add(cbf);
           cbf = new CustomButtonField(&quot;d&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm2.add(cbf);
           cbf = new CustomButtonField(&quot;v&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm2.add(cbf);
           cbf = new CustomButtonField(&quot;b&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm2.add(cbf);
           cbf = new CustomButtonField(&quot;n&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm2.add(cbf);
           cbf = new CustomButtonField(&quot;m&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm2.add(cbf);
           cbf = new CustomButtonField(&quot;确定&quot;, CustomButtonField.RECTANGLE, Field.FOCUSABLE);
           cbf.setChangeListener(this);
           hfm2.add(cbf);

           charVfm.add(hfm);
           charVfm.add(hfm1);
           charVfm.add(hfm2);



           /***********************************/
           //大写字母键盘
              HorizontalFieldManager bhfm = new HorizontalFieldManager(Manager.FIELD_HCENTER);

                // Rectangular button
              cbf = new CustomButtonField(&quot;Q&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
              cbf.setChangeListener(this);
                bhfm.add(cbf);
                cbf = new CustomButtonField(&quot;W&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm.add(cbf);
                cbf = new CustomButtonField(&quot;E&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm.add(cbf);
                cbf = new CustomButtonField(&quot;R&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm.add(cbf);
                cbf = new CustomButtonField(&quot;T&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm.add(cbf);
                cbf = new CustomButtonField(&quot;Y&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm.add(cbf);
                cbf = new CustomButtonField(&quot;U&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm.add(cbf);
                cbf = new CustomButtonField(&quot;I&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm.add(cbf);
                cbf = new CustomButtonField(&quot;O&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm.add(cbf);
                cbf = new CustomButtonField(&quot;P&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm.add(cbf);

                HorizontalFieldManager bhfm1 = new HorizontalFieldManager(Manager.FIELD_HCENTER);

                // Rectangular button
                cbf = new CustomButtonField(&quot;A&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm1.add(cbf);
                cbf = new CustomButtonField(&quot;S&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm1.add(cbf);
                cbf = new CustomButtonField(&quot;D&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm1.add(cbf);
                cbf = new CustomButtonField(&quot;F&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm1.add(cbf);
                cbf = new CustomButtonField(&quot;G&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm1.add(cbf);
                cbf = new CustomButtonField(&quot;H&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm1.add(cbf);
                cbf = new CustomButtonField(&quot;J&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm1.add(cbf);
                cbf = new CustomButtonField(&quot;K&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm1.add(cbf);
                cbf = new CustomButtonField(&quot;L&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm1.add(cbf);
                cbf = new CustomButtonField(&quot;←&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm1.add(cbf);

                HorizontalFieldManager bhfm2 = new HorizontalFieldManager(Manager.FIELD_HCENTER);
                cbf = new CustomButtonField(&quot;↓&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm2.add(cbf);
                // Rectangular button
                cbf = new CustomButtonField(&quot;Z&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm2.add(cbf);
                cbf = new CustomButtonField(&quot;X&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm2.add(cbf);
                cbf = new CustomButtonField(&quot;C&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm2.add(cbf);
                cbf = new CustomButtonField(&quot;V&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm2.add(cbf);
                cbf = new CustomButtonField(&quot;B&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm2.add(cbf);
                cbf = new CustomButtonField(&quot;N&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm2.add(cbf);
                cbf = new CustomButtonField(&quot;M&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm2.add(cbf);
                cbf = new CustomButtonField(&quot;确定&quot;, CustomButtonField.BIG, Field.FOCUSABLE);
                cbf.setChangeListener(this);
                bhfm2.add(cbf);

                bcharVfm.add(bhfm);
                bcharVfm.add(bhfm1);
                bcharVfm.add(bhfm2);
           /***********************************/
         //符号键盘
         String sign[] = new String[] { &quot;!&quot;, &quot;@&quot;, &quot;#&quot;, &quot;$&quot;, &quot;%&quot;, &quot;^&quot;, &quot;&amp;&quot;, &quot;←&quot;,
                       &quot;(&quot;, &quot;)&quot;, &quot;*&quot;, &quot;确定&quot; };
         HorizontalFieldManager sh1 = new HorizontalFieldManager();
         HorizontalFieldManager sh2 = new HorizontalFieldManager();
         HorizontalFieldManager sh3 = new HorizontalFieldManager();
          cbf = new CustomButtonField(sign[0], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          sh1.add(cbf);
          cbf = new CustomButtonField(sign[1], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          sh1.add(cbf);
          cbf = new CustomButtonField(sign[2], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          sh1.add(cbf);
          cbf = new CustomButtonField(sign[3], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          sh1.add(cbf);
          cbf = new CustomButtonField(sign[4], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          sh2.add(cbf);
          cbf = new CustomButtonField(sign[5], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          sh2.add(cbf);
          cbf = new CustomButtonField(sign[6], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          sh2.add(cbf);
          cbf = new CustomButtonField(sign[7], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          sh2.add(cbf);
          cbf = new CustomButtonField(sign[8], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          sh3.add(cbf);
          cbf = new CustomButtonField(sign[9], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          sh3.add(cbf);
          cbf = new CustomButtonField(sign[10], CustomButtonField.SIGN, Field.FOCUSABLE);
          cbf.setChangeListener(this);
          sh3.add(cbf);
          cbf = new CustomButtonField(sign[11], CustomButtonField.SIGN, Field.FOCUSABLE);
         cbf.setChangeListener(this);
         sh3.add(cbf);
         signVfm.add(sh1);
         signVfm.add(sh2);
         signVfm.add(sh3);


          vfm.add(label);
          vfm.add(passwd);
          vfm.add(buttonHfm);
          vfm.add(numVfm);
          add(vfm);
          Application.getApplication().addKeyListener(this);           
   }

   protected void paintBackground(Graphics graphics) {
        graphics.setColor(Color.WHITE);
   }

   int index = 0;//标识显示的键盘
   public void fieldChanged(Field field, int context) {
        play();
        if(field instanceof CustomButtonField){
             //virtKbd.setVisibility(VirtualKeyboard.HIDE_FORCE);
             if(&quot;数字&quot;.equals(((CustomButtonField)field).getText())){
                  if(index == 1){
                       vfm.replace(charVfm, numVfm);
                  }else if(index == 2){
                       vfm.replace(signVfm, numVfm);
                  }else if(index == 3){
                       vfm.replace(bcharVfm, numVfm);
                  }
                  index = 0;
             }else if(&quot;字母&quot;.equals(((CustomButtonField)field).getText())){
                  if(index == 0){
                       vfm.replace(numVfm, charVfm);
                  }else if(index == 2){
                       vfm.replace(signVfm, charVfm);
                  }else if(index == 3){
                       vfm.replace(bcharVfm, charVfm);
                  }
                  index = 1;
             }else if(&quot;符号&quot;.equals(((CustomButtonField)field).getText())){
                  if(index == 0){
                       vfm.replace(numVfm, signVfm);
                  }else if(index == 1){
                       vfm.replace(charVfm, signVfm);
                  }else if(index == 3){
                       vfm.replace(bcharVfm, signVfm);
                  }
                  index = 2;
             }else if(&quot;←&quot;.equals(((CustomButtonField)field).getText())){
                  if(passwd.getText().length()&gt;0){
                       passwd.setText(passwd.getText().substring(0, passwd.getText().length()-1));
                  }
             }else if(&quot;确定&quot;.equals(((CustomButtonField)field).getText())){
                  _edit.setText(passwd.getText());
                  _edit1.setFocus();
                  this.close();
             }else if(&quot;↑&quot;.equals(((CustomButtonField)field).getText())){
                  vfm.replace(charVfm, bcharVfm);
                  index = 3;
             }else if(&quot;↓&quot;.equals(((CustomButtonField)field).getText())){
                  vfm.replace(bcharVfm, charVfm);
                  index = 1;
             }else{
                  passwd.setText(passwd.getText() + ((CustomButtonField)field).getText());
             }
             passwd.setFocus();//设置点击按钮失去焦点
        }
   }

   public void play(){
        // create an instance of the player from the InputStream
        Class clazz;
        try {
             clazz = this.getClass();
            InputStream is = clazz.getResourceAsStream(&quot;notify.wav&quot;);
            //create an instance of the player from the InputStream
            Player player = javax.microedition.media.Manager.createPlayer(is, &quot;audio/mpeg&quot;);

             player.realize();
             player.prefetch();
             VolumeControl volumeControl = (VolumeControl) player.getControl(&quot;VolumeControl&quot;);
             volumeControl.setLevel(100);
             // start the player
             player.start();
        } catch (Exception e) {
             // TODO Auto-generated catch block
             e.printStackTrace();
        }
   }

   protected void sublayout(int width, int height) {
        layoutDelegate(Display.getWidth()-10, 210);
        setPosition(-15, 265);
        setExtent(Display.getWidth()-10, 180);
   }


     public boolean keyChar( char key, int status, int time ) {
       if(key == Keypad.KEY_ESCAPE){
            _edit1.setFocus();
             this.close();
             return true;
       }

      return false;
  }

  public boolean keyDown(int keycode, int time)
  {
       if(keycode == Keypad.KEY_ESCAPE){
            _edit1.setFocus();
             this.close();
             return true;
       }
      return false;
  }

  public boolean keyRepeat(int keycode, int time)
  {
      return false;
  }

  public boolean keyStatus(int keycode, int time)
  {
      return false;
  }

  public boolean keyUp(int keycode, int time)
  {
      return false;
  }   

}

/**
* CustomButtonField.java
*
* Copyright � 1998-2010 Research In Motion Ltd.
*
* Note: For the sake of simplicity, this sample application may not leverage
* resource bundles and resource strings.  However, it is STRONGLY recommended
* that application developers make use of the localization features available
* within the BlackBerry development platform to ensure a seamless application
* experience across a variety of languages and geographies.  For more information
* on localizing your application, please refer to the BlackBerry Java Development
* Environment Development Guide associated with this release.
*/

import net.rim.device.api.ui.*;
import net.rim.device.api.system.*;

/**
* CustomButtonField - class which creates button fields of various shapes.
* Demonstrates how to create custom ui fields.
*/
public class CustomButtonField extends Field implements DrawStyle {
   static final int RECTANGLE = 1;
   static final int SIGN = 2;
   static final int BIG = 3;
   static final int BUTTON = 4;

   private String _label;
   private int _shape;
   private Font _font;
   private int _labelHeight;
   private int _labelWidth;

   /**
   * Constructs a button with specified label, and default style and shape.
   */
   public CustomButtonField(String label) {
      this(label, RECTANGLE, 0);
   }

   /**
   * Constructs a button with specified label and shape, and default style.
   */
   public CustomButtonField(String label, int shape) {
      this(label, shape, Field.FIELD_BOTTOM);
   }

   /**
   * Constructs a button with specified label and style, and default shape.
   */
   public CustomButtonField(String label, long style) {
      this(label, RECTANGLE, style);
   }

   /**
   * Constructs a button with specified label, shape, and style.
   */
   public CustomButtonField(String label, int shape, long style) {
      super(style);

      _label = label;
      _shape = shape;
      _font = getFont();
      _labelHeight = _font.getHeight();
      _labelWidth = _font.getAdvance(_label);
      setMargin(2, 3, 2, 3);
      // setPadding(2,0,-2,0);
   }

   /**
   * @return The text on the button
   */
   String getText() {
        return _label;
   }

   /**
   * Field implementation.
   *
   * @see net.rim.device.api.ui.Field#getPreferredWidth()
   */
   public int getPreferredWidth() {
      if (_shape == SIGN) {
         return 83;
      }
      if (_shape == BIG) {
         return _labelWidth + 20;
      }
      if (_shape == BUTTON) {
         return _labelWidth + 78;
      }
      return _labelWidth + 22;
   }

   /**
   * Field implementation.
   *
   * @see net.rim.device.api.ui.Field#getPreferredHeight()
   */
   public int getPreferredHeight() {
      if (_shape == SIGN) {
         return 30;
      }
      return _labelHeight + 10;
   }

   /**
   * Field implementation.
   *
   * @see net.rim.device.api.ui.Field#drawFocus(Graphics, boolean)
   */
   protected void drawFocus(Graphics graphics, boolean on) {
      graphics.invert(1, 1, getWidth() - 2, getHeight() - 2);
   }

   /**
   * Field implementation.
   *
   * @see net.rim.device.api.ui.Field#layout(int, int)
   */
   protected void layout(int width, int height) {
      // Update the cached font - in case it has been changed.
      _font = getFont();
      _labelHeight = _font.getHeight();
      _labelWidth = _font.getAdvance(_label);

      // Calc width.
      width = Math.min(width, getPreferredWidth());

      // Calc height.
      height = Math.min(height, getPreferredHeight());

      // Set dimensions.
      setExtent(width, height);
   }

   /**
   * Field implementation.
   *
   * @see net.rim.device.api.ui.Field#paint(Graphics)
   */
   protected void paint(Graphics graphics) {
      int textX, textY, textWidth;
      int w = getWidth();
      int h = getHeight();

      graphics.drawRect(0, 0, w, h);

      textX = 4;
      textY = 2;
      textWidth = w - 6;

      graphics.drawText(_label, textX, textY, (int) (getStyle()
                &amp; DrawStyle.ELLIPSIS | DrawStyle.HALIGN_MASK), textWidth);
   }

   /**
   * Overridden so that the Event Dispatch thread can catch this event instead
   * of having it be caught here.
   *
   * @see net.rim.device.api.ui.Field#navigationClick(int, int)
   */
   protected boolean navigationClick(int status, int time) {
      fieldChangeNotify(0);
      return true;
   }

}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlackBerry </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlackBerry 开发：向服务器发请求]]></title>
      <url>/2012/04/22/blackberry-sending-request-to-server/</url>
      <content type="html"><![CDATA[<a id="more"></a>
<pre><code class="JAVA">public String httpFetch(String xml,String url) {
    String content = &quot;&quot;;
    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
    HttpConnection hconn = null;
    OutputStream out = null;




    String bodystr = xml.toString();
    try {
        hconn = (HttpConnection) Connector.open(url);
        //UrlRequestedEvent
        hconn.setRequestMethod(HttpConnection.POST);
        hconn.setRequestProperty(HttpProtocolConstants.HEADER_USER_AGENT, &quot;BlackBerry/5.0.0&quot;);
        hconn.setRequestProperty(HttpProtocolConstants.HEADER_CONTENT_LENGTH, String.valueOf(bodystr.getBytes().length));
        hconn.setRequestProperty(HttpProtocolConstants.HEADER_CONTENT_TYPE,&quot;application/x-www-form-urlencoded&quot;);
        out = hconn.openOutputStream();
        out.write(bodystr.getBytes());
        out.flush();

          int status = hconn.getResponseCode();

          if (status == HttpConnection.HTTP_OK) {
                // Is this html?
                String contentType = hconn.getHeaderField(HEADER_CONTENTTYPE);
                boolean htmlContent = (contentType != null &amp;&amp; contentType.startsWith(CONTENTTYPE_TEXTHTML));

                InputStream input = hconn.openInputStream();

                int len = 0;
                int size = 0;
                byte[] data = new byte[256];
                StringBuffer raw = new StringBuffer();

                while (-1 != (len = input.read(data))) {
                      raw.append(new String(data, 0, len));
                      size += len;
                }

                raw.insert(0, &quot;bytes received]\n&quot;);
                raw.insert(0, size);
                raw.insert(0, &#39;[&#39;);
                content = raw.toString();

                if (htmlContent) {
                      content = prepareData(raw.toString());
                }
                input.close();
          } else {
                content = &quot;response code = &quot; + status;
          }
          hconn.close();
    } catch (IOException e) {
          content = e.toString();
    }
    _fetchStarted = false;

    return content;
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlackBerry </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlackBerry 开发：监听浏览器]]></title>
      <url>/2012/04/17/blackberry-listening-browser/</url>
      <content type="html"><![CDATA[<pre><code class="JAVA">public final class PackageManager
{
    /**
     * Entry point for this application
     * @param args Command line arguments (not used)
     */
    public static void main(String[] args)
    {
        try
        {
            HttpFilterRegistry.registerFilter(&quot;com.unionpay.m.p&quot;, &quot;com.rim.samples.device.httpfilterdemo.filter&quot;);
        }
        catch(ControlledAccessException cae)
        {
            // Re-throw exception with explicit message
            throw new ControlledAccessException( cae + &quot; Http Filter Demo attempted to access API governed by Interactions/Browser Filtering &quot; +
                &quot;application permission.  Please set this permission to &#39;allow&#39; under Options/Security Options/Application Permissions&quot;);
        }
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlackBerry </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlackBerry 开发：文件操作]]></title>
      <url>/2012/04/12/blackberry-operating-files/</url>
      <content type="html"><![CDATA[<pre><code class="JAVA">/**
 * 文件操作
 *
 * @author Rolex
 * @date 2011-9-28
 */
public class FileUtil {

    /**
     *
     * 将内容保存到SD卡上的文件中，如果文件不存在，则新建
     *
     * @param content
     * @return
     */
    public static boolean writeFile(String content) {     
        boolean isWrite=false;
        try {
            DataOutputStream os = null;
            FileConnection file = null;            

            file = (FileConnection) Connector.open(&quot;file:///SDCard/config.xml&quot; , Connector.READ_WRITE);
            if(!file.exists()){
              file.create();
            }
            os = file.openDataOutputStream();
            os.write(content.getBytes());

            os.close();
            file.close();
            isWrite = true;
        }
        catch (Exception e) {
            e.printStackTrace();
        }
        return isWrite;
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlackBerry </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlackBerry 开发：圆角矩形布局]]></title>
      <url>/2012/04/07/blackberry-rounded-rectangle-layout/</url>
      <content type="html"><![CDATA[<pre><code class="JAVA">/**
 * 圆角的布局，内部元素遵守垂直布局的规则，可设置标题和图片,传空则不设置
 *
 * @author Rolex
 * @date 2011-9-23
 */
public class RoundRectFieldManager extends VerticalFieldManager {
    private static final int CORNER_RADIUS = 18;
    private static final int PANDDING = 5;
    private static final int MARGIN = 10;
    public RoundRectFieldManager(Bitmap bitmap, String title) {
        super(Manager.FIELD_HCENTER);
        // 横向放四个图片按钮
//          setPadding(0, 5, 0, 0); // OS 5.0未公开的API
        setMargin(MARGIN, MARGIN, MARGIN, MARGIN); // OS 5.0未公开的API
        if(title != null &amp;&amp; !&quot;&quot;.equals(title)){
            HorizontalFieldManager h = new HorizontalFieldManager(){
                protected void paintBackground(Graphics g) {

                    int oldColor = g.getColor();
                    try {
                        g.setColor(Color.RED);
                        g.fillRoundRect(0, 0, Display.getWidth() - MARGIN * 2, getHeight() + (PANDDING *2 + CORNER_RADIUS), CORNER_RADIUS, CORNER_RADIUS);// 画实心的圆角的矩形
                        g.setColor(Color.WHITE);
                        g.drawRoundRect(0, 0, Display.getWidth() - MARGIN * 2, getHeight() + (PANDDING *2 + CORNER_RADIUS), CORNER_RADIUS, CORNER_RADIUS); // 换个颜色，画圆角的边框
                    } finally {
                        g.setColor(oldColor);
                    }
                }
            };
            h.setPadding(PANDDING, PANDDING, PANDDING, PANDDING); // OS 5.0未公开的API
            h.add(new BitmapField(bitmap));
            h.add(new RichTextField(title,NON_FOCUSABLE ){
                protected void layout(int width, int height) {
                    width = Display.getWidth()- MARGIN * 2;
                    super.layout(width, height);
                }
            });
            add(h);
        }
    }

    protected void paintBackground(Graphics g) {
        int oldColor = g.getColor();
        try {
            g.setColor(Color.WHITE);
            g.fillRoundRect(0, 0, getWidth(), getHeight(), 20, 20);// 画实心的圆角的矩形
            g.setColor(Color.WHITE);
            g.drawRoundRect(0, 0, getWidth(), getHeight(), 20, 20); // 换个颜色，画圆角的边框
        } finally {
            g.setColor(oldColor);
        }
    }
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlackBerry </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlackBerry 开发：自定义输入框]]></title>
      <url>/2012/04/05/blackberry-customize-input/</url>
      <content type="html"><![CDATA[<pre><code class="JAVA">public InputBoxField(int boxWigth,int boxHeight,String boxText){
    super(Manager.NO_VERTICAL_SCROLL);//禁用垂直滚动
    this._boxHeight = boxHeight;
    this._boxWigth = boxWigth;
    this._boxText = boxText;
        _vfm = new VerticalFieldManager(Manager.NO_VERTICAL_SCROLL);
        //EditField.NO_NEWLINE    设置输入框不可换行
    _ef = new EditField(&quot;&quot;,&quot;&quot;,10,EditField.NO_NEWLINE){
                //创建一个EditedField，并设置其中字符的显示颜色。
            public void paint(Graphics g){
                //getManager().invalidate();
                g.setColor(Color.WHITE);
                super.paint(g);
            }
    };
    _ef.setBackground(BackgroundFactory.createSolidBackground(Color.BLACK));//设置EditedField的背景颜色
    _vfm.add(_ef);
    _vfm.setPadding((_boxHeight-_ef.getFont().getHeight())/2, 10, 10, 5);//设置输入区域和外边框的间距
    add(_vfm);
}
</code></pre>
<p>然后我们需要覆写sublayout方法，告诉布局管理器该组件的大小</p>
<pre><code class="JAVA">protected void sublayout(int maxWidth, int maxHeight) {
    if(_boxWigth == 0){
            _boxWigth = maxWidth;
    }
    if(_boxHeight == 0){
            _boxHeight = maxHeight;
    }
    //super.sublayout(maxWidth, maxHeight);
    setPositionChild(_vfm, 2, 0);
    layoutChild(_vfm, _boxWigth, _boxHeight);
    setExtent(_boxWigth, _boxHeight);
    }
</code></pre>
<p>覆写paint方法，在原有的EditedField的四周换上我们想要的边框并处理焦点事件。</p>
<pre><code class="Java">protected void paint(Graphics g) {
    super.paint(g);
    int oldColor = g.getColor();
    if(this.isFocus()){
            if(_ef.getText().equals(_boxText)){
                    _ef.setText(&quot;&quot;);
            }
            g.setColor(Color.BLUE);
            for(int i =0;i&lt;4;i++){

                    g.drawRoundRect(i,i,getWidth()-i*2,getHeight()-i*2,15,15);
            }       

    }else{
            if(_ef.getText().equals(&quot;&quot;)){
                    _ef.setText(_boxText);
            }

            g.setColor(Color.BLUE);
            g.drawRoundRect(3, 3, getWidth()-6, getHeight()-6,15,15);                }
    g.setColor(oldColor);
}
</code></pre>
<p>接下来覆写onFocus和onUnfocus方法</p>
<pre><code class="java">protected void onFocus(int direction) {
      super.onFocus(direction);
      _ef.setCursorPosition(_ef.getTextLength());
      invalidate();
}

protected void onUnfocus() {
    super.onUnfocus();
    invalidate();
}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlackBerry </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlackBerry 开发：APP 启动 APP]]></title>
      <url>/2012/04/04/blackberry-app-invoke-app/</url>
      <content type="html"><![CDATA[<pre><code>ApplicationManager.getApplicationManager().launch(&quot;AppName&quot;);
</code></pre>]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlackBerry </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlackBerry 开发：黑莓错误代码及解决方法大全]]></title>
      <url>/2012/03/30/blackberry-error-code-and-solution/</url>
      <content type="html"><![CDATA[<p>首先，了解几个名词解释以方便对下文的理解。<br>JVM—Java Virtual Machine(Java虚拟机)<br>C++—一种计算机编程语言<br>GC—Gabage Collection JAVA/.NET中的垃圾回收<br>CRC校验—循环冗余校验码（Cyclic Redundancy Check）<br>JIT编译器—（Just-In-Time）JAVA语言编译器</p>
<h3 id="101-Previous-startup-failed"><a href="#101-Previous-startup-failed" class="headerlink" title="101 Previous startup failed"></a>101 Previous startup failed</h3><p>当jvm（Java虚拟机）启动过程中，前一个启动的项目失败了，设备已经被重置。这个错误表明jvm在启动时找到“启动进行中”这个标志位已经设置了，当前屏幕信息为：有意停止“系统继续重置”这个死循环，来纠正系统当前不正确的启动操作</p>
<h3 id="102-Invalid-code-in-filesystem"><a href="#102-Invalid-code-in-filesystem" class="headerlink" title="102 Invalid code in filesystem"></a>102 Invalid code in filesystem</h3><p>在文件系统中发现无效的代码。手持设备的系统检查.cod文件的变动时，在一些.cod文件中检测到这个问题。他肯可能是表明生成过程中发生了错 误，即在cod文件中存在一个有问题的签名。如果一些用户操作设备导致这个问题的发生，文件系统的代码被破坏，复位的周期将是连续循环的。唯一的恢复方法 是擦去设备并且恢复一个新的系统。</p>
<h3 id="103-Cannot-find-starting-address"><a href="#103-Cannot-find-starting-address" class="headerlink" title="103 Cannot find starting address"></a>103 Cannot find starting address</h3><p>找不到启动的地址，用于启动系统的引导cod文件找不到。这个错误表明一个用于引导系统的cod文件没有安装到设备上，或者格式不正确。</p>
<h3 id="104-Uncaught"><a href="#104-Uncaught" class="headerlink" title="104 Uncaught: "></a>104 Uncaught: <java-type-name></java-type-name></h3><p>非预期：《java模块名》jvm诊断出一个非预期的java代码异常错误抛出，程序可以继续执行，或者手持设备可以用桌面管理器连是USB线安装一个程序调试器来查看这些错误信息。事件日志里应该包含了异常错误的信息</p>
<h3 id="105-Example-DbRecSize"><a href="#105-Example-DbRecSize" class="headerlink" title="105 Example, DbRecSize"></a>105 Example, DbRecSize</h3><p>举例，DbRecSize文件系统API已经为一种特定的操作返回一种错误状态码，他可能表明在jvm上存在一个无效的或者错误的文件系统</p>
<h3 id="106-Graphics-system-error"><a href="#106-Graphics-system-error" class="headerlink" title="106 Graphics system error"></a>106 Graphics system error</h3><p>图形系统错误，在设备的图形系统里一个错误发生并被检测到</p>
<h3 id="107-operator-new-called"><a href="#107-operator-new-called" class="headerlink" title="107 operator new () called"></a>107 operator new () called</h3><p>在jvm里，操作new()回调一个c++类，该函数代码没有被正确的从VMRamObject对象来继承，新操作符需要被正确的继承。提取当前的(-后复位)的BUGDISP</p>
<h3 id="108-operator-delete-called"><a href="#108-operator-delete-called" class="headerlink" title="108 operator delete () called"></a>108 operator delete () called</h3><p>在jvm里，操作delete()回调一个c++类，，该函数代码没有被正确的从VMRamObject对象来继承，新操作符需要被正确的继承。提取当前的(-后复位)的BUGDISP</p>
<h3 id="109-PriorityMessageCount-error"><a href="#109-PriorityMessageCount-error" class="headerlink" title="109 PriorityMessageCount error: "></a>109 PriorityMessageCount error: <priority-count></priority-count></h3><p>优先级统计信息计算错误：&lt;优先级计算&gt;当它应该总大于或者等于零时，RimPriorityMessageCount返回的值是负的。这表明在系统中这是一个错误。<br>提取当前(-后复位)的BUGDISP和查看系统事件记录</p>
<h3 id="110-Non-idle-event-downtime-error"><a href="#110-Non-idle-event-downtime-error" class="headerlink" title="110 Non-idle event downtime error:  "></a>110 Non-idle event downtime error: <down-time> <idle-down-time></idle-down-time></down-time></h3><p>非空闲状态时间事件错误：&lt;时间&gt; &lt;空闲时间&gt;在jvm空闲时间统计时检测到一个错误，代表JVM空闲了很长时间。<br>这通常表明在手持设备或者JVM中发生一个错误。如果计数器空闲了400天以上的设备时间,他也可能出现。</p>
<h3 id="111-Font-engine-error"><a href="#111-Font-engine-error" class="headerlink" title="111 Font engine error"></a>111 Font engine error</h3><p>字体引擎错误：一个系统设备的字体引擎错误检测到。请查看当前的BUGDISP和事件日志</p>
<h3 id="112-Java-Native-Assertion-Failure"><a href="#112-Java-Native-Assertion-Failure" class="headerlink" title="112 Java Native Assertion Failure"></a>112 Java Native Assertion Failure</h3><p>Java本地化实例失败。一个本地化代码错误检测到。请查看当前的BUGDISP和事件日志</p>
<h3 id="200-应用程序管理器抛出一个非预期的线程异常错误，程序无法继续执行。重新复位手持设备。"><a href="#200-应用程序管理器抛出一个非预期的线程异常错误，程序无法继续执行。重新复位手持设备。" class="headerlink" title="200 应用程序管理器抛出一个非预期的线程异常错误，程序无法继续执行。重新复位手持设备。"></a>200 应用程序管理器抛出一个非预期的线程异常错误，程序无法继续执行。重新复位手持设备。</h3><h3 id="201-Crypto-initialization-code-failed"><a href="#201-Crypto-initialization-code-failed" class="headerlink" title="201 Crypto initialization code failed"></a>201 Crypto initialization code failed</h3><p>Crypto初始化代码失败。Crypto模块初始化失败手持设备无法继续</p>
<h3 id="202-在密匙存储上检测到一个破解攻击行为，程序无法继续"><a href="#202-在密匙存储上检测到一个破解攻击行为，程序无法继续" class="headerlink" title="202 在密匙存储上检测到一个破解攻击行为，程序无法继续"></a>202 在密匙存储上检测到一个破解攻击行为，程序无法继续</h3><h3 id="203-Console-process-died"><a href="#203-Console-process-died" class="headerlink" title="203 Console process died"></a>203 Console process died</h3><p>控制台进程死亡。应用程序管理器控制台进程已经挂起。这看起来非常象执行程序时发生异常错误的现象</p>
<h3 id="204-Persistent-Content-Exception"><a href="#204-Persistent-Content-Exception" class="headerlink" title="204 Persistent Content Exception"></a>204 Persistent Content Exception</h3><p>本地内存内容异常。一个应用程序试图提交一个文本对象到本地内存里。这个情况将仅仅发生在：如果内容保护服务打开了，然后一个进程试图保存一些文本 标记数据在本地内存里。当这个异常没有被正确处理过，可能说明本地内存已经处于损坏的状态。我们需要重设和回滚到最后正常状态的提交点。说明：这个jvm 异常反映了在Java代码里有一个错误的地方，Jvm仅仅只是简单的诊断这个错误。如果这不是jvm的问题，那么事件日志将包含足够的Java代码错误信 息。</p>
<h3 id="300-303-Bad-load"><a href="#300-303-Bad-load" class="headerlink" title="300-303 Bad load"></a>300-303 Bad load</h3><p>无效的加载持续，运行应用程序加载器重新给手持设备加载操作系统和应用程序</p>
<h3 id="310-314-Hardware-failure"><a href="#310-314-Hardware-failure" class="headerlink" title="310-314 Hardware failure"></a>310-314 Hardware failure</h3><p>硬件错误。尝试硬复位手持设备：关机，拿掉电池，等待一会儿，换掉电池看看设备重新启动时会出现什么状况，或者运行应用程序加载器重新给手持设备加载操作系统和应用程序。注意：如果这些办法没有解决这个错误，请联系你的服务提供商</p>
<h3 id="320-325-AMX-failure"><a href="#320-325-AMX-failure" class="headerlink" title="320-325 AMX failure"></a>320-325 AMX failure</h3><p>AMX 失败。请运行应用程序加载器重新给手持设备加载操作系统和应用程序</p>
<h3 id="330-339-Application-tasks-failure"><a href="#330-339-Application-tasks-failure" class="headerlink" title="330-339 Application tasks failure"></a>330-339 Application tasks failure</h3><p>应用程序任务失败。请运行应用程序加载器重新给手持设备加载操作系统和应用程序</p>
<h3 id="340-343-Memory-failure"><a href="#340-343-Memory-failure" class="headerlink" title="340-343 Memory failure"></a>340-343 Memory failure</h3><p>内存错误。您可能看到手持设备报告如下错误代码：<br>Device Error 340<br>Device Error 341<br>Device Error 342<br>Device Error 343<br>原因：内存错误<br>解决：减少你手机里日历约会同步的个数<br>1、在桌面管理器里，双击Intellisync图标，点击配置PIM按钮<br>2、在设备应用程序列表中，选择日历<br>3、点击配置，高级设置，<br>4、在数据范围选项页，完成其中的一个任务来减少你手机里日历约会同步的个数，如果你选择了“调度最佳未来项目选择”的选项，手持设备仅仅只是同步未来的日历约会，如果你点击并输入了一个日期范围的调度项目选项，手持设备仅仅只是同步在选择日期范围内的日历计划约会.<br>5、点击OK保存改变，关闭窗口<br>6、在配置窗口，确定日历程序的复选框选择了，点击OK<br>7、在Intellisync窗口，确认同步PIM复选框已经选择了，然后点击立即同步。设备会减少至少一个以上的日历约会项目。<br>如果你仍然看到这个错误信息。请运行应用程序加载器重新给手持设备加载操作系统和应用程序</p>
<h3 id="350-359-Software-application-failure"><a href="#350-359-Software-application-failure" class="headerlink" title="350-359 Software application failure"></a>350-359 Software application failure</h3><p>应用程序软件错误，您可能看到手持设备报告如下错误代码：<br>Device Error 350<br>Device Error 352<br>Device Error 353<br>Device Error 354<br>Device Error 355<br>Device Error 356<br>Device Error 357<br>Device Error 358<br>Device Error 359<br>原因：应用程序软件错误<br>解决方案：尝试硬复位手持设备，运行应用程序加载器重新给手持设备加载操作系统和应用程序。在向导窗口，不要选择任何第三方应用程序。在高级选项里，选择清除当前所有已安装的应用程序复选框。</p>
<h3 id="360-363-Flash-memory-failure"><a href="#360-363-Flash-memory-failure" class="headerlink" title="360-363 Flash memory failure"></a>360-363 Flash memory failure</h3><p>Flash内存错误。尝试硬复位手持设备，运行应用程序加载器重新给手持设备加载操作系统和应用程序。</p>
<h3 id="365-368-This-one-is-often-followed-by-“OHHH-amp-”"><a href="#365-368-This-one-is-often-followed-by-“OHHH-amp-”" class="headerlink" title="365-368 This one is often followed by “OHHH @&amp;#%!!”"></a>365-368 This one is often followed by “OHHH @&amp;#%!!”</h3><p>这是一个经常跟随 “OHHH @&amp;#%!!”出现的错误，请联系服务提供商</p>
<h3 id="395-Unclassified-error-code"><a href="#395-Unclassified-error-code" class="headerlink" title="395 Unclassified error code"></a>395 Unclassified error code</h3><p>未分类的错误代码<br>原因：<br>设备395代码表明是一个未分类的错误代码。手持设备安装了第三方应用程序可能导致了这个错误产生<br>解决方案1<br>尝试硬复位手持设备：关机，拿掉电池，等待一会儿，换掉电池看看设备重新启动时会出现什么状况<br>解决方案2<br>清除和重新加载手持设备的数据<br>1、在黑莓桌面管理器里，用备份和还原工具创建你的手机的数据备份文件。如需更多信息，请参考桌面管理器在线帮助里的“手持设备备份信息”。警告：下面的步骤可能清除手持设备的数据<br>2、打开桌面管理器，双击应用程序加载器图标<br>3、单击下一步，出现应用程序选择窗口<br>4、确认必须的应用程序已经选择了，点击下一步<br>5、点击“高级”<br>6、选择“清除所有的应用程序数据和当前已经安装的应用程序”玄虚，点击下一步<br>7、点击完成。当手持设备的操作系统和应用程序重新加载时，手持设备的数据被清除，<br>8、使用备份和还原工具从备份的数据文件还原到手持设备中，如需更多信息，请参考桌面管理器在线帮助里的“手持设备还原信息”。</p>
<h3 id="400-564-Page-faults"><a href="#400-564-Page-faults" class="headerlink" title="400-564 Page faults"></a>400-564 Page faults</h3><p>页面文件失效。运行应用程序加载器重新给手持设备加载操作系统和应用程序</p>
<h3 id="410-Radio-failure"><a href="#410-Radio-failure" class="headerlink" title="410 Radio failure"></a>410 Radio failure</h3><p>无线电服务失败。<br>尝试硬复位手持设备，运行应用程序加载器重新给手持设备加载操作系统和应用程序。注意：如果这样都没有解决这个错误，请请联系服务提供商<br>Error:411=电池模块问题,更换电池<br>Error:499=软件问题,重启手持设备.</p>
<h3 id="501-VM-THREAD-SWITCHED"><a href="#501-VM-THREAD-SWITCHED" class="headerlink" title="501 VM_THREAD_SWITCHED"></a>501 VM_THREAD_SWITCHED</h3><p>线程已经被切换，内部错误，这是在VM中被内部使用的一个错误返回信息。它应该从会不报告为一个设备错误代码。</p>
<h3 id="502-VM-PROCESS-DEATH"><a href="#502-VM-PROCESS-DEATH" class="headerlink" title="502 VM_PROCESS_DEATH"></a>502 VM_PROCESS_DEATH</h3><p>进程已死（挂起），所有的进程已经退出，最后一个java进程已被终止，没有任何程序可以执行</p>
<h3 id="503-VM-THREAD-DEATH"><a href="#503-VM-THREAD-DEATH" class="headerlink" title="503 VM_THREAD_DEATH"></a>503 VM_THREAD_DEATH</h3><p>线程已死（挂起），内部错误，这是在VM中被内部使用的一个错误返回信息。它应该从不会报告为一个设备错误代码</p>
<h3 id="504-VM-THREAD-SWITCH"><a href="#504-VM-THREAD-SWITCH" class="headerlink" title="504 VM_THREAD_SWITCH"></a>504 VM_THREAD_SWITCH</h3><p>线程已经被切换，内部错误，这是在VM中被内部使用的一个错误返回信息。它应该从不会报告为一个设备错误代码</p>
<h3 id="505-VM-BAD-CODE5-I"><a href="#505-VM-BAD-CODE5-I" class="headerlink" title="505 VM_BAD_CODE5 I"></a>505 VM_BAD_CODE5 I</h3><p>无效的代码：无效字节代码，在JIT编译器里发生一个错误</p>
<h3 id="506-Uncaught-Exception"><a href="#506-Uncaught-Exception" class="headerlink" title="506 Uncaught Exception"></a>506 Uncaught Exception</h3><p>未知的异常：在初始化VM的java线程的时候一个未知的java异常被抛出，导致了系统被迫结束了唯一活动的线程。事件日志包含了异常的回滚记录!</p>
<h3 id="507-Unsatisfied-Link"><a href="#507-Unsatisfied-Link" class="headerlink" title="507 Unsatisfied Link"></a>507 Unsatisfied Link</h3><p>在cod文件里有不合适的文件链接关联，可能丢失了cod文件，（原文的英文是如此）<br>Device Error 5059<br>Device Error 5077<br>手持设备没有安装任何应用程序<br>原因1<br>当应用程序加载器工作时，黑莓设备上存在的应用程序已经被清除，但应用程序加载器加载新的应用程序时失败了<br>解决方案<br>1、确认你的电脑上已经正确安装了设备软件<br>2、请直接将您的黑莓设备直接连接到一台笔记本电脑的USB接口处<br>3、如果第三方程序（如：杀毒软件）已经使用了和桌面管理器手持设备的相同的COM端口，关闭第三方程序来释放COM端口<br>4、如果你使用USB数据线链接黑莓设备到你的电脑的串口，请用USB端口直接链接BB<br>5、在桌面管理器里，双击应用程序加载器<br>6、用应用程序加载器安装设备系统软件<br>原因2<br>如果你输入密码错误超过10次，你bb上所有的数据和程序都会被清除<br>解决<br>1、在桌面管理器里，双击应用程序加载器<br>2、用应用程序加载器安装设备系统软件</p>
<h3 id="508-Invalid-object"><a href="#508-Invalid-object" class="headerlink" title="508 Invalid object"></a>508 Invalid object</h3><p>无效的对象，当vm执行一个调试器命令时检测到一个问题：无效的对象</p>
<h3 id="509-VM-PPO-INFINITE-LOOP"><a href="#509-VM-PPO-INFINITE-LOOP" class="headerlink" title="509 VM_PPO_INFINITE_LOOP"></a>509 VM_PPO_INFINITE_LOOP</h3><p>在垃圾手机的PPO阶段中发现死循环，在GC的PPO阶段中，最大的迭代总数必须是系统中的文件句柄的最大数字。这个错误表明这个迭代总数已经超过 这个数，因而在PPO循环中或者不正确的文件系统中出现了一个瑕疵。在错误字符串中可以提取到一个特别的16进制整数值，是当前检测到的死循环记录的id 值</p>
<h3 id="510-Deadlock"><a href="#510-Deadlock" class="headerlink" title="510 Deadlock"></a>510 Deadlock</h3><p>死锁，所有的线程对象都在等待，但一个线程返回结果时已经死锁了。系统不能从这个死锁状态中恢复，因为所有的线程都被锁定了。</p>
<h3 id="511-Debug-connection-died"><a href="#511-Debug-connection-died" class="headerlink" title="511 Debug connection died"></a>511 Debug connection died</h3><p>调试器连接已经死锁，当调试的时候，vm的问题或者不正确的调试命令发送给vm时，可能导致这个问题发生</p>
<h3 id="512-GC-Aborted"><a href="#512-GC-Aborted" class="headerlink" title="512 GC Aborted"></a>512 GC Aborted</h3><p>GC（垃圾收集）已经终止，空间垃圾收集器程序被用户操作事件强制终止了，诸如挤压键盘或者移动滚轮操作</p>
<h3 id="513-needs-running"><a href="#513-needs-running" class="headerlink" title="513  needs running"></a>513 <clinit> needs running</clinit></h3><p><clinit>类需要先运行。此类名<clinit>能继续执行之前要求执行一个opcode，。</clinit></clinit></p>
<h3 id="514-needs-running"><a href="#514-needs-running" class="headerlink" title="514  needs running"></a>514 <init> needs running</init></h3><p><init>需要运行。一个新的类实例在使用之前必须通过默认构造函数初始化和分配内存空间。</init></p>
<h3 id="515-Object-group-too-big"><a href="#515-Object-group-too-big" class="headerlink" title="515 Object group too big"></a>515 Object group too big</h3><p>对象组太大。jvm不能正确的获得对象组，不是因为对象太多就是因为对象组太大</p>
<h3 id="516-Persistent-ids-exhausted"><a href="#516-Persistent-ids-exhausted" class="headerlink" title="516 Persistent ids exhausted"></a>516 Persistent ids exhausted</h3><p>ids固件设备衰竭。当访问一个固件对象时，jvm发现这个本地内存id计数器已经达到最大限制。对象不能被提交，同时报告一个致命的错误。这个错误可能从不会发生，除非这个设备大量使用了数年之久。</p>
<h3 id="517-Filesystem-corrupt"><a href="#517-Filesystem-corrupt" class="headerlink" title="517 Filesystem corrupt"></a>517 Filesystem corrupt</h3><p>文件系统不正确。在jvm本地内存里检测到一个错误（矛盾）的分配地址</p>
<h3 id="518-Unexpected-longjmp5"><a href="#518-Unexpected-longjmp5" class="headerlink" title="518 Unexpected longjmp5"></a>518 Unexpected longjmp5</h3><p>意外的longjmp指令。一个垃圾收集器指令方面结束了一个longjmp指令。这可能表明当指令没有中断即将完成操作时，这个标记阶段被这个错误中断了。这个情况应该从不会发生，因为当设备非空闲的时候，这些操作会被执行，同时,<br>仅仅当设备空闲时,垃圾收集器的工作才会被中断</p>
<h3 id="519-Internal-Error"><a href="#519-Internal-Error" class="headerlink" title="519 Internal Error"></a>519 Internal Error</h3><p>内部服务器错误。Jvm系统丢失或者被禁止</p>
<h3 id="520-Internal-Return"><a href="#520-Internal-Return" class="headerlink" title="520 Internal Return"></a>520 Internal Return</h3><p>内部返回一个错误，表明一个java方法返回的一种内部的状态需要执行</p>
<h3 id="521-Dangerous-Wait-An-Object"><a href="#521-Dangerous-Wait-An-Object" class="headerlink" title="521 Dangerous Wait An Object"></a>521 Dangerous Wait An Object</h3><p>一个危险的等待对象。一个线程执行Wait（）方法时被另外一个对象锁定。这个仅仅在基于jvm的模拟器里控制调试应用程序切换时才会检查</p>
<h3 id="522-Interlaced-synchronization"><a href="#522-Interlaced-synchronization" class="headerlink" title="522 Interlaced synchronization"></a>522 Interlaced synchronization</h3><p>交互式同步错误，对象的线程已经通过一个命令获得了2个锁定，但是，这2个已经取得的锁定类型并不匹配线程被锁定之前的命令。这表明一个即将发生潜在的死锁情况被报告。这个仅仅在基于jvm的模拟器里控制调试应用程序切换时才会检查</p>
<h3 id="523-System-process-died"><a href="#523-System-process-died" class="headerlink" title="523 System process died"></a>523 System process died</h3><p>系统进程已死（挂起）。一个致命的java程序错误导致系统已经被终止，设备无法继续正常的操作，请复位重新启动手持设备。</p>
<h3 id="524-LMM-error"><a href="#524-LMM-error" class="headerlink" title="524 LMM error"></a>524 LMM error</h3><p>LMM错误。一个对象被低内存管理器作了回收标记，但内存垃圾收集时他没有被正确释放。这个仅仅在基于jvm的模拟器里控制调试应用程序切换时才会检查</p>
<h3 id="525-Bad-persistent-object"><a href="#525-Bad-persistent-object" class="headerlink" title="525 Bad persistent object"></a>525 Bad persistent object</h3><p>损坏的本地内存对象。当垃圾收集期间，从本地内存根目录检测到一个自动操作提交到了一个非持久本地对象，这个类型的对象已经记录到事件日志里了</p>
<h3 id="526-java-lang-Object-not-found"><a href="#526-java-lang-Object-not-found" class="headerlink" title="526 java.lang.Object not found"></a>526 java.lang.Object not found</h3><p>类定义java.lang.Object对象未找到。</p>
<h3 id="527-java-lang-String-not-found"><a href="#527-java-lang-String-not-found" class="headerlink" title="527 java.lang.String not found"></a>527 java.lang.String not found</h3><p>类定义java.lang.String对象未找到</p>
<h3 id="528-–529-Corrupt-filesystem"><a href="#528-–529-Corrupt-filesystem" class="headerlink" title="528 –529 Corrupt filesystem"></a>528 –529 Corrupt filesystem</h3><p>错误的文件系统。不可恢复的错误，继续执行的话将会导致所有数据丢失。这个错误信息包含了内部“错误原因”的数字代码。<br>jvm编译器常见错误代码<br>1.根数组引用不是有效的数组引用<br>2.根数组类型不是Object[]<br>3.根数组大小小于1，如Object[0]</p>
<ol>
<li>root[0]里的内存不是有效的引用</li>
<li>root[0]类型不是一个长整型哈希表<br>6.数组头部段包含一个无效的引用</li>
<li>在本地Object[]的一个项目中包含一个无效的引用<br>8.一个对象类型引用了一个未知的cod文件<br>9.在内存里，一个cod文件中的对象的类型描叙文件大小不匹配</li>
<li>一个对象里面有一个无效的类型字段引用<br>11.对象中一个引用的类型字段链接到了另一对象的无效类型<br>12.在描叙符中一个本地Object[]丢失!<br>13.在本地内存中对象没有被标记为persis表<br>14.根数组被分割，一个分隔段无效<h3 id="530-VM-PREVENT-GC-OVERFLOW"><a href="#530-VM-PREVENT-GC-OVERFLOW" class="headerlink" title="530 VM_PREVENT_GC_OVERFLOW"></a>530 VM_PREVENT_GC_OVERFLOW</h3>_preventGC 溢出。原始对象的固定值会被保护起来防止被垃圾收集器收走。这个错误表明,<br>数值可能超出了被保护对象的固定的极限。如果设备被重置或者线程回滚事件被记录，这个实际的数值可以提取出来。<h3 id="531-Flash-exhausted"><a href="#531-Flash-exhausted" class="headerlink" title="531 Flash exhausted"></a>531 Flash exhausted</h3>内存已经耗尽用完。jvm无法容许超出内存空间的某些操作。如果jvm无法完成分配需要的内存空间大小，将会报告这个错误<h3 id="532-VM-ASSERTION-FAILED"><a href="#532-VM-ASSERTION-FAILED" class="headerlink" title="532 VM_ASSERTION_FAILED"></a>532 VM_ASSERTION_FAILED</h3>维护任务失败。通常，当设备没有启动允许维护状态时，这个jvm错误一般不会被报告，模拟器在调试状态时可能会报告这个错误，表明一个vm维护操作违反了约定。可以尝试输入BKPT来激活调试器，然后转储这个本地堆栈转交给vm组<h3 id="533-VM-RUN-METHOD"><a href="#533-VM-RUN-METHOD" class="headerlink" title="533 VM_RUN_METHOD"></a>533 VM_RUN_METHOD</h3><method>方法需要使用国际标准的ECMAScript脚本调用方法才能运行<h3 id="534-VM-FAST-RESET-DISABLED"><a href="#534-VM-FAST-RESET-DISABLED" class="headerlink" title="534 VM_FAST_RESET_DISABLED"></a>534 VM_FAST_RESET_DISABLED</h3>快速复位被禁止。内部过去经常用这个代码表示快速复位能力是无效的。请经常使用平台制定的代码<h3 id="535-VM-UNUSED-535"><a href="#535-VM-UNUSED-535" class="headerlink" title="535 VM_UNUSED_535"></a>535 VM_UNUSED_535</h3>未使用的vm错误。错误535意味着内存溢出。导致535错误的一个原因可能是一个运行的线程内存溢出，导致虚拟内存线程计划任务程序终止了。这个错误是已知的，发生在一个启动的队列期间，或如果主事件线程被停止了。<br>解决方案：<br>首先，硬启动手持设备。如果不能解决问题，从你的载体获得并安装最新版的黑莓手持设备ROM软件，然后，运行桌面管理器里的应用程序加载器更新手持设备。或者删除一些铃声和主题文件等等以释放存储空间<h3 id="536-VM-FAST-RESET-BAD-INSTANCE"><a href="#536-VM-FAST-RESET-BAD-INSTANCE" class="headerlink" title="536 VM_FAST_RESET_BAD_INSTANCE"></a>536 VM_FAST_RESET_BAD_INSTANCE</h3>vm快速复位实例检查失败。内部过去经常用这个代码表示：vm结构跳过了错误的地址空间或者vm已经被破坏了<h3 id="537-VM-FAST-RESET-BAD-HEAP"><a href="#537-VM-FAST-RESET-BAD-HEAP" class="headerlink" title="537 VM_FAST_RESET_BAD_HEAP"></a>537 VM_FAST_RESET_BAD_HEAP</h3>快速复位错误，堆检查失败。内部过去经常用这个代码表示：vm堆已经无效了，或者指针堆已经无效</method></li>
</ol>
<h3 id="538-VM-FAST-RESET-BAD-IRAM"><a href="#538-VM-FAST-RESET-BAD-IRAM" class="headerlink" title="538 VM_FAST_RESET_BAD_IRAM"></a>538 VM_FAST_RESET_BAD_IRAM</h3><p>快速复位IRAM损害，IRAM检查失败。内部过去经常用这个代码表示：vm的IRAM检查中检测到寄存在IRAM中无效的vm数据结构（线程+本地堆栈），或者指针</p>
<h3 id="539-VM-FAST-RESET-NOT-IDLE"><a href="#539-VM-FAST-RESET-NOT-IDLE" class="headerlink" title="539 VM_FAST_RESET_NOT_IDLE"></a>539 VM_FAST_RESET_NOT_IDLE</h3><p>快速复位状态非空闲。内部过去经常用这个代码表示：当复位发生时vm正忙，类似这样的问题导致快速复位无法继续</p>
<h3 id="540-VM-FAST-RESET-MULTIPLE-RESETS"><a href="#540-VM-FAST-RESET-MULTIPLE-RESETS" class="headerlink" title="540 VM_FAST_RESET_MULTIPLE_RESETS"></a>540 VM_FAST_RESET_MULTIPLE_RESETS</h3><p>多重复位错误。内部过去经常用这个代码表示：最近一次复位的时间小于最小复位时间间隔。由于禁止了短时间内多重复位次数，这个可以防止快速复位的死循环</p>
<h3 id="541-VM-HEAP-COMPACT-INFINITE-LOOP"><a href="#541-VM-HEAP-COMPACT-INFINITE-LOOP" class="headerlink" title="541 VM_HEAP_COMPACT_INFINITE_LOOP"></a>541 VM_HEAP_COMPACT_INFINITE_LOOP</h3><p>在堆压缩中检测到死循环。Vm在内存堆里检测到一个问题，表明这个内存块是无效的。当进行内存堆压缩时，在确认一个可能的死循环时这个问题可以被检 测到，当设备包含了这个错误条件时，bugdisp记录和事件日志可以快速提取这个错误信息。如果可能的话，内存映像将会保存下来。</p>
<h3 id="542-Transient-memory-leak"><a href="#542-Transient-memory-leak" class="headerlink" title="542 Transient memory leak"></a>542 Transient memory leak</h3><p>瞬间内存泄露。Jvm检测到某些内存没有被释放，这表明发生了内存泄露。希望原因能够尽早检测出来，避免这个情况的发生</p>
<h3 id="543-VM-FS-MISMATCH"><a href="#543-VM-FS-MISMATCH" class="headerlink" title="543 VM_FS_MISMATCH"></a>543 VM_FS_MISMATCH</h3><p>文件系统不匹配。安装了不兼容的java文件系统。Jvm检测到现有的系统代码和经常用于创建java文件系统的系统代码有不同。这意味着java本地方法可能没有被正确的编译链接，所以，不能肯定系统的完整性。系统无法通过使用vm<br>DLFX和DLPS命令恢复，也不能删除或修理本地内存的错误。这可能清除所有的数据和固件内容，请重新链接编译文件系统，才能匹配新的系统代码。恢复顺序非常<br>重要：1.删除应用程序，2.删除本地内存内容，3.复位设备</p>
<h3 id="544-VM-SECTION-MAP-OVERFLOW"><a href="#544-VM-SECTION-MAP-OVERFLOW" class="headerlink" title="544 VM_SECTION_MAP_OVERFLOW"></a>544 VM_SECTION_MAP_OVERFLOW</h3><p>一个模块引用超过了255个其他模块。Vm检测到一个模块试图引用超过了255个其他的模块。当错误检测到的时候，文件系统应该立即获取到该错误</p>
<h3 id="545-VM-INCOMPATIBLE-FILESYS"><a href="#545-VM-INCOMPATIBLE-FILESYS" class="headerlink" title="545 VM_INCOMPATIBLE_FILESYS"></a>545 VM_INCOMPATIBLE_FILESYS</h3><p>Vm检测到一个不兼容的或无效的文件系统存在。当错误检测到的时候，文件系统应该立即获取到该错误</p>
<h3 id="546-VM-UNUSED-546"><a href="#546-VM-UNUSED-546" class="headerlink" title="546 VM_UNUSED_546"></a>546 VM_UNUSED_546</h3><p>未使用（的内部错误代码）。Vm检测到文件系统中的内存映像是无效的（CRC冗余检查失败），重新复位机器好过复制错误的内存<br>内容</p>
<h3 id="547-VM-UNUSED-547"><a href="#547-VM-UNUSED-547" class="headerlink" title="547 VM_UNUSED_547"></a>547 VM_UNUSED_547</h3><p>未使用（的内部错误代码）。Vm错误</p>
<h3 id="548-VM-UNUSED-548"><a href="#548-VM-UNUSED-548" class="headerlink" title="548 VM_UNUSED_548"></a>548 VM_UNUSED_548</h3><p>未使用（的内部错误代码）。Vm错误</p>
<h3 id="549-VM-UNUSED-549"><a href="#549-VM-UNUSED-549" class="headerlink" title="549 VM_UNUSED_549"></a>549 VM_UNUSED_549</h3><p>未使用（的内部错误代码）。Vm错误</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlackBerry </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlackBerry 开发：读系统参数]]></title>
      <url>/2012/02/16/blackberry-reading-system-properties/</url>
      <content type="html"><![CDATA[<pre><code class="JAVA">String deviceId = DeviceInfo.getDeviceId() + &quot;&quot;;
String deviceName = DeviceInfo.getDeviceName();
String softName = DeviceInfo.getSoftwareVersion();
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlackBerry </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[BlackBerry 开发：自定义图片背景的 button]]></title>
      <url>/2011/09/23/blaskberry-button-with-customize-image-background/</url>
      <content type="html"><![CDATA[<pre><code class="java">/**
 * 自定义图片背景的button
 *
 * @author Rolex
 * @date 2011-9-23
 */
public class BitmapBackgroundButtonField extends Field {      
    private String _label;
    private int _labelHeight;
    private int _labelWidth;
    private Font _font;

    private Bitmap _currentBitmap;
    private Bitmap _onBitmap;
    private Bitmap _offBitmap;

    /**
     * Constructor.
     * @param text The text to be displayed on the button
     * @param style Combination of field style bits to specify display attributes
     */
    public BitmapBackgroundButtonField(String text, long style,Bitmap bitmap1, Bitmap bitmap2)
    {
        super(style);

        _font = getFont();
        _label = text;
        _labelHeight = _font.getHeight();
        _labelWidth = _font.getAdvance(_label);
        _onBitmap = bitmap1;
        _offBitmap = bitmap2;
        _currentBitmap = _offBitmap;
    }

    /**
     * @return The text on the button
     */
    String getText()
    {
        return _label;
    }

    /**
     * Field implementation.
     * @see net.rim.device.api.ui.Field#getPreferredHeight()
     */
    public int getPreferredHeight()
    {
        return 90;
    }

    /**
     * Field implementation.
     * @see net.rim.device.api.ui.Field#getPreferredWidth()
     */
    public int getPreferredWidth()
    {
        return 70;
    }

    /**
     * Field implementation.  Changes the picture when focus is gained.
     * @see net.rim.device.api.ui.Field#onFocus(int)
     */
    protected void onFocus(int direction)
    {
      _currentBitmap = _onBitmap;
        invalidate();
    }

    /**
     * Field implementation.  Changes picture back when focus is lost.
     * @see net.rim.device.api.ui.Field#onUnfocus()
     */
    protected void onUnfocus()
    {
      _currentBitmap = _offBitmap;
        invalidate();
    }

    /**
     * Field implementation.
     * @see net.rim.device.api.ui.Field#drawFocus(Graphics, boolean)
     */
    protected void drawFocus(Graphics graphics, boolean on)
    {
    }

    /**
     * Field implementation.
     * @see net.rim.device.api.ui.Field#layout(int, int)
     */
    protected void layout(int width, int height)
    {
        setExtent(Math.min( width, getPreferredWidth()),
        Math.min( height, getPreferredHeight()));
    }

    /**
     * Field implementation.
     * @see net.rim.device.api.ui.Field#paint(Graphics)
     */
    protected void paint(Graphics graphics)
    {      
        // First draw the background colour and picture
        graphics.setColor(Color.WHITE);
        graphics.fillRect(0, 0, getWidth(), getHeight());
        graphics.drawBitmap(0, 0, getWidth(), getHeight(), _currentBitmap, 0, 0);

        // Then draw the text
        graphics.setColor(Color.BLACK);
        graphics.setFont(_font.derive(Font.BOLD, 13));

//        graphics.drawText(_label, 4, 70,
//            (int)( getStyle() &amp; DrawStyle.ELLIPSIS | DrawStyle.HALIGN_MASK ),
//            getWidth() - 6 );
        graphics.drawText(_label, 0, _currentBitmap.getHeight() + 4, graphics.HCENTER);
    }

    /**
     * Overridden so that the Event Dispatch thread can catch this event
     * instead of having it be caught here..
     * @see net.rim.device.api.ui.Field#navigationClick(int, int)
     */
    protected boolean navigationClick(int status, int time)
    {
        fieldChangeNotify(1);
        return true;
    }

}
</code></pre>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlackBerry </tag>
            
        </tags>
        
    </entry>
    
  
  
    
    <entry>
      <title></title>
      <url>/404.html</url>
      <content type="html"><![CDATA[<div class="row margin-bottom-40">
<!-- BEGIN CONTENT -->
<div class="col-md-12 col-sm-12">
  <br><br><br><br>
  <div class="content-page page-404">
    <div class="number">
      404
    </div>
    <div class="details">
      <h3>Oops!  You're lost.</h3>
      <p>
      We can not find the page you're looking for.<br>
      <a href="/index.html" class="link">Return home</a> or try the search bar below.
      </p>
    </div>
  </div>
  <br><br><br><br>
</div>
<!-- END CONTENT -->
</div>
]]></content>
    </entry>
    
    <entry>
      <title></title>
      <url>/index.html</url>
      <content type="html"><![CDATA[<div class="container-fluid flush-with-header">
  <div class="row margin-bottom-40 row-corporate bg-light-1">
    <div class="container">
      <div class="col-xs-8 col-sm-6 row-corporate-text-container">
	<div class="row-corporate-text">
	  <h1>We are here to <b class="require">help you</b>.</h1>
	  <h4 class="wow fadeIn">Lorem ipsum dolor sit amet, dolore eiusmod quis
	  tempor incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde omnis
	  iste natus error sit voluptatem.</h4>
	</div>
      </div>
      <div class="col-xs-4 col-sm-6">
	<img src="/metronic/assets/pages/img/frontend-slider/ipadmini.png">
      </div>
    </div>
  </div>
</div>
<div class="container">
    <div class="row service-box margin-bottom-40">
      <div class="col-md-4 col-sm-4">
	<div class="service-box-heading">
	  <em><i class="fa fa-location-arrow blue wow rollIn"></i></em>
	  <span>Multipurpose Template</span>
	</div>
	<p>Lorem ipsum dolor sit amet, dolore eiusmod quis tempor incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde omnis iste natus error sit voluptatem.</p>
	  <img class="img-responsive" src="/asset1.png">
      </div>
      <div class="col-md-4 col-sm-4">
	<div class="service-box-heading">
	  <em><i class="fa fa-check red wow rollIn"></i></em>
	  <span>Well Documented</span>
	</div>
	<p>Lorem ipsum dolor sit amet, dolore eiusmod quis tempor incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde omnis iste natus error sit voluptatem.</p>
	  <img class="img-responsive" src="/asset3.jpg">
      </div>
      <div class="col-md-4 col-sm-4">
	<div class="service-box-heading">
	  <em><i class="fa fa-compress green wow rollIn"></i></em>
	  <span>Responsive Design</span>
	</div>
	<p>Lorem ipsum dolor sit amet, dolore eiusmod quis tempor incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde omnis iste natus error sit voluptatem.</p>
	  <img class="img-responsive" src="/asset1.jpg">
      </div>
    </div>
    </div>
<div class="container-fluid">
<div class="row margin-bottom-40 row-corporate bg-light-2">
  <div class="container">
    <div class="col-xs-4 col-xs-pull-4 col-sm-pull-0 col-sm-6 wow fadeIn">
      <img src="/metronic/assets/pages/img/frontend-slider/iphone_right.png">
    </div>
    <div class="col-xs-6 row-corporate-text-container">
    <div class="row-corporate-text">
      <h1>We're committed to our <b class="wow fadeIn require">process</b>.</h1>
      <h4 class="wow fadeIn">Lorem ipsum dolor sit amet, dolore eiusmod quis
      tempor incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde
      omnis iste.</h4>
    </div>
    </div>
  </div>
</div>
</div>

<div class="main">
  <div class="container">
    <!-- BEGIN STEPS -->
    <div class="row margin-bottom-40 front-steps-wrapper front-steps-count-3 wow
    fadeIn">
      <div class="col-md-4 col-sm-4 front-step-col">
	<div class="front-step front-step1">
	  <h2>Goal definition</h2>
	  <p>Lorem ipsum dolor sit amet sit consectetur adipisicing eiusmod tempor.</p>
	</div>
      </div>
      <div class="col-md-4 col-sm-4 front-step-col">
	<div class="front-step front-step2">
	  <h2>Analyse</h2>
	  <p>Lorem ipsum dolor sit amet sit consectetur adipisicing eiusmod tempor.</p>
	</div>
      </div>
      <div class="col-md-4 col-sm-4 front-step-col">
	<div class="front-step front-step3">
	  <h2>Implementation</h2>
	  <p>Lorem ipsum dolor sit amet sit consectetur adipisicing eiusmod tempor.</p>
	</div>
      </div>
    </div>
    <!-- END STEPS -->

    <!-- BEGIN RECENT WORKS -->
    <div class="row recent-work margin-bottom-40">
      <div class="col-md-3">
	<h2 class="wow fadeIn"><a href="/projects/">Recent Work</a></h2>
	<p class="wow fadeIn">Lorem ipsum dolor sit amet, dolore eiusmod quis tempor incididunt ut et dolore Ut veniam unde voluptatem. Sed unde omnis iste natus error sit voluptatem.</p>
      </div>
      <div class="col-md-9">
	<div class="owl-carousel owl-carousel3">
	  <div class="recent-work-item">
	    <em>
	      <img src="metronic/assets/pages/img/works/img1.jpg" alt="Amazing Project" class="img-responsive">
	      <a href="portfolio-item.html"><i class="fa fa-link"></i></a>
	      <a href="metronic/assets/pages/img/works/img1.jpg" class="fancybox-button" title="Project Name #1" data-rel="fancybox-button"><i class="fa fa-search"></i></a>
	    </em>
	    <a class="recent-work-description" href="/projects/#project1">
	      <strong>Amazing Project</strong>
	      <b>Agenda corp.</b>
	    </a>
	  </div>
	  <div class="recent-work-item">
	    <em>
	      <img src="metronic/assets/pages/img/works/img2.jpg" alt="Amazing Project" class="img-responsive">
	      <a href="portfolio-item.html"><i class="fa fa-link"></i></a>
	      <a href="metronic/assets/pages/img/works/img2.jpg" class="fancybox-button" title="Project Name #2" data-rel="fancybox-button"><i class="fa fa-search"></i></a>
	    </em>
	    <a class="recent-work-description" href="/projects/#project1">
	      <strong>Amazing Project</strong>
	      <b>Agenda corp.</b>
	    </a>
	  </div>
	  <div class="recent-work-item">
	    <em>
	      <img src="metronic/assets/pages/img/works/img3.jpg" alt="Amazing Project" class="img-responsive">
	      <a href="portfolio-item.html"><i class="fa fa-link"></i></a>
	      <a href="metronic/assets/pages/img/works/img3.jpg" class="fancybox-button" title="Project Name #3" data-rel="fancybox-button"><i class="fa fa-search"></i></a>
	    </em>
	    <a class="recent-work-description" href="/projects/#project1">
	      <strong>Amazing Project</strong>
	      <b>Agenda corp.</b>
	    </a>
	  </div>
	  <div class="recent-work-item">
	    <em>
	      <img src="metronic/assets/pages/img/works/img4.jpg" alt="Amazing Project" class="img-responsive">
	      <a href="portfolio-item.html"><i class="fa fa-link"></i></a>
	      <a href="metronic/assets/pages/img/works/img4.jpg" class="fancybox-button" title="Project Name #4" data-rel="fancybox-button"><i class="fa fa-search"></i></a>
	    </em>
	    <a class="recent-work-description" href="/projects/#project1">
	      <strong>Amazing Project</strong>
	      <b>Agenda corp.</b>
	    </a>
	  </div>
	  <div class="recent-work-item">
	    <em>
	      <img src="metronic/assets/pages/img/works/img5.jpg" alt="Amazing Project" class="img-responsive">
	      <a href="portfolio-item.html"><i class="fa fa-link"></i></a>
	      <a href="metronic/assets/pages/img/works/img5.jpg" class="fancybox-button" title="Project Name #5" data-rel="fancybox-button"><i class="fa fa-search"></i></a>
	    </em>
	    <a class="recent-work-description" href="/projects/#project1">
	      <strong>Amazing Project</strong>
	      <b>Agenda corp.</b>
	    </a>
	  </div>
	  <div class="recent-work-item">
	    <em>
	      <img src="metronic/assets/pages/img/works/img6.jpg" alt="Amazing Project" class="img-responsive">
	      <a href="portfolio-item.html"><i class="fa fa-link"></i></a>
	      <a href="metronic/assets/pages/img/works/img6.jpg" class="fancybox-button" title="Project Name #6" data-rel="fancybox-button"><i class="fa fa-search"></i></a>
	    </em>
	    <a class="recent-work-description" href="/projects/#project1">
	      <strong>Amazing Project</strong>
	      <b>Agenda corp.</b>
	    </a>
	  </div>
	  <div class="recent-work-item">
	    <em>
	      <img src="metronic/assets/pages/img/works/img3.jpg" alt="Amazing Project" class="img-responsive">
	      <a href="portfolio-item.html"><i class="fa fa-link"></i></a>
	      <a href="metronic/assets/pages/img/works/img3.jpg" class="fancybox-button" title="Project Name #3" data-rel="fancybox-button"><i class="fa fa-search"></i></a>
	    </em>
	    <a class="recent-work-description" href="/projects/#project1">
	      <strong>Amazing Project</strong>
	      <b>Agenda corp.</b>
	    </a>
	  </div>
	  <div class="recent-work-item">
	    <em>
	      <img src="metronic/assets/pages/img/works/img4.jpg" alt="Amazing Project" class="img-responsive">
	      <a href="portfolio-item.html"><i class="fa fa-link"></i></a>
	      <a href="metronic/assets/pages/img/works/img4.jpg" class="fancybox-button" title="Project Name #4" data-rel="fancybox-button"><i class="fa fa-search"></i></a>
	    </em>
	    <a class="recent-work-description" href="/projects/#project1">
	      <strong>Amazing Project</strong>
	      <b>Agenda corp.</b>
	    </a>
	  </div>
	</div>       
      </div>
    </div>   
    <!-- END RECENT WORKS -->

    <!-- BEGIN TABS AND TESTIMONIALS -->
    <div class="row mix-block margin-bottom-40">
      <!-- TABS -->
      <div class="col-md-7 tab-style-1">
	<ul class="nav nav-tabs">
	  <li class="active"><a href="#tab-1" data-toggle="tab">Multipurpose</a></li>
	  <li><a href="#tab-2" data-toggle="tab">Documented</a></li>
	  <li><a href="#tab-3" data-toggle="tab">Responsive</a></li>
	  <li><a href="#tab-4" data-toggle="tab">Clean & Fresh</a></li>
	</ul>
	<div class="tab-content">
	  <div class="tab-pane row fade in active" id="tab-1">
	    <div class="col-md-3 col-sm-3">
	      <a href="metronic/assets/pages/img/works/img6.jpg" class="fancybox-button" title="Image Title" data-rel="fancybox-button">
		<img class="img-responsive" src="metronic/assets/pages/img/works/img6.jpg" alt="">
	      </a>
	    </div>
	    <div class="col-md-9 col-sm-9">
	      <p class="margin-bottom-10">Raw denim you probably haven't heard of them jean shorts Austin. Nesciunt tofu stumptown aliqua, retro synth master cleanse. Mustache cliche tempor, williamsburg carles vegan helvetica. Cosby sweater eu banh mi, qui irure terry richardson ex squid Aliquip placeat salvia cillum iphone.</p>
	      <p><a class="more" href="javascript:;" target="_blank" rel="external">Read more <i class="icon-angle-right"></i></a></p>
	    </div>
	  </div>
	  <div class="tab-pane row fade" id="tab-2">
	    <div class="col-md-9 col-sm-9">
	      <p>Food truck fixie locavore, accusamus mcsweeney's marfa nulla single-origin coffee squid. Exercitation +1 labore velit, blog sartorial PBR leggings next level wes anderson artisan four loko farm-to-table craft beer twee. Qui photo booth letterpress, commodo enim craft beer mlkshk aliquip jean shorts ullamco ad vinyl cillum PBR. Homo nostrud organic, assumenda labore aesthetic magna delectus mollit. Keytar helvetica VHS salvia..</p>
	    </div>
	    <div class="col-md-3 col-sm-3">
	      <a href="metronic/assets/temp/works/img10.jpg" class="fancybox-button" title="Image Title" data-rel="fancybox-button">
		<img class="img-responsive" src="metronic/assets/pages/img/works/img1.jpg" alt="">
	      </a>
	    </div>
	  </div>
	  <div class="tab-pane fade" id="tab-3">
	    <p>Etsy mixtape wayfarers, ethical wes anderson tofu before they sold out mcsweeney's organic lomo retro fanny pack lo-fi farm-to-table readymade. Messenger bag gentrify pitchfork tattooed craft beer, iphone skateboard locavore carles etsy salvia banksy hoodie helvetica. DIY synth PBR banksy irony. Leggings gentrify squid 8-bit cred pitchfork. Williamsburg banh mi whatever gluten-free, carles pitchfork biodiesel fixie etsy retro mlkshk vice blog. Scenester cred you probably haven't heard of them, vinyl craft beer blog stumptown. Pitchfork sustainable tofu synth chambray yr.</p>
	  </div>
	  <div class="tab-pane fade" id="tab-4">
	    <p>Trust fund seitan letterpress, keytar raw denim keffiyeh etsy art party before they sold out master cleanse gluten-free squid scenester freegan cosby sweater. Fanny pack portland seitan DIY, art party locavore wolf cliche high life echo park Austin. Cred vinyl keffiyeh DIY salvia PBR, banh mi before they sold out farm-to-table VHS viral locavore cosby sweater. Lomo wolf viral, mustache readymade thundercats keffiyeh craft beer marfa ethical. Wolf salvia freegan, sartorial keffiyeh echo park vegan.</p>
	  </div>
	</div>
      </div>
      <!-- END TABS -->

      <!-- TESTIMONIALS -->
      <div class="col-md-5 testimonials-v1">
	<div id="myCarousel" class="carousel slide">
	  <!-- Carousel items -->
	  <div class="carousel-inner">
	    <div class="active item">
	      <blockquote><p>Denim you probably haven't heard of. Lorem ipsum dolor met consectetur adipisicing sit amet, consectetur adipisicing elit, of them jean shorts sed magna aliqua. Lorem ipsum dolor met.</p></blockquote>
	      <div class="carousel-info">
		<img class="pull-left" src="metronic/assets/pages/img/people/img1-small.jpg" alt="">
		<div class="pull-left">
		  <span class="testimonials-name">Lina Mars</span>
		  <span class="testimonials-post">Commercial Director</span>
		</div>
	      </div>
	    </div>
	    <div class="item">
	      <blockquote><p>Raw denim you Mustache cliche tempor, williamsburg carles vegan helvetica probably haven't heard of them jean shorts austin. Nesciunt tofu stumptown aliqua, retro synth master cleanse. Mustache cliche tempor, williamsburg carles vegan helvetica.</p></blockquote>
	      <div class="carousel-info">
		<img class="pull-left" src="metronic/assets/pages/img/people/img5-small.jpg" alt="">
		<div class="pull-left">
		  <span class="testimonials-name">Kate Ford</span>
		  <span class="testimonials-post">Commercial Director</span>
		</div>
	      </div>
	    </div>
	    <div class="item">
	      <blockquote><p>Reprehenderit butcher stache cliche tempor, williamsburg carles vegan helvetica.retro keffiyeh dreamcatcher synth. Cosby sweater eu banh mi, qui irure terry richardson ex squid Aliquip placeat salvia cillum iphone.</p></blockquote>
	      <div class="carousel-info">
		<img class="pull-left" src="metronic/assets/pages/img/people/img2-small.jpg" alt="">
		<div class="pull-left">
		  <span class="testimonials-name">Jake Witson</span>
		  <span class="testimonials-post">Commercial Director</span>
		</div>
	      </div>
	    </div>
	  </div>

	  <!-- Carousel nav -->
	  <a class="left-btn" href="#myCarousel" data-slide="prev"></a>
	  <a class="right-btn" href="#myCarousel" data-slide="next"></a>
	</div>
      </div>
      <!-- END TESTIMONIALS -->
    </div>                
    <!-- END TABS AND TESTIMONIALS -->
    <!-- BEGIN BLOCKQUOTE BLOCK -->   
    <div class="row quote-v1 margin-bottom-40 ">
      <div class="col-md-9">
	<span>Metronic - The Most Complete &amp; Popular Admin &amp; Frontend Theme</span>
      </div>
      <div class="col-md-3 text-right">
	<a class="btn-transparent" href="http://www.keenthemes.com/preview/index.php?theme=metronic_admin" target="_blank"><i class="fa fa-rocket margin-right-10"></i>Preview Admin</a>
      </div>
    </div>
    <!-- END BLOCKQUOTE BLOCK -->


    <!-- BEGIN CLIENTS -->
    <div class="row margin-bottom-40 our-clients">
      <div class="col-md-3">
	<h2><a href="javascript:;" target="_blank" rel="external">Our Clients</a></h2>
	<p>Lorem dipsum folor margade sitede lametep eiusmod psumquis dolore.</p>
      </div>
      <div class="col-md-9">
	<div class="owl-carousel owl-carousel6-brands">
	  <div class="client-item">
	    <a href="javascript:;" target="_blank" rel="external">
	      <img src="metronic/assets/pages/img/clients/client_1_gray.png" class="img-responsive" alt="">
	      <img src="metronic/assets/pages/img/clients/client_1.png" class="color-img img-responsive" alt="">
	    </a>
	  </div>
	  <div class="client-item">
	    <a href="javascript:;" target="_blank" rel="external">
	      <img src="metronic/assets/pages/img/clients/client_2_gray.png" class="img-responsive" alt="">
	      <img src="metronic/assets/pages/img/clients/client_2.png" class="color-img img-responsive" alt="">
	    </a>
	  </div>
	  <div class="client-item">
	    <a href="javascript:;" target="_blank" rel="external">
	      <img src="metronic/assets/pages/img/clients/client_3_gray.png" class="img-responsive" alt="">
	      <img src="metronic/assets/pages/img/clients/client_3.png" class="color-img img-responsive" alt="">
	    </a>
	  </div>
	  <div class="client-item">
	    <a href="javascript:;" target="_blank" rel="external">
	      <img src="metronic/assets/pages/img/clients/client_4_gray.png" class="img-responsive" alt="">
	      <img src="metronic/assets/pages/img/clients/client_4.png" class="color-img img-responsive" alt="">
	    </a>
	  </div>
	  <div class="client-item">
	    <a href="javascript:;" target="_blank" rel="external">
	      <img src="metronic/assets/pages/img/clients/client_5_gray.png" class="img-responsive" alt="">
	      <img src="metronic/assets/pages/img/clients/client_5.png" class="color-img img-responsive" alt="">
	    </a>
	  </div>
	  <div class="client-item">
	    <a href="javascript:;" target="_blank" rel="external">
	      <img src="metronic/assets/pages/img/clients/client_6_gray.png" class="img-responsive" alt="">
	      <img src="metronic/assets/pages/img/clients/client_6.png" class="color-img img-responsive" alt="">
	    </a>
	  </div>
	  <div class="client-item">
	    <a href="javascript:;" target="_blank" rel="external">
	      <img src="metronic/assets/pages/img/clients/client_7_gray.png" class="img-responsive" alt="">
	      <img src="metronic/assets/pages/img/clients/client_7.png" class="color-img img-responsive" alt="">
	    </a>
	  </div>
	  <div class="client-item">
	    <a href="javascript:;" target="_blank" rel="external">
	      <img src="metronic/assets/pages/img/clients/client_8_gray.png" class="img-responsive" alt="">
	      <img src="metronic/assets/pages/img/clients/client_8.png" class="color-img img-responsive" alt="">
	    </a>
	  </div>                  
	</div>
      </div>          
    </div>
    <!-- END CLIENTS -->
  </div>
</div>

]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[About Us]]></title>
      <url>/about/index.html</url>
      <content type="html"><![CDATA[<!-- BEGIN SIDEBAR & CONTENT -->
<div class="row margin-bottom-40">
  <!-- BEGIN CONTENT -->
  <div class="col-md-12 col-sm-12">
    <div class="content-page">
      <div class="row margin-bottom-30">
	<!-- BEGIN INFO BLOCK -->               
	<div class="col-md-7">
	  <h2 class="no-top-space">title</h2>
	  <p>comment</p> 
	  <p>skill</p> 
	  <!-- BEGIN LISTS -->
	  <div class="row front-lists-v1">
	    <div class="col-md-6">
	      <ul class="list-unstyled margin-bottom-20">
		<li><i class="fa fa-check"></i> Java</li>
		<li><i class="fa fa-check"></i> Scala </li>
		<li><i class="fa fa-check"></i> Spark</li>
	      </ul>
	    </div>
	    <div class="col-md-6">
	      <ul class="list-unstyled">
		<li><i class="fa fa-check"></i> Guiar</li>
	      </ul>
	    </div>
	  </div>
	  <!-- END LISTS -->
	</div>
	<!-- END INFO BLOCK -->   

	<!-- BEGIN CAROUSEL -->            
	<div class="col-md-5 front-carousel">
	  <div id="myCarousel" class="carousel slide">
	    <!-- Carousel items -->
	    <div class="carousel-inner">
	      <div class="item active">
                <img src="../metronic/assets/pages/img/index-sliders/slide1.jpg">
		<div class="carousel-caption">
		  <p>Excepturi sint occaecati cupiditate non provident</p>
		</div>
	      </div>
	      <div class="item">
                <img src="../metronic/assets/pages/img/index-sliders/slide2.jpg">
		<div class="carousel-caption">
		  <p>Ducimus qui blanditiis praesentium voluptatum</p>
		</div>
	      </div>
	      <div class="item">
                <img src="../metronic/assets/pages/img/index-sliders/slide3.jpg">
		<div class="carousel-caption">
		  <p>Ut non libero consectetur adipiscing elit magna</p>
		</div>
	      </div>
	    </div>
	    <!-- Carousel nav -->
	    <a class="carousel-control left" href="#myCarousel" data-slide="prev">
	      <i class="fa fa-angle-left"></i>
	    </a>
	    <a class="carousel-control right" href="#myCarousel" data-slide="next">
	      <i class="fa fa-angle-right"></i>
	    </a>
	  </div>                
	</div>
	<!-- END CAROUSEL -->
      </div>

      <div class="row margin-bottom-40">
	<!-- BEGIN TESTIMONIALS -->
	<div class="col-md-7 testimonials-v1">
	  <div id="myCarousel1" class="carousel slide">
	    <!-- Carousel items -->
	    <div class="carousel-inner">
	      <div class="active item">
		<blockquote><p>Denim you probably haven't heard of. Lorem ipsum dolor met consectetur adipisicing sit amet, consectetur adipisicing elit, of them jean shorts sed magna aliqua. Lorem ipsum dolor met consectetur adipisicing sit amet do eiusmod dolore.</p></blockquote>
		<div class="carousel-info">
		  <img src="../metronic/assets/pages/img/people/img1-small.jpg">
		  <div class="pull-left">
		    <span class="testimonials-name">Lina Mars</span>
		    <span class="testimonials-post">Commercial Director</span>
		  </div>
		</div>
	      </div>
	    </div>
	    <!-- Carousel nav -->
	    <a class="left-btn" href="#myCarousel1" data-slide="prev"></a>
	    <a class="right-btn" href="#myCarousel1" data-slide="next"></a>
	  </div>
	</div>
	<!-- END TESTIMONIALS --> 

      </div>

    </div>
  </div>
  <!-- END CONTENT -->
</div>
<!-- END SIDEBAR & CONTENT -->
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Contact]]></title>
      <url>/contact/index.html</url>
      <content type="html"><![CDATA[<h2>Let us help</h2>
<p>Lorem ipsum sdolor sic amit, bolero carles.</p>
<!-- BEGIN FORM-->
<form action="#" role="form">
  <div class="form-group">
    <label for="contacts-name">Name</label>
    <input type="text" class="form-control" id="contacts-name">
  </div>
  <div class="form-group">
    <label for="contacts-email">Email</label>
    <input type="email" class="form-control" id="contacts-email">
  </div>
  <div class="form-group">
    <label for="contacts-message">Message</label>
    <textarea class="form-control" rows="5" id="contacts-message"></textarea>
  </div>
  <button type="submit" class="btn btn-primary"><i class="icon-ok"></i> Send</button>
  <button type="button" class="btn btn-default">Cancel</button>
</form>
<!-- END FORM-->
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Login]]></title>
      <url>/login/index.html</url>
      <content type="html"><![CDATA[<!-- BEGIN SIDEBAR & CONTENT -->
<div class="row margin-bottom-40">
  <br><br>
  <!-- BEGIN CONTENT -->
  <div class="col-md-12 col-sm-12">
    <div class="content-form-page">
      <div class="row">
	<div class="col-md-7 col-sm-7">
	  <form class="form-horizontal form-without-legend" role="form">
	    <div class="form-group">
	      <label for="email" class="col-lg-4 control-label">Email <span class="require">*</span></label>
	      <div class="col-lg-8">
		<input type="text" class="form-control" id="email">
	      </div>
	    </div>
	    <div class="form-group">
	      <label for="password" class="col-lg-4 control-label">Password <span class="require">*</span></label>
	      <div class="col-lg-8">
		<input type="text" class="form-control" id="password">
	      </div>
	    </div>
	    <div class="row">
	      <div class="col-lg-8 col-md-offset-4 padding-left-0">
		<a href="page-forgotton-password.html">Forget Password?</a>
	      </div>
	    </div>
	    <div class="row">
	      <div class="col-lg-8 col-md-offset-4 padding-left-0 padding-top-20">
		<button type="submit" class="btn btn-primary">Login</button>
	      </div>
	    </div>
	    <div class="row">
	      <div class="col-lg-8 col-md-offset-4 padding-left-0 padding-top-10 padding-right-30">
		<hr>
		<div class="login-socio">
		  <p class="text-muted">or login using:</p>
		  <ul class="social-icons">
		    <li><a href="javascript:;" data-original-title="facebook" class="facebook" title="facebook" target="_blank" rel="external"></a></li>
		    <li><a href="javascript:;" data-original-title="Twitter" class="twitter" title="Twitter" target="_blank" rel="external"></a></li>
		    <li><a href="javascript:;" data-original-title="Google Plus" class="googleplus" title="Google Plus" target="_blank" rel="external"></a></li>
		    <li><a href="javascript:;" data-original-title="Linkedin" class="linkedin" title="LinkedIn" target="_blank" rel="external"></a></li>
		  </ul>
		</div>
	      </div>
	    </div>
	  </form>
	</div>
	<div class="col-md-4 col-sm-4 pull-right">
	  <div class="form-info">
	    <h2><em>Important</em> Information</h2>
	    <p>Duis autem vel eum iriure at dolor vulputate velit esse vel molestie at dolore.</p>

	    <button type="button" class="btn btn-default">More details</button>
	  </div>
	</div>
      </div>
    </div>
  </div>
  <!-- END CONTENT -->
</div>
<!-- END SIDEBAR & CONTENT -->
]]></content>
    </entry>
    
    <entry>
      <title></title>
      <url>/java/java.html</url>
      <content type="html"><![CDATA[<div class="container">
  <ul class="breadcrumb">
    <li><a href="/">Home</a></li>
    <li class="active">Archive</li>
  </ul>
<div id="main">
  
</div>
</div>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Projects]]></title>
      <url>/projects/index.html</url>
      <content type="html"><![CDATA[<!-- BEGIN SIDEBAR & CONTENT -->
<div class="row margin-bottom-40">
  <div class="col-md-12 col-sm-12">
    <div class="content-page">
      <div class="filter-v1">
	<ul class="mix-filter">
	  <li data-filter="all" class="filter active">All</li>
	  <li data-filter="category_1" class="filter">UI Design</li>
	  <li data-filter="category_2" class="filter">Web Development</li>
	  <li data-filter="category_3" class="filter">Photography</li>
	  <li data-filter="category_3 category_1" class="filter">Wordpress and Logo</li>
	</ul>
	<div class="row mix-grid thumbnails">
	  <div class="col-md-4 col-sm-6 mix category_1 mix_all" style="display: block;  opacity: 1;">
	    <div class="mix-inner">
	      <img alt="" src="/metronic/assets/pages/img/works/img1.jpg" class="img-responsive">
	      <div class="mix-details">
		<h4>Cascusamus et iusto odio</h4>
		<p>At vero eos et accusamus et iusto odio digniss imos duc sasdimus qui sint blanditiis prae sentium voluptatum deleniti atque corrupti quos dolores.</p>
		<a class="mix-link"><i class="fa fa-link"></i></a>
		<a title="Project Name" href="#project1" class="mix-preview"><i class="fa fa-search"></i></a>
	      </div>           
	      <div class="mix-info container">
		<h2>Project Name</h2>
		<p>Lorem ipsum dolor sit amet, dolore eiusmod quis tempor
		incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde
		omnis iste natus error sit voluptatem.</p>
		<div class="row quote-v1 margin-bottom-30">
		  <div class="col-md-7 quote-v1-inner">
		    <span>Lorem ipsum dolor sit amet, consectetuer adipiscing tempor</span>
		  </div>
		  <div class="col-md-5 quote-v1-inner text-right">
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-rocket margin-right-10"></i>Adipiscing</a>
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-gift margin-right-10"></i>Get it FREE</a>
		  </div>
		</div>
		<div class="row front-lists-v2 margin-bottom-15">
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-html5"></i> HTML5/CSS3</li>
		      <li><i class="fa fa-bell"></i> Web Deisgn</li>
		      <li><i class="fa fa-globe"></i> Web Development</li>
		      <li><i class="fa fa-shopping-cart"></i> Shoping Cart</li>
		    </ul>
		  </div>
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-dropbox"></i> Free Storage</li>
		      <li><i class="fa fa-cloud"></i> Cloud Hosting</li>
		      <li><i class="fa fa-comments"></i> Free Support</li>
		      <li><i class="fa fa-star"></i> Awesome UI</li>
		    </ul>
		  </div>
		</div>
		<a class="btn btn-lg btn-primary" style="color: white;" href="javascript:;" target="_blank" rel="external"> Visit Project</a>
		<a class="btn btn-lg btn-default back" href="javascript:;" target="_blank" rel="external"> Back</a>
	      </div>               
	    </div>                       
	  </div>
	  <div class="col-md-4 col-sm-6 mix category_2 mix_all" style="display: block;  opacity: 1;">
	    <div class="mix-inner">
	      <img alt="" src="/metronic/assets/pages/img/works/img2.jpg" class="img-responsive">
	      <div class="mix-details">
		<h4>Cascusamus et iusto odio</h4>
		<p>At vero eos et accusamus et iusto odio digniss imos duc sasdimus qui sint blanditiis prae sentium voluptatum deleniti atque corrupti quos dolores.</p>
		<a class="mix-link"><i class="fa fa-link"></i></a>
		<a title="Project Name" href="#project2" class="mix-preview"><i class="fa fa-search"></i></a>
	      </div>               
	      <div class="mix-info container">
		<h2>Project Name</h2>
		<p>Lorem ipsum dolor sit amet, dolore eiusmod quis tempor
		incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde
		omnis iste natus error sit voluptatem.</p>
		<div class="row quote-v1 margin-bottom-30">
		  <div class="col-md-7 quote-v1-inner">
		    <span>Lorem ipsum dolor sit amet, consectetuer adipiscing tempor</span>
		  </div>
		  <div class="col-md-5 quote-v1-inner text-right">
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-rocket margin-right-10"></i>Adipiscing</a>
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-gift margin-right-10"></i>Get it FREE</a>
		  </div>
		</div>
		<div class="row front-lists-v2 margin-bottom-15">
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-html5"></i> HTML5/CSS3</li>
		      <li><i class="fa fa-bell"></i> Web Deisgn</li>
		      <li><i class="fa fa-globe"></i> Web Development</li>
		      <li><i class="fa fa-shopping-cart"></i> Shoping Cart</li>
		    </ul>
		  </div>
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-dropbox"></i> Free Storage</li>
		      <li><i class="fa fa-cloud"></i> Cloud Hosting</li>
		      <li><i class="fa fa-comments"></i> Free Support</li>
		      <li><i class="fa fa-star"></i> Awesome UI</li>
		    </ul>
		  </div>
		</div>
		<a class="btn btn-lg btn-primary" style="color: white;" href="javascript:;" target="_blank" rel="external"> Visit Project</a>
		<a class="btn btn-lg btn-default back" href="javascript:;" target="_blank" rel="external"> Back</a>
	      </div>               
	    </div>                    
	  </div>
	  <div class="col-md-4 col-sm-6 mix category_3 mix_all" style="display: block;  opacity: 1;">
	    <div class="mix-inner">
	      <img alt="" src="/metronic/assets/pages/img/works/img3.jpg" class="img-responsive">
	      <div class="mix-details">
		<h4>Cascusamus et iusto odio</h4>
		<p>At vero eos et accusamus et iusto odio digniss imos duc sasdimus qui sint blanditiis prae sentium voluptatum deleniti atque corrupti quos dolores.</p>
		<a class="mix-link"><i class="fa fa-link"></i></a>
		<a title="Project Name" href="#projectz" class="mix-preview"><i class="fa fa-search"></i></a>
	      </div>              
	      <div class="mix-info container">
		<h2>Project Name</h2>
		<p>Lorem ipsum dolor sit amet, dolore eiusmod quis tempor
		incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde
		omnis iste natus error sit voluptatem.</p>
		<div class="row quote-v1 margin-bottom-30">
		  <div class="col-md-7 quote-v1-inner">
		    <span>Lorem ipsum dolor sit amet, consectetuer adipiscing tempor</span>
		  </div>
		  <div class="col-md-5 quote-v1-inner text-right">
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-rocket margin-right-10"></i>Adipiscing</a>
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-gift margin-right-10"></i>Get it FREE</a>
		  </div>
		</div>
		<div class="row front-lists-v2 margin-bottom-15">
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-html5"></i> HTML5/CSS3</li>
		      <li><i class="fa fa-bell"></i> Web Deisgn</li>
		      <li><i class="fa fa-globe"></i> Web Development</li>
		      <li><i class="fa fa-shopping-cart"></i> Shoping Cart</li>
		    </ul>
		  </div>
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-dropbox"></i> Free Storage</li>
		      <li><i class="fa fa-cloud"></i> Cloud Hosting</li>
		      <li><i class="fa fa-comments"></i> Free Support</li>
		      <li><i class="fa fa-star"></i> Awesome UI</li>
		    </ul>
		  </div>
		</div>
		<a class="btn btn-lg btn-primary" style="color: white;" href="javascript:;" target="_blank" rel="external"> Visit Project</a>
		<a class="btn btn-lg btn-default back" href="javascript:;" target="_blank" rel="external"> Back</a>
	      </div>               
	    </div>      
	  </div>
	  <div class="col-md-4 col-sm-6 mix category_1 category_2 mix_all" style="display: block;  opacity: 1;">
	    <div class="mix-inner">
	      <img alt="" src="/metronic/assets/pages/img/works/img4.jpg" class="img-responsive">
	      <div class="mix-details">
		<h4>Cascusamus et iusto odio</h4>
		<p>At vero eos et accusamus et iusto odio digniss imos duc sasdimus qui sint blanditiis prae sentium voluptatum deleniti atque corrupti quos dolores.</p>
		<a class="mix-link"><i class="fa fa-link"></i></a>
		<a title="Project Name" href="#project3" class="mix-preview"><i class="fa fa-search"></i></a>
	      </div>                  
	    </div>                      
	  </div>
	  <div class="col-md-4 col-sm-6 mix category_2 category_1 mix_all" style="display: block;  opacity: 1;">
	    <div class="mix-inner">
	      <img alt="" src="/metronic/assets/pages/img/works/img5.jpg" class="img-responsive">
	      <div class="mix-details">
		<h4>Cascusamus et iusto odio</h4>
		<p>At vero eos et accusamus et iusto odio digniss imos duc sasdimus qui sint blanditiis prae sentium voluptatum deleniti atque corrupti quos dolores.</p>
		<a class="mix-link"><i class="fa fa-link"></i></a>
		<a title="Project Name" href="#project3" class="mix-preview"><i class="fa fa-search"></i></a>
	      </div>     
	      <div class="mix-info container">
		<h2>Project Name</h2>
		<p>Lorem ipsum dolor sit amet, dolore eiusmod quis tempor
		incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde
		omnis iste natus error sit voluptatem.</p>
		<div class="row quote-v1 margin-bottom-30">
		  <div class="col-md-7 quote-v1-inner">
		    <span>Lorem ipsum dolor sit amet, consectetuer adipiscing tempor</span>
		  </div>
		  <div class="col-md-5 quote-v1-inner text-right">
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-rocket margin-right-10"></i>Adipiscing</a>
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-gift margin-right-10"></i>Get it FREE</a>
		  </div>
		</div>
		<div class="row front-lists-v2 margin-bottom-15">
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-html5"></i> HTML5/CSS3</li>
		      <li><i class="fa fa-bell"></i> Web Deisgn</li>
		      <li><i class="fa fa-globe"></i> Web Development</li>
		      <li><i class="fa fa-shopping-cart"></i> Shoping Cart</li>
		    </ul>
		  </div>
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-dropbox"></i> Free Storage</li>
		      <li><i class="fa fa-cloud"></i> Cloud Hosting</li>
		      <li><i class="fa fa-comments"></i> Free Support</li>
		      <li><i class="fa fa-star"></i> Awesome UI</li>
		    </ul>
		  </div>
		</div>
		<a class="btn btn-lg btn-primary" style="color: white;" href="javascript:;" target="_blank" rel="external"> Visit Project</a>
		<a class="btn btn-lg btn-default back" href="javascript:;" target="_blank" rel="external"> Back</a>
	      </div>               
	    </div>                                   
	  </div>
	  <div class="col-md-4 col-sm-6 mix category_1 category_2 mix_all" style="display: block;  opacity: 1;">
	    <div class="mix-inner">
	      <img alt="" src="/metronic/assets/pages/img/works/img6.jpg" class="img-responsive">
	      <div class="mix-details">
		<h4>Cascusamus et iusto odio</h4>
		<p>At vero eos et accusamus et iusto odio digniss imos duc sasdimus qui sint blanditiis prae sentium voluptatum deleniti atque corrupti quos dolores.</p>
		<a class="mix-link"><i class="fa fa-link"></i></a>
		<a title="Project Name" href="#project4" class="mix-preview"><i class="fa fa-search"></i></a>
	      </div>     
	    </div>                                   
	  </div>
	  <div class="col-md-4 col-sm-6 mix category_2 category_3 mix_all" style="display: block;  opacity: 1;">
	    <div class="mix-inner">
	      <img alt="" src="/metronic/assets/pages/img/works/img1.jpg" class="img-responsive">
	      <div class="mix-details">
		<h4>Cascusamus et iusto odio</h4>
		<p>At vero eos et accusamus et iusto odio digniss imos duc sasdimus qui sint blanditiis prae sentium voluptatum deleniti atque corrupti quos dolores.</p>
		<a class="mix-link"><i class="fa fa-link"></i></a>
		<a title="Project Name" href="#project5" class="mix-preview"><i class="fa fa-search"></i></a>
	      </div>    
	      <div class="mix-info container">
		<h2>Project Name</h2>
		<p>Lorem ipsum dolor sit amet, dolore eiusmod quis tempor
		incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde
		omnis iste natus error sit voluptatem.</p>
		<div class="row quote-v1 margin-bottom-30">
		  <div class="col-md-7 quote-v1-inner">
		    <span>Lorem ipsum dolor sit amet, consectetuer adipiscing tempor</span>
		  </div>
		  <div class="col-md-5 quote-v1-inner text-right">
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-rocket margin-right-10"></i>Adipiscing</a>
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-gift margin-right-10"></i>Get it FREE</a>
		  </div>
		</div>
		<div class="row front-lists-v2 margin-bottom-15">
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-html5"></i> HTML5/CSS3</li>
		      <li><i class="fa fa-bell"></i> Web Deisgn</li>
		      <li><i class="fa fa-globe"></i> Web Development</li>
		      <li><i class="fa fa-shopping-cart"></i> Shoping Cart</li>
		    </ul>
		  </div>
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-dropbox"></i> Free Storage</li>
		      <li><i class="fa fa-cloud"></i> Cloud Hosting</li>
		      <li><i class="fa fa-comments"></i> Free Support</li>
		      <li><i class="fa fa-star"></i> Awesome UI</li>
		    </ul>
		  </div>
		</div>
		<a class="btn btn-lg btn-primary" style="color: white;" href="javascript:;" target="_blank" rel="external"> Visit Project</a>
		<a class="btn btn-lg btn-default back" href="javascript:;" target="_blank" rel="external"> Back</a>
	      </div>               
	    </div>                                    
	  </div>
	  <div class="col-md-4 col-sm-6 mix category_1 category_2 mix_all" style="display: block;  opacity: 1;">
	    <div class="mix-inner">
	      <img alt="" src="/metronic/assets/pages/img/works/img2.jpg" class="img-responsive">
	      <div class="mix-details">
		<h4>Cascusamus et iusto odio</h4>
		<p>At vero eos et accusamus et iusto odio digniss imos duc sasdimus qui sint blanditiis prae sentium voluptatum deleniti atque corrupti quos dolores.</p>
		<a class="mix-link"><i class="fa fa-link"></i></a>
		<a title="Project Name" href="#project6" class="mix-preview"><i class="fa fa-search"></i></a>
	      </div>   
	      <div class="mix-info container">
		<h2>Project Name</h2>
		<p>Lorem ipsum dolor sit amet, dolore eiusmod quis tempor
		incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde
		omnis iste natus error sit voluptatem.</p>
		<div class="row quote-v1 margin-bottom-30">
		  <div class="col-md-7 quote-v1-inner">
		    <span>Lorem ipsum dolor sit amet, consectetuer adipiscing tempor</span>
		  </div>
		  <div class="col-md-5 quote-v1-inner text-right">
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-rocket margin-right-10"></i>Adipiscing</a>
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-gift margin-right-10"></i>Get it FREE</a>
		  </div>
		</div>
		<div class="row front-lists-v2 margin-bottom-15">
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-html5"></i> HTML5/CSS3</li>
		      <li><i class="fa fa-bell"></i> Web Deisgn</li>
		      <li><i class="fa fa-globe"></i> Web Development</li>
		      <li><i class="fa fa-shopping-cart"></i> Shoping Cart</li>
		    </ul>
		  </div>
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-dropbox"></i> Free Storage</li>
		      <li><i class="fa fa-cloud"></i> Cloud Hosting</li>
		      <li><i class="fa fa-comments"></i> Free Support</li>
		      <li><i class="fa fa-star"></i> Awesome UI</li>
		    </ul>
		  </div>
		</div>
		<a class="btn btn-lg btn-primary" style="color: white;" href="javascript:;" target="_blank" rel="external"> Visit Project</a>
		<a class="btn btn-lg btn-default back" href="javascript:;" target="_blank" rel="external"> Back</a>
	      </div>               
	    </div>                                     
	  </div>
	  <div class="col-md-4 col-sm-6 mix category_3 mix_all" style="display: block;  opacity: 1;">
	    <div class="mix-inner">
	      <img alt="" src="/metronic/assets/pages/img/works/img4.jpg" class="img-responsive">
	      <div class="mix-details">
		<h4>Cascusamus et iusto odio</h4>
		<p>At vero eos et accusamus et iusto odio digniss imos duc sasdimus qui sint blanditiis prae sentium voluptatum deleniti atque corrupti quos dolores.</p>
		<a class="mix-link"><i class="fa fa-link"></i></a>
		<a title="Project Name" href="#project7" class="mix-preview"><i class="fa fa-search"></i></a>
	      </div>    
	      <div class="mix-info container">
		<h2>Project Name</h2>
		<p>Lorem ipsum dolor sit amet, dolore eiusmod quis tempor
		incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde
		omnis iste natus error sit voluptatem.</p>
		<div class="row quote-v1 margin-bottom-30">
		  <div class="col-md-7 quote-v1-inner">
		    <span>Lorem ipsum dolor sit amet, consectetuer adipiscing tempor</span>
		  </div>
		  <div class="col-md-5 quote-v1-inner text-right">
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-rocket margin-right-10"></i>Adipiscing</a>
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-gift margin-right-10"></i>Get it FREE</a>
		  </div>
		</div>
		<div class="row front-lists-v2 margin-bottom-15">
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-html5"></i> HTML5/CSS3</li>
		      <li><i class="fa fa-bell"></i> Web Deisgn</li>
		      <li><i class="fa fa-globe"></i> Web Development</li>
		      <li><i class="fa fa-shopping-cart"></i> Shoping Cart</li>
		    </ul>
		  </div>
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-dropbox"></i> Free Storage</li>
		      <li><i class="fa fa-cloud"></i> Cloud Hosting</li>
		      <li><i class="fa fa-comments"></i> Free Support</li>
		      <li><i class="fa fa-star"></i> Awesome UI</li>
		    </ul>
		  </div>
		</div>
		<a class="btn btn-lg btn-primary" style="color: white;" href="javascript:;" target="_blank" rel="external"> Visit Project</a>
		<a class="btn btn-lg btn-default back" href="javascript:;" target="_blank" rel="external"> Back</a>
	      </div>               
	    </div>                                    
	  </div>
	  <div class="col-md-4 col-sm-6 mix category_1 mix_all" style="display: block;  opacity: 1;">
	    <div class="mix-inner">
	      <img alt="" src="/metronic/assets/pages/img/works/img3.jpg" class="img-responsive">
	      <div class="mix-details">
		<h4>Cascusamus et iusto odio</h4>
		<p>At vero eos et accusamus et iusto odio digniss imos duc sasdimus qui sint blanditiis prae sentium voluptatum deleniti atque corrupti quos dolores.</p>
		<a class="mix-link"><i class="fa fa-link"></i></a>
		<a title="Project Name" href="#project8" class="mix-preview"><i class="fa fa-search"></i></a>
	      </div> 
	      <div class="mix-info container">
		<h2>Project Name</h2>
		<p>Lorem ipsum dolor sit amet, dolore eiusmod quis tempor
		incididunt ut et dolore Ut veniam unde nostrudlaboris. Sed unde
		omnis iste natus error sit voluptatem.</p>
		<div class="row quote-v1 margin-bottom-30">
		  <div class="col-md-7 quote-v1-inner">
		    <span>Lorem ipsum dolor sit amet, consectetuer adipiscing tempor</span>
		  </div>
		  <div class="col-md-5 quote-v1-inner text-right">
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-rocket margin-right-10"></i>Adipiscing</a>
		    <a href="javascript:;" class="btn-transparent" target="_blank" rel="external"><i class="fa fa-gift margin-right-10"></i>Get it FREE</a>
		  </div>
		</div>
		<div class="row front-lists-v2 margin-bottom-15">
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-html5"></i> HTML5/CSS3</li>
		      <li><i class="fa fa-bell"></i> Web Deisgn</li>
		      <li><i class="fa fa-globe"></i> Web Development</li>
		      <li><i class="fa fa-shopping-cart"></i> Shoping Cart</li>
		    </ul>
		  </div>
		  <div class="col-md-6">
		    <ul class="list-unstyled">
		      <li><i class="fa fa-dropbox"></i> Free Storage</li>
		      <li><i class="fa fa-cloud"></i> Cloud Hosting</li>
		      <li><i class="fa fa-comments"></i> Free Support</li>
		      <li><i class="fa fa-star"></i> Awesome UI</li>
		    </ul>
		  </div>
		</div>
		<a class="btn btn-lg btn-primary" style="color: white;" href="javascript:;" target="_blank" rel="external"> Visit Project</a>
		<a class="btn btn-lg btn-default back" href="javascript:;" target="_blank" rel="external"> Back</a>
	      </div>               
	    </div>                                       
	  </div>
	</div>
      </div>
    </div>
  </div>
</div>
]]></content>
    </entry>
    
  
</search>
